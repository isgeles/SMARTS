{"episode_reward_max": 219.54263608187424, "episode_reward_min": -570.7029739196424, "episode_reward_mean": -246.63529656551304, "episode_len_mean": 111.57142857142857, "episodes_this_iter": 7, "policy_reward_min": {"AGENT-3": -178.89110802047512, "AGENT-0": -177.65985491520405, "AGENT-2": -178.38073063441567, "AGENT-1": -130.8277898918602}, "policy_reward_max": {"AGENT-3": 43.899378720898866, "AGENT-0": 65.52762051495297, "AGENT-2": 43.84301041084104, "AGENT-1": 66.27262643518134}, "policy_reward_mean": {"AGENT-3": -69.86970778415322, "AGENT-0": -63.49348737839124, "AGENT-2": -70.15366857462213, "AGENT-1": -43.11843282834646}, "custom_metrics": {"mean_ego_speed_mean": 43.44375, "mean_ego_speed_min": 41.661500000000004, "mean_ego_speed_max": 44.2825, "distance_travelled_mean": 98.21942857142858, "distance_travelled_min": 75.91925, "distance_travelled_max": 124.83000000000001}, "hist_stats": {"episode_reward": [-49.0895277605261, 219.54263608187424, -34.13791819942123, -570.7029739196424, -365.7686327913458, -548.095876366606, -378.1947830029239], "episode_lengths": [119, 117, 118, 121, 82, 106, 118], "policy_AGENT-3_reward": [-42.861068504920574, 43.899378720898866, -15.730402546728273, -131.7471347390881, -70.83185982622055, -178.89110802047512, -92.92575957253881], "policy_AGENT-0_reward": [-4.534897519603049, 65.52762051495297, -1.9747886535083201, -177.65985491520405, -112.03207950027694, -95.4818225475154, -118.29858902758383], "policy_AGENT-2_reward": [-42.783563007598474, 43.84301041084104, -15.781465467228609, -130.46819437349032, -70.87675276677673, -178.38073063441567, -96.62798418368615], "policy_AGENT-1_reward": [41.09000127159612, 66.27262643518134, -0.6512615319560524, -130.8277898918602, -112.02794069807172, -95.34221516419939, -70.34245021911534]}, "sampler_perf": {"mean_env_wait_ms": 85.41944664683875, "mean_raw_obs_processing_ms": 2.9753811938523134, "mean_inference_ms": 7.719403356250537, "mean_action_processing_ms": 0.1884714533283125}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 1008, "timers": {"learn_time_ms": 992.183, "learn_throughput": 32.252, "update_time_ms": 17.876}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": -0.6640374660491943, "min_q": -1.8838696479797363, "max_q": 1.0776493549346924, "mean_td_error": 0.3743542730808258, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": -0.3529685139656067, "min_q": -1.245610237121582, "max_q": 0.9293068647384644, "mean_td_error": -0.20343467593193054, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": -0.7001955509185791, "min_q": -2.019658088684082, "max_q": 1.045949935913086, "mean_td_error": 0.5962680578231812, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": -1.1900112628936768, "min_q": -2.307056427001953, "max_q": -0.1208503246307373, "mean_td_error": -0.36232274770736694, "model": {}}}, "num_steps_sampled": 1008, "num_steps_trained": 32, "last_target_update_ts": 1008, "num_target_updates": 1}, "done": false, "episodes_total": 7, "training_iteration": 1, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-43-13", "timestamp": 1624264993, "time_this_iter_s": 42.378509759902954, "time_total_s": 42.378509759902954, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f898c0bd440>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f898c0bd050>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c0bddd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c0bdf80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd320>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079050>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c0bddd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c0bdf80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd320>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079050>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c0bddd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c0bdf80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd320>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079050>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c0bddd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c0bdf80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd320>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079050>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f898c0bdb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 42.378509759902954, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 55.17213114754098, "ram_util_percent": 81.77377049180328}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 252.84904071776774, "episode_reward_min": -869.0256252706633, "episode_reward_mean": -266.16705968766604, "episode_len_mean": 115.125, "episodes_this_iter": 9, "policy_reward_min": {"AGENT-3": -218.6495705430483, "AGENT-0": -238.67455199242482, "AGENT-2": -219.54683426168634, "AGENT-1": -192.1546684735044}, "policy_reward_max": {"AGENT-3": 60.882845286347084, "AGENT-0": 65.52762051495297, "AGENT-2": 67.8539188188227, "AGENT-1": 85.08516745924527}, "policy_reward_mean": {"AGENT-3": -64.0758267997141, "AGENT-0": -74.12100454216755, "AGENT-2": -74.21293133284404, "AGENT-1": -53.75729701294036}, "custom_metrics": {"mean_ego_speed_mean": 42.686265625000004, "mean_ego_speed_min": 40.233250000000005, "mean_ego_speed_max": 44.403, "distance_travelled_mean": 98.680640625, "distance_travelled_min": 75.48474999999999, "distance_travelled_max": 124.83000000000001}, "hist_stats": {"episode_reward": [-315.4765346868379, -235.78989103807115, -636.9677597383476, -14.47129388855019, -188.0075123389498, 252.84904071776774, -191.0868434243213, -334.24945937609203, -869.0256252706633, -49.0895277605261, 219.54263608187424, -34.13791819942123, -570.7029739196424, -365.7686327913458, -548.095876366606, -378.1947830029239], "episode_lengths": [113, 107, 112, 122, 123, 123, 112, 126, 123, 119, 117, 118, 121, 82, 106, 118], "policy_AGENT-3_reward": [-46.85901437305522, -49.71195558472984, -122.73230572648562, -22.518374276588382, -71.75018882051901, 60.882845286347084, -30.808678115797054, -33.978032152476665, -218.6495705430483, -42.861068504920574, 43.899378720898866, -15.730402546728273, -131.7471347390881, -70.83185982622055, -178.89110802047512, -92.92575957253881], "policy_AGENT-0_reward": [-110.83588150166379, -67.78007167006972, -182.56626990274012, 13.996313204020556, -44.242611867897445, 39.02710915335282, -75.1933234424076, -75.21237300611205, -238.67455199242482, -4.534897519603049, 65.52762051495297, -1.9747886535083201, -177.65985491520405, -112.03207950027694, -95.4818225475154, -118.29858902758383], "policy_AGENT-2_reward": [-46.8222729259098, -50.53918606652537, -209.49880867469213, -22.41278813281122, -71.71935028577666, 67.8539188188227, -30.838333043555885, -112.80756673101503, -219.54683426168634, -42.783563007598474, 43.84301041084104, -15.781465467228609, -130.46819437349032, -70.87675276677673, -178.38073063441567, -96.62798418368615], "policy_AGENT-1_reward": [-110.9593658862091, -67.75867771674618, -122.17037543442939, 16.463555316828906, -0.29536136475667263, 85.08516745924527, -54.24650882256064, -112.25148748648837, -192.1546684735044, 41.09000127159612, 66.27262643518134, -0.6512615319560524, -130.8277898918602, -112.02794069807172, -95.34221516419939, -70.34245021911534]}, "sampler_perf": {"mean_env_wait_ms": 81.90711228119405, "mean_raw_obs_processing_ms": 2.962887606580485, "mean_inference_ms": 6.4878907531671866, "mean_action_processing_ms": 0.1855682665580346}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 2016, "timers": {"learn_time_ms": 10.811, "learn_throughput": 2959.839, "update_time_ms": 14.92}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": -0.7923635244369507, "min_q": -3.909233808517456, "max_q": 4.779758930206299, "mean_td_error": 1.4918793439865112, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": -1.087059736251831, "min_q": -4.789768218994141, "max_q": 2.633589744567871, "mean_td_error": 1.4949549436569214, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": -0.10508859902620316, "min_q": -3.3196914196014404, "max_q": 4.333057403564453, "mean_td_error": 1.6907131671905518, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": -1.4548232555389404, "min_q": -5.500477313995361, "max_q": 3.525669574737549, "mean_td_error": 1.4388864040374756, "model": {}}}, "num_steps_sampled": 2016, "num_steps_trained": 2720, "last_target_update_ts": 2016, "num_target_updates": 3}, "done": false, "episodes_total": 16, "training_iteration": 2, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-43-53", "timestamp": 1624265033, "time_this_iter_s": 39.265624046325684, "time_total_s": 81.64413380622864, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f899cf71e60>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f898e396dd0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396560>, action_adapter=<function AgentSpec.<lambda> at 0x7f898e396ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c34f950>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079ef0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396560>, action_adapter=<function AgentSpec.<lambda> at 0x7f898e396ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c34f950>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079ef0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396560>, action_adapter=<function AgentSpec.<lambda> at 0x7f898e396ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c34f950>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079ef0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396560>, action_adapter=<function AgentSpec.<lambda> at 0x7f898e396ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c34f950>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079ef0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f898c079440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 81.64413380622864, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 51.21071428571429, "ram_util_percent": 84.86785714285715}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 357.91930792688134, "episode_reward_min": -869.0256252706633, "episode_reward_mean": -292.4401298154478, "episode_len_mean": 116.58333333333333, "episodes_this_iter": 8, "policy_reward_min": {"AGENT-3": -218.6495705430483, "AGENT-2": -219.54683426168634, "AGENT-0": -250.7564293731004, "AGENT-1": -192.1546684735044}, "policy_reward_max": {"AGENT-3": 83.24388456154338, "AGENT-2": 83.3296868080183, "AGENT-0": 74.50739681846153, "AGENT-1": 116.83833973885797}, "policy_reward_mean": {"AGENT-3": -71.86860607700447, "AGENT-2": -79.55708332383188, "AGENT-0": -79.4775722111166, "AGENT-1": -61.53686820349484}, "custom_metrics": {"mean_ego_speed_mean": 42.15853125, "mean_ego_speed_min": 37.4835, "mean_ego_speed_max": 44.403, "distance_travelled_mean": 101.01452083333334, "distance_travelled_min": 75.48474999999999, "distance_travelled_max": 124.83000000000001}, "hist_stats": {"episode_reward": [357.91930792688134, -706.2846239316171, -3.306460726910646, -522.006644597566, -394.2093327167674, -553.3520295256233, -188.35629230394676, -750.2940846925408, -49.0895277605261, 219.54263608187424, -34.13791819942123, -570.7029739196424, -365.7686327913458, -548.095876366606, -378.1947830029239, -315.4765346868379, -235.78989103807115, -636.9677597383476, -14.47129388855019, -188.0075123389498, 252.84904071776774, -191.0868434243213, -334.24945937609203, -869.0256252706633], "episode_lengths": [125, 114, 121, 121, 101, 123, 122, 129, 119, 117, 118, 121, 82, 106, 118, 113, 107, 112, 122, 123, 123, 112, 126, 123], "policy_AGENT-3_reward": [83.24388456154338, -122.69521366380397, -16.325319966749806, -135.24122272252916, -117.82055455739373, -176.20983338889783, -43.139533551978786, -171.4455237628716, -42.861068504920574, 43.899378720898866, -15.730402546728273, -131.7471347390881, -70.83185982622055, -178.89110802047512, -92.92575957253881, -46.85901437305522, -49.71195558472984, -122.73230572648562, -22.518374276588382, -71.75018882051901, 60.882845286347084, -30.808678115797054, -33.978032152476665, -218.6495705430483], "policy_AGENT-2_reward": [83.3296868080183, -210.70384412192243, 10.987144328894253, -135.21971642757256, -117.69474103635258, -116.26458699352183, -43.1729865759878, -193.2240544280157, -42.783563007598474, 43.84301041084104, -15.781465467228609, -130.46819437349032, -70.87675276677673, -178.38073063441567, -96.62798418368615, -46.8222729259098, -50.53918606652537, -209.49880867469213, -22.41278813281122, -71.71935028577666, 67.8539188188227, -30.838333043555885, -112.80756673101503, -219.54683426168634], "policy_AGENT-0_reward": [74.50739681846153, -250.7564293731004, 11.5474127587693, -114.36150404878217, -79.21538539575228, -115.70758846380178, -52.21709751631647, -195.32246517159516, -4.534897519603049, 65.52762051495297, -1.9747886535083201, -177.65985491520405, -112.03207950027694, -95.4818225475154, -118.29858902758383, -110.83588150166379, -67.78007167006972, -182.56626990274012, 13.996313204020556, -44.242611867897445, 39.02710915335282, -75.1933234424076, -75.21237300611205, -238.67455199242482], "policy_AGENT-1_reward": [116.83833973885797, -122.1291367727901, -9.515697847824393, -137.1842013986815, -79.47865172726877, -145.17002067940183, -49.82667465966379, -190.30204133005813, 41.09000127159612, 66.27262643518134, -0.6512615319560524, -130.8277898918602, -112.02794069807172, -95.34221516419939, -70.34245021911534, -110.9593658862091, -67.75867771674618, -122.17037543442939, 16.463555316828906, -0.29536136475667263, 85.08516745924527, -54.24650882256064, -112.25148748648837, -192.1546684735044]}, "sampler_perf": {"mean_env_wait_ms": 80.03900476087806, "mean_raw_obs_processing_ms": 2.9091682183438388, "mean_inference_ms": 5.911727027655246, "mean_action_processing_ms": 0.1837127394910465}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 3024, "timers": {"learn_time_ms": 11.167, "learn_throughput": 2865.58, "update_time_ms": 14.168}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": -0.6931953430175781, "min_q": -6.828693866729736, "max_q": 6.672591209411621, "mean_td_error": 3.5549135208129883, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": -2.405627727508545, "min_q": -8.315095901489258, "max_q": 6.9216718673706055, "mean_td_error": 5.233992099761963, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": -2.726290702819824, "min_q": -7.027350902557373, "max_q": 7.691611289978027, "mean_td_error": 1.7413649559020996, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": -2.514267683029175, "min_q": -8.251391410827637, "max_q": 8.386310577392578, "mean_td_error": 2.753070831298828, "model": {}}}, "num_steps_sampled": 3024, "num_steps_trained": 5408, "last_target_update_ts": 3024, "num_target_updates": 5}, "done": false, "episodes_total": 24, "training_iteration": 3, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-44-30", "timestamp": 1624265070, "time_this_iter_s": 37.34069800376892, "time_total_s": 118.98483180999756, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f898c0bd170>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f898c0bd9e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f899cf8ae60>, action_adapter=<function AgentSpec.<lambda> at 0x7f899cf8ab00>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079050>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079c20>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f899cf8ae60>, action_adapter=<function AgentSpec.<lambda> at 0x7f899cf8ab00>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079050>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079c20>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f899cf8ae60>, action_adapter=<function AgentSpec.<lambda> at 0x7f899cf8ab00>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079050>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079c20>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f899cf8ae60>, action_adapter=<function AgentSpec.<lambda> at 0x7f899cf8ab00>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079050>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079c20>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c7c1320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 118.98483180999756, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 51.546296296296305, "ram_util_percent": 85.27037037037034}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 357.91930792688134, "episode_reward_min": -869.0256252706633, "episode_reward_mean": -267.03270406852045, "episode_len_mean": 121.5625, "episodes_this_iter": 8, "policy_reward_min": {"AGENT-3": -218.6495705430483, "AGENT-0": -250.7564293731004, "AGENT-2": -219.54683426168634, "AGENT-1": -192.1546684735044}, "policy_reward_max": {"AGENT-3": 83.24388456154338, "AGENT-0": 266.6115005900778, "AGENT-2": 83.3296868080183, "AGENT-1": 215.07051116388416}, "policy_reward_mean": {"AGENT-3": -76.66990756960543, "AGENT-0": -63.88154150175463, "AGENT-2": -81.30197805901288, "AGENT-1": -45.179276938147495}, "custom_metrics": {"mean_ego_speed_mean": 41.9557734375, "mean_ego_speed_min": 37.4835, "mean_ego_speed_max": 44.624, "distance_travelled_mean": 100.6269296875, "distance_travelled_min": 75.48474999999999, "distance_travelled_max": 124.83000000000001}, "hist_stats": {"episode_reward": [180.35869523571705, 229.87443080217656, 189.80790743174532, -477.4845517469688, -433.7518814211228, -693.938550752084, 33.03084893021221, -554.3803131015827, -49.0895277605261, 219.54263608187424, -34.13791819942123, -570.7029739196424, -365.7686327913458, -548.095876366606, -378.1947830029239, -315.4765346868379, -235.78989103807115, -636.9677597383476, -14.47129388855019, -188.0075123389498, 252.84904071776774, -191.0868434243213, -334.24945937609203, -869.0256252706633, 357.91930792688134, -706.2846239316171, -3.306460726910646, -522.006644597566, -394.2093327167674, -553.3520295256233, -188.35629230394676, -750.2940846925408], "episode_lengths": [260, 137, 128, 89, 143, 107, 118, 110, 119, 117, 118, 121, 82, 106, 118, 113, 107, 112, 122, 123, 123, 112, 126, 123, 125, 114, 121, 121, 101, 123, 122, 129], "policy_AGENT-3_reward": [-150.67362981087098, -0.8524113498859909, 2.2020770678050745, -95.06260123959731, -163.94941022611053, -161.20957895880292, -37.279954625156556, -121.7649872366475, -42.861068504920574, 43.899378720898866, -15.730402546728273, -131.7471347390881, -70.83185982622055, -178.89110802047512, -92.92575957253881, -46.85901437305522, -49.71195558472984, -122.73230572648562, -22.518374276588382, -71.75018882051901, 60.882845286347084, -30.808678115797054, -33.978032152476665, -218.6495705430483, 83.24388456154338, -122.69521366380397, -16.325319966749806, -135.24122272252916, -117.82055455739373, -176.20983338889783, -43.139533551978786, -171.4455237628716], "policy_AGENT-0_reward": [266.6115005900778, 96.22263750542568, 96.78908942175022, -143.55349736438262, -199.7300825790453, -161.9801852537422, 53.27492434580155, -144.38198165523502, -4.534897519603049, 65.52762051495297, -1.9747886535083201, -177.65985491520405, -112.03207950027694, -95.4818225475154, -118.29858902758383, -110.83588150166379, -67.78007167006972, -182.56626990274012, 13.996313204020556, -44.242611867897445, 39.02710915335282, -75.1933234424076, -75.21237300611205, -238.67455199242482, 74.50739681846153, -250.7564293731004, 11.5474127587693, -114.36150404878217, -79.21538539575228, -115.70758846380178, -52.21709751631647, -195.32246517159516], "policy_AGENT-2_reward": [-150.6496867073742, -0.6568215880630608, 2.3032139604815245, -95.1237099154512, -35.27036163930682, -208.54686471661554, -37.316275493156226, -167.03279201696165, -42.783563007598474, 43.84301041084104, -15.781465467228609, -130.46819437349032, -70.87675276677673, -178.38073063441567, -96.62798418368615, -46.8222729259098, -50.53918606652537, -209.49880867469213, -22.41278813281122, -71.71935028577666, 67.8539188188227, -30.838333043555885, -112.80756673101503, -219.54683426168634, 83.3296868080183, -210.70384412192243, 10.987144328894253, -135.21971642757256, -117.69474103635258, -116.26458699352183, -43.1729865759878, -193.2240544280157], "policy_AGENT-1_reward": [215.07051116388416, 135.16102623469976, 88.5135269817085, -143.74474322753773, -34.80202697666027, -162.201921822923, 54.35215470272344, -121.20055219273824, 41.09000127159612, 66.27262643518134, -0.6512615319560524, -130.8277898918602, -112.02794069807172, -95.34221516419939, -70.34245021911534, -110.9593658862091, -67.75867771674618, -122.17037543442939, 16.463555316828906, -0.29536136475667263, 85.08516745924527, -54.24650882256064, -112.25148748648837, -192.1546684735044, 116.83833973885797, -122.1291367727901, -9.515697847824393, -137.1842013986815, -79.47865172726877, -145.17002067940183, -49.82667465966379, -190.30204133005813]}, "sampler_perf": {"mean_env_wait_ms": 78.57035480122315, "mean_raw_obs_processing_ms": 2.900748828344198, "mean_inference_ms": 5.529312499711731, "mean_action_processing_ms": 0.18359302854566573}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 4032, "timers": {"learn_time_ms": 11.191, "learn_throughput": 2859.407, "update_time_ms": 14.328}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": -2.2945785522460938, "min_q": -11.149337768554688, "max_q": 12.420385360717773, "mean_td_error": 2.3882458209991455, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": -2.08194637298584, "min_q": -11.827815055847168, "max_q": 10.007255554199219, "mean_td_error": 8.017995834350586, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": -2.3961830139160156, "min_q": -10.640449523925781, "max_q": 5.820858001708984, "mean_td_error": 5.686392784118652, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": -4.79535436630249, "min_q": -12.186866760253906, "max_q": 7.163724899291992, "mean_td_error": 0.14403408765792847, "model": {}}}, "num_steps_sampled": 4032, "num_steps_trained": 8096, "last_target_update_ts": 4032, "num_target_updates": 7}, "done": false, "episodes_total": 32, "training_iteration": 4, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-45-09", "timestamp": 1624265109, "time_this_iter_s": 38.471965074539185, "time_total_s": 157.45679688453674, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f898c0bdef0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f898c0bd0e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd320>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c0bdf80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c0bdcb0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1290>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd320>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c0bdf80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c0bdcb0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1290>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd320>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c0bdf80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c0bdcb0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1290>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd320>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c0bdf80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c0bdcb0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1290>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c7c1ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 157.45679688453674, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 48.68727272727272, "ram_util_percent": 85.50909090909094}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 357.91930792688134, "episode_reward_min": -1169.9075047250058, "episode_reward_mean": -288.8759059470385, "episode_len_mean": 119.275, "episodes_this_iter": 8, "policy_reward_min": {"AGENT-3": -218.6495705430483, "AGENT-0": -448.8965319625391, "AGENT-2": -449.4788037794044, "AGENT-1": -192.1546684735044}, "policy_reward_max": {"AGENT-3": 83.24388456154338, "AGENT-0": 266.6115005900778, "AGENT-2": 83.3296868080183, "AGENT-1": 215.07051116388416}, "policy_reward_mean": {"AGENT-3": -76.72584561121849, "AGENT-0": -74.54541590593642, "AGENT-2": -87.84731607738733, "AGENT-1": -49.75732835249631}, "custom_metrics": {"mean_ego_speed_mean": 41.8655125, "mean_ego_speed_min": 36.49875, "mean_ego_speed_max": 46.443999999999996, "distance_travelled_mean": 98.56685, "distance_travelled_min": 35.4155, "distance_travelled_max": 124.85125}, "hist_stats": {"episode_reward": [-323.9157533551002, -165.3538876239856, -1169.9075047250058, -459.0706951858064, 70.3799473871102, -570.633914140485, -460.77756995140226, 69.28966990578853, -49.0895277605261, 219.54263608187424, -34.13791819942123, -570.7029739196424, -365.7686327913458, -548.095876366606, -378.1947830029239, -315.4765346868379, -235.78989103807115, -636.9677597383476, -14.47129388855019, -188.0075123389498, 252.84904071776774, -191.0868434243213, -334.24945937609203, -869.0256252706633, 357.91930792688134, -706.2846239316171, -3.306460726910646, -522.006644597566, -394.2093327167674, -553.3520295256233, -188.35629230394676, -750.2940846925408, 180.35869523571705, 229.87443080217656, 189.80790743174532, -477.4845517469688, -433.7518814211228, -693.938550752084, 33.03084893021221, -554.3803131015827], "episode_lengths": [148, 32, 136, 120, 127, 97, 101, 120, 119, 117, 118, 121, 82, 106, 118, 113, 107, 112, 122, 123, 123, 112, 126, 123, 125, 114, 121, 121, 101, 123, 122, 129, 260, 137, 128, 89, 143, 107, 118, 110], "policy_AGENT-3_reward": [-77.61125736890139, -16.029414777035907, -136.04740790082292, -127.73826841262483, -15.321489445211672, -125.33143121586008, -123.86286147485411, 6.345348373945244, -42.861068504920574, 43.899378720898866, -15.730402546728273, -131.7471347390881, -70.83185982622055, -178.89110802047512, -92.92575957253881, -46.85901437305522, -49.71195558472984, -122.73230572648562, -22.518374276588382, -71.75018882051901, 60.882845286347084, -30.808678115797054, -33.978032152476665, -218.6495705430483, 83.24388456154338, -122.69521366380397, -16.325319966749806, -135.24122272252916, -117.82055455739373, -176.20983338889783, -43.139533551978786, -171.4455237628716, -150.67362981087098, -0.8524113498859909, 2.2020770678050745, -95.06260123959731, -163.94941022611053, -161.20957895880292, -37.279954625156556, -121.7649872366475], "policy_AGENT-0_reward": [-91.89141988068845, -66.73939115774922, -448.8965319625391, -103.97170645757771, 27.342029521430348, -160.0129928141722, -117.44272621796819, 24.005430787956115, -4.534897519603049, 65.52762051495297, -1.9747886535083201, -177.65985491520405, -112.03207950027694, -95.4818225475154, -118.29858902758383, -110.83588150166379, -67.78007167006972, -182.56626990274012, 13.996313204020556, -44.242611867897445, 39.02710915335282, -75.1933234424076, -75.21237300611205, -238.67455199242482, 74.50739681846153, -250.7564293731004, 11.5474127587693, -114.36150404878217, -79.21538539575228, -115.70758846380178, -52.21709751631647, -195.32246517159516, 266.6115005900778, 96.22263750542568, 96.78908942175022, -143.55349736438262, -199.7300825790453, -161.9801852537422, 53.27492434580155, -144.38198165523502], "policy_AGENT-2_reward": [-100.21171472626442, -15.975959039946044, -449.4788037794044, -123.47193924394513, -15.236451069665401, -125.30607751707818, -102.00806965189634, 19.459669821118542, -42.783563007598474, 43.84301041084104, -15.781465467228609, -130.46819437349032, -70.87675276677673, -178.38073063441567, -96.62798418368615, -46.8222729259098, -50.53918606652537, -209.49880867469213, -22.41278813281122, -71.71935028577666, 67.8539188188227, -30.838333043555885, -112.80756673101503, -219.54683426168634, 83.3296868080183, -210.70384412192243, 10.987144328894253, -135.21971642757256, -117.69474103635258, -116.26458699352183, -43.1729865759878, -193.2240544280157, -150.6496867073742, -0.6568215880630608, 2.3032139604815245, -95.1237099154512, -35.27036163930682, -208.54686471661554, -37.316275493156226, -167.03279201696165], "policy_AGENT-1_reward": [-54.20136137924673, -66.60912264925443, -135.48476108224037, -103.88878107165871, 73.5958583805569, -159.98341259337462, -117.46391260668335, 19.47922092276882, 41.09000127159612, 66.27262643518134, -0.6512615319560524, -130.8277898918602, -112.02794069807172, -95.34221516419939, -70.34245021911534, -110.9593658862091, -67.75867771674618, -122.17037543442939, 16.463555316828906, -0.29536136475667263, 85.08516745924527, -54.24650882256064, -112.25148748648837, -192.1546684735044, 116.83833973885797, -122.1291367727901, -9.515697847824393, -137.1842013986815, -79.47865172726877, -145.17002067940183, -49.82667465966379, -190.30204133005813, 215.07051116388416, 135.16102623469976, 88.5135269817085, -143.74474322753773, -34.80202697666027, -162.201921822923, 54.35215470272344, -121.20055219273824]}, "sampler_perf": {"mean_env_wait_ms": 77.15196881314816, "mean_raw_obs_processing_ms": 2.8868813725995457, "mean_inference_ms": 5.2374352181669535, "mean_action_processing_ms": 0.18279882303336822}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 5040, "timers": {"learn_time_ms": 11.06, "learn_throughput": 2893.347, "update_time_ms": 11.469}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 0.48748040199279785, "min_q": -15.220264434814453, "max_q": 26.28636932373047, "mean_td_error": 5.588789939880371, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": -3.085367202758789, "min_q": -14.334794998168945, "max_q": 24.538347244262695, "mean_td_error": 2.244159460067749, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": -1.8706926107406616, "min_q": -10.101629257202148, "max_q": 12.581412315368652, "mean_td_error": 4.751505374908447, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": -4.584429740905762, "min_q": -15.206282615661621, "max_q": 12.13608169555664, "mean_td_error": 2.1231799125671387, "model": {}}}, "num_steps_sampled": 5040, "num_steps_trained": 10784, "last_target_update_ts": 5040, "num_target_updates": 9}, "done": false, "episodes_total": 40, "training_iteration": 5, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-45-46", "timestamp": 1624265146, "time_this_iter_s": 36.02513098716736, "time_total_s": 193.4819278717041, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f899cf71dd0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f899cf71e60>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898e3964d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd560>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd9e0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898e3964d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd560>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd9e0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898e3964d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd560>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd9e0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898e3964d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd560>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd9e0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c7c1c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 193.4819278717041, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 48.442307692307686, "ram_util_percent": 86.52884615384619}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 698.4631058776095, "episode_reward_min": -1169.9075047250058, "episode_reward_mean": -231.08046495240103, "episode_len_mean": 120.85714285714286, "episodes_this_iter": 9, "policy_reward_min": {"AGENT-3": -218.6495705430483, "AGENT-2": -449.4788037794044, "AGENT-0": -448.8965319625391, "AGENT-1": -192.1546684735044}, "policy_reward_max": {"AGENT-3": 155.79079414571663, "AGENT-2": 136.14784654743104, "AGENT-0": 394.38970453780024, "AGENT-1": 372.9943443423514}, "policy_reward_mean": {"AGENT-3": -70.63355677478306, "AGENT-2": -74.09682474621584, "AGENT-0": -51.72483791098008, "AGENT-1": -34.62524552042205}, "custom_metrics": {"mean_ego_speed_mean": 41.83058163265306, "mean_ego_speed_min": 36.49875, "mean_ego_speed_max": 46.443999999999996, "distance_travelled_mean": 96.14242857142858, "distance_travelled_min": 35.4155, "distance_travelled_max": 124.85125}, "hist_stats": {"episode_reward": [-216.0425687012854, -194.2165301744098, 617.3350042344224, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929, -49.0895277605261, 219.54263608187424, -34.13791819942123, -570.7029739196424, -365.7686327913458, -548.095876366606, -378.1947830029239, -315.4765346868379, -235.78989103807115, -636.9677597383476, -14.47129388855019, -188.0075123389498, 252.84904071776774, -191.0868434243213, -334.24945937609203, -869.0256252706633, 357.91930792688134, -706.2846239316171, -3.306460726910646, -522.006644597566, -394.2093327167674, -553.3520295256233, -188.35629230394676, -750.2940846925408, 180.35869523571705, 229.87443080217656, 189.80790743174532, -477.4845517469688, -433.7518814211228, -693.938550752084, 33.03084893021221, -554.3803131015827, -323.9157533551002, -165.3538876239856, -1169.9075047250058, -459.0706951858064, 70.3799473871102, -570.633914140485, -460.77756995140226, 69.28966990578853], "episode_lengths": [103, 71, 121, 155, 118, 156, 206, 82, 139, 119, 117, 118, 121, 82, 106, 118, 113, 107, 112, 122, 123, 123, 112, 126, 123, 125, 114, 121, 121, 101, 123, 122, 129, 260, 137, 128, 89, 143, 107, 118, 110, 148, 32, 136, 120, 127, 97, 101, 120], "policy_AGENT-3_reward": [-31.63959386777298, -51.153216819152256, 155.79079414571663, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477, -42.861068504920574, 43.899378720898866, -15.730402546728273, -131.7471347390881, -70.83185982622055, -178.89110802047512, -92.92575957253881, -46.85901437305522, -49.71195558472984, -122.73230572648562, -22.518374276588382, -71.75018882051901, 60.882845286347084, -30.808678115797054, -33.978032152476665, -218.6495705430483, 83.24388456154338, -122.69521366380397, -16.325319966749806, -135.24122272252916, -117.82055455739373, -176.20983338889783, -43.139533551978786, -171.4455237628716, -150.67362981087098, -0.8524113498859909, 2.2020770678050745, -95.06260123959731, -163.94941022611053, -161.20957895880292, -37.279954625156556, -121.7649872366475, -77.61125736890139, -16.029414777035907, -136.04740790082292, -127.73826841262483, -15.321489445211672, -125.33143121586008, -123.86286147485411, 6.345348373945244], "policy_AGENT-2_reward": [-53.114488980805774, -46.52268778681753, 136.14784654743104, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224, -42.783563007598474, 43.84301041084104, -15.781465467228609, -130.46819437349032, -70.87675276677673, -178.38073063441567, -96.62798418368615, -46.8222729259098, -50.53918606652537, -209.49880867469213, -22.41278813281122, -71.71935028577666, 67.8539188188227, -30.838333043555885, -112.80756673101503, -219.54683426168634, 83.3296868080183, -210.70384412192243, 10.987144328894253, -135.21971642757256, -117.69474103635258, -116.26458699352183, -43.1729865759878, -193.2240544280157, -150.6496867073742, -0.6568215880630608, 2.3032139604815245, -95.1237099154512, -35.27036163930682, -208.54686471661554, -37.316275493156226, -167.03279201696165, -100.21171472626442, -15.975959039946044, -449.4788037794044, -123.47193924394513, -15.236451069665401, -125.30607751707818, -102.00806965189634, 19.459669821118542], "policy_AGENT-0_reward": [-65.62780830452024, -45.951918648349896, 163.97063846018455, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587, -4.534897519603049, 65.52762051495297, -1.9747886535083201, -177.65985491520405, -112.03207950027694, -95.4818225475154, -118.29858902758383, -110.83588150166379, -67.78007167006972, -182.56626990274012, 13.996313204020556, -44.242611867897445, 39.02710915335282, -75.1933234424076, -75.21237300611205, -238.67455199242482, 74.50739681846153, -250.7564293731004, 11.5474127587693, -114.36150404878217, -79.21538539575228, -115.70758846380178, -52.21709751631647, -195.32246517159516, 266.6115005900778, 96.22263750542568, 96.78908942175022, -143.55349736438262, -199.7300825790453, -161.9801852537422, 53.27492434580155, -144.38198165523502, -91.89141988068845, -66.73939115774922, -448.8965319625391, -103.97170645757771, 27.342029521430348, -160.0129928141722, -117.44272621796819, 24.005430787956115], "policy_AGENT-1_reward": [-65.66067754818633, -50.588706920090075, 161.42572508109038, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445, 41.09000127159612, 66.27262643518134, -0.6512615319560524, -130.8277898918602, -112.02794069807172, -95.34221516419939, -70.34245021911534, -110.9593658862091, -67.75867771674618, -122.17037543442939, 16.463555316828906, -0.29536136475667263, 85.08516745924527, -54.24650882256064, -112.25148748648837, -192.1546684735044, 116.83833973885797, -122.1291367727901, -9.515697847824393, -137.1842013986815, -79.47865172726877, -145.17002067940183, -49.82667465966379, -190.30204133005813, 215.07051116388416, 135.16102623469976, 88.5135269817085, -143.74474322753773, -34.80202697666027, -162.201921822923, 54.35215470272344, -121.20055219273824, -54.20136137924673, -66.60912264925443, -135.48476108224037, -103.88878107165871, 73.5958583805569, -159.98341259337462, -117.46391260668335, 19.47922092276882]}, "sampler_perf": {"mean_env_wait_ms": 75.68254000424538, "mean_raw_obs_processing_ms": 2.869305461501515, "mean_inference_ms": 4.969997939889703, "mean_action_processing_ms": 0.18152195759651238}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 6048, "timers": {"learn_time_ms": 11.318, "learn_throughput": 2827.464, "update_time_ms": 13.331}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 3.0506956577301025, "min_q": -18.599327087402344, "max_q": 44.14773941040039, "mean_td_error": 1.6297953128814697, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": -3.5029964447021484, "min_q": -17.31686782836914, "max_q": 15.208548545837402, "mean_td_error": -1.2667765617370605, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": -2.276675224304199, "min_q": -15.926828384399414, "max_q": 12.715794563293457, "mean_td_error": 4.846531391143799, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": -4.558081150054932, "min_q": -16.9747371673584, "max_q": 13.770711898803711, "mean_td_error": -0.23941458761692047, "model": {}}}, "num_steps_sampled": 6048, "num_steps_trained": 13472, "last_target_update_ts": 6048, "num_target_updates": 11}, "done": false, "episodes_total": 49, "training_iteration": 6, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-46-20", "timestamp": 1624265180, "time_this_iter_s": 34.34224200248718, "time_total_s": 227.82416987419128, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c7c1200>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c7c1b00>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c079440>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c079680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079560>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079200>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c079440>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c079680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079560>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079200>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c079440>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c079680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079560>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079200>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c079440>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c079680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079560>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079200>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f898c0799e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 227.82416987419128, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 47.326530612244895, "ram_util_percent": 86.68571428571427}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 698.4631058776095, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": -253.9960108139587, "episode_len_mean": 119.98245614035088, "episodes_this_iter": 8, "policy_reward_min": {"AGENT-3": -233.85995857534215, "AGENT-0": -448.8965319625391, "AGENT-2": -449.4788037794044, "AGENT-1": -349.05580841413826}, "policy_reward_max": {"AGENT-3": 155.79079414571663, "AGENT-0": 394.38970453780024, "AGENT-2": 136.14784654743104, "AGENT-1": 372.9943443423514}, "policy_reward_mean": {"AGENT-3": -74.21738572021822, "AGENT-0": -58.902518811215856, "AGENT-2": -77.85239459709084, "AGENT-1": -43.02371168543374}, "custom_metrics": {"mean_ego_speed_mean": 41.768578947368425, "mean_ego_speed_min": 34.679500000000004, "mean_ego_speed_max": 46.443999999999996, "distance_travelled_mean": 94.69863596491228, "distance_travelled_min": 35.4155, "distance_travelled_max": 124.85125}, "hist_stats": {"episode_reward": [-48.87212301200027, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, -49.0895277605261, 219.54263608187424, -34.13791819942123, -570.7029739196424, -365.7686327913458, -548.095876366606, -378.1947830029239, -315.4765346868379, -235.78989103807115, -636.9677597383476, -14.47129388855019, -188.0075123389498, 252.84904071776774, -191.0868434243213, -334.24945937609203, -869.0256252706633, 357.91930792688134, -706.2846239316171, -3.306460726910646, -522.006644597566, -394.2093327167674, -553.3520295256233, -188.35629230394676, -750.2940846925408, 180.35869523571705, 229.87443080217656, 189.80790743174532, -477.4845517469688, -433.7518814211228, -693.938550752084, 33.03084893021221, -554.3803131015827, -323.9157533551002, -165.3538876239856, -1169.9075047250058, -459.0706951858064, 70.3799473871102, -570.633914140485, -460.77756995140226, 69.28966990578853, -216.0425687012854, -194.2165301744098, 617.3350042344224, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929], "episode_lengths": [149, 98, 140, 122, 44, 113, 137, 114, 119, 117, 118, 121, 82, 106, 118, 113, 107, 112, 122, 123, 123, 112, 126, 123, 125, 114, 121, 121, 101, 123, 122, 129, 260, 137, 128, 89, 143, 107, 118, 110, 148, 32, 136, 120, 127, 97, 101, 120, 103, 71, 121, 155, 118, 156, 206, 82, 139], "policy_AGENT-3_reward": [1.4932620478289884, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -42.861068504920574, 43.899378720898866, -15.730402546728273, -131.7471347390881, -70.83185982622055, -178.89110802047512, -92.92575957253881, -46.85901437305522, -49.71195558472984, -122.73230572648562, -22.518374276588382, -71.75018882051901, 60.882845286347084, -30.808678115797054, -33.978032152476665, -218.6495705430483, 83.24388456154338, -122.69521366380397, -16.325319966749806, -135.24122272252916, -117.82055455739373, -176.20983338889783, -43.139533551978786, -171.4455237628716, -150.67362981087098, -0.8524113498859909, 2.2020770678050745, -95.06260123959731, -163.94941022611053, -161.20957895880292, -37.279954625156556, -121.7649872366475, -77.61125736890139, -16.029414777035907, -136.04740790082292, -127.73826841262483, -15.321489445211672, -125.33143121586008, -123.86286147485411, 6.345348373945244, -31.63959386777298, -51.153216819152256, 155.79079414571663, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477], "policy_AGENT-0_reward": [-8.77693138390639, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, -4.534897519603049, 65.52762051495297, -1.9747886535083201, -177.65985491520405, -112.03207950027694, -95.4818225475154, -118.29858902758383, -110.83588150166379, -67.78007167006972, -182.56626990274012, 13.996313204020556, -44.242611867897445, 39.02710915335282, -75.1933234424076, -75.21237300611205, -238.67455199242482, 74.50739681846153, -250.7564293731004, 11.5474127587693, -114.36150404878217, -79.21538539575228, -115.70758846380178, -52.21709751631647, -195.32246517159516, 266.6115005900778, 96.22263750542568, 96.78908942175022, -143.55349736438262, -199.7300825790453, -161.9801852537422, 53.27492434580155, -144.38198165523502, -91.89141988068845, -66.73939115774922, -448.8965319625391, -103.97170645757771, 27.342029521430348, -160.0129928141722, -117.44272621796819, 24.005430787956115, -65.62780830452024, -45.951918648349896, 163.97063846018455, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587], "policy_AGENT-2_reward": [-43.75892882928075, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -42.783563007598474, 43.84301041084104, -15.781465467228609, -130.46819437349032, -70.87675276677673, -178.38073063441567, -96.62798418368615, -46.8222729259098, -50.53918606652537, -209.49880867469213, -22.41278813281122, -71.71935028577666, 67.8539188188227, -30.838333043555885, -112.80756673101503, -219.54683426168634, 83.3296868080183, -210.70384412192243, 10.987144328894253, -135.21971642757256, -117.69474103635258, -116.26458699352183, -43.1729865759878, -193.2240544280157, -150.6496867073742, -0.6568215880630608, 2.3032139604815245, -95.1237099154512, -35.27036163930682, -208.54686471661554, -37.316275493156226, -167.03279201696165, -100.21171472626442, -15.975959039946044, -449.4788037794044, -123.47193924394513, -15.236451069665401, -125.30607751707818, -102.00806965189634, 19.459669821118542, -53.114488980805774, -46.52268778681753, 136.14784654743104, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224], "policy_AGENT-1_reward": [2.170475153358211, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 41.09000127159612, 66.27262643518134, -0.6512615319560524, -130.8277898918602, -112.02794069807172, -95.34221516419939, -70.34245021911534, -110.9593658862091, -67.75867771674618, -122.17037543442939, 16.463555316828906, -0.29536136475667263, 85.08516745924527, -54.24650882256064, -112.25148748648837, -192.1546684735044, 116.83833973885797, -122.1291367727901, -9.515697847824393, -137.1842013986815, -79.47865172726877, -145.17002067940183, -49.82667465966379, -190.30204133005813, 215.07051116388416, 135.16102623469976, 88.5135269817085, -143.74474322753773, -34.80202697666027, -162.201921822923, 54.35215470272344, -121.20055219273824, -54.20136137924673, -66.60912264925443, -135.48476108224037, -103.88878107165871, 73.5958583805569, -159.98341259337462, -117.46391260668335, 19.47922092276882, -65.66067754818633, -50.588706920090075, 161.42572508109038, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445]}, "sampler_perf": {"mean_env_wait_ms": 74.45817768796644, "mean_raw_obs_processing_ms": 2.8523021679146647, "mean_inference_ms": 4.777346202552404, "mean_action_processing_ms": 0.18013310483993297}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 7056, "timers": {"learn_time_ms": 10.794, "learn_throughput": 2964.677, "update_time_ms": 12.777}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 5.595043182373047, "min_q": -21.75147819519043, "max_q": 44.653282165527344, "mean_td_error": 6.575587272644043, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": -3.2575573921203613, "min_q": -20.014833450317383, "max_q": 52.659828186035156, "mean_td_error": -0.11512276530265808, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": -8.653458595275879, "min_q": -23.282392501831055, "max_q": 18.13402557373047, "mean_td_error": 1.3984529972076416, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": -5.703568935394287, "min_q": -22.710126876831055, "max_q": 17.93825912475586, "mean_td_error": 3.0103886127471924, "model": {}}}, "num_steps_sampled": 7056, "num_steps_trained": 16160, "last_target_update_ts": 7056, "num_target_updates": 13}, "done": false, "episodes_total": 57, "training_iteration": 7, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-46-53", "timestamp": 1624265213, "time_this_iter_s": 32.808919191360474, "time_total_s": 260.63308906555176, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c7c1d40>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c7c1440>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1cb0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c13b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c18c0>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079830>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1cb0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c13b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c18c0>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079830>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1cb0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c13b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c18c0>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079830>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1cb0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c13b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c18c0>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079830>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f898c079320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 260.63308906555176, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 48.008510638297885, "ram_util_percent": 86.85957446808511}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 698.4631058776095, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": -234.35326537034152, "episode_len_mean": 126.0, "episodes_this_iter": 6, "policy_reward_min": {"AGENT-3": -233.85995857534215, "AGENT-2": -449.4788037794044, "AGENT-0": -448.8965319625391, "AGENT-1": -349.05580841413826}, "policy_reward_max": {"AGENT-3": 225.81289307132477, "AGENT-2": 213.26918793587532, "AGENT-0": 394.38970453780024, "AGENT-1": 372.9943443423514}, "policy_reward_mean": {"AGENT-3": -70.11483722944463, "AGENT-2": -70.75589046752505, "AGENT-0": -49.42368975410101, "AGENT-1": -44.05884791927081}, "custom_metrics": {"mean_ego_speed_mean": 41.54986507936509, "mean_ego_speed_min": 28.9185, "mean_ego_speed_max": 46.5985, "distance_travelled_mean": 94.28517063492066, "distance_travelled_min": 35.4155, "distance_travelled_max": 124.85125}, "hist_stats": {"episode_reward": [166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -49.0895277605261, 219.54263608187424, -34.13791819942123, -570.7029739196424, -365.7686327913458, -548.095876366606, -378.1947830029239, -315.4765346868379, -235.78989103807115, -636.9677597383476, -14.47129388855019, -188.0075123389498, 252.84904071776774, -191.0868434243213, -334.24945937609203, -869.0256252706633, 357.91930792688134, -706.2846239316171, -3.306460726910646, -522.006644597566, -394.2093327167674, -553.3520295256233, -188.35629230394676, -750.2940846925408, 180.35869523571705, 229.87443080217656, 189.80790743174532, -477.4845517469688, -433.7518814211228, -693.938550752084, 33.03084893021221, -554.3803131015827, -323.9157533551002, -165.3538876239856, -1169.9075047250058, -459.0706951858064, 70.3799473871102, -570.633914140485, -460.77756995140226, 69.28966990578853, -216.0425687012854, -194.2165301744098, 617.3350042344224, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929, -48.87212301200027, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859], "episode_lengths": [265, 94, 135, 215, 272, 118, 119, 117, 118, 121, 82, 106, 118, 113, 107, 112, 122, 123, 123, 112, 126, 123, 125, 114, 121, 121, 101, 123, 122, 129, 260, 137, 128, 89, 143, 107, 118, 110, 148, 32, 136, 120, 127, 97, 101, 120, 103, 71, 121, 155, 118, 156, 206, 82, 139, 149, 98, 140, 122, 44, 113, 137, 114], "policy_AGENT-3_reward": [-14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, -42.861068504920574, 43.899378720898866, -15.730402546728273, -131.7471347390881, -70.83185982622055, -178.89110802047512, -92.92575957253881, -46.85901437305522, -49.71195558472984, -122.73230572648562, -22.518374276588382, -71.75018882051901, 60.882845286347084, -30.808678115797054, -33.978032152476665, -218.6495705430483, 83.24388456154338, -122.69521366380397, -16.325319966749806, -135.24122272252916, -117.82055455739373, -176.20983338889783, -43.139533551978786, -171.4455237628716, -150.67362981087098, -0.8524113498859909, 2.2020770678050745, -95.06260123959731, -163.94941022611053, -161.20957895880292, -37.279954625156556, -121.7649872366475, -77.61125736890139, -16.029414777035907, -136.04740790082292, -127.73826841262483, -15.321489445211672, -125.33143121586008, -123.86286147485411, 6.345348373945244, -31.63959386777298, -51.153216819152256, 155.79079414571663, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477, 1.4932620478289884, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447], "policy_AGENT-2_reward": [-14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -42.783563007598474, 43.84301041084104, -15.781465467228609, -130.46819437349032, -70.87675276677673, -178.38073063441567, -96.62798418368615, -46.8222729259098, -50.53918606652537, -209.49880867469213, -22.41278813281122, -71.71935028577666, 67.8539188188227, -30.838333043555885, -112.80756673101503, -219.54683426168634, 83.3296868080183, -210.70384412192243, 10.987144328894253, -135.21971642757256, -117.69474103635258, -116.26458699352183, -43.1729865759878, -193.2240544280157, -150.6496867073742, -0.6568215880630608, 2.3032139604815245, -95.1237099154512, -35.27036163930682, -208.54686471661554, -37.316275493156226, -167.03279201696165, -100.21171472626442, -15.975959039946044, -449.4788037794044, -123.47193924394513, -15.236451069665401, -125.30607751707818, -102.00806965189634, 19.459669821118542, -53.114488980805774, -46.52268778681753, 136.14784654743104, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224, -43.75892882928075, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558], "policy_AGENT-0_reward": [74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -4.534897519603049, 65.52762051495297, -1.9747886535083201, -177.65985491520405, -112.03207950027694, -95.4818225475154, -118.29858902758383, -110.83588150166379, -67.78007167006972, -182.56626990274012, 13.996313204020556, -44.242611867897445, 39.02710915335282, -75.1933234424076, -75.21237300611205, -238.67455199242482, 74.50739681846153, -250.7564293731004, 11.5474127587693, -114.36150404878217, -79.21538539575228, -115.70758846380178, -52.21709751631647, -195.32246517159516, 266.6115005900778, 96.22263750542568, 96.78908942175022, -143.55349736438262, -199.7300825790453, -161.9801852537422, 53.27492434580155, -144.38198165523502, -91.89141988068845, -66.73939115774922, -448.8965319625391, -103.97170645757771, 27.342029521430348, -160.0129928141722, -117.44272621796819, 24.005430787956115, -65.62780830452024, -45.951918648349896, 163.97063846018455, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587, -8.77693138390639, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082], "policy_AGENT-1_reward": [120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 41.09000127159612, 66.27262643518134, -0.6512615319560524, -130.8277898918602, -112.02794069807172, -95.34221516419939, -70.34245021911534, -110.9593658862091, -67.75867771674618, -122.17037543442939, 16.463555316828906, -0.29536136475667263, 85.08516745924527, -54.24650882256064, -112.25148748648837, -192.1546684735044, 116.83833973885797, -122.1291367727901, -9.515697847824393, -137.1842013986815, -79.47865172726877, -145.17002067940183, -49.82667465966379, -190.30204133005813, 215.07051116388416, 135.16102623469976, 88.5135269817085, -143.74474322753773, -34.80202697666027, -162.201921822923, 54.35215470272344, -121.20055219273824, -54.20136137924673, -66.60912264925443, -135.48476108224037, -103.88878107165871, 73.5958583805569, -159.98341259337462, -117.46391260668335, 19.47922092276882, -65.66067754818633, -50.588706920090075, 161.42572508109038, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445, 2.170475153358211, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429]}, "sampler_perf": {"mean_env_wait_ms": 73.54553970415985, "mean_raw_obs_processing_ms": 2.835234514030194, "mean_inference_ms": 4.650856002429226, "mean_action_processing_ms": 0.17913993200012635}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 8064, "timers": {"learn_time_ms": 10.612, "learn_throughput": 3015.377, "update_time_ms": 11.84}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 2.4498202800750732, "min_q": -25.88245964050293, "max_q": 35.27689743041992, "mean_td_error": 3.1301984786987305, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": -0.39880871772766113, "min_q": -22.62126350402832, "max_q": 33.91360092163086, "mean_td_error": 4.467973232269287, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": -4.616118431091309, "min_q": -23.925395965576172, "max_q": 31.20423698425293, "mean_td_error": 5.599636077880859, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": -5.690845966339111, "min_q": -25.4935302734375, "max_q": 27.19880485534668, "mean_td_error": 0.21256166696548462, "model": {}}}, "num_steps_sampled": 8064, "num_steps_trained": 18848, "last_target_update_ts": 8064, "num_target_updates": 15}, "done": false, "episodes_total": 63, "training_iteration": 8, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-47-25", "timestamp": 1624265245, "time_this_iter_s": 31.95694661140442, "time_total_s": 292.5900356769562, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c7c1dd0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c7c1c20>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c079200>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c079560>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079680>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079440>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c079200>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c079560>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079680>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079440>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c079200>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c079560>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079680>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079440>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c079200>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c079560>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079680>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079440>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f898c0bd290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 292.5900356769562, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 44.817391304347815, "ram_util_percent": 87.04347826086956}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 698.4631058776095, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": -238.65512284527, "episode_len_mean": 128.04285714285714, "episodes_this_iter": 7, "policy_reward_min": {"AGENT-3": -360.74714809698355, "AGENT-2": -449.4788037794044, "AGENT-0": -448.8965319625391, "AGENT-1": -349.05580841413826}, "policy_reward_max": {"AGENT-3": 225.81289307132477, "AGENT-2": 213.26918793587532, "AGENT-0": 394.38970453780024, "AGENT-1": 372.9943443423514}, "policy_reward_mean": {"AGENT-3": -69.11421232096416, "AGENT-2": -72.21979563392594, "AGENT-0": -52.52944645460527, "AGENT-1": -44.791668435774646}, "custom_metrics": {"mean_ego_speed_mean": 41.573642857142865, "mean_ego_speed_min": 28.9185, "mean_ego_speed_max": 48.630250000000004, "distance_travelled_mean": 94.43093928571427, "distance_travelled_min": 35.4155, "distance_travelled_max": 124.85125}, "hist_stats": {"episode_reward": [-33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -49.0895277605261, 219.54263608187424, -34.13791819942123, -570.7029739196424, -365.7686327913458, -548.095876366606, -378.1947830029239, -315.4765346868379, -235.78989103807115, -636.9677597383476, -14.47129388855019, -188.0075123389498, 252.84904071776774, -191.0868434243213, -334.24945937609203, -869.0256252706633, 357.91930792688134, -706.2846239316171, -3.306460726910646, -522.006644597566, -394.2093327167674, -553.3520295256233, -188.35629230394676, -750.2940846925408, 180.35869523571705, 229.87443080217656, 189.80790743174532, -477.4845517469688, -433.7518814211228, -693.938550752084, 33.03084893021221, -554.3803131015827, -323.9157533551002, -165.3538876239856, -1169.9075047250058, -459.0706951858064, 70.3799473871102, -570.633914140485, -460.77756995140226, 69.28966990578853, -216.0425687012854, -194.2165301744098, 617.3350042344224, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929, -48.87212301200027, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276], "episode_lengths": [193, 111, 155, 128, 112, 170, 156, 119, 117, 118, 121, 82, 106, 118, 113, 107, 112, 122, 123, 123, 112, 126, 123, 125, 114, 121, 121, 101, 123, 122, 129, 260, 137, 128, 89, 143, 107, 118, 110, 148, 32, 136, 120, 127, 97, 101, 120, 103, 71, 121, 155, 118, 156, 206, 82, 139, 149, 98, 140, 122, 44, 113, 137, 114, 265, 94, 135, 215, 272, 118], "policy_AGENT-3_reward": [22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -42.861068504920574, 43.899378720898866, -15.730402546728273, -131.7471347390881, -70.83185982622055, -178.89110802047512, -92.92575957253881, -46.85901437305522, -49.71195558472984, -122.73230572648562, -22.518374276588382, -71.75018882051901, 60.882845286347084, -30.808678115797054, -33.978032152476665, -218.6495705430483, 83.24388456154338, -122.69521366380397, -16.325319966749806, -135.24122272252916, -117.82055455739373, -176.20983338889783, -43.139533551978786, -171.4455237628716, -150.67362981087098, -0.8524113498859909, 2.2020770678050745, -95.06260123959731, -163.94941022611053, -161.20957895880292, -37.279954625156556, -121.7649872366475, -77.61125736890139, -16.029414777035907, -136.04740790082292, -127.73826841262483, -15.321489445211672, -125.33143121586008, -123.86286147485411, 6.345348373945244, -31.63959386777298, -51.153216819152256, 155.79079414571663, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477, 1.4932620478289884, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812], "policy_AGENT-2_reward": [-29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -42.783563007598474, 43.84301041084104, -15.781465467228609, -130.46819437349032, -70.87675276677673, -178.38073063441567, -96.62798418368615, -46.8222729259098, -50.53918606652537, -209.49880867469213, -22.41278813281122, -71.71935028577666, 67.8539188188227, -30.838333043555885, -112.80756673101503, -219.54683426168634, 83.3296868080183, -210.70384412192243, 10.987144328894253, -135.21971642757256, -117.69474103635258, -116.26458699352183, -43.1729865759878, -193.2240544280157, -150.6496867073742, -0.6568215880630608, 2.3032139604815245, -95.1237099154512, -35.27036163930682, -208.54686471661554, -37.316275493156226, -167.03279201696165, -100.21171472626442, -15.975959039946044, -449.4788037794044, -123.47193924394513, -15.236451069665401, -125.30607751707818, -102.00806965189634, 19.459669821118542, -53.114488980805774, -46.52268778681753, 136.14784654743104, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224, -43.75892882928075, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326], "policy_AGENT-0_reward": [-48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -4.534897519603049, 65.52762051495297, -1.9747886535083201, -177.65985491520405, -112.03207950027694, -95.4818225475154, -118.29858902758383, -110.83588150166379, -67.78007167006972, -182.56626990274012, 13.996313204020556, -44.242611867897445, 39.02710915335282, -75.1933234424076, -75.21237300611205, -238.67455199242482, 74.50739681846153, -250.7564293731004, 11.5474127587693, -114.36150404878217, -79.21538539575228, -115.70758846380178, -52.21709751631647, -195.32246517159516, 266.6115005900778, 96.22263750542568, 96.78908942175022, -143.55349736438262, -199.7300825790453, -161.9801852537422, 53.27492434580155, -144.38198165523502, -91.89141988068845, -66.73939115774922, -448.8965319625391, -103.97170645757771, 27.342029521430348, -160.0129928141722, -117.44272621796819, 24.005430787956115, -65.62780830452024, -45.951918648349896, 163.97063846018455, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587, -8.77693138390639, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221], "policy_AGENT-1_reward": [22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, 41.09000127159612, 66.27262643518134, -0.6512615319560524, -130.8277898918602, -112.02794069807172, -95.34221516419939, -70.34245021911534, -110.9593658862091, -67.75867771674618, -122.17037543442939, 16.463555316828906, -0.29536136475667263, 85.08516745924527, -54.24650882256064, -112.25148748648837, -192.1546684735044, 116.83833973885797, -122.1291367727901, -9.515697847824393, -137.1842013986815, -79.47865172726877, -145.17002067940183, -49.82667465966379, -190.30204133005813, 215.07051116388416, 135.16102623469976, 88.5135269817085, -143.74474322753773, -34.80202697666027, -162.201921822923, 54.35215470272344, -121.20055219273824, -54.20136137924673, -66.60912264925443, -135.48476108224037, -103.88878107165871, 73.5958583805569, -159.98341259337462, -117.46391260668335, 19.47922092276882, -65.66067754818633, -50.588706920090075, 161.42572508109038, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445, 2.170475153358211, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649]}, "sampler_perf": {"mean_env_wait_ms": 72.53318352802198, "mean_raw_obs_processing_ms": 2.8146968472096074, "mean_inference_ms": 4.5186634438668305, "mean_action_processing_ms": 0.17795151273955756}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 9072, "timers": {"learn_time_ms": 10.997, "learn_throughput": 2909.825, "update_time_ms": 11.279}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 4.030498027801514, "min_q": -38.45594024658203, "max_q": 65.7233657836914, "mean_td_error": 6.10509729385376, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 2.7534589767456055, "min_q": -22.6210880279541, "max_q": 79.80818939208984, "mean_td_error": 7.262898921966553, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": -3.370709180831909, "min_q": -36.32649230957031, "max_q": 42.89347457885742, "mean_td_error": 4.8816633224487305, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": -12.160171508789062, "min_q": -34.63557052612305, "max_q": 10.366533279418945, "mean_td_error": 0.206518292427063, "model": {}}}, "num_steps_sampled": 9072, "num_steps_trained": 21536, "last_target_update_ts": 9072, "num_target_updates": 17}, "done": false, "episodes_total": 70, "training_iteration": 9, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-48-00", "timestamp": 1624265280, "time_this_iter_s": 34.33943963050842, "time_total_s": 326.9294753074646, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f898c0bdd40>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f898c0bd170>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7c10e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1cb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c13b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c15f0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7c10e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1cb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c13b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c15f0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7c10e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1cb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c13b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c15f0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7c10e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1cb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c13b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c15f0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f898c079dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 326.9294753074646, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 44.29591836734693, "ram_util_percent": 87.23673469387754}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 698.4631058776095, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": -230.99974266257874, "episode_len_mean": 130.93333333333334, "episodes_this_iter": 5, "policy_reward_min": {"AGENT-3": -360.74714809698355, "AGENT-2": -449.4788037794044, "AGENT-0": -448.8965319625391, "AGENT-1": -349.05580841413826}, "policy_reward_max": {"AGENT-3": 225.81289307132477, "AGENT-2": 264.7940748719771, "AGENT-0": 394.38970453780024, "AGENT-1": 372.9943443423514}, "policy_reward_mean": {"AGENT-3": -70.80521246434606, "AGENT-2": -72.5659102442666, "AGENT-0": -48.067130095546275, "AGENT-1": -39.56148985841979}, "custom_metrics": {"mean_ego_speed_mean": 41.56049, "mean_ego_speed_min": 28.9185, "mean_ego_speed_max": 49.18825, "distance_travelled_mean": 93.79490000000001, "distance_travelled_min": 35.4155, "distance_travelled_max": 124.85125}, "hist_stats": {"episode_reward": [-692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -49.0895277605261, 219.54263608187424, -34.13791819942123, -570.7029739196424, -365.7686327913458, -548.095876366606, -378.1947830029239, -315.4765346868379, -235.78989103807115, -636.9677597383476, -14.47129388855019, -188.0075123389498, 252.84904071776774, -191.0868434243213, -334.24945937609203, -869.0256252706633, 357.91930792688134, -706.2846239316171, -3.306460726910646, -522.006644597566, -394.2093327167674, -553.3520295256233, -188.35629230394676, -750.2940846925408, 180.35869523571705, 229.87443080217656, 189.80790743174532, -477.4845517469688, -433.7518814211228, -693.938550752084, 33.03084893021221, -554.3803131015827, -323.9157533551002, -165.3538876239856, -1169.9075047250058, -459.0706951858064, 70.3799473871102, -570.633914140485, -460.77756995140226, 69.28966990578853, -216.0425687012854, -194.2165301744098, 617.3350042344224, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929, -48.87212301200027, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783], "episode_lengths": [153, 157, 219, 112, 216, 119, 117, 118, 121, 82, 106, 118, 113, 107, 112, 122, 123, 123, 112, 126, 123, 125, 114, 121, 121, 101, 123, 122, 129, 260, 137, 128, 89, 143, 107, 118, 110, 148, 32, 136, 120, 127, 97, 101, 120, 103, 71, 121, 155, 118, 156, 206, 82, 139, 149, 98, 140, 122, 44, 113, 137, 114, 265, 94, 135, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156], "policy_AGENT-3_reward": [-43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -42.861068504920574, 43.899378720898866, -15.730402546728273, -131.7471347390881, -70.83185982622055, -178.89110802047512, -92.92575957253881, -46.85901437305522, -49.71195558472984, -122.73230572648562, -22.518374276588382, -71.75018882051901, 60.882845286347084, -30.808678115797054, -33.978032152476665, -218.6495705430483, 83.24388456154338, -122.69521366380397, -16.325319966749806, -135.24122272252916, -117.82055455739373, -176.20983338889783, -43.139533551978786, -171.4455237628716, -150.67362981087098, -0.8524113498859909, 2.2020770678050745, -95.06260123959731, -163.94941022611053, -161.20957895880292, -37.279954625156556, -121.7649872366475, -77.61125736890139, -16.029414777035907, -136.04740790082292, -127.73826841262483, -15.321489445211672, -125.33143121586008, -123.86286147485411, 6.345348373945244, -31.63959386777298, -51.153216819152256, 155.79079414571663, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477, 1.4932620478289884, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314], "policy_AGENT-2_reward": [-303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -42.783563007598474, 43.84301041084104, -15.781465467228609, -130.46819437349032, -70.87675276677673, -178.38073063441567, -96.62798418368615, -46.8222729259098, -50.53918606652537, -209.49880867469213, -22.41278813281122, -71.71935028577666, 67.8539188188227, -30.838333043555885, -112.80756673101503, -219.54683426168634, 83.3296868080183, -210.70384412192243, 10.987144328894253, -135.21971642757256, -117.69474103635258, -116.26458699352183, -43.1729865759878, -193.2240544280157, -150.6496867073742, -0.6568215880630608, 2.3032139604815245, -95.1237099154512, -35.27036163930682, -208.54686471661554, -37.316275493156226, -167.03279201696165, -100.21171472626442, -15.975959039946044, -449.4788037794044, -123.47193924394513, -15.236451069665401, -125.30607751707818, -102.00806965189634, 19.459669821118542, -53.114488980805774, -46.52268778681753, 136.14784654743104, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224, -43.75892882928075, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763], "policy_AGENT-0_reward": [-302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.534897519603049, 65.52762051495297, -1.9747886535083201, -177.65985491520405, -112.03207950027694, -95.4818225475154, -118.29858902758383, -110.83588150166379, -67.78007167006972, -182.56626990274012, 13.996313204020556, -44.242611867897445, 39.02710915335282, -75.1933234424076, -75.21237300611205, -238.67455199242482, 74.50739681846153, -250.7564293731004, 11.5474127587693, -114.36150404878217, -79.21538539575228, -115.70758846380178, -52.21709751631647, -195.32246517159516, 266.6115005900778, 96.22263750542568, 96.78908942175022, -143.55349736438262, -199.7300825790453, -161.9801852537422, 53.27492434580155, -144.38198165523502, -91.89141988068845, -66.73939115774922, -448.8965319625391, -103.97170645757771, 27.342029521430348, -160.0129928141722, -117.44272621796819, 24.005430787956115, -65.62780830452024, -45.951918648349896, 163.97063846018455, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587, -8.77693138390639, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946], "policy_AGENT-1_reward": [-42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, 41.09000127159612, 66.27262643518134, -0.6512615319560524, -130.8277898918602, -112.02794069807172, -95.34221516419939, -70.34245021911534, -110.9593658862091, -67.75867771674618, -122.17037543442939, 16.463555316828906, -0.29536136475667263, 85.08516745924527, -54.24650882256064, -112.25148748648837, -192.1546684735044, 116.83833973885797, -122.1291367727901, -9.515697847824393, -137.1842013986815, -79.47865172726877, -145.17002067940183, -49.82667465966379, -190.30204133005813, 215.07051116388416, 135.16102623469976, 88.5135269817085, -143.74474322753773, -34.80202697666027, -162.201921822923, 54.35215470272344, -121.20055219273824, -54.20136137924673, -66.60912264925443, -135.48476108224037, -103.88878107165871, 73.5958583805569, -159.98341259337462, -117.46391260668335, 19.47922092276882, -65.66067754818633, -50.588706920090075, 161.42572508109038, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445, 2.170475153358211, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555]}, "sampler_perf": {"mean_env_wait_ms": 71.81820761423393, "mean_raw_obs_processing_ms": 2.7960567423576776, "mean_inference_ms": 4.435519092895771, "mean_action_processing_ms": 0.17707850682886245}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 10080, "timers": {"learn_time_ms": 10.91, "learn_throughput": 2933.073, "update_time_ms": 11.668}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 0.7697887420654297, "min_q": -40.43326187133789, "max_q": 85.18358612060547, "mean_td_error": -3.135389566421509, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 8.336883544921875, "min_q": -28.478065490722656, "max_q": 94.60313415527344, "mean_td_error": 6.921878814697266, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": -1.181512475013733, "min_q": -35.23028564453125, "max_q": 61.566246032714844, "mean_td_error": 3.9879372119903564, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": -7.507495880126953, "min_q": -34.521095275878906, "max_q": 21.73059844970703, "mean_td_error": 2.109969139099121, "model": {}}}, "num_steps_sampled": 10080, "num_steps_trained": 24224, "last_target_update_ts": 10080, "num_target_updates": 19}, "done": false, "episodes_total": 75, "training_iteration": 10, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-48-29", "timestamp": 1624265309, "time_this_iter_s": 29.71780562400818, "time_total_s": 356.6472809314728, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c74d200>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c74d320>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74d560>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74d680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74d7a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74d8c0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74d560>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74d680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74d7a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74d8c0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74d560>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74d680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74d7a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74d8c0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74d560>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74d680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74d7a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74d8c0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f898c079b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 356.6472809314728, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 46.109302325581396, "ram_util_percent": 87.51627906976744}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 945.655231152511, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": -212.75711644844571, "episode_len_mean": 131.0609756097561, "episodes_this_iter": 7, "policy_reward_min": {"AGENT-3": -360.74714809698355, "AGENT-2": -449.4788037794044, "AGENT-0": -448.8965319625391, "AGENT-1": -349.05580841413826}, "policy_reward_max": {"AGENT-3": 225.81289307132477, "AGENT-2": 300.1854170002415, "AGENT-0": 394.38970453780024, "AGENT-1": 398.8860293627402}, "policy_reward_mean": {"AGENT-3": -66.62993749971534, "AGENT-2": -64.55991407755054, "AGENT-0": -45.34496392274887, "AGENT-1": -36.22230094843097}, "custom_metrics": {"mean_ego_speed_mean": 41.58007317073171, "mean_ego_speed_min": 28.9185, "mean_ego_speed_max": 50.7675, "distance_travelled_mean": 91.91683536585366, "distance_travelled_min": 20.213500000000003, "distance_travelled_max": 124.85125}, "hist_stats": {"episode_reward": [-258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -49.0895277605261, 219.54263608187424, -34.13791819942123, -570.7029739196424, -365.7686327913458, -548.095876366606, -378.1947830029239, -315.4765346868379, -235.78989103807115, -636.9677597383476, -14.47129388855019, -188.0075123389498, 252.84904071776774, -191.0868434243213, -334.24945937609203, -869.0256252706633, 357.91930792688134, -706.2846239316171, -3.306460726910646, -522.006644597566, -394.2093327167674, -553.3520295256233, -188.35629230394676, -750.2940846925408, 180.35869523571705, 229.87443080217656, 189.80790743174532, -477.4845517469688, -433.7518814211228, -693.938550752084, 33.03084893021221, -554.3803131015827, -323.9157533551002, -165.3538876239856, -1169.9075047250058, -459.0706951858064, 70.3799473871102, -570.633914140485, -460.77756995140226, 69.28966990578853, -216.0425687012854, -194.2165301744098, 617.3350042344224, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929, -48.87212301200027, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954], "episode_lengths": [90, 22, 111, 86, 192, 208, 218, 119, 117, 118, 121, 82, 106, 118, 113, 107, 112, 122, 123, 123, 112, 126, 123, 125, 114, 121, 121, 101, 123, 122, 129, 260, 137, 128, 89, 143, 107, 118, 110, 148, 32, 136, 120, 127, 97, 101, 120, 103, 71, 121, 155, 118, 156, 206, 82, 139, 149, 98, 140, 122, 44, 113, 137, 114, 265, 94, 135, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216], "policy_AGENT-3_reward": [-125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -42.861068504920574, 43.899378720898866, -15.730402546728273, -131.7471347390881, -70.83185982622055, -178.89110802047512, -92.92575957253881, -46.85901437305522, -49.71195558472984, -122.73230572648562, -22.518374276588382, -71.75018882051901, 60.882845286347084, -30.808678115797054, -33.978032152476665, -218.6495705430483, 83.24388456154338, -122.69521366380397, -16.325319966749806, -135.24122272252916, -117.82055455739373, -176.20983338889783, -43.139533551978786, -171.4455237628716, -150.67362981087098, -0.8524113498859909, 2.2020770678050745, -95.06260123959731, -163.94941022611053, -161.20957895880292, -37.279954625156556, -121.7649872366475, -77.61125736890139, -16.029414777035907, -136.04740790082292, -127.73826841262483, -15.321489445211672, -125.33143121586008, -123.86286147485411, 6.345348373945244, -31.63959386777298, -51.153216819152256, 155.79079414571663, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477, 1.4932620478289884, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038], "policy_AGENT-2_reward": [-4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -42.783563007598474, 43.84301041084104, -15.781465467228609, -130.46819437349032, -70.87675276677673, -178.38073063441567, -96.62798418368615, -46.8222729259098, -50.53918606652537, -209.49880867469213, -22.41278813281122, -71.71935028577666, 67.8539188188227, -30.838333043555885, -112.80756673101503, -219.54683426168634, 83.3296868080183, -210.70384412192243, 10.987144328894253, -135.21971642757256, -117.69474103635258, -116.26458699352183, -43.1729865759878, -193.2240544280157, -150.6496867073742, -0.6568215880630608, 2.3032139604815245, -95.1237099154512, -35.27036163930682, -208.54686471661554, -37.316275493156226, -167.03279201696165, -100.21171472626442, -15.975959039946044, -449.4788037794044, -123.47193924394513, -15.236451069665401, -125.30607751707818, -102.00806965189634, 19.459669821118542, -53.114488980805774, -46.52268778681753, 136.14784654743104, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224, -43.75892882928075, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305], "policy_AGENT-0_reward": [-4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -4.534897519603049, 65.52762051495297, -1.9747886535083201, -177.65985491520405, -112.03207950027694, -95.4818225475154, -118.29858902758383, -110.83588150166379, -67.78007167006972, -182.56626990274012, 13.996313204020556, -44.242611867897445, 39.02710915335282, -75.1933234424076, -75.21237300611205, -238.67455199242482, 74.50739681846153, -250.7564293731004, 11.5474127587693, -114.36150404878217, -79.21538539575228, -115.70758846380178, -52.21709751631647, -195.32246517159516, 266.6115005900778, 96.22263750542568, 96.78908942175022, -143.55349736438262, -199.7300825790453, -161.9801852537422, 53.27492434580155, -144.38198165523502, -91.89141988068845, -66.73939115774922, -448.8965319625391, -103.97170645757771, 27.342029521430348, -160.0129928141722, -117.44272621796819, 24.005430787956115, -65.62780830452024, -45.951918648349896, 163.97063846018455, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587, -8.77693138390639, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538], "policy_AGENT-1_reward": [-124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, 41.09000127159612, 66.27262643518134, -0.6512615319560524, -130.8277898918602, -112.02794069807172, -95.34221516419939, -70.34245021911534, -110.9593658862091, -67.75867771674618, -122.17037543442939, 16.463555316828906, -0.29536136475667263, 85.08516745924527, -54.24650882256064, -112.25148748648837, -192.1546684735044, 116.83833973885797, -122.1291367727901, -9.515697847824393, -137.1842013986815, -79.47865172726877, -145.17002067940183, -49.82667465966379, -190.30204133005813, 215.07051116388416, 135.16102623469976, 88.5135269817085, -143.74474322753773, -34.80202697666027, -162.201921822923, 54.35215470272344, -121.20055219273824, -54.20136137924673, -66.60912264925443, -135.48476108224037, -103.88878107165871, 73.5958583805569, -159.98341259337462, -117.46391260668335, 19.47922092276882, -65.66067754818633, -50.588706920090075, 161.42572508109038, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445, 2.170475153358211, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744]}, "sampler_perf": {"mean_env_wait_ms": 70.92331992926529, "mean_raw_obs_processing_ms": 2.773518239060821, "mean_inference_ms": 4.332561682904746, "mean_action_processing_ms": 0.17601702526476778}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 11088, "timers": {"learn_time_ms": 8.247, "learn_throughput": 3880.392, "update_time_ms": 11.675}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": -7.039424896240234, "min_q": -51.20185852050781, "max_q": 40.836727142333984, "mean_td_error": -0.6128581166267395, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 6.2548604011535645, "min_q": -26.434019088745117, "max_q": 104.0643081665039, "mean_td_error": 4.041869163513184, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": -1.0581562519073486, "min_q": -43.099483489990234, "max_q": 78.70404052734375, "mean_td_error": -0.21416699886322021, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": -3.9558887481689453, "min_q": -40.03746032714844, "max_q": 27.699588775634766, "mean_td_error": 4.626841068267822, "model": {}}}, "num_steps_sampled": 11088, "num_steps_trained": 26912, "last_target_update_ts": 11088, "num_target_updates": 21}, "done": false, "episodes_total": 82, "training_iteration": 11, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-48-58", "timestamp": 1624265338, "time_this_iter_s": 28.392385959625244, "time_total_s": 385.039666891098, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f898c079170>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f898e396560>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c109e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7f899cf71e60>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c34f950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c109e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7f899cf71e60>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c34f950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c109e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7f899cf71e60>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c34f950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c109e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7f899cf71e60>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c34f950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c74def0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 385.039666891098, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 49.91219512195122, "ram_util_percent": 87.77804878048781}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 945.655231152511, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": -219.19335361318636, "episode_len_mean": 128.02173913043478, "episodes_this_iter": 10, "policy_reward_min": {"AGENT-3": -363.889908520441, "AGENT-2": -449.4788037794044, "AGENT-0": -448.8965319625391, "AGENT-1": -349.05580841413826}, "policy_reward_max": {"AGENT-3": 225.81289307132477, "AGENT-2": 300.1854170002415, "AGENT-0": 394.38970453780024, "AGENT-1": 398.8860293627402}, "policy_reward_mean": {"AGENT-3": -69.68161545279872, "AGENT-2": -62.07314101133693, "AGENT-0": -47.562284823631444, "AGENT-1": -39.8763123254193}, "custom_metrics": {"mean_ego_speed_mean": 42.014883152173915, "mean_ego_speed_min": 28.9185, "mean_ego_speed_max": 50.7675, "distance_travelled_mean": 88.31516304347826, "distance_travelled_min": 20.213500000000003, "distance_travelled_max": 124.85125}, "hist_stats": {"episode_reward": [-821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, -49.0895277605261, 219.54263608187424, -34.13791819942123, -570.7029739196424, -365.7686327913458, -548.095876366606, -378.1947830029239, -315.4765346868379, -235.78989103807115, -636.9677597383476, -14.47129388855019, -188.0075123389498, 252.84904071776774, -191.0868434243213, -334.24945937609203, -869.0256252706633, 357.91930792688134, -706.2846239316171, -3.306460726910646, -522.006644597566, -394.2093327167674, -553.3520295256233, -188.35629230394676, -750.2940846925408, 180.35869523571705, 229.87443080217656, 189.80790743174532, -477.4845517469688, -433.7518814211228, -693.938550752084, 33.03084893021221, -554.3803131015827, -323.9157533551002, -165.3538876239856, -1169.9075047250058, -459.0706951858064, 70.3799473871102, -570.633914140485, -460.77756995140226, 69.28966990578853, -216.0425687012854, -194.2165301744098, 617.3350042344224, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929, -48.87212301200027, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816], "episode_lengths": [150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 119, 117, 118, 121, 82, 106, 118, 113, 107, 112, 122, 123, 123, 112, 126, 123, 125, 114, 121, 121, 101, 123, 122, 129, 260, 137, 128, 89, 143, 107, 118, 110, 148, 32, 136, 120, 127, 97, 101, 120, 103, 71, 121, 155, 118, 156, 206, 82, 139, 149, 98, 140, 122, 44, 113, 137, 114, 265, 94, 135, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218], "policy_AGENT-3_reward": [-363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, -42.861068504920574, 43.899378720898866, -15.730402546728273, -131.7471347390881, -70.83185982622055, -178.89110802047512, -92.92575957253881, -46.85901437305522, -49.71195558472984, -122.73230572648562, -22.518374276588382, -71.75018882051901, 60.882845286347084, -30.808678115797054, -33.978032152476665, -218.6495705430483, 83.24388456154338, -122.69521366380397, -16.325319966749806, -135.24122272252916, -117.82055455739373, -176.20983338889783, -43.139533551978786, -171.4455237628716, -150.67362981087098, -0.8524113498859909, 2.2020770678050745, -95.06260123959731, -163.94941022611053, -161.20957895880292, -37.279954625156556, -121.7649872366475, -77.61125736890139, -16.029414777035907, -136.04740790082292, -127.73826841262483, -15.321489445211672, -125.33143121586008, -123.86286147485411, 6.345348373945244, -31.63959386777298, -51.153216819152256, 155.79079414571663, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477, 1.4932620478289884, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194], "policy_AGENT-2_reward": [-30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, -42.783563007598474, 43.84301041084104, -15.781465467228609, -130.46819437349032, -70.87675276677673, -178.38073063441567, -96.62798418368615, -46.8222729259098, -50.53918606652537, -209.49880867469213, -22.41278813281122, -71.71935028577666, 67.8539188188227, -30.838333043555885, -112.80756673101503, -219.54683426168634, 83.3296868080183, -210.70384412192243, 10.987144328894253, -135.21971642757256, -117.69474103635258, -116.26458699352183, -43.1729865759878, -193.2240544280157, -150.6496867073742, -0.6568215880630608, 2.3032139604815245, -95.1237099154512, -35.27036163930682, -208.54686471661554, -37.316275493156226, -167.03279201696165, -100.21171472626442, -15.975959039946044, -449.4788037794044, -123.47193924394513, -15.236451069665401, -125.30607751707818, -102.00806965189634, 19.459669821118542, -53.114488980805774, -46.52268778681753, 136.14784654743104, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224, -43.75892882928075, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415], "policy_AGENT-0_reward": [-397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, -4.534897519603049, 65.52762051495297, -1.9747886535083201, -177.65985491520405, -112.03207950027694, -95.4818225475154, -118.29858902758383, -110.83588150166379, -67.78007167006972, -182.56626990274012, 13.996313204020556, -44.242611867897445, 39.02710915335282, -75.1933234424076, -75.21237300611205, -238.67455199242482, 74.50739681846153, -250.7564293731004, 11.5474127587693, -114.36150404878217, -79.21538539575228, -115.70758846380178, -52.21709751631647, -195.32246517159516, 266.6115005900778, 96.22263750542568, 96.78908942175022, -143.55349736438262, -199.7300825790453, -161.9801852537422, 53.27492434580155, -144.38198165523502, -91.89141988068845, -66.73939115774922, -448.8965319625391, -103.97170645757771, 27.342029521430348, -160.0129928141722, -117.44272621796819, 24.005430787956115, -65.62780830452024, -45.951918648349896, 163.97063846018455, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587, -8.77693138390639, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906], "policy_AGENT-1_reward": [-29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 41.09000127159612, 66.27262643518134, -0.6512615319560524, -130.8277898918602, -112.02794069807172, -95.34221516419939, -70.34245021911534, -110.9593658862091, -67.75867771674618, -122.17037543442939, 16.463555316828906, -0.29536136475667263, 85.08516745924527, -54.24650882256064, -112.25148748648837, -192.1546684735044, 116.83833973885797, -122.1291367727901, -9.515697847824393, -137.1842013986815, -79.47865172726877, -145.17002067940183, -49.82667465966379, -190.30204133005813, 215.07051116388416, 135.16102623469976, 88.5135269817085, -143.74474322753773, -34.80202697666027, -162.201921822923, 54.35215470272344, -121.20055219273824, -54.20136137924673, -66.60912264925443, -135.48476108224037, -103.88878107165871, 73.5958583805569, -159.98341259337462, -117.46391260668335, 19.47922092276882, -65.66067754818633, -50.588706920090075, 161.42572508109038, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445, 2.170475153358211, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037]}, "sampler_perf": {"mean_env_wait_ms": 69.66211853399287, "mean_raw_obs_processing_ms": 2.7457196742755863, "mean_inference_ms": 4.197919410771172, "mean_action_processing_ms": 0.17460333110019582}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 12096, "timers": {"learn_time_ms": 11.119, "learn_throughput": 2877.837, "update_time_ms": 11.33}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 18.6395263671875, "min_q": -38.67375946044922, "max_q": 113.50439453125, "mean_td_error": 14.024523735046387, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 27.647151947021484, "min_q": -25.13404655456543, "max_q": 113.43679809570312, "mean_td_error": 11.279800415039062, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 2.2298178672790527, "min_q": -59.091739654541016, "max_q": 72.07504272460938, "mean_td_error": 0.09441912174224854, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": -6.74124813079834, "min_q": -43.14755630493164, "max_q": 41.167240142822266, "mean_td_error": 5.9710001945495605, "model": {}}}, "num_steps_sampled": 12096, "num_steps_trained": 29600, "last_target_update_ts": 12096, "num_target_updates": 23}, "done": false, "episodes_total": 92, "training_iteration": 12, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-49-28", "timestamp": 1624265368, "time_this_iter_s": 29.642637729644775, "time_total_s": 414.6823046207428, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c74d830>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c74d710>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74d4d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74d3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74d200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74ddd0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74d4d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74d3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74d200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74ddd0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74d4d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74d3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74d200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74ddd0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74d4d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74d3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74d200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74ddd0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c7c1cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 414.6823046207428, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 46.90238095238095, "ram_util_percent": 88.04999999999998}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 945.655231152511, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": -194.8156188108792, "episode_len_mean": 132.64285714285714, "episodes_this_iter": 6, "policy_reward_min": {"AGENT-2": -449.4788037794044, "AGENT-1": -349.05580841413826, "AGENT-0": -448.8965319625391, "AGENT-3": -363.889908520441}, "policy_reward_max": {"AGENT-2": 300.1854170002415, "AGENT-1": 398.8860293627402, "AGENT-0": 394.38970453780024, "AGENT-3": 280.32567811960837}, "policy_reward_mean": {"AGENT-2": -50.92399908961803, "AGENT-1": -40.06212264007982, "AGENT-0": -36.78947533101733, "AGENT-3": -67.04002175016403}, "custom_metrics": {"mean_ego_speed_mean": 41.82673469387755, "mean_ego_speed_min": 15.644, "mean_ego_speed_max": 50.7675, "distance_travelled_mean": 88.0941275510204, "distance_travelled_min": 20.213500000000003, "distance_travelled_max": 124.85125}, "hist_stats": {"episode_reward": [707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -49.0895277605261, 219.54263608187424, -34.13791819942123, -570.7029739196424, -365.7686327913458, -548.095876366606, -378.1947830029239, -315.4765346868379, -235.78989103807115, -636.9677597383476, -14.47129388855019, -188.0075123389498, 252.84904071776774, -191.0868434243213, -334.24945937609203, -869.0256252706633, 357.91930792688134, -706.2846239316171, -3.306460726910646, -522.006644597566, -394.2093327167674, -553.3520295256233, -188.35629230394676, -750.2940846925408, 180.35869523571705, 229.87443080217656, 189.80790743174532, -477.4845517469688, -433.7518814211228, -693.938550752084, 33.03084893021221, -554.3803131015827, -323.9157533551002, -165.3538876239856, -1169.9075047250058, -459.0706951858064, 70.3799473871102, -570.633914140485, -460.77756995140226, 69.28966990578853, -216.0425687012854, -194.2165301744098, 617.3350042344224, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929, -48.87212301200027, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643], "episode_lengths": [396, 204, 195, 108, 215, 103, 119, 117, 118, 121, 82, 106, 118, 113, 107, 112, 122, 123, 123, 112, 126, 123, 125, 114, 121, 121, 101, 123, 122, 129, 260, 137, 128, 89, 143, 107, 118, 110, 148, 32, 136, 120, 127, 97, 101, 120, 103, 71, 121, 155, 118, 156, 206, 82, 139, 149, 98, 140, 122, 44, 113, 137, 114, 265, 94, 135, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77], "policy_AGENT-2_reward": [116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -42.783563007598474, 43.84301041084104, -15.781465467228609, -130.46819437349032, -70.87675276677673, -178.38073063441567, -96.62798418368615, -46.8222729259098, -50.53918606652537, -209.49880867469213, -22.41278813281122, -71.71935028577666, 67.8539188188227, -30.838333043555885, -112.80756673101503, -219.54683426168634, 83.3296868080183, -210.70384412192243, 10.987144328894253, -135.21971642757256, -117.69474103635258, -116.26458699352183, -43.1729865759878, -193.2240544280157, -150.6496867073742, -0.6568215880630608, 2.3032139604815245, -95.1237099154512, -35.27036163930682, -208.54686471661554, -37.316275493156226, -167.03279201696165, -100.21171472626442, -15.975959039946044, -449.4788037794044, -123.47193924394513, -15.236451069665401, -125.30607751707818, -102.00806965189634, 19.459669821118542, -53.114488980805774, -46.52268778681753, 136.14784654743104, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224, -43.75892882928075, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144], "policy_AGENT-1_reward": [136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, 41.09000127159612, 66.27262643518134, -0.6512615319560524, -130.8277898918602, -112.02794069807172, -95.34221516419939, -70.34245021911534, -110.9593658862091, -67.75867771674618, -122.17037543442939, 16.463555316828906, -0.29536136475667263, 85.08516745924527, -54.24650882256064, -112.25148748648837, -192.1546684735044, 116.83833973885797, -122.1291367727901, -9.515697847824393, -137.1842013986815, -79.47865172726877, -145.17002067940183, -49.82667465966379, -190.30204133005813, 215.07051116388416, 135.16102623469976, 88.5135269817085, -143.74474322753773, -34.80202697666027, -162.201921822923, 54.35215470272344, -121.20055219273824, -54.20136137924673, -66.60912264925443, -135.48476108224037, -103.88878107165871, 73.5958583805569, -159.98341259337462, -117.46391260668335, 19.47922092276882, -65.66067754818633, -50.588706920090075, 161.42572508109038, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445, 2.170475153358211, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617], "policy_AGENT-0_reward": [173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -4.534897519603049, 65.52762051495297, -1.9747886535083201, -177.65985491520405, -112.03207950027694, -95.4818225475154, -118.29858902758383, -110.83588150166379, -67.78007167006972, -182.56626990274012, 13.996313204020556, -44.242611867897445, 39.02710915335282, -75.1933234424076, -75.21237300611205, -238.67455199242482, 74.50739681846153, -250.7564293731004, 11.5474127587693, -114.36150404878217, -79.21538539575228, -115.70758846380178, -52.21709751631647, -195.32246517159516, 266.6115005900778, 96.22263750542568, 96.78908942175022, -143.55349736438262, -199.7300825790453, -161.9801852537422, 53.27492434580155, -144.38198165523502, -91.89141988068845, -66.73939115774922, -448.8965319625391, -103.97170645757771, 27.342029521430348, -160.0129928141722, -117.44272621796819, 24.005430787956115, -65.62780830452024, -45.951918648349896, 163.97063846018455, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587, -8.77693138390639, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155], "policy_AGENT-3_reward": [280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -42.861068504920574, 43.899378720898866, -15.730402546728273, -131.7471347390881, -70.83185982622055, -178.89110802047512, -92.92575957253881, -46.85901437305522, -49.71195558472984, -122.73230572648562, -22.518374276588382, -71.75018882051901, 60.882845286347084, -30.808678115797054, -33.978032152476665, -218.6495705430483, 83.24388456154338, -122.69521366380397, -16.325319966749806, -135.24122272252916, -117.82055455739373, -176.20983338889783, -43.139533551978786, -171.4455237628716, -150.67362981087098, -0.8524113498859909, 2.2020770678050745, -95.06260123959731, -163.94941022611053, -161.20957895880292, -37.279954625156556, -121.7649872366475, -77.61125736890139, -16.029414777035907, -136.04740790082292, -127.73826841262483, -15.321489445211672, -125.33143121586008, -123.86286147485411, 6.345348373945244, -31.63959386777298, -51.153216819152256, 155.79079414571663, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477, 1.4932620478289884, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921]}, "sampler_perf": {"mean_env_wait_ms": 68.92897818597704, "mean_raw_obs_processing_ms": 2.7289379472707287, "mean_inference_ms": 4.124614133563507, "mean_action_processing_ms": 0.17375808820537875}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 13104, "timers": {"learn_time_ms": 11.201, "learn_throughput": 2856.772, "update_time_ms": 11.143}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": -0.9219350814819336, "min_q": -62.40238952636719, "max_q": 124.03424835205078, "mean_td_error": 1.9769479036331177, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": -0.6771848201751709, "min_q": -41.85670471191406, "max_q": 73.62737274169922, "mean_td_error": 2.494175434112549, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 5.184607028961182, "min_q": -34.90663146972656, "max_q": 104.21726989746094, "mean_td_error": 4.878859519958496, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": -4.625134468078613, "min_q": -51.627586364746094, "max_q": 38.1519889831543, "mean_td_error": 3.2636666297912598, "model": {}}}, "num_steps_sampled": 13104, "num_steps_trained": 32288, "last_target_update_ts": 13104, "num_target_updates": 25}, "done": false, "episodes_total": 98, "training_iteration": 13, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-49-52", "timestamp": 1624265392, "time_this_iter_s": 23.84711003303528, "time_total_s": 438.5294146537781, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f899cf8ab00>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f899cf8acb0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c0bddd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079170>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c34f710>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c0bddd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079170>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c34f710>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c0bddd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079170>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c34f710>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c0bddd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c0bd9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079170>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c34f710>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f898c079a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 438.5294146537781, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 49.741176470588236, "ram_util_percent": 88.43823529411765}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 945.655231152511, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": -190.06259529063212, "episode_len_mean": 132.55, "episodes_this_iter": 3, "policy_reward_min": {"AGENT-3": -363.889908520441, "AGENT-0": -448.8965319625391, "AGENT-2": -449.4788037794044, "AGENT-1": -349.05580841413826}, "policy_reward_max": {"AGENT-3": 280.32567811960837, "AGENT-0": 394.38970453780024, "AGENT-2": 300.1854170002415, "AGENT-1": 398.8860293627402}, "policy_reward_mean": {"AGENT-3": -67.72227002955775, "AGENT-0": -33.97549231050269, "AGENT-2": -46.25849609783853, "AGENT-1": -42.106336852733165}, "custom_metrics": {"mean_ego_speed_mean": 41.78165, "mean_ego_speed_min": 15.644, "mean_ego_speed_max": 50.7675, "distance_travelled_mean": 87.33080999999999, "distance_travelled_min": 20.213500000000003, "distance_travelled_max": 124.85125}, "hist_stats": {"episode_reward": [-584.8127017597103, 292.2406171178581, 329.15367128427056, 219.54263608187424, -34.13791819942123, -570.7029739196424, -365.7686327913458, -548.095876366606, -378.1947830029239, -315.4765346868379, -235.78989103807115, -636.9677597383476, -14.47129388855019, -188.0075123389498, 252.84904071776774, -191.0868434243213, -334.24945937609203, -869.0256252706633, 357.91930792688134, -706.2846239316171, -3.306460726910646, -522.006644597566, -394.2093327167674, -553.3520295256233, -188.35629230394676, -750.2940846925408, 180.35869523571705, 229.87443080217656, 189.80790743174532, -477.4845517469688, -433.7518814211228, -693.938550752084, 33.03084893021221, -554.3803131015827, -323.9157533551002, -165.3538876239856, -1169.9075047250058, -459.0706951858064, 70.3799473871102, -570.633914140485, -460.77756995140226, 69.28966990578853, -216.0425687012854, -194.2165301744098, 617.3350042344224, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929, -48.87212301200027, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204], "episode_lengths": [138, 115, 122, 117, 118, 121, 82, 106, 118, 113, 107, 112, 122, 123, 123, 112, 126, 123, 125, 114, 121, 121, 101, 123, 122, 129, 260, 137, 128, 89, 143, 107, 118, 110, 148, 32, 136, 120, 127, 97, 101, 120, 103, 71, 121, 155, 118, 156, 206, 82, 139, 149, 98, 140, 122, 44, 113, 137, 114, 265, 94, 135, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103], "policy_AGENT-3_reward": [-82.34010734400835, -82.76617269867458, -80.05965990193836, 43.899378720898866, -15.730402546728273, -131.7471347390881, -70.83185982622055, -178.89110802047512, -92.92575957253881, -46.85901437305522, -49.71195558472984, -122.73230572648562, -22.518374276588382, -71.75018882051901, 60.882845286347084, -30.808678115797054, -33.978032152476665, -218.6495705430483, 83.24388456154338, -122.69521366380397, -16.325319966749806, -135.24122272252916, -117.82055455739373, -176.20983338889783, -43.139533551978786, -171.4455237628716, -150.67362981087098, -0.8524113498859909, 2.2020770678050745, -95.06260123959731, -163.94941022611053, -161.20957895880292, -37.279954625156556, -121.7649872366475, -77.61125736890139, -16.029414777035907, -136.04740790082292, -127.73826841262483, -15.321489445211672, -125.33143121586008, -123.86286147485411, 6.345348373945244, -31.63959386777298, -51.153216819152256, 155.79079414571663, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477, 1.4932620478289884, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226], "policy_AGENT-0_reward": [-192.78768752548626, 191.24352515228435, 204.82861624302814, 65.52762051495297, -1.9747886535083201, -177.65985491520405, -112.03207950027694, -95.4818225475154, -118.29858902758383, -110.83588150166379, -67.78007167006972, -182.56626990274012, 13.996313204020556, -44.242611867897445, 39.02710915335282, -75.1933234424076, -75.21237300611205, -238.67455199242482, 74.50739681846153, -250.7564293731004, 11.5474127587693, -114.36150404878217, -79.21538539575228, -115.70758846380178, -52.21709751631647, -195.32246517159516, 266.6115005900778, 96.22263750542568, 96.78908942175022, -143.55349736438262, -199.7300825790453, -161.9801852537422, 53.27492434580155, -144.38198165523502, -91.89141988068845, -66.73939115774922, -448.8965319625391, -103.97170645757771, 27.342029521430348, -160.0129928141722, -117.44272621796819, 24.005430787956115, -65.62780830452024, -45.951918648349896, 163.97063846018455, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587, -8.77693138390639, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624], "policy_AGENT-2_reward": [-227.90569718991588, 265.96994666981743, 283.8544885112112, 43.84301041084104, -15.781465467228609, -130.46819437349032, -70.87675276677673, -178.38073063441567, -96.62798418368615, -46.8222729259098, -50.53918606652537, -209.49880867469213, -22.41278813281122, -71.71935028577666, 67.8539188188227, -30.838333043555885, -112.80756673101503, -219.54683426168634, 83.3296868080183, -210.70384412192243, 10.987144328894253, -135.21971642757256, -117.69474103635258, -116.26458699352183, -43.1729865759878, -193.2240544280157, -150.6496867073742, -0.6568215880630608, 2.3032139604815245, -95.1237099154512, -35.27036163930682, -208.54686471661554, -37.316275493156226, -167.03279201696165, -100.21171472626442, -15.975959039946044, -449.4788037794044, -123.47193924394513, -15.236451069665401, -125.30607751707818, -102.00806965189634, 19.459669821118542, -53.114488980805774, -46.52268778681753, 136.14784654743104, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224, -43.75892882928075, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448], "policy_AGENT-1_reward": [-81.77920970029976, -82.20668200556881, -79.46977356803025, 66.27262643518134, -0.6512615319560524, -130.8277898918602, -112.02794069807172, -95.34221516419939, -70.34245021911534, -110.9593658862091, -67.75867771674618, -122.17037543442939, 16.463555316828906, -0.29536136475667263, 85.08516745924527, -54.24650882256064, -112.25148748648837, -192.1546684735044, 116.83833973885797, -122.1291367727901, -9.515697847824393, -137.1842013986815, -79.47865172726877, -145.17002067940183, -49.82667465966379, -190.30204133005813, 215.07051116388416, 135.16102623469976, 88.5135269817085, -143.74474322753773, -34.80202697666027, -162.201921822923, 54.35215470272344, -121.20055219273824, -54.20136137924673, -66.60912264925443, -135.48476108224037, -103.88878107165871, 73.5958583805569, -159.98341259337462, -117.46391260668335, 19.47922092276882, -65.66067754818633, -50.588706920090075, 161.42572508109038, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445, 2.170475153358211, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126]}, "sampler_perf": {"mean_env_wait_ms": 68.44617050041585, "mean_raw_obs_processing_ms": 2.719731991730791, "mean_inference_ms": 4.06143295529279, "mean_action_processing_ms": 0.173366102512611}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 14112, "timers": {"learn_time_ms": 11.292, "learn_throughput": 2833.941, "update_time_ms": 11.121}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": -0.8765363693237305, "min_q": -67.68009948730469, "max_q": 110.25431823730469, "mean_td_error": -0.21706461906433105, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 13.084815979003906, "min_q": -36.72841262817383, "max_q": 120.07672119140625, "mean_td_error": 6.008601188659668, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 5.192303657531738, "min_q": -63.220916748046875, "max_q": 114.59895324707031, "mean_td_error": 4.898503303527832, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": -3.388176679611206, "min_q": -49.220069885253906, "max_q": 67.67684173583984, "mean_td_error": 2.614112615585327, "model": {}}}, "num_steps_sampled": 14112, "num_steps_trained": 34976, "last_target_update_ts": 14112, "num_target_updates": 27}, "done": false, "episodes_total": 101, "training_iteration": 14, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-50-15", "timestamp": 1624265415, "time_this_iter_s": 22.802074909210205, "time_total_s": 461.3314895629883, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c74d950>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c74dcb0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7590e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c759200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c759320>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c759440>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7590e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c759200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c759320>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c759440>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7590e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c759200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c759320>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c759440>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7590e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c759200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c759320>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c759440>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f898e396560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 461.3314895629883, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 51.509090909090915, "ram_util_percent": 88.57272727272726}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 988.0485882287246, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": -141.74552695954245, "episode_len_mean": 138.76, "episodes_this_iter": 8, "policy_reward_min": {"AGENT-3": -363.889908520441, "AGENT-2": -449.4788037794044, "AGENT-0": -448.8965319625391, "AGENT-1": -349.05580841413826}, "policy_reward_max": {"AGENT-3": 280.32567811960837, "AGENT-2": 300.1854170002415, "AGENT-0": 413.52694646805065, "AGENT-1": 438.14037134981965}, "policy_reward_mean": {"AGENT-3": -63.6676994447143, "AGENT-2": -37.49719488735584, "AGENT-0": -14.134503393928957, "AGENT-1": -26.446129233543335}, "custom_metrics": {"mean_ego_speed_mean": 41.800435, "mean_ego_speed_min": 15.644, "mean_ego_speed_max": 50.7675, "distance_travelled_mean": 86.1679525, "distance_travelled_min": 20.213500000000003, "distance_travelled_max": 124.85125}, "hist_stats": {"episode_reward": [988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -636.9677597383476, -14.47129388855019, -188.0075123389498, 252.84904071776774, -191.0868434243213, -334.24945937609203, -869.0256252706633, 357.91930792688134, -706.2846239316171, -3.306460726910646, -522.006644597566, -394.2093327167674, -553.3520295256233, -188.35629230394676, -750.2940846925408, 180.35869523571705, 229.87443080217656, 189.80790743174532, -477.4845517469688, -433.7518814211228, -693.938550752084, 33.03084893021221, -554.3803131015827, -323.9157533551002, -165.3538876239856, -1169.9075047250058, -459.0706951858064, 70.3799473871102, -570.633914140485, -460.77756995140226, 69.28966990578853, -216.0425687012854, -194.2165301744098, 617.3350042344224, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929, -48.87212301200027, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056], "episode_lengths": [284, 177, 85, 24, 266, 124, 267, 276, 112, 122, 123, 123, 112, 126, 123, 125, 114, 121, 121, 101, 123, 122, 129, 260, 137, 128, 89, 143, 107, 118, 110, 148, 32, 136, 120, 127, 97, 101, 120, 103, 71, 121, 155, 118, 156, 206, 82, 139, 149, 98, 140, 122, 44, 113, 137, 114, 265, 94, 135, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122], "policy_AGENT-3_reward": [101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -122.73230572648562, -22.518374276588382, -71.75018882051901, 60.882845286347084, -30.808678115797054, -33.978032152476665, -218.6495705430483, 83.24388456154338, -122.69521366380397, -16.325319966749806, -135.24122272252916, -117.82055455739373, -176.20983338889783, -43.139533551978786, -171.4455237628716, -150.67362981087098, -0.8524113498859909, 2.2020770678050745, -95.06260123959731, -163.94941022611053, -161.20957895880292, -37.279954625156556, -121.7649872366475, -77.61125736890139, -16.029414777035907, -136.04740790082292, -127.73826841262483, -15.321489445211672, -125.33143121586008, -123.86286147485411, 6.345348373945244, -31.63959386777298, -51.153216819152256, 155.79079414571663, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477, 1.4932620478289884, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836], "policy_AGENT-2_reward": [101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -209.49880867469213, -22.41278813281122, -71.71935028577666, 67.8539188188227, -30.838333043555885, -112.80756673101503, -219.54683426168634, 83.3296868080183, -210.70384412192243, 10.987144328894253, -135.21971642757256, -117.69474103635258, -116.26458699352183, -43.1729865759878, -193.2240544280157, -150.6496867073742, -0.6568215880630608, 2.3032139604815245, -95.1237099154512, -35.27036163930682, -208.54686471661554, -37.316275493156226, -167.03279201696165, -100.21171472626442, -15.975959039946044, -449.4788037794044, -123.47193924394513, -15.236451069665401, -125.30607751707818, -102.00806965189634, 19.459669821118542, -53.114488980805774, -46.52268778681753, 136.14784654743104, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224, -43.75892882928075, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112], "policy_AGENT-0_reward": [413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -182.56626990274012, 13.996313204020556, -44.242611867897445, 39.02710915335282, -75.1933234424076, -75.21237300611205, -238.67455199242482, 74.50739681846153, -250.7564293731004, 11.5474127587693, -114.36150404878217, -79.21538539575228, -115.70758846380178, -52.21709751631647, -195.32246517159516, 266.6115005900778, 96.22263750542568, 96.78908942175022, -143.55349736438262, -199.7300825790453, -161.9801852537422, 53.27492434580155, -144.38198165523502, -91.89141988068845, -66.73939115774922, -448.8965319625391, -103.97170645757771, 27.342029521430348, -160.0129928141722, -117.44272621796819, 24.005430787956115, -65.62780830452024, -45.951918648349896, 163.97063846018455, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587, -8.77693138390639, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814], "policy_AGENT-1_reward": [371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -122.17037543442939, 16.463555316828906, -0.29536136475667263, 85.08516745924527, -54.24650882256064, -112.25148748648837, -192.1546684735044, 116.83833973885797, -122.1291367727901, -9.515697847824393, -137.1842013986815, -79.47865172726877, -145.17002067940183, -49.82667465966379, -190.30204133005813, 215.07051116388416, 135.16102623469976, 88.5135269817085, -143.74474322753773, -34.80202697666027, -162.201921822923, 54.35215470272344, -121.20055219273824, -54.20136137924673, -66.60912264925443, -135.48476108224037, -103.88878107165871, 73.5958583805569, -159.98341259337462, -117.46391260668335, 19.47922092276882, -65.66067754818633, -50.588706920090075, 161.42572508109038, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445, 2.170475153358211, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025]}, "sampler_perf": {"mean_env_wait_ms": 66.21237515306778, "mean_raw_obs_processing_ms": 2.6763137344680485, "mean_inference_ms": 3.712017124933989, "mean_action_processing_ms": 0.17113843140983295}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 15120, "timers": {"learn_time_ms": 10.936, "learn_throughput": 2926.212, "update_time_ms": 10.547}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 16.593852996826172, "min_q": -49.153263092041016, "max_q": 151.11526489257812, "mean_td_error": -0.4033270478248596, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 15.61083698272705, "min_q": -30.765090942382812, "max_q": 144.2107696533203, "mean_td_error": 1.9230921268463135, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": -2.5400161743164062, "min_q": -73.4030990600586, "max_q": 126.50886535644531, "mean_td_error": 7.504968643188477, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": -10.885534286499023, "min_q": -63.299293518066406, "max_q": 62.19431686401367, "mean_td_error": 2.2659859657287598, "model": {}}}, "num_steps_sampled": 15120, "num_steps_trained": 37664, "last_target_update_ts": 15120, "num_target_updates": 29}, "done": false, "episodes_total": 109, "training_iteration": 15, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-50-45", "timestamp": 1624265445, "time_this_iter_s": 29.85670518875122, "time_total_s": 491.1881947517395, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f899cf2a200>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c74d440>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e3964d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898e396dd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c109e60>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1320>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e3964d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898e396dd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c109e60>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1320>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e3964d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898e396dd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c109e60>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1320>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e3964d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898e396dd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c109e60>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1320>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c759b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 491.1881947517395, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 45.76279069767442, "ram_util_percent": 88.81162790697675}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 988.0485882287246, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": -143.38851134741833, "episode_len_mean": 135.34, "episodes_this_iter": 10, "policy_reward_min": {"AGENT-3": -363.889908520441, "AGENT-2": -449.4788037794044, "AGENT-0": -448.8965319625391, "AGENT-1": -349.05580841413826}, "policy_reward_max": {"AGENT-3": 280.32567811960837, "AGENT-2": 300.1854170002415, "AGENT-0": 413.52694646805065, "AGENT-1": 438.14037134981965}, "policy_reward_mean": {"AGENT-3": -69.16569684929732, "AGENT-2": -35.83024373772124, "AGENT-0": -9.375362710125591, "AGENT-1": -29.017208050274125}, "custom_metrics": {"mean_ego_speed_mean": 42.458805000000005, "mean_ego_speed_min": 15.644, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 81.74163250000001, "distance_travelled_min": 20.213500000000003, "distance_travelled_max": 124.85125}, "hist_stats": {"episode_reward": [-401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -522.006644597566, -394.2093327167674, -553.3520295256233, -188.35629230394676, -750.2940846925408, 180.35869523571705, 229.87443080217656, 189.80790743174532, -477.4845517469688, -433.7518814211228, -693.938550752084, 33.03084893021221, -554.3803131015827, -323.9157533551002, -165.3538876239856, -1169.9075047250058, -459.0706951858064, 70.3799473871102, -570.633914140485, -460.77756995140226, 69.28966990578853, -216.0425687012854, -194.2165301744098, 617.3350042344224, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929, -48.87212301200027, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195], "episode_lengths": [119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 121, 101, 123, 122, 129, 260, 137, 128, 89, 143, 107, 118, 110, 148, 32, 136, 120, 127, 97, 101, 120, 103, 71, 121, 155, 118, 156, 206, 82, 139, 149, 98, 140, 122, 44, 113, 137, 114, 265, 94, 135, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276], "policy_AGENT-3_reward": [-193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -135.24122272252916, -117.82055455739373, -176.20983338889783, -43.139533551978786, -171.4455237628716, -150.67362981087098, -0.8524113498859909, 2.2020770678050745, -95.06260123959731, -163.94941022611053, -161.20957895880292, -37.279954625156556, -121.7649872366475, -77.61125736890139, -16.029414777035907, -136.04740790082292, -127.73826841262483, -15.321489445211672, -125.33143121586008, -123.86286147485411, 6.345348373945244, -31.63959386777298, -51.153216819152256, 155.79079414571663, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477, 1.4932620478289884, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666], "policy_AGENT-2_reward": [-14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -135.21971642757256, -117.69474103635258, -116.26458699352183, -43.1729865759878, -193.2240544280157, -150.6496867073742, -0.6568215880630608, 2.3032139604815245, -95.1237099154512, -35.27036163930682, -208.54686471661554, -37.316275493156226, -167.03279201696165, -100.21171472626442, -15.975959039946044, -449.4788037794044, -123.47193924394513, -15.236451069665401, -125.30607751707818, -102.00806965189634, 19.459669821118542, -53.114488980805774, -46.52268778681753, 136.14784654743104, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224, -43.75892882928075, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246], "policy_AGENT-0_reward": [-14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -114.36150404878217, -79.21538539575228, -115.70758846380178, -52.21709751631647, -195.32246517159516, 266.6115005900778, 96.22263750542568, 96.78908942175022, -143.55349736438262, -199.7300825790453, -161.9801852537422, 53.27492434580155, -144.38198165523502, -91.89141988068845, -66.73939115774922, -448.8965319625391, -103.97170645757771, 27.342029521430348, -160.0129928141722, -117.44272621796819, 24.005430787956115, -65.62780830452024, -45.951918648349896, 163.97063846018455, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587, -8.77693138390639, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637], "policy_AGENT-1_reward": [-179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -137.1842013986815, -79.47865172726877, -145.17002067940183, -49.82667465966379, -190.30204133005813, 215.07051116388416, 135.16102623469976, 88.5135269817085, -143.74474322753773, -34.80202697666027, -162.201921822923, 54.35215470272344, -121.20055219273824, -54.20136137924673, -66.60912264925443, -135.48476108224037, -103.88878107165871, 73.5958583805569, -159.98341259337462, -117.46391260668335, 19.47922092276882, -65.66067754818633, -50.588706920090075, 161.42572508109038, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445, 2.170475153358211, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007]}, "sampler_perf": {"mean_env_wait_ms": 63.972052056192915, "mean_raw_obs_processing_ms": 2.633746804021132, "mean_inference_ms": 3.4689052424740994, "mean_action_processing_ms": 0.1687549313509254}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 16128, "timers": {"learn_time_ms": 11.125, "learn_throughput": 2876.456, "update_time_ms": 11.327}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 5.747612953186035, "min_q": -85.26189422607422, "max_q": 92.69586944580078, "mean_td_error": 5.407485008239746, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 5.195967674255371, "min_q": -34.422218322753906, "max_q": 139.36729431152344, "mean_td_error": 2.285743236541748, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 11.113876342773438, "min_q": -71.4437026977539, "max_q": 137.41921997070312, "mean_td_error": 6.801590919494629, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": -12.91773796081543, "min_q": -50.09606170654297, "max_q": 65.47956085205078, "mean_td_error": 9.034049987792969, "model": {}}}, "num_steps_sampled": 16128, "num_steps_trained": 40352, "last_target_update_ts": 16128, "num_target_updates": 31}, "done": false, "episodes_total": 119, "training_iteration": 16, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-51-16", "timestamp": 1624265476, "time_this_iter_s": 30.82538104057312, "time_total_s": 522.0135757923126, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f899cf8ac20>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c759440>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7590e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c759b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c759cb0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7590e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c759b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c759cb0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7590e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c759b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c759cb0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7590e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c759b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c759cb0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c759ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 522.0135757923126, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 47.75, "ram_util_percent": 89.10909090909091}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 1023.4885759447682, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": -111.26863214284793, "episode_len_mean": 137.81, "episodes_this_iter": 5, "policy_reward_min": {"AGENT-3": -363.889908520441, "AGENT-0": -448.8965319625391, "AGENT-2": -449.4788037794044, "AGENT-1": -349.05580841413826}, "policy_reward_max": {"AGENT-3": 280.32567811960837, "AGENT-0": 413.52694646805065, "AGENT-2": 300.1854170002415, "AGENT-1": 438.14037134981965}, "policy_reward_mean": {"AGENT-3": -63.42544841616606, "AGENT-0": -0.4150615294874758, "AGENT-2": -29.10572871258742, "AGENT-1": -18.32239348460697}, "custom_metrics": {"mean_ego_speed_mean": 42.51788500000001, "mean_ego_speed_min": 15.644, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 81.066655, "distance_travelled_min": 20.213500000000003, "distance_travelled_max": 124.85125}, "hist_stats": {"episode_reward": [-155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, 180.35869523571705, 229.87443080217656, 189.80790743174532, -477.4845517469688, -433.7518814211228, -693.938550752084, 33.03084893021221, -554.3803131015827, -323.9157533551002, -165.3538876239856, -1169.9075047250058, -459.0706951858064, 70.3799473871102, -570.633914140485, -460.77756995140226, 69.28966990578853, -216.0425687012854, -194.2165301744098, 617.3350042344224, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929, -48.87212301200027, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877], "episode_lengths": [158, 248, 116, 177, 144, 260, 137, 128, 89, 143, 107, 118, 110, 148, 32, 136, 120, 127, 97, 101, 120, 103, 71, 121, 155, 118, 156, 206, 82, 139, 149, 98, 140, 122, 44, 113, 137, 114, 265, 94, 135, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49], "policy_AGENT-3_reward": [-0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -150.67362981087098, -0.8524113498859909, 2.2020770678050745, -95.06260123959731, -163.94941022611053, -161.20957895880292, -37.279954625156556, -121.7649872366475, -77.61125736890139, -16.029414777035907, -136.04740790082292, -127.73826841262483, -15.321489445211672, -125.33143121586008, -123.86286147485411, 6.345348373945244, -31.63959386777298, -51.153216819152256, 155.79079414571663, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477, 1.4932620478289884, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374], "policy_AGENT-0_reward": [-32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, 266.6115005900778, 96.22263750542568, 96.78908942175022, -143.55349736438262, -199.7300825790453, -161.9801852537422, 53.27492434580155, -144.38198165523502, -91.89141988068845, -66.73939115774922, -448.8965319625391, -103.97170645757771, 27.342029521430348, -160.0129928141722, -117.44272621796819, 24.005430787956115, -65.62780830452024, -45.951918648349896, 163.97063846018455, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587, -8.77693138390639, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972], "policy_AGENT-2_reward": [-61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -150.6496867073742, -0.6568215880630608, 2.3032139604815245, -95.1237099154512, -35.27036163930682, -208.54686471661554, -37.316275493156226, -167.03279201696165, -100.21171472626442, -15.975959039946044, -449.4788037794044, -123.47193924394513, -15.236451069665401, -125.30607751707818, -102.00806965189634, 19.459669821118542, -53.114488980805774, -46.52268778681753, 136.14784654743104, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224, -43.75892882928075, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286], "policy_AGENT-1_reward": [-61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, 215.07051116388416, 135.16102623469976, 88.5135269817085, -143.74474322753773, -34.80202697666027, -162.201921822923, 54.35215470272344, -121.20055219273824, -54.20136137924673, -66.60912264925443, -135.48476108224037, -103.88878107165871, 73.5958583805569, -159.98341259337462, -117.46391260668335, 19.47922092276882, -65.66067754818633, -50.588706920090075, 161.42572508109038, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445, 2.170475153358211, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082]}, "sampler_perf": {"mean_env_wait_ms": 62.88921551788517, "mean_raw_obs_processing_ms": 2.6139377034845404, "mean_inference_ms": 3.371904926607824, "mean_action_processing_ms": 0.1674683307819484}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 17136, "timers": {"learn_time_ms": 10.389, "learn_throughput": 3080.034, "update_time_ms": 11.341}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": -4.5052170753479, "min_q": -80.95179748535156, "max_q": 163.93112182617188, "mean_td_error": -1.723114252090454, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 28.83072280883789, "min_q": -46.42754364013672, "max_q": 174.5651092529297, "mean_td_error": 0.04964160919189453, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 13.42241096496582, "min_q": -43.80337905883789, "max_q": 155.748046875, "mean_td_error": 12.520936965942383, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 0.8284852504730225, "min_q": -76.38937377929688, "max_q": 96.37606811523438, "mean_td_error": 3.8281936645507812, "model": {}}}, "num_steps_sampled": 17136, "num_steps_trained": 43040, "last_target_update_ts": 17136, "num_target_updates": 33}, "done": false, "episodes_total": 124, "training_iteration": 17, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-51-44", "timestamp": 1624265504, "time_this_iter_s": 27.872606992721558, "time_total_s": 549.8861827850342, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f898e396f80>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f898e396ef0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c079320>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c0790e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c079320>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c0790e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c079320>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c0790e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898c079320>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c0790e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f898c079d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 549.8861827850342, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 47.33, "ram_util_percent": 89.3}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 1023.4885759447682, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": -118.69209513990302, "episode_len_mean": 135.38, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-3": -363.889908520441, "AGENT-0": -448.8965319625391, "AGENT-2": -449.4788037794044, "AGENT-1": -349.05580841413826}, "policy_reward_max": {"AGENT-3": 280.32567811960837, "AGENT-0": 413.52694646805065, "AGENT-2": 300.1854170002415, "AGENT-1": 438.14037134981965}, "policy_reward_mean": {"AGENT-3": -63.209027040684035, "AGENT-0": -4.404953199976872, "AGENT-2": -27.96585433577623, "AGENT-1": -23.112260563465856}, "custom_metrics": {"mean_ego_speed_mean": 42.69812499999999, "mean_ego_speed_min": 15.644, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 80.27174249999999, "distance_travelled_min": 20.213500000000003, "distance_travelled_max": 124.85125}, "hist_stats": {"episode_reward": [-118.32045334299534, -213.79272032461813, 189.80790743174532, -477.4845517469688, -433.7518814211228, -693.938550752084, 33.03084893021221, -554.3803131015827, -323.9157533551002, -165.3538876239856, -1169.9075047250058, -459.0706951858064, 70.3799473871102, -570.633914140485, -460.77756995140226, 69.28966990578853, -216.0425687012854, -194.2165301744098, 617.3350042344224, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929, -48.87212301200027, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758], "episode_lengths": [79, 75, 128, 89, 143, 107, 118, 110, 148, 32, 136, 120, 127, 97, 101, 120, 103, 71, 121, 155, 118, 156, 206, 82, 139, 149, 98, 140, 122, 44, 113, 137, 114, 265, 94, 135, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144], "policy_AGENT-3_reward": [-30.931836595582514, -98.952067016972, 2.2020770678050745, -95.06260123959731, -163.94941022611053, -161.20957895880292, -37.279954625156556, -121.7649872366475, -77.61125736890139, -16.029414777035907, -136.04740790082292, -127.73826841262483, -15.321489445211672, -125.33143121586008, -123.86286147485411, 6.345348373945244, -31.63959386777298, -51.153216819152256, 155.79079414571663, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477, 1.4932620478289884, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307], "policy_AGENT-0_reward": [-28.220118766343884, -7.934910187091856, 96.78908942175022, -143.55349736438262, -199.7300825790453, -161.9801852537422, 53.27492434580155, -144.38198165523502, -91.89141988068845, -66.73939115774922, -448.8965319625391, -103.97170645757771, 27.342029521430348, -160.0129928141722, -117.44272621796819, 24.005430787956115, -65.62780830452024, -45.951918648349896, 163.97063846018455, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587, -8.77693138390639, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827], "policy_AGENT-2_reward": [-28.803063282604487, -8.51600733171361, 2.3032139604815245, -95.1237099154512, -35.27036163930682, -208.54686471661554, -37.316275493156226, -167.03279201696165, -100.21171472626442, -15.975959039946044, -449.4788037794044, -123.47193924394513, -15.236451069665401, -125.30607751707818, -102.00806965189634, 19.459669821118542, -53.114488980805774, -46.52268778681753, 136.14784654743104, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224, -43.75892882928075, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092], "policy_AGENT-1_reward": [-30.365434698464412, -98.38973578884068, 88.5135269817085, -143.74474322753773, -34.80202697666027, -162.201921822923, 54.35215470272344, -121.20055219273824, -54.20136137924673, -66.60912264925443, -135.48476108224037, -103.88878107165871, 73.5958583805569, -159.98341259337462, -117.46391260668335, 19.47922092276882, -65.66067754818633, -50.588706920090075, 161.42572508109038, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445, 2.170475153358211, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345]}, "sampler_perf": {"mean_env_wait_ms": 62.60663915157699, "mean_raw_obs_processing_ms": 2.6041316441513653, "mean_inference_ms": 3.3456321876176403, "mean_action_processing_ms": 0.16712248734631388}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 18144, "timers": {"learn_time_ms": 10.893, "learn_throughput": 2937.728, "update_time_ms": 11.038}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 36.69964599609375, "min_q": -62.59272003173828, "max_q": 189.39459228515625, "mean_td_error": 0.9926671385765076, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 25.874345779418945, "min_q": -35.14864730834961, "max_q": 166.51673889160156, "mean_td_error": 8.561081886291504, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": -5.100372314453125, "min_q": -70.9787368774414, "max_q": 169.82672119140625, "mean_td_error": 4.623577117919922, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 1.750312328338623, "min_q": -85.55865478515625, "max_q": 91.35408020019531, "mean_td_error": 1.2361036539077759, "model": {}}}, "num_steps_sampled": 18144, "num_steps_trained": 45728, "last_target_update_ts": 18144, "num_target_updates": 35}, "done": false, "episodes_total": 126, "training_iteration": 18, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-52-07", "timestamp": 1624265527, "time_this_iter_s": 23.321244955062866, "time_total_s": 573.207427740097, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c759560>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c759680>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759c20>, action_adapter=<function AgentSpec.<lambda> at 0x7f899cf71e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7f899cf8aa70>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c109e60>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759c20>, action_adapter=<function AgentSpec.<lambda> at 0x7f899cf71e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7f899cf8aa70>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c109e60>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759c20>, action_adapter=<function AgentSpec.<lambda> at 0x7f899cf71e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7f899cf8aa70>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c109e60>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759c20>, action_adapter=<function AgentSpec.<lambda> at 0x7f899cf71e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7f899cf8aa70>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c109e60>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c74d950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 573.207427740097, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 50.814705882352946, "ram_util_percent": 89.48529411764706}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 10878.874770563621, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": -11.801426508584258, "episode_len_mean": 142.82, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-0": -448.8965319625391, "AGENT-3": -363.889908520441, "AGENT-2": -449.4788037794044, "AGENT-1": -349.05580841413826}, "policy_reward_max": {"AGENT-0": 5516.407792653364, "AGENT-3": 5541.395518316764, "AGENT-2": 300.1854170002415, "AGENT-1": 438.14037134981965}, "policy_reward_mean": {"AGENT-0": 49.79123383233929, "AGENT-3": -7.817092628194449, "AGENT-2": -28.88616184982826, "AGENT-1": -24.889405862900524}, "custom_metrics": {"mean_ego_speed_mean": 42.505517499999996, "mean_ego_speed_min": 15.644, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 79.90630999999999, "distance_travelled_min": 20.213500000000003, "distance_travelled_max": 124.85125}, "hist_stats": {"episode_reward": [10878.874770563621, -477.4845517469688, -433.7518814211228, -693.938550752084, 33.03084893021221, -554.3803131015827, -323.9157533551002, -165.3538876239856, -1169.9075047250058, -459.0706951858064, 70.3799473871102, -570.633914140485, -460.77756995140226, 69.28966990578853, -216.0425687012854, -194.2165301744098, 617.3350042344224, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929, -48.87212301200027, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813], "episode_lengths": [872, 89, 143, 107, 118, 110, 148, 32, 136, 120, 127, 97, 101, 120, 103, 71, 121, 155, 118, 156, 206, 82, 139, 149, 98, 140, 122, 44, 113, 137, 114, 265, 94, 135, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75], "policy_AGENT-0_reward": [5516.407792653364, -143.55349736438262, -199.7300825790453, -161.9801852537422, 53.27492434580155, -144.38198165523502, -91.89141988068845, -66.73939115774922, -448.8965319625391, -103.97170645757771, 27.342029521430348, -160.0129928141722, -117.44272621796819, 24.005430787956115, -65.62780830452024, -45.951918648349896, 163.97063846018455, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587, -8.77693138390639, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856], "policy_AGENT-3_reward": [5541.395518316764, -95.06260123959731, -163.94941022611053, -161.20957895880292, -37.279954625156556, -121.7649872366475, -77.61125736890139, -16.029414777035907, -136.04740790082292, -127.73826841262483, -15.321489445211672, -125.33143121586008, -123.86286147485411, 6.345348373945244, -31.63959386777298, -51.153216819152256, 155.79079414571663, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477, 1.4932620478289884, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972], "policy_AGENT-2_reward": [-89.7275374447214, -95.1237099154512, -35.27036163930682, -208.54686471661554, -37.316275493156226, -167.03279201696165, -100.21171472626442, -15.975959039946044, -449.4788037794044, -123.47193924394513, -15.236451069665401, -125.30607751707818, -102.00806965189634, 19.459669821118542, -53.114488980805774, -46.52268778681753, 136.14784654743104, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224, -43.75892882928075, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361], "policy_AGENT-1_reward": [-89.20100296175775, -143.74474322753773, -34.80202697666027, -162.201921822923, 54.35215470272344, -121.20055219273824, -54.20136137924673, -66.60912264925443, -135.48476108224037, -103.88878107165871, 73.5958583805569, -159.98341259337462, -117.46391260668335, 19.47922092276882, -65.66067754818633, -50.588706920090075, 161.42572508109038, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445, 2.170475153358211, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068]}, "sampler_perf": {"mean_env_wait_ms": 62.38653163944696, "mean_raw_obs_processing_ms": 2.5992410685142784, "mean_inference_ms": 3.330349740510651, "mean_action_processing_ms": 0.16690128317260539}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 19152, "timers": {"learn_time_ms": 10.437, "learn_throughput": 3065.998, "update_time_ms": 10.7}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 27.7003231048584, "min_q": -91.18891906738281, "max_q": 197.99212646484375, "mean_td_error": -3.3261122703552246, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 24.34563636779785, "min_q": -45.0521240234375, "max_q": 188.8144989013672, "mean_td_error": 9.634328842163086, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 14.159161567687988, "min_q": -91.0761489868164, "max_q": 169.01376342773438, "mean_td_error": 5.388205051422119, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": -2.7214126586914062, "min_q": -56.32835388183594, "max_q": 87.14583587646484, "mean_td_error": 2.7336761951446533, "model": {}}}, "num_steps_sampled": 19152, "num_steps_trained": 48416, "last_target_update_ts": 19152, "num_target_updates": 37}, "done": false, "episodes_total": 127, "training_iteration": 19, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-52-30", "timestamp": 1624265550, "time_this_iter_s": 22.8655686378479, "time_total_s": 596.072996377945, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f898c0bddd0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c7598c0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74db00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74def0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74df80>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74de60>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74db00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74def0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74df80>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74de60>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74db00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74def0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74df80>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74de60>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74db00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74def0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74df80>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74de60>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f898c079830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 596.072996377945, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 45.263636363636365, "ram_util_percent": 89.73333333333335}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 12973.46047414889, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": 139.70834347848523, "episode_len_mean": 158.36, "episodes_this_iter": 6, "policy_reward_min": {"AGENT-2": -449.4788037794044, "AGENT-1": -349.05580841413826, "AGENT-0": -448.8965319625391, "AGENT-3": -363.889908520441}, "policy_reward_max": {"AGENT-2": 347.08351424424194, "AGENT-1": 438.14037134981965, "AGENT-0": 6366.511265538906, "AGENT-3": 6436.763672030127}, "policy_reward_mean": {"AGENT-2": -16.44689077058432, "AGENT-1": -22.009918773940136, "AGENT-0": 120.38228041230762, "AGENT-3": 57.78287261070246}, "custom_metrics": {"mean_ego_speed_mean": 42.161044999999994, "mean_ego_speed_min": 12.130749999999999, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 77.5437825, "distance_travelled_min": 20.213500000000003, "distance_travelled_max": 124.49975}, "hist_stats": {"episode_reward": [12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, -165.3538876239856, -1169.9075047250058, -459.0706951858064, 70.3799473871102, -570.633914140485, -460.77756995140226, 69.28966990578853, -216.0425687012854, -194.2165301744098, 617.3350042344224, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929, -48.87212301200027, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621], "episode_lengths": [968, 661, 94, 36, 24, 486, 32, 136, 120, 127, 97, 101, 120, 103, 71, 121, 155, 118, 156, 206, 82, 139, 149, 98, 140, 122, 44, 113, 137, 114, 265, 94, 135, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872], "policy_AGENT-2_reward": [84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -15.975959039946044, -449.4788037794044, -123.47193924394513, -15.236451069665401, -125.30607751707818, -102.00806965189634, 19.459669821118542, -53.114488980805774, -46.52268778681753, 136.14784654743104, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224, -43.75892882928075, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214], "policy_AGENT-1_reward": [85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, -66.60912264925443, -135.48476108224037, -103.88878107165871, 73.5958583805569, -159.98341259337462, -117.46391260668335, 19.47922092276882, -65.66067754818633, -50.588706920090075, 161.42572508109038, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445, 2.170475153358211, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775], "policy_AGENT-0_reward": [6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -66.73939115774922, -448.8965319625391, -103.97170645757771, 27.342029521430348, -160.0129928141722, -117.44272621796819, 24.005430787956115, -65.62780830452024, -45.951918648349896, 163.97063846018455, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587, -8.77693138390639, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364], "policy_AGENT-3_reward": [6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, -16.029414777035907, -136.04740790082292, -127.73826841262483, -15.321489445211672, -125.33143121586008, -123.86286147485411, 6.345348373945244, -31.63959386777298, -51.153216819152256, 155.79079414571663, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477, 1.4932620478289884, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764]}, "sampler_perf": {"mean_env_wait_ms": 61.02948087799396, "mean_raw_obs_processing_ms": 2.561219743777036, "mean_inference_ms": 3.22655755533165, "mean_action_processing_ms": 0.1650219316118695}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 20160, "timers": {"learn_time_ms": 10.56, "learn_throughput": 3030.279, "update_time_ms": 10.936}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 24.430213928222656, "min_q": -91.36775970458984, "max_q": 210.0572967529297, "mean_td_error": 9.05366325378418, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 27.27005958557129, "min_q": -54.57321548461914, "max_q": 197.6541748046875, "mean_td_error": 8.191512107849121, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 11.23379898071289, "min_q": -53.64727020263672, "max_q": 166.7425079345703, "mean_td_error": 2.647181987762451, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 23.038436889648438, "min_q": -89.88533020019531, "max_q": 117.68241882324219, "mean_td_error": 1.8517680168151855, "model": {}}}, "num_steps_sampled": 20160, "num_steps_trained": 51104, "last_target_update_ts": 20160, "num_target_updates": 39}, "done": false, "episodes_total": 133, "training_iteration": 20, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-52-56", "timestamp": 1624265576, "time_this_iter_s": 25.913021326065063, "time_total_s": 621.98601770401, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c759830>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f898e396ef0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c079050>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079320>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c079050>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079320>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c079050>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079320>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c079050>, reward_adapter=<function AgentSpec.<lambda> at 0x7f898c079320>, info_adapter=<function AgentSpec.<lambda> at 0x7f898c079950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c7c14d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 621.98601770401, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 45.4945945945946, "ram_util_percent": 89.92432432432433}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 12973.46047414889, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": 160.14715922485993, "episode_len_mean": 162.28, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-3": -363.889908520441, "AGENT-0": -397.5273453084139, "AGENT-2": -333.71515894074736, "AGENT-1": -349.05580841413826}, "policy_reward_max": {"AGENT-3": 6436.763672030127, "AGENT-0": 6366.511265538906, "AGENT-2": 347.08351424424194, "AGENT-1": 438.14037134981965}, "policy_reward_mean": {"AGENT-3": 59.45497635427186, "AGENT-0": 129.14427835051183, "AGENT-2": -8.884638757798518, "AGENT-1": -19.567456722124884}, "custom_metrics": {"mean_ego_speed_mean": 42.15884, "mean_ego_speed_min": 12.130749999999999, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 77.855765, "distance_travelled_min": 20.213500000000003, "distance_travelled_max": 124.49975}, "hist_stats": {"episode_reward": [166.53786705508386, 542.082315233391, -459.0706951858064, 70.3799473871102, -570.633914140485, -460.77756995140226, 69.28966990578853, -216.0425687012854, -194.2165301744098, 617.3350042344224, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929, -48.87212301200027, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199], "episode_lengths": [101, 459, 120, 127, 97, 101, 120, 103, 71, 121, 155, 118, 156, 206, 82, 139, 149, 98, 140, 122, 44, 113, 137, 114, 265, 94, 135, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486], "policy_AGENT-3_reward": [102.52586455182774, -87.39231287274569, -127.73826841262483, -15.321489445211672, -125.33143121586008, -123.86286147485411, 6.345348373945244, -31.63959386777298, -51.153216819152256, 155.79079414571663, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477, 1.4932620478289884, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258], "policy_AGENT-0_reward": [-32.201592677238146, 392.7654633773706, -103.97170645757771, 27.342029521430348, -160.0129928141722, -117.44272621796819, 24.005430787956115, -65.62780830452024, -45.951918648349896, 163.97063846018455, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587, -8.77693138390639, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226], "policy_AGENT-2_reward": [-32.768884394612726, 323.5393228538424, -123.47193924394513, -15.236451069665401, -125.30607751707818, -102.00806965189634, 19.459669821118542, -53.114488980805774, -46.52268778681753, 136.14784654743104, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224, -43.75892882928075, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194], "policy_AGENT-1_reward": [128.98247957510705, -86.83015812507608, -103.88878107165871, 73.5958583805569, -159.98341259337462, -117.46391260668335, 19.47922092276882, -65.66067754818633, -50.588706920090075, 161.42572508109038, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445, 2.170475153358211, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374]}, "sampler_perf": {"mean_env_wait_ms": 60.700508876752394, "mean_raw_obs_processing_ms": 2.5487819149520847, "mean_inference_ms": 3.2023026398433747, "mean_action_processing_ms": 0.1646240765885226}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 21168, "timers": {"learn_time_ms": 10.984, "learn_throughput": 2913.381, "update_time_ms": 10.943}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 46.61810302734375, "min_q": -71.70484924316406, "max_q": 221.42774963378906, "mean_td_error": -1.5214149951934814, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 30.295372009277344, "min_q": -45.40066909790039, "max_q": 201.12847900390625, "mean_td_error": 10.71908187866211, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 9.35329532623291, "min_q": -70.59822845458984, "max_q": 156.7088165283203, "mean_td_error": 4.880720138549805, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 0.5197911262512207, "min_q": -94.57334899902344, "max_q": 132.38937377929688, "mean_td_error": 0.7373824715614319, "model": {}}}, "num_steps_sampled": 21168, "num_steps_trained": 53792, "last_target_update_ts": 21168, "num_target_updates": 41}, "done": false, "episodes_total": 135, "training_iteration": 21, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-53-20", "timestamp": 1624265600, "time_this_iter_s": 23.784459114074707, "time_total_s": 645.7704768180847, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c7c15f0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c7c17a0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759c20>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7598c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c759710>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c759b90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759c20>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7598c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c759710>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c759b90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759c20>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7598c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c759710>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c759b90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759c20>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7598c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c759710>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c759b90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f898c079dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 645.7704768180847, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 42.8235294117647, "ram_util_percent": 90.10294117647058}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 12973.46047414889, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": 168.39294510888783, "episode_len_mean": 167.24, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-0": -397.5273453084139, "AGENT-3": -363.889908520441, "AGENT-2": -333.71515894074736, "AGENT-1": -349.05580841413826}, "policy_reward_max": {"AGENT-0": 6366.511265538906, "AGENT-3": 6436.763672030127, "AGENT-2": 347.08351424424194, "AGENT-1": 438.14037134981965}, "policy_reward_mean": {"AGENT-0": 134.1722712419193, "AGENT-3": 59.150549118583825, "AGENT-2": -4.356220180613565, "AGENT-1": -20.573655071001337}, "custom_metrics": {"mean_ego_speed_mean": 42.170705, "mean_ego_speed_min": 12.130749999999999, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 78.043985, "distance_travelled_min": 20.213500000000003, "distance_travelled_max": 124.49975}, "hist_stats": {"episode_reward": [561.2385273798845, -125.3506867757891, -570.633914140485, -460.77756995140226, 69.28966990578853, -216.0425687012854, -194.2165301744098, 617.3350042344224, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929, -48.87212301200027, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391], "episode_lengths": [479, 264, 97, 101, 120, 103, 71, 121, 155, 118, 156, 206, 82, 139, 149, 98, 140, 122, 44, 113, 137, 114, 265, 94, 135, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459], "policy_AGENT-0_reward": [388.9690713563988, 37.20054084819917, -160.0129928141722, -117.44272621796819, 24.005430787956115, -65.62780830452024, -45.951918648349896, 163.97063846018455, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587, -8.77693138390639, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706], "policy_AGENT-3_reward": [-85.46201332478523, -88.04046810185478, -125.33143121586008, -123.86286147485411, 6.345348373945244, -31.63959386777298, -51.153216819152256, 155.79079414571663, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477, 1.4932620478289884, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569], "policy_AGENT-2_reward": [342.63694644382497, -28.503479038940316, -125.30607751707818, -102.00806965189634, 19.459669821118542, -53.114488980805774, -46.52268778681753, 136.14784654743104, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224, -43.75892882928075, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424], "policy_AGENT-1_reward": [-84.90547709555425, -46.00728048319322, -159.98341259337462, -117.46391260668335, 19.47922092276882, -65.66067754818633, -50.588706920090075, 161.42572508109038, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445, 2.170475153358211, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608]}, "sampler_perf": {"mean_env_wait_ms": 60.289832912969366, "mean_raw_obs_processing_ms": 2.539221058576509, "mean_inference_ms": 3.1734672503806136, "mean_action_processing_ms": 0.16418592343462213}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 22176, "timers": {"learn_time_ms": 11.238, "learn_throughput": 2847.445, "update_time_ms": 11.158}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 36.42036437988281, "min_q": -71.45867919921875, "max_q": 230.51666259765625, "mean_td_error": 19.877613067626953, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 22.626230239868164, "min_q": -63.68417739868164, "max_q": 222.3249053955078, "mean_td_error": 6.285710334777832, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 14.7614107131958, "min_q": -49.80830001831055, "max_q": 206.38038635253906, "mean_td_error": 11.24040699005127, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 30.551918029785156, "min_q": -76.7162857055664, "max_q": 144.5989227294922, "mean_td_error": -4.711381435394287, "model": {}}}, "num_steps_sampled": 22176, "num_steps_trained": 56480, "last_target_update_ts": 22176, "num_target_updates": 43}, "done": false, "episodes_total": 137, "training_iteration": 22, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-53-44", "timestamp": 1624265624, "time_this_iter_s": 23.75866460800171, "time_total_s": 669.5291414260864, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c6bb170>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c6bb290>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb4d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb710>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb830>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb4d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb710>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb830>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb4d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb710>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb830>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb4d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb710>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb830>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f898c079cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 669.5291414260864, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 48.029411764705884, "ram_util_percent": 90.28823529411767}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 12973.46047414889, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": 183.53407474360873, "episode_len_mean": 168.88, "episodes_this_iter": 3, "policy_reward_min": {"AGENT-3": -363.889908520441, "AGENT-2": -333.71515894074736, "AGENT-0": -397.5273453084139, "AGENT-1": -349.05580841413826}, "policy_reward_max": {"AGENT-3": 6436.763672030127, "AGENT-2": 347.08351424424194, "AGENT-0": 6366.511265538906, "AGENT-1": 438.14037134981965}, "policy_reward_mean": {"AGENT-3": 61.20396743328996, "AGENT-2": -1.527671853272413, "AGENT-0": 139.91455141616146, "AGENT-1": -16.056772252569914}, "custom_metrics": {"mean_ego_speed_mean": 42.31165, "mean_ego_speed_min": 12.130749999999999, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 76.88098, "distance_travelled_min": 20.213500000000003, "distance_travelled_max": 124.49975}, "hist_stats": {"episode_reward": [1050.0600846826287, -241.74367084526486, -256.32526455137474, -216.0425687012854, -194.2165301744098, 617.3350042344224, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929, -48.87212301200027, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891], "episode_lengths": [353, 29, 100, 103, 71, 121, 155, 118, 156, 206, 82, 139, 149, 98, 140, 122, 44, 113, 137, 114, 265, 94, 135, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264], "policy_AGENT-3_reward": [143.88008411071937, -88.63187915665873, -92.75531780021515, -31.63959386777298, -51.153216819152256, 155.79079414571663, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477, 1.4932620478289884, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478], "policy_AGENT-2_reward": [143.8260134232015, -32.80523919291318, -36.02041884402871, -53.114488980805774, -46.52268778681753, 136.14784654743104, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224, -43.75892882928075, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316], "policy_AGENT-0_reward": [388.47786715433523, -32.24003327357256, -35.46010470073113, -65.62780830452024, -45.951918648349896, 163.97063846018455, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587, -8.77693138390639, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917], "policy_AGENT-1_reward": [373.8761199943731, -88.0665192221204, -92.08942320639954, -65.66067754818633, -50.588706920090075, 161.42572508109038, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445, 2.170475153358211, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322]}, "sampler_perf": {"mean_env_wait_ms": 59.53736198832452, "mean_raw_obs_processing_ms": 2.514277226191475, "mean_inference_ms": 3.1222757019705893, "mean_action_processing_ms": 0.1630404084150354}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 23184, "timers": {"learn_time_ms": 11.041, "learn_throughput": 2898.345, "update_time_ms": 10.985}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 15.508623123168945, "min_q": -89.636962890625, "max_q": 239.43556213378906, "mean_td_error": -3.316707134246826, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 22.701997756958008, "min_q": -70.08824157714844, "max_q": 237.41307067871094, "mean_td_error": 12.988983154296875, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 16.42180061340332, "min_q": -52.57621383666992, "max_q": 214.0127410888672, "mean_td_error": 14.927299499511719, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 19.244871139526367, "min_q": -94.37957000732422, "max_q": 159.25184631347656, "mean_td_error": 13.258197784423828, "model": {}}}, "num_steps_sampled": 23184, "num_steps_trained": 59168, "last_target_update_ts": 23184, "num_target_updates": 45}, "done": false, "episodes_total": 140, "training_iteration": 23, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-54-09", "timestamp": 1624265649, "time_this_iter_s": 24.924917936325073, "time_total_s": 694.4540593624115, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f899cf71ef0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f898c0bd560>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74de60>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74dc20>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74df80>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74def0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74de60>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74dc20>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74df80>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74def0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74de60>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74dc20>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74df80>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74def0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74de60>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74dc20>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74df80>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74def0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c6bbb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 694.4540593624115, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 47.44722222222222, "ram_util_percent": 90.51388888888889}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": 339.6090987662742, "episode_len_mean": 182.75, "episodes_this_iter": 3, "policy_reward_min": {"AGENT-2": -333.71515894074736, "AGENT-1": -349.05580841413826, "AGENT-0": -397.5273453084139, "AGENT-3": -395.58223943950634}, "policy_reward_max": {"AGENT-2": 488.8653400920767, "AGENT-1": 561.4160940184095, "AGENT-0": 7567.171809869095, "AGENT-3": 7570.081488567667}, "policy_reward_mean": {"AGENT-2": 3.7159635252147556, "AGENT-1": -9.673136347705615, "AGENT-0": 212.69320574939476, "AGENT-3": 132.87306583937044}, "custom_metrics": {"mean_ego_speed_mean": 41.91920749999999, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 77.368025, "distance_travelled_min": 20.213500000000003, "distance_travelled_max": 124.49975}, "hist_stats": {"episode_reward": [16187.534732547267, -792.6277756096342, 419.671350687639, -348.51169303842437, -200.05750595758857, 164.34065968980434, 698.4631058776095, -504.18269799816613, 214.965681281929, -48.87212301200027, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474], "episode_lengths": [999, 310, 373, 155, 118, 156, 206, 82, 139, 149, 98, 140, 122, 44, 113, 137, 114, 265, 94, 135, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100], "policy_AGENT-2_reward": [488.8653400920767, -19.12150360858304, 91.13037114503068, -8.779874730929357, -15.118705435089188, -38.61385334518388, -34.46803711704748, -153.21379929117302, 96.83183067053224, -43.75892882928075, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871], "policy_AGENT-1_reward": [561.4160940184095, -18.38472688296107, 140.50856396379544, -146.77941415496556, -69.18934584605952, 139.51152074562216, 372.9943443423514, -98.84096778492092, 50.783625684330445, 2.170475153358211, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954], "policy_AGENT-0_reward": [7567.171809869095, -359.5393056785828, 122.62384064013298, -45.607119306270384, -14.543442693325625, 102.08926539064865, 394.38970453780024, -98.88287990416003, 57.46313906742587, -8.77693138390639, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113], "policy_AGENT-3_reward": [7570.081488567667, -395.58223943950634, 65.40857493867931, -147.3452848462588, -101.20601198311421, -38.64627310128248, -34.452905885495056, -153.2450510179122, 9.887085859640477, 1.4932620478289884, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515]}, "sampler_perf": {"mean_env_wait_ms": 58.97497771603278, "mean_raw_obs_processing_ms": 2.4926364448301257, "mean_inference_ms": 3.0894182553856893, "mean_action_processing_ms": 0.16238826153327765}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 24192, "timers": {"learn_time_ms": 10.715, "learn_throughput": 2986.399, "update_time_ms": 10.415}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 52.079986572265625, "min_q": -105.47037506103516, "max_q": 236.11839294433594, "mean_td_error": 5.928477764129639, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 39.09571075439453, "min_q": -42.39138412475586, "max_q": 217.9982147216797, "mean_td_error": -2.1871726512908936, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 40.594844818115234, "min_q": -57.048770904541016, "max_q": 213.99330139160156, "mean_td_error": 7.434394836425781, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 24.358552932739258, "min_q": -64.58525085449219, "max_q": 178.17308044433594, "mean_td_error": 2.6421566009521484, "model": {}}}, "num_steps_sampled": 24192, "num_steps_trained": 61856, "last_target_update_ts": 24192, "num_target_updates": 47}, "done": false, "episodes_total": 143, "training_iteration": 24, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-54-35", "timestamp": 1624265675, "time_this_iter_s": 25.174673795700073, "time_total_s": 719.6287331581116, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f898c0793b0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c6bb830>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb290>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb200>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb290>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb200>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb290>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb200>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb290>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb200>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c759e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 719.6287331581116, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 46.30277777777778, "ram_util_percent": 90.7138888888889}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -1200.1076383135749, "episode_reward_mean": 310.75782050664793, "episode_len_mean": 183.74, "episodes_this_iter": 7, "policy_reward_min": {"AGENT-3": -395.58223943950634, "AGENT-0": -397.5273453084139, "AGENT-2": -333.71515894074736, "AGENT-1": -349.05580841413826}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-0": 7567.171809869095, "AGENT-2": 488.8653400920767, "AGENT-1": 561.4160940184095}, "policy_reward_mean": {"AGENT-3": 126.77529883419633, "AGENT-0": 198.8961656118346, "AGENT-2": 1.7606304267819448, "AGENT-1": -16.674274366164713}, "custom_metrics": {"mean_ego_speed_mean": 41.995465, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 75.5494725, "distance_travelled_min": 20.089750000000002, "distance_travelled_max": 124.49975}, "hist_stats": {"episode_reward": [-264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -425.8112673680406, -1200.1076383135749, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639], "episode_lengths": [326, 35, 21, 137, 408, 149, 28, 98, 140, 122, 44, 113, 137, 114, 265, 94, 135, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373], "policy_AGENT-3_reward": [-54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -11.561873899776494, -233.85995857534215, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931], "policy_AGENT-0_reward": [-34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -186.6102460481835, -383.2779969694592, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298], "policy_AGENT-2_reward": [-88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -216.64312338179815, -233.91387435463474, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068], "policy_AGENT-1_reward": [-87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -10.996024038282457, -349.05580841413826, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544]}, "sampler_perf": {"mean_env_wait_ms": 57.68169083512894, "mean_raw_obs_processing_ms": 2.4430042533523184, "mean_inference_ms": 3.004029625374431, "mean_action_processing_ms": 0.16070838564366668}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 25200, "timers": {"learn_time_ms": 11.165, "learn_throughput": 2866.026, "update_time_ms": 11.182}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 44.177982330322266, "min_q": -100.50572967529297, "max_q": 252.57008361816406, "mean_td_error": -4.840446949005127, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 42.99403381347656, "min_q": -62.50493621826172, "max_q": 221.55714416503906, "mean_td_error": 1.869659423828125, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 32.134647369384766, "min_q": -60.115116119384766, "max_q": 238.52163696289062, "mean_td_error": 10.116978645324707, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 2.4367613792419434, "min_q": -99.37271881103516, "max_q": 180.6321563720703, "mean_td_error": 0.8292775750160217, "model": {}}}, "num_steps_sampled": 25200, "num_steps_trained": 64544, "last_target_update_ts": 25200, "num_target_updates": 49}, "done": false, "episodes_total": 150, "training_iteration": 25, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-55-02", "timestamp": 1624265702, "time_this_iter_s": 27.215537786483765, "time_total_s": 746.8442709445953, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f898c079b00>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f898c079170>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1950>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c17a0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1950>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c17a0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1950>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c17a0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f898e396dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1950>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c17a0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f898c0bd9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 746.8442709445953, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 48.88974358974359, "ram_util_percent": 90.97435897435898}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -1100.5320869124155, "episode_reward_mean": 316.20357316210357, "episode_len_mean": 183.02, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-3": -395.58223943950634, "AGENT-2": -333.71515894074736, "AGENT-0": -397.5273453084139, "AGENT-1": -262.7438042781683}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-2": 488.8653400920767, "AGENT-0": 7567.171809869095, "AGENT-1": 561.4160940184095}, "policy_reward_mean": {"AGENT-3": 125.62935840152088, "AGENT-2": 4.666827166719493, "AGENT-0": 200.06563415166772, "AGENT-1": -14.158246557804269}, "custom_metrics": {"mean_ego_speed_mean": 42.1350425, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 74.87599, "distance_travelled_min": 20.089750000000002, "distance_travelled_max": 124.49975}, "hist_stats": {"episode_reward": [-648.1299490774692, -433.2136910585809, 178.78150370633196, -281.0217629321214, -360.1685717657071, -369.4780555696951, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744], "episode_lengths": [143, 23, 122, 44, 113, 137, 114, 265, 94, 135, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28], "policy_AGENT-3_reward": [-276.6417250318054, -83.37415071085707, 7.951362964620939, -46.09017873006594, -177.38031386145835, -96.89221938767024, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633], "policy_AGENT-2_reward": [-26.139372066583192, -133.79795167609495, 7.901731656281609, -46.132794595815845, -16.763870339156114, -74.81741607444124, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181], "policy_AGENT-0_reward": [-319.71893652113556, -133.22245251319737, 93.99138263813566, -94.42982962986562, -16.20426373344531, -101.4409015927452, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123], "policy_AGENT-1_reward": [-25.629915457944833, -82.8191361584315, 68.93702644729379, -94.36895997637403, -149.82012383164735, -96.32751851483852, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809]}, "sampler_perf": {"mean_env_wait_ms": 57.30677957749785, "mean_raw_obs_processing_ms": 2.4293328053806094, "mean_inference_ms": 2.9825084869021543, "mean_action_processing_ms": 0.16027721050503632}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 26208, "timers": {"learn_time_ms": 11.404, "learn_throughput": 2806.018, "update_time_ms": 11.181}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 36.13973617553711, "min_q": -123.15463256835938, "max_q": 270.95391845703125, "mean_td_error": 1.603621006011963, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 49.45946502685547, "min_q": -45.03644943237305, "max_q": 254.6405029296875, "mean_td_error": 10.359053611755371, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 60.11647033691406, "min_q": -59.551883697509766, "max_q": 220.84901428222656, "mean_td_error": 21.09564971923828, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 27.583593368530273, "min_q": -134.8601531982422, "max_q": 205.66506958007812, "mean_td_error": 17.63140106201172, "model": {}}}, "num_steps_sampled": 26208, "num_steps_trained": 67232, "last_target_update_ts": 26208, "num_target_updates": 51}, "done": false, "episodes_total": 152, "training_iteration": 26, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-55-27", "timestamp": 1624265727, "time_this_iter_s": 24.502925395965576, "time_total_s": 771.3471963405609, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c6bb050>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c6bb0e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c678050>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c678170>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c678290>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6783b0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c678050>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c678170>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c678290>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6783b0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c678050>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c678170>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c678290>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6783b0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c678050>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c678170>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c678290>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6783b0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f898c0bddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 771.3471963405609, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 45.54, "ram_util_percent": 91.16571428571429}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -1100.5320869124155, "episode_reward_mean": 473.52085754999774, "episode_len_mean": 200.5, "episodes_this_iter": 4, "policy_reward_min": {"AGENT-3": -395.58223943950634, "AGENT-0": -397.5273453084139, "AGENT-2": -333.71515894074736, "AGENT-1": -262.7438042781683}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-0": 7567.171809869095, "AGENT-2": 488.8653400920767, "AGENT-1": 561.4160940184095}, "policy_reward_mean": {"AGENT-3": 200.9910893144406, "AGENT-0": 276.1029703108918, "AGENT-2": 6.515967450752851, "AGENT-1": -10.089169526087614}, "custom_metrics": {"mean_ego_speed_mean": 41.8028775, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 75.289015, "distance_travelled_min": 20.089750000000002, "distance_travelled_max": 124.49975}, "hist_stats": {"episode_reward": [-352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -648.1519184731859, 166.51414620581286, -291.4208158370981, -426.417283864455, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809], "episode_lengths": [648, 405, 112, 999, 114, 265, 94, 135, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23], "policy_AGENT-3_reward": [-89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, -213.00678464620447, -14.425027659363268, -41.15305924820282, -172.3706225577475, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707], "policy_AGENT-0_reward": [17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -126.17772788181082, 74.90348480010789, -94.04700838716731, -44.97901034829233, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737], "policy_AGENT-2_reward": [-192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -182.7138035507558, -14.362749940178446, -62.13762485398424, -45.534542544373096, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495], "policy_AGENT-1_reward": [-88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, -126.25360239441429, 120.3984390052467, -94.08312334774372, -163.53310841404166, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315]}, "sampler_perf": {"mean_env_wait_ms": 56.616122548592415, "mean_raw_obs_processing_ms": 2.4021009556927155, "mean_inference_ms": 2.9408574056594676, "mean_action_processing_ms": 0.15947423805353034}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 27216, "timers": {"learn_time_ms": 11.007, "learn_throughput": 2907.197, "update_time_ms": 10.702}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 98.64643859863281, "min_q": -121.61319732666016, "max_q": 279.16510009765625, "mean_td_error": 7.075742244720459, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 55.46832275390625, "min_q": -46.91324996948242, "max_q": 257.7136535644531, "mean_td_error": 7.689112663269043, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 47.16558837890625, "min_q": -44.4306755065918, "max_q": 248.85398864746094, "mean_td_error": -0.9265584945678711, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 49.523582458496094, "min_q": -95.8248519897461, "max_q": 206.32171630859375, "mean_td_error": 14.289027214050293, "model": {}}}, "num_steps_sampled": 27216, "num_steps_trained": 69920, "last_target_update_ts": 27216, "num_target_updates": 53}, "done": false, "episodes_total": 156, "training_iteration": 27, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-55-56", "timestamp": 1624265756, "time_this_iter_s": 29.001476764678955, "time_total_s": 800.3486731052399, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c7597a0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c6bbf80>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f899cf71e60>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74df80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74dc20>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74de60>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f899cf71e60>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74df80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74dc20>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74de60>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f899cf71e60>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74df80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74dc20>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74de60>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f899cf71e60>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c74df80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c74dc20>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c74de60>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c678710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 800.3486731052399, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 41.252380952380946, "ram_util_percent": 91.39285714285714}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -1100.5320869124155, "episode_reward_mean": 476.59379934720994, "episode_len_mean": 201.44, "episodes_this_iter": 4, "policy_reward_min": {"AGENT-3": -395.58223943950634, "AGENT-2": -552.396916831616, "AGENT-0": -503.958948183327, "AGENT-1": -262.7438042781683}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-2": 488.8653400920767, "AGENT-0": 7567.171809869095, "AGENT-1": 561.4160940184095}, "policy_reward_mean": {"AGENT-3": 206.64974932293643, "AGENT-2": 4.1054602160620615, "AGENT-0": 272.02142773332724, "AGENT-1": -6.182837925115956}, "custom_metrics": {"mean_ego_speed_mean": 41.883712499999994, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 75.1962775, "distance_travelled_min": 20.089750000000002, "distance_travelled_max": 124.49975}, "hist_stats": {"episode_reward": [-747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 428.51510468913455, 248.281419914736, -411.95567304400276, -33.20364007863423, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075], "episode_lengths": [207, 120, 351, 24, 215, 272, 118, 193, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999], "policy_AGENT-3_reward": [153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 225.81289307132477, -81.77358743420315, -102.9343555743812, 22.435527364855403, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499], "policy_AGENT-2_reward": [-552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, -5.369656032797096, 213.26918793587532, -105.89922198444326, -29.98219766469774, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979], "policy_AGENT-0_reward": [-503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 213.01808833321155, 197.99888093201224, -103.14331759893221, -48.656764016437684, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545], "policy_AGENT-1_reward": [154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, -4.946220682604405, -81.21306151894848, -99.97877788624649, 22.999794237645666, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213]}, "sampler_perf": {"mean_env_wait_ms": 55.96486314597055, "mean_raw_obs_processing_ms": 2.3749816667552675, "mean_inference_ms": 2.902168135920706, "mean_action_processing_ms": 0.1586920961590095}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 28224, "timers": {"learn_time_ms": 10.614, "learn_throughput": 3014.984, "update_time_ms": 10.599}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 29.090065002441406, "min_q": -130.64024353027344, "max_q": 296.75836181640625, "mean_td_error": -2.687720537185669, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 66.24481201171875, "min_q": -46.895774841308594, "max_q": 277.1289367675781, "mean_td_error": -1.038171648979187, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 21.410335540771484, "min_q": -67.57665252685547, "max_q": 179.69622802734375, "mean_td_error": -0.9641677737236023, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 61.70150375366211, "min_q": -133.3645477294922, "max_q": 214.76881408691406, "mean_td_error": 6.026116847991943, "model": {}}}, "num_steps_sampled": 28224, "num_steps_trained": 72608, "last_target_update_ts": 28224, "num_target_updates": 55}, "done": false, "episodes_total": 160, "training_iteration": 28, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-56-21", "timestamp": 1624265781, "time_this_iter_s": 25.25735378265381, "time_total_s": 825.6060268878937, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c6bbd40>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f898c079b00>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c678290>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c678170>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c678050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c678ef0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c678290>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c678170>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c678050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c678ef0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c678290>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c678170>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c678050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c678ef0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c678290>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c678170>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c678050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c678ef0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c7c1320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 825.6060268878937, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 43.716666666666676, "ram_util_percent": 91.56388888888888}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -1100.5320869124155, "episode_reward_mean": 504.86501440549745, "episode_len_mean": 204.13, "episodes_this_iter": 4, "policy_reward_min": {"AGENT-3": -395.58223943950634, "AGENT-2": -552.396916831616, "AGENT-0": -503.958948183327, "AGENT-1": -262.7438042781683}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-2": 488.8653400920767, "AGENT-0": 7567.171809869095, "AGENT-1": 561.4160940184095}, "policy_reward_mean": {"AGENT-3": 209.8633290464869, "AGENT-2": 16.120698056920872, "AGENT-0": 275.1633479157243, "AGENT-1": 3.717639386365068}, "custom_metrics": {"mean_ego_speed_mean": 42.200542500000005, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 74.4715375, "distance_travelled_min": 20.089750000000002, "distance_travelled_max": 124.49975}, "hist_stats": {"episode_reward": [1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, -176.3731307189792, -949.7699233877726, 88.54030528748737, -358.8492755134362, -496.9258635893378, -15.021352836712783, -692.8012333210156, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014], "episode_lengths": [189, 22, 689, 167, 111, 155, 128, 112, 170, 156, 153, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24], "policy_AGENT-3_reward": [184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 27.31275685968211, -360.74714809698355, 65.85574546837766, -94.56868470803259, -154.40327291771, 73.3549590173314, -43.46805586170829, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488], "policy_AGENT-2_reward": [444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, -95.0075414351233, -96.45013006143304, -18.520672744489957, -86.58721209997552, -174.83251288661992, -96.38432802839763, -303.64214146187834, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336], "policy_AGENT-0_reward": [130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, -14.140199968129998, -396.5433716919929, -17.962146524989315, -86.03101954025504, -103.68545997650877, 103.65016440430946, -302.78726839527513, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954], "policy_AGENT-1_reward": [511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, -94.538146175408, -96.02927353736305, 59.167379088588866, -91.66235916517287, -64.0046178084991, -95.64214822995555, -42.903767602153636, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633]}, "sampler_perf": {"mean_env_wait_ms": 55.30101650445551, "mean_raw_obs_processing_ms": 2.3480104547384, "mean_inference_ms": 2.863475909067447, "mean_action_processing_ms": 0.15786640065247948}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 29232, "timers": {"learn_time_ms": 10.241, "learn_throughput": 3124.714, "update_time_ms": 11.065}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 56.413604736328125, "min_q": -131.47010803222656, "max_q": 236.99227905273438, "mean_td_error": 8.293970108032227, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 16.533992767333984, "min_q": -75.8199462890625, "max_q": 255.08343505859375, "mean_td_error": 0.9539644718170166, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 41.75785827636719, "min_q": -75.91085052490234, "max_q": 273.7301940917969, "mean_td_error": 5.505587577819824, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 73.10199737548828, "min_q": -149.97454833984375, "max_q": 226.62474060058594, "mean_td_error": 3.3581438064575195, "model": {}}}, "num_steps_sampled": 29232, "num_steps_trained": 75296, "last_target_update_ts": 29232, "num_target_updates": 57}, "done": false, "episodes_total": 164, "training_iteration": 29, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-56-55", "timestamp": 1624265815, "time_this_iter_s": 33.791372299194336, "time_total_s": 859.397399187088, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c7c1e60>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c7c1560>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb050>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bbdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6bbb00>, info_adapter=<function AgentSpec.<lambda> at 0x7f899cf71e60>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb050>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bbdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6bbb00>, info_adapter=<function AgentSpec.<lambda> at 0x7f899cf71e60>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb050>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bbdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6bbb00>, info_adapter=<function AgentSpec.<lambda> at 0x7f899cf71e60>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb050>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bbdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6bbb00>, info_adapter=<function AgentSpec.<lambda> at 0x7f899cf71e60>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c678cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 859.397399187088, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 40.542857142857144, "ram_util_percent": 91.1795918367347}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -1100.5320869124155, "episode_reward_mean": 519.4010325159924, "episode_len_mean": 206.69, "episodes_this_iter": 7, "policy_reward_min": {"AGENT-3": -395.58223943950634, "AGENT-2": -552.396916831616, "AGENT-0": -503.958948183327, "AGENT-1": -262.7438042781683}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-2": 488.8653400920767, "AGENT-0": 7567.171809869095, "AGENT-1": 561.4160940184095}, "policy_reward_mean": {"AGENT-3": 207.88913522096763, "AGENT-2": 24.53764544848183, "AGENT-0": 273.89201085962674, "AGENT-1": 13.082240986916005}, "custom_metrics": {"mean_ego_speed_mean": 42.3638075, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 73.13657, "distance_travelled_min": 19.163, "distance_travelled_max": 124.518}, "hist_stats": {"episode_reward": [1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, -1100.5320869124155, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286], "episode_lengths": [461, 21, 291, 246, 20, 109, 93, 157, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167], "policy_AGENT-3_reward": [119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, -284.4478132550589, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756], "policy_AGENT-2_reward": [369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, -286.1920659408636, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801], "policy_AGENT-0_reward": [172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, -267.1484034383256, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293], "policy_AGENT-1_reward": [544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, -262.7438042781683, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752]}, "sampler_perf": {"mean_env_wait_ms": 54.26445197830515, "mean_raw_obs_processing_ms": 2.307737376885971, "mean_inference_ms": 2.8047803487393783, "mean_action_processing_ms": 0.15665357210638564}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 30240, "timers": {"learn_time_ms": 10.864, "learn_throughput": 2945.425, "update_time_ms": 10.776}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 51.32984924316406, "min_q": -99.9874267578125, "max_q": 322.1710510253906, "mean_td_error": 12.059240341186523, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 71.2340087890625, "min_q": -61.91255569458008, "max_q": 265.12701416015625, "mean_td_error": 17.855846405029297, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 13.542655944824219, "min_q": -94.44865417480469, "max_q": 151.65969848632812, "mean_td_error": 6.386447906494141, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 68.34637451171875, "min_q": -77.04547882080078, "max_q": 248.97584533691406, "mean_td_error": 6.966093063354492, "model": {}}}, "num_steps_sampled": 30240, "num_steps_trained": 77984, "last_target_update_ts": 30240, "num_target_updates": 59}, "done": false, "episodes_total": 171, "training_iteration": 30, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-57-23", "timestamp": 1624265843, "time_this_iter_s": 27.617185354232788, "time_total_s": 887.0145845413208, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c678b90>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c678e60>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67a050>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c67a5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c67a4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c67a200>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67a050>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c67a5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c67a4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c67a200>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67a050>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c67a5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c67a4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c67a200>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67a050>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c67a5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c67a4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c67a200>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c67a710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 887.0145845413208, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 42.984615384615395, "ram_util_percent": 91.41538461538461}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -880.765990575195, "episode_reward_mean": 540.5843907825189, "episode_len_mean": 209.74, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-0": -503.958948183327, "AGENT-3": -395.58223943950634, "AGENT-2": -552.396916831616, "AGENT-1": -179.05618310321358}, "policy_reward_max": {"AGENT-0": 7567.171809869095, "AGENT-3": 7570.081488567667, "AGENT-2": 488.8653400920767, "AGENT-1": 561.4160940184095}, "policy_reward_mean": {"AGENT-0": 280.3151657170947, "AGENT-3": 212.024565359039, "AGENT-2": 31.246520184259452, "AGENT-1": 16.99813952212533}, "custom_metrics": {"mean_ego_speed_mean": 42.426104999999986, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 73.1453675, "distance_travelled_min": 19.163, "distance_travelled_max": 124.518}, "hist_stats": {"episode_reward": [1017.8037397402185, 486.2893901215538, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853], "episode_lengths": [462, 219, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93], "policy_AGENT-0_reward": [375.16708230847235, 218.10019647573714, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104], "policy_AGENT-3_reward": [129.09520055208066, -2.7308756586652714, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076], "policy_AGENT-2_reward": [384.6954076368992, -2.7346544956819505, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182], "policy_AGENT-1_reward": [128.84604924276437, 273.6547238001633, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723]}, "sampler_perf": {"mean_env_wait_ms": 54.10844911227108, "mean_raw_obs_processing_ms": 2.300536972042941, "mean_inference_ms": 2.7952039936204898, "mean_action_processing_ms": 0.15648098131532406}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 31248, "timers": {"learn_time_ms": 10.98, "learn_throughput": 2914.482, "update_time_ms": 15.156}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 48.11674499511719, "min_q": -132.48260498046875, "max_q": 314.629638671875, "mean_td_error": -1.5257781744003296, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 103.8230209350586, "min_q": -49.07395935058594, "max_q": 310.18316650390625, "mean_td_error": 15.207601547241211, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 37.280052185058594, "min_q": -138.10537719726562, "max_q": 279.8316650390625, "mean_td_error": 12.233017921447754, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 52.26160430908203, "min_q": -110.88079833984375, "max_q": 250.21624755859375, "mean_td_error": 8.514248847961426, "model": {}}}, "num_steps_sampled": 31248, "num_steps_trained": 80672, "last_target_update_ts": 31248, "num_target_updates": 61}, "done": false, "episodes_total": 172, "training_iteration": 31, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-57-45", "timestamp": 1624265865, "time_this_iter_s": 21.89079451560974, "time_total_s": 908.9053790569305, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c6bbb00>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c6bb0e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb950>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bbcb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb950>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bbcb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb950>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bbcb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb950>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bbcb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c67ab90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 908.9053790569305, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 50.215624999999996, "ram_util_percent": 91.64999999999999}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -880.765990575195, "episode_reward_mean": 537.3712581203354, "episode_len_mean": 212.82, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-3": -395.58223943950634, "AGENT-0": -503.958948183327, "AGENT-2": -552.396916831616, "AGENT-1": -179.05618310321358}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-0": 7567.171809869095, "AGENT-2": 488.8653400920767, "AGENT-1": 561.4160940184095}, "policy_reward_mean": {"AGENT-3": 213.20773463308905, "AGENT-0": 277.6273061948558, "AGENT-2": 30.800275299127016, "AGENT-1": 15.735941993263179}, "custom_metrics": {"mean_ego_speed_mean": 42.356449999999995, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 73.50279000000002, "distance_travelled_min": 19.163, "distance_travelled_max": 124.518}, "hist_stats": {"episode_reward": [164.97612390320154, 293.189122294963, 394.73270729240954, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185], "episode_lengths": [527, 112, 216, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462], "policy_AGENT-3_reward": [115.5860517463331, -82.50688831658124, -59.24243926645038, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066], "policy_AGENT-0_reward": [-50.68575574815381, 192.82859527148514, 231.03337474277538, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235], "policy_AGENT-2_reward": [-47.35914300892605, 264.7940748719771, -59.28278691873305, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992], "policy_AGENT-1_reward": [147.43497091394806, -81.92665953191818, 282.22455873481744, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437]}, "sampler_perf": {"mean_env_wait_ms": 53.98608602451876, "mean_raw_obs_processing_ms": 2.2935038046039304, "mean_inference_ms": 2.788601760545981, "mean_action_processing_ms": 0.15635648195253282}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 32256, "timers": {"learn_time_ms": 11.375, "learn_throughput": 2813.134, "update_time_ms": 13.341}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 36.417816162109375, "min_q": -163.3624267578125, "max_q": 335.45831298828125, "mean_td_error": 3.2348294258117676, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 75.237548828125, "min_q": -42.19458770751953, "max_q": 322.1371154785156, "mean_td_error": 3.813873291015625, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 3.315277099609375, "min_q": -127.0618896484375, "max_q": 186.61947631835938, "mean_td_error": 8.699836730957031, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 58.89971160888672, "min_q": -95.50294494628906, "max_q": 248.41783142089844, "mean_td_error": 9.910308837890625, "model": {}}}, "num_steps_sampled": 32256, "num_steps_trained": 83360, "last_target_update_ts": 32256, "num_target_updates": 63}, "done": false, "episodes_total": 173, "training_iteration": 32, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-58-02", "timestamp": 1624265882, "time_this_iter_s": 16.529694080352783, "time_total_s": 925.4350731372833, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f898c079830>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c67a440>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67a560>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c67a0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c67a680>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c67aa70>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67a560>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c67a0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c67a680>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c67aa70>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67a560>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c67a0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c67a680>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c67aa70>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67a560>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c67a0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c67a680>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c67aa70>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c74dc20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 925.4350731372833, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 51.074999999999996, "ram_util_percent": 91.83333333333333}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -880.765990575195, "episode_reward_mean": 532.9694656594891, "episode_len_mean": 219.79, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-3": -395.58223943950634, "AGENT-2": -552.396916831616, "AGENT-0": -503.958948183327, "AGENT-1": -179.05618310321358}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-2": 488.8653400920767, "AGENT-0": 7567.171809869095, "AGENT-1": 561.4160940184095}, "policy_reward_mean": {"AGENT-3": 215.25253349823765, "AGENT-2": 31.27996328182304, "AGENT-0": 272.06544166125207, "AGENT-1": 14.371527218176086}, "custom_metrics": {"mean_ego_speed_mean": 42.192382499999994, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 73.322805, "distance_travelled_min": 19.163, "distance_travelled_max": 124.518}, "hist_stats": {"episode_reward": [672.0794835503924, -424.3369000476369, -258.91620348388307, -228.339233068619, -345.5844407324372, -845.0998652143363, 945.655231152511, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154], "episode_lengths": [999, 26, 90, 22, 111, 86, 192, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527], "policy_AGENT-3_reward": [143.71029225897985, -80.97973332714594, -125.43770728423108, -82.77468163328399, -31.9881009342465, -89.42323369361688, 107.22075352782348, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331], "policy_AGENT-2_reward": [385.24109083108897, -131.76100460824247, -4.515866632512357, -31.961115961825847, -32.006709402063194, -333.71515894074736, 300.09555973432543, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605], "policy_AGENT-0_reward": [-1.1485638679071295, -131.17591947820839, -4.089307225572503, -31.393126885892187, -128.21794797785927, -333.1239186898729, 139.4528885276225, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381], "policy_AGENT-1_reward": [144.27666432823037, -80.42024263404016, -124.87332234156712, -82.21030858761695, -153.37168241826794, -88.83755389009934, 398.8860293627402, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806]}, "sampler_perf": {"mean_env_wait_ms": 53.688546560923506, "mean_raw_obs_processing_ms": 2.2834758423055637, "mean_inference_ms": 2.772492856714749, "mean_action_processing_ms": 0.15598445973372546}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 33264, "timers": {"learn_time_ms": 11.057, "learn_throughput": 2894.114, "update_time_ms": 11.48}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 63.907936096191406, "min_q": -100.05611419677734, "max_q": 328.7929382324219, "mean_td_error": 6.988682270050049, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 66.60967254638672, "min_q": -64.72608947753906, "max_q": 340.3809509277344, "mean_td_error": 2.64945125579834, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 26.67022132873535, "min_q": -155.08773803710938, "max_q": 258.7967834472656, "mean_td_error": 8.322901725769043, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 84.93669891357422, "min_q": -36.166229248046875, "max_q": 289.3755798339844, "mean_td_error": 12.16425895690918, "model": {}}}, "num_steps_sampled": 33264, "num_steps_trained": 86048, "last_target_update_ts": 33264, "num_target_updates": 65}, "done": false, "episodes_total": 175, "training_iteration": 33, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-58-18", "timestamp": 1624265898, "time_this_iter_s": 15.836356401443481, "time_total_s": 941.2714295387268, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c67ac20>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c74db90>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bbc20>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1440>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1b90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bbc20>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1440>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1b90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bbc20>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1440>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1b90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bbc20>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1440>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1b90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c7595f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 941.2714295387268, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 53.591304347826096, "ram_util_percent": 91.41739130434786}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -880.765990575195, "episode_reward_mean": 571.369299372193, "episode_len_mean": 236.78, "episodes_this_iter": 5, "policy_reward_min": {"AGENT-3": -395.58223943950634, "AGENT-2": -552.396916831616, "AGENT-0": -503.958948183327, "AGENT-1": -179.05618310321358}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-2": 488.8653400920767, "AGENT-0": 7567.171809869095, "AGENT-1": 561.4160940184095}, "policy_reward_mean": {"AGENT-3": 220.95375733627606, "AGENT-2": 37.00843067504933, "AGENT-0": 285.2392811694941, "AGENT-1": 28.16783019137331}, "custom_metrics": {"mean_ego_speed_mean": 42.239315, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 74.4166975, "distance_travelled_min": 19.163, "distance_travelled_max": 124.518}, "hist_stats": {"episode_reward": [842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 125.96427786041258, 485.21738440720816, -821.4787510146997, -172.68627131589642, 246.653978389027, -346.5549083362832, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369], "episode_lengths": [659, 23, 272, 999, 247, 208, 218, 150, 152, 180, 19, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26], "policy_AGENT-3_reward": [-6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 123.45166242483458, -54.31263255798194, -363.889908520441, -73.60549944016353, -93.85715773363401, -61.870634790413995, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594], "policy_AGENT-2_reward": [-6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, -49.55181183656744, 300.1854170002415, -30.32506521008382, -34.356118238072845, 216.98182080563708, -111.98967595916878, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247], "policy_AGENT-0_reward": [361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, -48.97389673779071, 293.09302448992906, -397.5273453084139, -33.79517727964469, 216.82354363265458, -111.413847197326, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839], "policy_AGENT-1_reward": [493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 101.03832400993603, -53.74842452498037, -29.736431975761164, -30.929476358015215, -93.29422831563095, -61.280750389374425, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016]}, "sampler_perf": {"mean_env_wait_ms": 52.93048699201731, "mean_raw_obs_processing_ms": 2.245852266621105, "mean_inference_ms": 2.7303697150161566, "mean_action_processing_ms": 0.15513149719782404}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 34272, "timers": {"learn_time_ms": 10.524, "learn_throughput": 3040.59, "update_time_ms": 11.352}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 45.242218017578125, "min_q": -159.2254180908203, "max_q": 363.470703125, "mean_td_error": 4.468572616577148, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 57.96120071411133, "min_q": -47.74924087524414, "max_q": 289.7118225097656, "mean_td_error": 9.419711112976074, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 46.503387451171875, "min_q": -155.513671875, "max_q": 294.0963134765625, "mean_td_error": 3.5900540351867676, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 52.81663513183594, "min_q": -115.29136657714844, "max_q": 273.4523620605469, "mean_td_error": -1.4895637035369873, "model": {}}}, "num_steps_sampled": 34272, "num_steps_trained": 88736, "last_target_update_ts": 34272, "num_target_updates": 67}, "done": false, "episodes_total": 180, "training_iteration": 34, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-58-49", "timestamp": 1624265929, "time_this_iter_s": 31.33797025680542, "time_total_s": 972.6093997955322, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c74da70>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c74db00>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67ad40>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c67a8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c67ae60>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c67af80>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67ad40>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c67a8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c67ae60>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c67af80>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67ad40>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c67a8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c67ae60>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c67af80>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67ad40>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c67a8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c67ae60>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c67af80>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c6890e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 972.6093997955322, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 41.964444444444446, "ram_util_percent": 91.56}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -1124.703775550179, "episode_reward_mean": 593.8438311399929, "episode_len_mean": 237.52, "episodes_this_iter": 6, "policy_reward_min": {"AGENT-3": -395.58223943950634, "AGENT-2": -552.396916831616, "AGENT-0": -505.3701028027561, "AGENT-1": -179.05618310321358}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-2": 488.8653400920767, "AGENT-0": 7567.171809869095, "AGENT-1": 561.4160940184095}, "policy_reward_mean": {"AGENT-3": 227.24492546938188, "AGENT-2": 38.88306160458867, "AGENT-0": 294.0096872418311, "AGENT-1": 33.7061568241909}, "custom_metrics": {"mean_ego_speed_mean": 42.2045075, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 75.1179125, "distance_travelled_min": 19.163, "distance_travelled_max": 124.518}, "hist_stats": {"episode_reward": [1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, -135.95961837346516, -232.28973303486904, -59.663597387150205, -423.6864761096126, -433.6448865148445, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905], "episode_lengths": [217, 22, 185, 177, 186, 214, 110, 142, 142, 29, 30, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247], "policy_AGENT-3_reward": [237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, -36.93554418124937, -91.61772868504536, 71.30893663016869, -81.81015095646072, -84.66935820445738, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577], "policy_AGENT-2_reward": [237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -35.126033883229674, -33.23206232482338, -84.86264291536372, -130.59270110338701, -132.6421240814468, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496], "policy_AGENT-0_reward": [489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -34.56199158336362, -32.66792165204747, 38.059756981063714, -130.03127610803563, -132.2179452439708, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812], "policy_AGENT-1_reward": [489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, -29.336048725622444, -74.772020372953, -84.16964808301887, -81.25234794172914, -84.11545898496942, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012]}, "sampler_perf": {"mean_env_wait_ms": 52.132146866967915, "mean_raw_obs_processing_ms": 2.2096664847738974, "mean_inference_ms": 2.6870674909754975, "mean_action_processing_ms": 0.15417182747884656}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 35280, "timers": {"learn_time_ms": 10.869, "learn_throughput": 2944.114, "update_time_ms": 12.417}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 24.048072814941406, "min_q": -177.4922637939453, "max_q": 342.4294128417969, "mean_td_error": 10.064096450805664, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 39.767791748046875, "min_q": -69.23155975341797, "max_q": 343.2236328125, "mean_td_error": -0.48889875411987305, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 41.379661560058594, "min_q": -163.3982391357422, "max_q": 281.6926574707031, "mean_td_error": 4.316428184509277, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 105.66691589355469, "min_q": -158.23524475097656, "max_q": 280.5255126953125, "mean_td_error": 17.89665985107422, "model": {}}}, "num_steps_sampled": 35280, "num_steps_trained": 91424, "last_target_update_ts": 35280, "num_target_updates": 69}, "done": false, "episodes_total": 186, "training_iteration": 35, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-59-16", "timestamp": 1624265956, "time_this_iter_s": 26.383000373840332, "time_total_s": 998.9924001693726, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c6bbb00>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c6bbcb0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67a7a0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c34f710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7597a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c759c20>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67a7a0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c34f710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7597a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c759c20>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67a7a0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c34f710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7597a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c759c20>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67a7a0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c34f710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7597a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c759c20>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c689560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 998.9924001693726, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 45.61081081081081, "ram_util_percent": 91.79459459459461}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -1761.0572487911854, "episode_reward_mean": 600.8018304008843, "episode_len_mean": 240.32, "episodes_this_iter": 5, "policy_reward_min": {"AGENT-3": -815.8205249906721, "AGENT-0": -877.5287333117959, "AGENT-2": -552.396916831616, "AGENT-1": -179.05618310321358}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-0": 7567.171809869095, "AGENT-2": 488.8653400920767, "AGENT-1": 561.4160940184095}, "policy_reward_mean": {"AGENT-3": 222.69412811597093, "AGENT-0": 291.48855787758276, "AGENT-2": 47.1635530871724, "AGENT-1": 39.455591320158085}, "custom_metrics": {"mean_ego_speed_mean": 42.08195250000001, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 76.20384250000001, "distance_travelled_min": 19.163, "distance_travelled_max": 124.518}, "hist_stats": {"episode_reward": [42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -340.39471994280643, 707.5068547286526, 491.43992301977374, 312.7591257577934, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971], "episode_lengths": [170, 148, 31, 187, 197, 77, 396, 204, 195, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214], "policy_AGENT-3_reward": [181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -130.10670079912921, 280.32567811960837, -58.502736057125, -85.27309137675678, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294], "policy_AGENT-0_reward": [-217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -40.110958349601155, 173.98028034526482, 310.1129449984631, 248.35546786102344, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996], "policy_AGENT-2_reward": [-158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -40.6714157739144, 116.67474559092453, 297.7695605455797, 234.3939768440376, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141], "policy_AGENT-1_reward": [236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -129.5056450201617, 136.52615067285473, -57.9398464671442, -84.71722757051077, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953]}, "sampler_perf": {"mean_env_wait_ms": 51.51576897149546, "mean_raw_obs_processing_ms": 2.1760673046013665, "mean_inference_ms": 2.6539493460720887, "mean_action_processing_ms": 0.15340082254876578}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 36288, "timers": {"learn_time_ms": 10.837, "learn_throughput": 2952.728, "update_time_ms": 11.148}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 76.8212890625, "min_q": -97.79067993164062, "max_q": 355.2281188964844, "mean_td_error": 4.076805114746094, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 72.39033508300781, "min_q": -59.94205093383789, "max_q": 315.13055419921875, "mean_td_error": 11.48353099822998, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 45.483978271484375, "min_q": -174.01901245117188, "max_q": 316.0318298339844, "mean_td_error": 5.581325531005859, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 84.32881164550781, "min_q": -36.93450164794922, "max_q": 301.1897277832031, "mean_td_error": 20.45232391357422, "model": {}}}, "num_steps_sampled": 36288, "num_steps_trained": 94112, "last_target_update_ts": 36288, "num_target_updates": 71}, "done": false, "episodes_total": 191, "training_iteration": 36, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_08-59-45", "timestamp": 1624265985, "time_this_iter_s": 28.497546911239624, "time_total_s": 1027.4899470806122, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c74db00>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c74da70>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759680>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb950>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689d40>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759680>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb950>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689d40>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759680>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb950>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689d40>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759680>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb950>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689d40>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c6789e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1027.4899470806122, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 45.78536585365854, "ram_util_percent": 91.91463414634147}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -1761.0572487911854, "episode_reward_mean": 597.7087256792439, "episode_len_mean": 241.77, "episodes_this_iter": 4, "policy_reward_min": {"AGENT-3": -815.8205249906721, "AGENT-2": -552.396916831616, "AGENT-0": -877.5287333117959, "AGENT-1": -179.05618310321358}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-2": 625.4441189084074, "AGENT-0": 7567.171809869095, "AGENT-1": 561.4160940184095}, "policy_reward_mean": {"AGENT-3": 217.53888803004259, "AGENT-2": 46.66238982541609, "AGENT-0": 287.77441116169945, "AGENT-1": 45.73303666208562}, "custom_metrics": {"mean_ego_speed_mean": 42.293279999999996, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 75.93348, "distance_travelled_min": 19.163, "distance_travelled_max": 124.518}, "hist_stats": {"episode_reward": [-1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -346.71266234482715, 185.7155982650174, -276.8509504794204, -584.8127017597103, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126], "episode_lengths": [373, 22, 428, 194, 108, 215, 103, 138, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197], "policy_AGENT-3_reward": [-630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -108.76492324259941, -84.95725719081612, -102.04118011090226, -82.34010734400835, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333], "policy_AGENT-2_reward": [-35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -65.42001853079128, 173.3869817846662, -36.62818397398448, -227.90569718991588, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876], "policy_AGENT-0_reward": [-569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -107.70129629641062, 181.67790523714598, -36.063680811092624, -192.78768752548626, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487], "policy_AGENT-1_reward": [-34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -64.82642427502599, -84.39203156597875, -102.11790558344126, -81.77920970029976, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723]}, "sampler_perf": {"mean_env_wait_ms": 51.01926611606595, "mean_raw_obs_processing_ms": 2.1506005206814476, "mean_inference_ms": 2.627053568704037, "mean_action_processing_ms": 0.1527749502686651}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 37296, "timers": {"learn_time_ms": 10.787, "learn_throughput": 2966.518, "update_time_ms": 10.781}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 108.03898620605469, "min_q": -149.46060180664062, "max_q": 391.1304931640625, "mean_td_error": 17.736677169799805, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 59.11407470703125, "min_q": -46.768123626708984, "max_q": 360.1507263183594, "mean_td_error": -2.9887633323669434, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 66.79429626464844, "min_q": -182.61636352539062, "max_q": 350.41668701171875, "mean_td_error": 10.06834602355957, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 39.522987365722656, "min_q": -205.98214721679688, "max_q": 333.00726318359375, "mean_td_error": 6.719460487365723, "model": {}}}, "num_steps_sampled": 37296, "num_steps_trained": 96800, "last_target_update_ts": 37296, "num_target_updates": 73}, "done": false, "episodes_total": 195, "training_iteration": 37, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-00-12", "timestamp": 1624266012, "time_this_iter_s": 26.939897060394287, "time_total_s": 1054.4298441410065, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c6bbe60>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c67a830>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74d9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c34f710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c759b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7597a0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74d9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c34f710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c759b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7597a0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74d9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c34f710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c759b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7597a0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c74d9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c34f710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c759b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7597a0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c689dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1054.4298441410065, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 43.707692307692305, "ram_util_percent": 91.15128205128202}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 558.4349140755022, "episode_len_mean": 246.09, "episodes_this_iter": 4, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-2": -552.396916831616, "AGENT-0": -1887.6784051212405, "AGENT-1": -179.05618310321358}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-2": 625.4441189084074, "AGENT-0": 7567.171809869095, "AGENT-1": 561.4160940184095}, "policy_reward_mean": {"AGENT-3": 197.34846020860238, "AGENT-2": 47.040960082953944, "AGENT-0": 266.0978213968675, "AGENT-1": 47.94767238707814}, "custom_metrics": {"mean_ego_speed_mean": 42.30273249999999, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 75.7222075, "distance_travelled_min": 19.163, "distance_travelled_max": 124.518}, "hist_stats": {"episode_reward": [-3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, 292.2406171178581, 329.15367128427056, 988.0485882287246, 242.51893197288697, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202], "episode_lengths": [495, 98, 335, 68, 115, 122, 284, 177, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194], "policy_AGENT-3_reward": [-1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, -82.76617269867458, -80.05965990193836, 101.35697331926785, 14.163354635218, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486], "policy_AGENT-2_reward": [-22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 265.96994666981743, 283.8544885112112, 101.2997812359582, 14.117790681194252, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074], "policy_AGENT-0_reward": [-1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, 191.24352515228435, 204.82861624302814, 413.52694646805065, 117.5072484032754, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114], "policy_AGENT-1_reward": [-22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -82.20668200556881, -79.46977356803025, 371.86488720544867, 96.73053825319944, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548]}, "sampler_perf": {"mean_env_wait_ms": 50.56196384865246, "mean_raw_obs_processing_ms": 2.1279039801731203, "mean_inference_ms": 2.6030817239520463, "mean_action_processing_ms": 0.15221105035930807}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 38304, "timers": {"learn_time_ms": 10.656, "learn_throughput": 3003.131, "update_time_ms": 11.217}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 47.09368896484375, "min_q": -182.8369598388672, "max_q": 375.8434143066406, "mean_td_error": 13.665629386901855, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 51.634605407714844, "min_q": -78.23072814941406, "max_q": 249.1598358154297, "mean_td_error": 3.1377344131469727, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 86.74815368652344, "min_q": -45.096282958984375, "max_q": 336.77099609375, "mean_td_error": -3.6289827823638916, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 74.83589172363281, "min_q": -215.65345764160156, "max_q": 324.51873779296875, "mean_td_error": 3.892864227294922, "model": {}}}, "num_steps_sampled": 38304, "num_steps_trained": 99488, "last_target_update_ts": 38304, "num_target_updates": 75}, "done": false, "episodes_total": 199, "training_iteration": 38, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-00-39", "timestamp": 1624266039, "time_this_iter_s": 26.57560896873474, "time_total_s": 1081.0054531097412, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c6bbcb0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c6bbb00>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67ad40>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c079d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689ef0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67ad40>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c079d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689ef0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67ad40>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c079d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689ef0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c67ad40>, action_adapter=<function AgentSpec.<lambda> at 0x7f898c079d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689ef0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c7c1e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1081.0054531097412, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 45.339473684210525, "ram_util_percent": 92.27894736842107}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 543.0710719147922, "episode_len_mean": 252.09, "episodes_this_iter": 4, "policy_reward_min": {"AGENT-2": -552.396916831616, "AGENT-1": -240.17540347939786, "AGENT-0": -1887.6784051212405, "AGENT-3": -1917.8029490524984}, "policy_reward_max": {"AGENT-2": 625.4441189084074, "AGENT-1": 561.4160940184095, "AGENT-0": 7567.171809869095, "AGENT-3": 7570.081488567667}, "policy_reward_mean": {"AGENT-2": 45.05022532709114, "AGENT-1": 45.085696450812456, "AGENT-0": 255.37816480305418, "AGENT-3": 197.55698533383438}, "custom_metrics": {"mean_ego_speed_mean": 41.967512500000005, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 76.31971, "distance_travelled_min": 19.163, "distance_travelled_max": 124.518}, "hist_stats": {"episode_reward": [-215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -238.69773531354255, -432.431728141239, 880.2979505625993, 635.0915647061364, 147.08801929025918, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023], "episode_lengths": [375, 374, 408, 141, 85, 24, 266, 124, 267, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68], "policy_AGENT-2_reward": [104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -14.604642083480158, -136.05132850502324, 34.17619897943221, -33.91352173847363, 160.04481549284674, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997], "policy_AGENT-1_reward": [-240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, -104.75268022412891, -80.09751904544156, 438.14037134981965, 388.5414768332677, -55.163921303559576, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497], "policy_AGENT-0_reward": [-184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -14.01999977103075, -135.62116520448427, 373.761173754599, 314.2770735272832, 97.95519377458452, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051], "policy_AGENT-3_reward": [104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, -105.32041323490265, -80.66171538628998, 34.220206478748125, -33.81346391594076, -55.74806867361233, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272]}, "sampler_perf": {"mean_env_wait_ms": 50.117622411027206, "mean_raw_obs_processing_ms": 2.1027049026653652, "mean_inference_ms": 2.57973757074066, "mean_action_processing_ms": 0.1516736201434853}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 39312, "timers": {"learn_time_ms": 11.219, "learn_throughput": 2852.225, "update_time_ms": 10.972}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 58.77631378173828, "min_q": -125.45014190673828, "max_q": 412.5964660644531, "mean_td_error": -1.1905187368392944, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 77.74468994140625, "min_q": -58.416507720947266, "max_q": 379.8269958496094, "mean_td_error": 2.611849784851074, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 98.5426254272461, "min_q": -124.50626373291016, "max_q": 364.3341369628906, "mean_td_error": 11.770427703857422, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 62.33380126953125, "min_q": -200.16004943847656, "max_q": 361.0724182128906, "mean_td_error": 19.72978973388672, "model": {}}}, "num_steps_sampled": 39312, "num_steps_trained": 102176, "last_target_update_ts": 39312, "num_target_updates": 77}, "done": false, "episodes_total": 203, "training_iteration": 39, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-01-09", "timestamp": 1624266069, "time_this_iter_s": 30.667835235595703, "time_total_s": 1111.673288345337, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c6bb0e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c6bb050>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c17a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6788c0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c17a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6788c0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c17a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6788c0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c17a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6788c0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c7c1560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1111.673288345337, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 40.477272727272734, "ram_util_percent": 92.53863636363636}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 563.5849265207875, "episode_len_mean": 255.46, "episodes_this_iter": 5, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-0": -1887.6784051212405, "AGENT-2": -552.396916831616, "AGENT-1": -240.17540347939786}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-0": 7567.171809869095, "AGENT-2": 625.4441189084074, "AGENT-1": 561.4160940184095}, "policy_reward_mean": {"AGENT-3": 203.92393005609597, "AGENT-0": 259.9311664616786, "AGENT-2": 55.77380512118198, "AGENT-1": 43.95602488183063}, "custom_metrics": {"mean_ego_speed_mean": 41.926117500000004, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 77.39415, "distance_travelled_min": 19.163, "distance_travelled_max": 124.518}, "hist_stats": {"episode_reward": [-231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, 381.16726788017195, -401.6224819069583, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736], "episode_lengths": [353, 263, 310, 26, 151, 276, 119, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141], "policy_AGENT-3_reward": [179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -11.537670680080666, -193.51384099522113, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698], "policy_AGENT-0_reward": [-295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, 198.17695340422637, -14.236707939667523, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025], "policy_AGENT-2_reward": [-307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, 205.4074509786246, -14.815749868855832, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608], "policy_AGENT-1_reward": [191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -10.879465822598007, -179.05618310321358, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239]}, "sampler_perf": {"mean_env_wait_ms": 49.58968523100438, "mean_raw_obs_processing_ms": 2.069866237409228, "mean_inference_ms": 2.5520002608947783, "mean_action_processing_ms": 0.15103199522629135}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 40320, "timers": {"learn_time_ms": 10.633, "learn_throughput": 3009.413, "update_time_ms": 11.4}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 88.30570983886719, "min_q": -198.91690063476562, "max_q": 396.3548278808594, "mean_td_error": 17.58111572265625, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 49.73664474487305, "min_q": -74.4547119140625, "max_q": 341.7835998535156, "mean_td_error": 4.223387718200684, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 55.841163635253906, "min_q": -125.98521423339844, "max_q": 338.21588134765625, "mean_td_error": 25.80486488342285, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 68.96549987792969, "min_q": -235.1748809814453, "max_q": 370.90673828125, "mean_td_error": 25.90287208557129, "model": {}}}, "num_steps_sampled": 40320, "num_steps_trained": 104864, "last_target_update_ts": 40320, "num_target_updates": 79}, "done": false, "episodes_total": 208, "training_iteration": 40, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-01-37", "timestamp": 1624266097, "time_this_iter_s": 27.755947828292847, "time_total_s": 1139.4292361736298, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c6bbcb0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c74df80>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1170>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c18c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689c20>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689e60>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1170>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c18c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689c20>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689e60>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1170>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c18c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689c20>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689e60>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1170>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c18c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689c20>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689e60>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c759c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1139.4292361736298, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 44.707499999999996, "ram_util_percent": 92.60749999999999}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 550.6369854541249, "episode_len_mean": 256.59, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-2": -552.396916831616, "AGENT-0": -1887.6784051212405, "AGENT-1": -240.17540347939786}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-2": 625.4441189084074, "AGENT-0": 7567.171809869095, "AGENT-1": 561.4160940184095}, "policy_reward_mean": {"AGENT-3": 198.22737366457096, "AGENT-2": 54.27208286861965, "AGENT-0": 251.86357728706867, "AGENT-1": 46.27395163386532}, "custom_metrics": {"mean_ego_speed_mean": 41.873447500000005, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 77.2975525, "distance_travelled_min": 19.163, "distance_travelled_max": 124.518}, "hist_stats": {"episode_reward": [-930.3285013776364, -384.92081931540594, -456.9704816507432, -198.42637380077684, 701.634920199117, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596], "episode_lengths": [238, 270, 33, 89, 211, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151], "policy_AGENT-3_reward": [-470.2254890207935, -304.4816618070087, -82.10540334666499, -90.74068386771393, 14.454486758643343, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173], "policy_AGENT-2_reward": [-33.73764472908894, 74.15712058262372, -146.9362721939446, -9.04552432917019, 14.403338131252326, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863], "policy_AGENT-0_reward": [-393.3154197404889, -229.50325225594494, -146.38577448937744, -8.463720015998565, 306.6048045625837, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828], "policy_AGENT-1_reward": [-33.04994788726492, 74.90697416492395, -81.54303162075618, -90.17644558789415, 366.1722907466375, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606]}, "sampler_perf": {"mean_env_wait_ms": 49.37254259915925, "mean_raw_obs_processing_ms": 2.05616191783021, "mean_inference_ms": 2.5413822491697244, "mean_action_processing_ms": 0.150761274742605}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 41328, "timers": {"learn_time_ms": 11.034, "learn_throughput": 2900.03, "update_time_ms": 11.211}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 79.19540405273438, "min_q": -120.26676177978516, "max_q": 414.4170837402344, "mean_td_error": 19.242813110351562, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 73.84797668457031, "min_q": -67.02742004394531, "max_q": 284.6124572753906, "mean_td_error": 15.864157676696777, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 96.37666320800781, "min_q": -118.44953918457031, "max_q": 367.4954528808594, "mean_td_error": -9.308744430541992, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 114.24787902832031, "min_q": -254.3026580810547, "max_q": 386.6018371582031, "mean_td_error": 18.239994049072266, "model": {}}}, "num_steps_sampled": 41328, "num_steps_trained": 107552, "last_target_update_ts": 41328, "num_target_updates": 81}, "done": false, "episodes_total": 210, "training_iteration": 41, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-02-01", "timestamp": 1624266121, "time_this_iter_s": 23.575584888458252, "time_total_s": 1163.004821062088, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f898c34f830>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c6bbe60>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1560>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c67a9e0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1560>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c67a9e0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1560>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c67a9e0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6bb9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1560>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c67a9e0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c689950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1163.004821062088, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 48.482352941176465, "ram_util_percent": 92.20294117647057}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 571.4616646704997, "episode_len_mean": 266.9, "episodes_this_iter": 3, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-0": -1887.6784051212405, "AGENT-2": -552.396916831616, "AGENT-1": -240.17540347939786}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-0": 7567.171809869095, "AGENT-2": 625.4441189084074, "AGENT-1": 561.4160940184095}, "policy_reward_mean": {"AGENT-3": 203.51005952096833, "AGENT-0": 257.1479731041951, "AGENT-2": 61.30823877912411, "AGENT-1": 49.495393266211934}, "custom_metrics": {"mean_ego_speed_mean": 41.682359999999996, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 78.67692, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [461.2219978024416, 1749.0903326197467, -81.60634403711293, -425.4495380713371, -200.87796781326657, -396.0890741546059, -436.1767071480476, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594], "episode_lengths": [415, 467, 482, 109, 86, 114, 24, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270], "policy_AGENT-3_reward": [216.69566436042106, 208.80235490062046, -55.62103407704742, -166.56849854535244, -91.98311493062447, -171.0008545560794, -84.28323165318176, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087], "policy_AGENT-0_reward": [6.715110435916458, 652.1169039164746, 21.3628774174582, -52.31243611322033, -8.456197902382128, -32.32605753750696, -133.86198664145317, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494], "policy_AGENT-2_reward": [-51.88198065094656, 606.205477053206, 7.713636256324337, -52.85785156447308, -9.020417585075624, -32.87827166218236, -134.30774789393658, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372], "policy_AGENT-1_reward": [289.69320365704954, 281.9655967494474, -55.06182363384826, -153.71075184829135, -91.41823739518424, -159.88389039883708, -83.72374095947607, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395]}, "sampler_perf": {"mean_env_wait_ms": 49.04386010018832, "mean_raw_obs_processing_ms": 2.036426051040034, "mean_inference_ms": 2.52519612967407, "mean_action_processing_ms": 0.1503537395962281}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 42336, "timers": {"learn_time_ms": 10.867, "learn_throughput": 2944.734, "update_time_ms": 10.824}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 67.009521484375, "min_q": -213.02322387695312, "max_q": 406.595458984375, "mean_td_error": 15.13110065460205, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 84.08381652832031, "min_q": -51.252464294433594, "max_q": 338.1990966796875, "mean_td_error": 8.917502403259277, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 85.93133544921875, "min_q": -146.5931854248047, "max_q": 375.9964294433594, "mean_td_error": 13.13072681427002, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 87.64265441894531, "min_q": -204.2061309814453, "max_q": 372.0849304199219, "mean_td_error": 5.592426300048828, "model": {}}}, "num_steps_sampled": 42336, "num_steps_trained": 110240, "last_target_update_ts": 42336, "num_target_updates": 83}, "done": false, "episodes_total": 213, "training_iteration": 42, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-02-27", "timestamp": 1624266147, "time_this_iter_s": 26.053508043289185, "time_total_s": 1189.0583291053772, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c6897a0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c678560>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1440>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1560>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1440>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1560>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1440>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1560>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1440>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1560>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c678b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1189.0583291053772, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 44.81578947368421, "ram_util_percent": 92.35526315789475}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 608.2816629095013, "episode_len_mean": 271.87, "episodes_this_iter": 4, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-2": -552.396916831616, "AGENT-0": -1887.6784051212405, "AGENT-1": -240.17540347939786}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-2": 1054.350185154991, "AGENT-0": 7567.171809869095, "AGENT-1": 956.4789700613206}, "policy_reward_mean": {"AGENT-3": 208.79089607744714, "AGENT-2": 73.21233813210388, "AGENT-0": 263.0807552514184, "AGENT-1": 63.19767344853166}, "custom_metrics": {"mean_ego_speed_mean": 41.4396475, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.474999999999994, "distance_travelled_mean": 79.71466, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [-838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -435.99853731499894, -246.95342717676877, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293], "episode_lengths": [183, 77, 213, 357, 25, 49, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482], "policy_AGENT-3_reward": [-416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, -84.29324848060074, -95.09630425908374, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742], "policy_AGENT-2_reward": [-29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, -134.19592600545687, -29.007237360421286, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337], "policy_AGENT-0_reward": [-363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -133.77560504204632, -28.439578150672972, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582], "policy_AGENT-1_reward": [-28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -83.7337577868951, -94.41030740659082, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826]}, "sampler_perf": {"mean_env_wait_ms": 48.6567733322189, "mean_raw_obs_processing_ms": 2.007144075985195, "mean_inference_ms": 2.5062162269443427, "mean_action_processing_ms": 0.1498810811518246}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 43344, "timers": {"learn_time_ms": 10.452, "learn_throughput": 3061.759, "update_time_ms": 11.421}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 28.23529052734375, "min_q": -172.3350830078125, "max_q": 298.2456359863281, "mean_td_error": -4.387439727783203, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 107.75140380859375, "min_q": -43.950042724609375, "max_q": 394.0901184082031, "mean_td_error": -0.4072991609573364, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 112.61763000488281, "min_q": -34.85759735107422, "max_q": 373.6399230957031, "mean_td_error": 36.512367248535156, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 92.20330810546875, "min_q": -241.76744079589844, "max_q": 402.2863464355469, "mean_td_error": 6.4273681640625, "model": {}}}, "num_steps_sampled": 43344, "num_steps_trained": 112928, "last_target_update_ts": 43344, "num_target_updates": 85}, "done": false, "episodes_total": 217, "training_iteration": 43, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-02-53", "timestamp": 1624266173, "time_this_iter_s": 26.022864818572998, "time_total_s": 1215.0811939239502, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f898c34f830>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f898c079d40>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6898c0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c689290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689cb0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689830>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6898c0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c689290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689cb0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689830>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6898c0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c689290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689cb0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689830>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6898c0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c689290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689cb0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689830>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c5f18c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1215.0811939239502, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 48.04054054054053, "ram_util_percent": 92.58918918918917}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 611.5354977084393, "episode_len_mean": 275.67, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-2": -552.396916831616, "AGENT-1": -357.6524258796918, "AGENT-0": -1887.6784051212405, "AGENT-3": -1917.8029490524984}, "policy_reward_max": {"AGENT-2": 1054.350185154991, "AGENT-1": 956.4789700613206, "AGENT-0": 7567.171809869095, "AGENT-3": 7570.081488567667}, "policy_reward_mean": {"AGENT-2": 75.02752550845562, "AGENT-1": 62.80995547244311, "AGENT-0": 261.3170952697285, "AGENT-3": 212.3809214578119}, "custom_metrics": {"mean_ego_speed_mean": 41.160785000000004, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.3665, "distance_travelled_mean": 80.636735, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [-563.7912024926624, 206.22271789469164, -155.82322171017586, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283], "episode_lengths": [341, 113, 158, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357], "policy_AGENT-2_reward": [50.50570769270446, -32.190133423409875, -61.8631098769371, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991], "policy_AGENT-1_reward": [-357.6524258796918, 140.73656307734922, -61.25254836096856, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206], "policy_AGENT-0_reward": [-306.93089656145673, -31.650284800254735, -32.19881500528787, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115], "policy_AGENT-3_reward": [50.2864122557822, 129.3265730410071, -0.5087484669822038, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151]}, "sampler_perf": {"mean_env_wait_ms": 48.45588875469676, "mean_raw_obs_processing_ms": 1.9898857685544653, "mean_inference_ms": 2.496597371536202, "mean_action_processing_ms": 0.14963987682206728}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 44352, "timers": {"learn_time_ms": 10.742, "learn_throughput": 2979.015, "update_time_ms": 11.182}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 97.6204833984375, "min_q": -157.45924377441406, "max_q": 456.1963195800781, "mean_td_error": 5.282329559326172, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 94.87387084960938, "min_q": -46.69303894042969, "max_q": 371.69671630859375, "mean_td_error": 11.560229301452637, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 92.06343841552734, "min_q": -216.60890197753906, "max_q": 382.725830078125, "mean_td_error": 18.723745346069336, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 92.73664855957031, "min_q": -284.3859558105469, "max_q": 367.9683532714844, "mean_td_error": 8.914443016052246, "model": {}}}, "num_steps_sampled": 44352, "num_steps_trained": 115616, "last_target_update_ts": 44352, "num_target_updates": 87}, "done": false, "episodes_total": 219, "training_iteration": 44, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-03-17", "timestamp": 1624266197, "time_this_iter_s": 23.030190467834473, "time_total_s": 1238.1113843917847, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c6bbef0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c5f1560>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1320>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c5f17a0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1320>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c5f17a0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1320>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c5f17a0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1320>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c5f17a0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c67a320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1238.1113843917847, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 50.18484848484849, "ram_util_percent": 92.75757575757575}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 698.6546114113513, "episode_len_mean": 279.69, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-0": -1887.6784051212405, "AGENT-2": -552.396916831616, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-0": 7567.171809869095, "AGENT-2": 1054.350185154991, "AGENT-1": 4227.098438707324}, "policy_reward_mean": {"AGENT-3": 213.08139388202474, "AGENT-0": 303.14941655228887, "AGENT-2": 76.73033563391165, "AGENT-1": 105.69346534312602}, "custom_metrics": {"mean_ego_speed_mean": 40.979855, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.3665, "distance_travelled_mean": 80.55177499999999, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [8556.088148581028, 735.0750801690997, -348.47945878142434, 1023.4885759447682, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164], "episode_lengths": [560, 248, 116, 177, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113], "policy_AGENT-3_reward": [69.53849395430328, 20.442489944018448, -140.4904747011844, 217.04550538264536, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071], "policy_AGENT-0_reward": [4151.033313250751, 362.0540800013941, -39.55415781250948, 163.7674296095849, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735], "policy_AGENT-2_reward": [108.41790266866613, 20.603916364869885, -40.118377495202985, 233.2474640424121, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875], "policy_AGENT-1_reward": [4227.098438707324, 331.974593858817, -128.31644877252722, 409.42817691012397, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922]}, "sampler_perf": {"mean_env_wait_ms": 48.3369732293193, "mean_raw_obs_processing_ms": 1.983842238903331, "mean_inference_ms": 2.4910386853182827, "mean_action_processing_ms": 0.14949575288248731}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 45360, "timers": {"learn_time_ms": 10.747, "learn_throughput": 2977.548, "update_time_ms": 11.788}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 128.1157684326172, "min_q": -110.55973815917969, "max_q": 443.9182434082031, "mean_td_error": -11.92643928527832, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 106.71846771240234, "min_q": -44.933448791503906, "max_q": 364.0122375488281, "mean_td_error": 3.5125904083251953, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 70.96088409423828, "min_q": -69.32106018066406, "max_q": 326.55401611328125, "mean_td_error": 4.98618221282959, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 123.8064956665039, "min_q": -199.91815185546875, "max_q": 401.36444091796875, "mean_td_error": 23.62697982788086, "model": {}}}, "num_steps_sampled": 45360, "num_steps_trained": 118304, "last_target_update_ts": 45360, "num_target_updates": 89}, "done": false, "episodes_total": 220, "training_iteration": 45, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-03-42", "timestamp": 1624266222, "time_this_iter_s": 24.50160813331604, "time_total_s": 1262.6129925251007, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f898c079b90>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f898c079f80>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689440>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689cb0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689440>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689cb0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689440>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689cb0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689440>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689cb0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c5f1cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1262.6129925251007, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 48.705714285714286, "ram_util_percent": 92.33428571428571}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 16187.534732547267, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 811.3857375351349, "episode_len_mean": 288.39, "episodes_this_iter": 3, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-2": -552.396916831616, "AGENT-0": -1887.6784051212405, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 7570.081488567667, "AGENT-2": 1054.350185154991, "AGENT-0": 7567.171809869095, "AGENT-1": 5974.29088858555}, "policy_reward_mean": {"AGENT-3": 212.31119136706383, "AGENT-2": 77.68303950350241, "AGENT-0": 361.57351045174977, "AGENT-1": 159.8179962128194}, "custom_metrics": {"mean_ego_speed_mean": 40.80892, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.3665, "distance_travelled_mean": 80.57489249999999, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [984.7269331196521, -265.9655923527992, 11964.435468943962, -450.4914390016758, -118.32045334299534, -213.79272032461813, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028], "episode_lengths": [304, 108, 999, 144, 79, 75, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560], "policy_AGENT-3_reward": [144.65462883194616, -102.36327181605955, -22.314087886500186, -166.32059682904307, -30.931836595582514, -98.952067016972, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328], "policy_AGENT-2_reward": [336.5933419830226, -35.097043905592805, 7.507091793726815, -84.99447598321092, -28.803063282604487, -8.51600733171361, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613], "policy_AGENT-0_reward": [358.2489100656159, -34.52374477228021, 6004.951576451219, -114.86245932561827, -28.220118766343884, -7.934910187091856, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751], "policy_AGENT-1_reward": [145.2300522390685, -93.98153185886669, 5974.29088858555, -84.31390686380345, -30.365434698464412, -98.38973578884068, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324]}, "sampler_perf": {"mean_env_wait_ms": 48.02771048136973, "mean_raw_obs_processing_ms": 1.9646909772299646, "mean_inference_ms": 2.4756925451688896, "mean_action_processing_ms": 0.1491182591554078}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 46368, "timers": {"learn_time_ms": 11.075, "learn_throughput": 2889.323, "update_time_ms": 13.836}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 85.87004852294922, "min_q": -171.63706970214844, "max_q": 468.12481689453125, "mean_td_error": -3.3673529624938965, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 65.61091613769531, "min_q": -90.92433166503906, "max_q": 410.7597961425781, "mean_td_error": 12.473149299621582, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 94.02410888671875, "min_q": -78.02855682373047, "max_q": 392.5887145996094, "mean_td_error": 17.289073944091797, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 166.87924194335938, "min_q": -295.95953369140625, "max_q": 406.7320556640625, "mean_td_error": 37.516639709472656, "model": {}}}, "num_steps_sampled": 46368, "num_steps_trained": 120992, "last_target_update_ts": 46368, "num_target_updates": 91}, "done": false, "episodes_total": 223, "training_iteration": 46, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-04-07", "timestamp": 1624266247, "time_this_iter_s": 25.610525846481323, "time_total_s": 1288.223518371582, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c5f1f80>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c678c20>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c678950>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc320>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c678950>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc320>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c678950>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc320>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c678950>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc320>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c6787a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1288.223518371582, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 50.05675675675676, "ram_util_percent": 92.56756756756754}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 18990.27692727228, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 1064.4996302403854, "episode_len_mean": 303.72, "episodes_this_iter": 3, "policy_reward_min": {"AGENT-2": -552.396916831616, "AGENT-1": -357.6524258796918, "AGENT-0": -1887.6784051212405, "AGENT-3": -1917.8029490524984}, "policy_reward_max": {"AGENT-2": 1054.350185154991, "AGENT-1": 5974.29088858555, "AGENT-0": 8981.751322892642, "AGENT-3": 8986.118090110682}, "policy_reward_mean": {"AGENT-2": 87.83926709913757, "AGENT-1": 192.81459063813222, "AGENT-0": 474.43262266360523, "AGENT-3": 309.4131498395108}, "custom_metrics": {"mean_ego_speed_mean": 40.04022750000001, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.3665, "distance_travelled_mean": 81.70070500000001, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [18990.27692727228, 1992.6370605227469, 3545.8706700607263, 10878.874770563621, 12973.46047414889, 179.28137026008582, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962], "episode_lengths": [999, 475, 357, 872, 968, 661, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999], "policy_AGENT-2_reward": [469.3655550436909, 365.8789995163216, 58.06465840597534, -89.7275374447214, 84.7020797754002, 259.38368317884107, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815], "policy_AGENT-1_reward": [553.0419592252724, 777.1598847084296, 1756.3885212464666, -89.20100296175775, 85.48345680446596, -87.05829211222968, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555], "policy_AGENT-0_reward": [8981.751322892642, 458.36413636018636, 1694.7782736536706, 5516.407792653364, 6366.511265538906, 94.57729289422153, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219], "policy_AGENT-3_reward": [8986.118090110682, 391.23403993780437, 36.63921675461524, 5541.395518316764, 6436.763672030127, -87.62131370074671, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186]}, "sampler_perf": {"mean_env_wait_ms": 47.74326771805213, "mean_raw_obs_processing_ms": 1.9455975005231663, "mean_inference_ms": 2.4613960600423788, "mean_action_processing_ms": 0.14878288032867304}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 47376, "timers": {"learn_time_ms": 10.677, "learn_throughput": 2997.029, "update_time_ms": 10.19}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 74.64378356933594, "min_q": -182.8392333984375, "max_q": 444.0543212890625, "mean_td_error": 19.946855545043945, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 89.0882568359375, "min_q": -60.94268035888672, "max_q": 382.2480773925781, "mean_td_error": 12.027778625488281, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 69.3096923828125, "min_q": -80.3476791381836, "max_q": 234.10610961914062, "mean_td_error": 11.703173637390137, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 92.2686767578125, "min_q": -258.66571044921875, "max_q": 438.89306640625, "mean_td_error": 25.801395416259766, "model": {}}}, "num_steps_sampled": 47376, "num_steps_trained": 123680, "last_target_update_ts": 47376, "num_target_updates": 93}, "done": false, "episodes_total": 226, "training_iteration": 47, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-04-34", "timestamp": 1624266274, "time_this_iter_s": 26.990066289901733, "time_total_s": 1315.2135846614838, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c7597a0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c5f1680>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c678440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c678710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6788c0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c678dd0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c678440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c678710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6788c0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c678dd0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c678440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c678710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6788c0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c678dd0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c678440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c678710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6788c0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c678dd0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c4bc680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1315.2135846614838, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 46.54871794871795, "ram_util_percent": 92.86666666666667}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 18990.27692727228, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 819.080242247399, "episode_len_mean": 283.18, "episodes_this_iter": 3, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-0": -1887.6784051212405, "AGENT-2": -552.396916831616, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 8986.118090110682, "AGENT-0": 8981.751322892642, "AGENT-2": 1054.350185154991, "AGENT-1": 5974.29088858555}, "policy_reward_mean": {"AGENT-3": 187.8350768316458, "AGENT-0": 351.3625798446867, "AGENT-2": 84.91943273734985, "AGENT-1": 194.96315283371663}, "custom_metrics": {"mean_ego_speed_mean": 40.7201875, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.3665, "distance_travelled_mean": 81.96297999999999, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [252.27059029046936, -219.13732034862412, -543.4554542678886, -762.8155182699588, -270.63154405265044, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263], "episode_lengths": [142, 89, 216, 94, 36, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357], "policy_AGENT-3_reward": [138.56996067297456, -90.88506869165732, -314.954316121668, -313.80032990653103, -100.86768142588517, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524], "policy_AGENT-0_reward": [-28.787383607569872, -29.013459808092392, -271.7070873897027, -364.94254762665895, -34.44707473192996, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706], "policy_AGENT-2_reward": [-29.355094151940108, -29.577796475005115, 21.30767995769113, -42.314669503682595, -35.03740457375994, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534], "policy_AGENT-1_reward": [171.84310737700494, -69.66099537386931, 21.898269285791827, -41.757971233086806, -100.27938332107546, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666]}, "sampler_perf": {"mean_env_wait_ms": 47.49562932361456, "mean_raw_obs_processing_ms": 1.9314683269434918, "mean_inference_ms": 2.449547961010287, "mean_action_processing_ms": 0.14848438486342094}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 48384, "timers": {"learn_time_ms": 15.873, "learn_throughput": 2016.02, "update_time_ms": 14.395}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 125.65341186523438, "min_q": -157.42835998535156, "max_q": 478.02130126953125, "mean_td_error": 4.786527633666992, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 161.55364990234375, "min_q": -70.44085693359375, "max_q": 414.829833984375, "mean_td_error": 13.978866577148438, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 124.33753204345703, "min_q": -115.04521179199219, "max_q": 342.1524963378906, "mean_td_error": -3.3028645515441895, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 113.13876342773438, "min_q": -108.581787109375, "max_q": 443.6427001953125, "mean_td_error": 21.745834350585938, "model": {}}}, "num_steps_sampled": 48384, "num_steps_trained": 126368, "last_target_update_ts": 48384, "num_target_updates": 95}, "done": false, "episodes_total": 229, "training_iteration": 48, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-05-07", "timestamp": 1624266307, "time_this_iter_s": 32.22216534614563, "time_total_s": 1347.4357500076294, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c67a3b0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c5f1ef0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1d40>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c5f15f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1560>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1d40>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c5f15f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1560>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1d40>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c5f15f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1560>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1d40>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c5f15f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1560>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c689cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1347.4357500076294, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 47.373913043478254, "ram_util_percent": 92.94782608695652}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 18990.27692727228, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 891.5669294523973, "episode_len_mean": 288.85, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-0": -1887.6784051212405, "AGENT-2": -552.396916831616, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 8986.118090110682, "AGENT-0": 8981.751322892642, "AGENT-2": 1722.4488033837736, "AGENT-1": 5974.29088858555}, "policy_reward_mean": {"AGENT-3": 205.09677547577314, "AGENT-0": 372.5982100678277, "AGENT-2": 102.57468964673926, "AGENT-1": 211.29725426205724}, "custom_metrics": {"mean_ego_speed_mean": 40.4567575, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.3665, "distance_travelled_mean": 82.901965, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [-221.8233316846136, 6437.044989861819, -153.53762222058356, 734.7796373945199, 166.53786705508386, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886], "episode_lengths": [103, 594, 24, 486, 101, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216], "policy_AGENT-3_reward": [-77.03137120981295, 1388.5332242901225, -63.925066677313495, 32.56945391482258, 102.52586455182774, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668], "policy_AGENT-0_reward": [-33.685210755578005, 1757.8586107110934, -12.848752863416122, 321.9922323984226, -32.201592677238146, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027], "policy_AGENT-2_reward": [-34.27518652227463, 1722.4488033837736, -13.391813704402473, 347.08351424424194, -32.768884394612726, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113], "policy_AGENT-1_reward": [-76.83156319694797, 1568.2043514768468, -63.37198897545149, 33.13443683703374, 128.98247957510705, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827]}, "sampler_perf": {"mean_env_wait_ms": 47.35909634623292, "mean_raw_obs_processing_ms": 1.9203869731860106, "mean_inference_ms": 2.4428800220692324, "mean_action_processing_ms": 0.14835166295994978}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 49392, "timers": {"learn_time_ms": 13.994, "learn_throughput": 2286.725, "update_time_ms": 17.155}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 93.43486022949219, "min_q": -152.19395446777344, "max_q": 490.8810119628906, "mean_td_error": 21.52720069885254, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 136.97567749023438, "min_q": -24.305036544799805, "max_q": 390.85369873046875, "mean_td_error": 36.779300689697266, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 112.86860656738281, "min_q": -178.2967987060547, "max_q": 365.73779296875, "mean_td_error": 18.311098098754883, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 149.71420288085938, "min_q": -72.91171264648438, "max_q": 457.5215759277344, "mean_td_error": 13.995110511779785, "model": {}}}, "num_steps_sampled": 49392, "num_steps_trained": 129056, "last_target_update_ts": 49392, "num_target_updates": 97}, "done": false, "episodes_total": 231, "training_iteration": 49, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-05-42", "timestamp": 1624266342, "time_this_iter_s": 34.78946399688721, "time_total_s": 1382.2252140045166, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c67ab90>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c67a9e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759b90>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6898c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689320>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759b90>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6898c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689320>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759b90>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6898c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689320>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c759b90>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6898c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689320>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c4bcef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1382.2252140045166, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 46.52448979591836, "ram_util_percent": 92.93673469387754}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 18990.27692727228, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 903.9859606517163, "episode_len_mean": 291.1, "episodes_this_iter": 3, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-2": -552.396916831616, "AGENT-0": -1887.6784051212405, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 8986.118090110682, "AGENT-2": 1722.4488033837736, "AGENT-0": 8981.751322892642, "AGENT-1": 5974.29088858555}, "policy_reward_mean": {"AGENT-3": 205.245124825152, "AGENT-2": 108.37441212912383, "AGENT-0": 379.17049353270085, "AGENT-1": 211.19593016473985}, "custom_metrics": {"mean_ego_speed_mean": 40.412262500000004, "mean_ego_speed_min": 2.88875, "mean_ego_speed_max": 53.3665, "distance_travelled_mean": 83.6782325, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [938.2804150638907, -303.9922512037695, 1355.3948383007964, 542.082315233391, 561.2385273798845, -125.3506867757891, 1050.0600846826287, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819], "episode_lengths": [316, 101, 419, 459, 479, 264, 353, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594], "policy_AGENT-3_reward": [77.44065504434514, -116.65496286627078, 125.21949454914949, -87.39231287274569, -85.46201332478523, -88.04046810185478, 143.88008411071937, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225], "policy_AGENT-2_reward": [367.5375009346923, -36.3445658105404, 549.7021292595308, 323.5393228538424, 342.63694644382497, -28.503479038940316, 143.8260134232015, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736], "policy_AGENT-0_reward": [415.28550710282803, -35.79434916075682, 554.6790754029955, 392.7654633773706, 388.9690713563988, 37.20054084819917, 388.47786715433523, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934], "policy_AGENT-1_reward": [78.01675198202545, -115.19837336620144, 125.79413908911883, -86.83015812507608, -84.90547709555425, -46.00728048319322, 373.8761199943731, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468]}, "sampler_perf": {"mean_env_wait_ms": 47.13207139417906, "mean_raw_obs_processing_ms": 1.9058937245643677, "mean_inference_ms": 2.4327423404358783, "mean_action_processing_ms": 0.1481057172770404}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 50400, "timers": {"learn_time_ms": 13.409, "learn_throughput": 2386.488, "update_time_ms": 13.543}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 78.00239562988281, "min_q": -126.48556518554688, "max_q": 472.2396240234375, "mean_td_error": 1.8430616855621338, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 152.2261199951172, "min_q": -41.719905853271484, "max_q": 435.58148193359375, "mean_td_error": 28.867969512939453, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 103.81013488769531, "min_q": -203.0094451904297, "max_q": 321.2958984375, "mean_td_error": 12.780619621276855, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 153.236572265625, "min_q": -49.347984313964844, "max_q": 425.3455505371094, "mean_td_error": 12.005770683288574, "model": {}}}, "num_steps_sampled": 50400, "num_steps_trained": 131744, "last_target_update_ts": 50400, "num_target_updates": 99}, "done": false, "episodes_total": 234, "training_iteration": 50, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-06-21", "timestamp": 1624266381, "time_this_iter_s": 38.54914355278015, "time_total_s": 1420.7743575572968, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c4bc9e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c4bcc20>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcf80>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc320>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcf80>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc320>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcf80>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc320>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcf80>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc320>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c678440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1420.7743575572968, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 45.33090909090909, "ram_util_percent": 93.16909090909091}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 18990.27692727228, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 1097.7005513205718, "episode_len_mean": 293.57, "episodes_this_iter": 4, "policy_reward_min": {"AGENT-2": -552.396916831616, "AGENT-1": -357.6524258796918, "AGENT-0": -1887.6784051212405, "AGENT-3": -1917.8029490524984}, "policy_reward_max": {"AGENT-2": 1722.4488033837736, "AGENT-1": 5974.29088858555, "AGENT-0": 8981.751322892642, "AGENT-3": 8986.118090110682}, "policy_reward_mean": {"AGENT-2": 124.55674410401322, "AGENT-1": 233.5260108945448, "AGENT-0": 451.908840453479, "AGENT-3": 287.7089558685348}, "custom_metrics": {"mean_ego_speed_mean": 39.84435250000001, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.3665, "distance_travelled_mean": 83.64154, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -241.74367084526486, -256.32526455137474, 16187.534732547267, -792.6277756096342, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964], "episode_lengths": [999, 130, 352, 321, 29, 100, 999, 310, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419], "policy_AGENT-2_reward": [402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, -32.80523919291318, -36.02041884402871, 488.8653400920767, -19.12150360858304, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308], "policy_AGENT-1_reward": [500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -88.0665192221204, -92.08942320639954, 561.4160940184095, -18.38472688296107, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883], "policy_AGENT-0_reward": [6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -32.24003327357256, -35.46010470073113, 7567.171809869095, -359.5393056785828, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955], "policy_AGENT-3_reward": [6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, -88.63187915665873, -92.75531780021515, 7570.081488567667, -395.58223943950634, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949]}, "sampler_perf": {"mean_env_wait_ms": 46.96599549278475, "mean_raw_obs_processing_ms": 1.8871614280548425, "mean_inference_ms": 2.423470010693781, "mean_action_processing_ms": 0.14802984235025768}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 51408, "timers": {"learn_time_ms": 12.297, "learn_throughput": 2602.299, "update_time_ms": 13.292}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 142.39047241210938, "min_q": -34.27117919921875, "max_q": 511.6676940917969, "mean_td_error": 5.613925933837891, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 140.9954833984375, "min_q": -39.73105239868164, "max_q": 428.9178466796875, "mean_td_error": -0.06391382217407227, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 92.414306640625, "min_q": -192.25796508789062, "max_q": 359.5316467285156, "mean_td_error": 17.16472625732422, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 74.60926055908203, "min_q": -265.6568298339844, "max_q": 472.1026306152344, "mean_td_error": 0.6937294006347656, "model": {}}}, "num_steps_sampled": 51408, "num_steps_trained": 134432, "last_target_update_ts": 51408, "num_target_updates": 101}, "done": false, "episodes_total": 238, "training_iteration": 51, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-06-59", "timestamp": 1624266419, "time_this_iter_s": 38.4573175907135, "time_total_s": 1459.2316751480103, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c6785f0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c678950>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6784d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc830>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc8c0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6784d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc830>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc8c0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6784d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc830>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc8c0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6784d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc830>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc8c0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c62f4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1459.2316751480103, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 48.8090909090909, "ram_util_percent": 93.34181818181816}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 18990.27692727228, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 1010.7674255938651, "episode_len_mean": 287.83, "episodes_this_iter": 4, "policy_reward_min": {"AGENT-2": -552.396916831616, "AGENT-1": -357.6524258796918, "AGENT-0": -1887.6784051212405, "AGENT-3": -1917.8029490524984}, "policy_reward_max": {"AGENT-2": 1727.7321038080192, "AGENT-1": 5974.29088858555, "AGENT-0": 8981.751322892642, "AGENT-3": 8986.118090110682}, "policy_reward_mean": {"AGENT-2": 150.16707519213713, "AGENT-1": 233.84644061356462, "AGENT-0": 404.43199604325565, "AGENT-3": 222.32191374490765}, "custom_metrics": {"mean_ego_speed_mean": 40.096222499999996, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.357, "distance_travelled_mean": 84.65997499999999, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [-472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 419.671350687639, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114], "episode_lengths": [157, 85, 271, 351, 373, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321], "policy_AGENT-2_reward": [83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 91.13037114503068, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063], "policy_AGENT-1_reward": [-303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 140.50856396379544, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093], "policy_AGENT-0_reward": [-337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 122.62384064013298, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722], "policy_AGENT-3_reward": [83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, 65.40857493867931, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294]}, "sampler_perf": {"mean_env_wait_ms": 46.82264428897358, "mean_raw_obs_processing_ms": 1.8731690918717894, "mean_inference_ms": 2.415157228491995, "mean_action_processing_ms": 0.14800364661198365}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 52416, "timers": {"learn_time_ms": 13.286, "learn_throughput": 2408.599, "update_time_ms": 12.19}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 111.25434875488281, "min_q": -48.16181182861328, "max_q": 514.655029296875, "mean_td_error": 2.0653209686279297, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 147.24844360351562, "min_q": -59.80672073364258, "max_q": 430.76519775390625, "mean_td_error": 32.65140914916992, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 158.37344360351562, "min_q": -82.20942687988281, "max_q": 401.21484375, "mean_td_error": 12.391436576843262, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 131.44073486328125, "min_q": -339.76751708984375, "max_q": 451.89984130859375, "mean_td_error": 15.761903762817383, "model": {}}}, "num_steps_sampled": 52416, "num_steps_trained": 137120, "last_target_update_ts": 52416, "num_target_updates": 103}, "done": false, "episodes_total": 242, "training_iteration": 52, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-07-40", "timestamp": 1624266460, "time_this_iter_s": 40.872164487838745, "time_total_s": 1500.103839635849, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c4bcf80>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c4bccb0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcb90>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c67acb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c67a9e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c62fcb0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcb90>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c67acb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c67a9e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c62fcb0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcb90>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c67acb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c67a9e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c62fcb0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcb90>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c67acb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c67a9e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c62fcb0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c62f0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1500.103839635849, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 45.430508474576264, "ram_util_percent": 93.43050847457624}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 18990.27692727228, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 1014.233382047663, "episode_len_mean": 287.79, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-2": -552.396916831616, "AGENT-0": -1887.6784051212405, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 8986.118090110682, "AGENT-2": 1727.7321038080192, "AGENT-0": 8981.751322892642, "AGENT-1": 5974.29088858555}, "policy_reward_mean": {"AGENT-3": 221.0700502635764, "AGENT-2": 153.2351047709429, "AGENT-0": 403.50314330244066, "AGENT-1": 236.42508371070315}, "custom_metrics": {"mean_ego_speed_mean": 40.040947499999994, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.357, "distance_travelled_mean": 84.62379500000002, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [766.2669960674366, -264.4425158457491, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305], "episode_lengths": [369, 326, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351], "policy_AGENT-3_reward": [-59.77777319444996, -54.065641855970455, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217], "policy_AGENT-2_reward": [397.93332902560655, -88.54278473116139, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192], "policy_AGENT-0_reward": [29.7385665586299, -34.028823795705335, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457], "policy_AGENT-1_reward": [398.3728736776508, -87.80526546291173, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927]}, "sampler_perf": {"mean_env_wait_ms": 46.77618786167127, "mean_raw_obs_processing_ms": 1.8706155788412355, "mean_inference_ms": 2.41349198849979, "mean_action_processing_ms": 0.14797481824818315}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 53424, "timers": {"learn_time_ms": 11.528, "learn_throughput": 2775.812, "update_time_ms": 12.813}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 160.84799194335938, "min_q": -270.6224060058594, "max_q": 519.8273315429688, "mean_td_error": 3.961402416229248, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 103.72894287109375, "min_q": -44.060272216796875, "max_q": 437.969970703125, "mean_td_error": -8.802817344665527, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 118.01573181152344, "min_q": -279.85845947265625, "max_q": 342.68328857421875, "mean_td_error": 0.941087007522583, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 160.48106384277344, "min_q": -51.15777587890625, "max_q": 462.0299377441406, "mean_td_error": 24.589113235473633, "model": {}}}, "num_steps_sampled": 53424, "num_steps_trained": 139808, "last_target_update_ts": 53424, "num_target_updates": 105}, "done": false, "episodes_total": 243, "training_iteration": 53, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-08-20", "timestamp": 1624266500, "time_this_iter_s": 39.39771294593811, "time_total_s": 1539.501552581787, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f898c34f710>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c5f1cb0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c689f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c689320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6898c0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c689f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c689320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6898c0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c689f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c689320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6898c0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c689f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c689320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c689b00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6898c0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c62fd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1539.501552581787, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 47.714035087719296, "ram_util_percent": 93.38947368421053}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 18990.27692727228, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 1158.8011811574302, "episode_len_mean": 290.72, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-0": -1887.6784051212405, "AGENT-3": -1917.8029490524984, "AGENT-2": -552.396916831616, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-0": 8981.751322892642, "AGENT-3": 8986.118090110682, "AGENT-2": 3511.953009643477, "AGENT-1": 5974.29088858555}, "policy_reward_mean": {"AGENT-0": 439.2538150476742, "AGENT-3": 256.7334815186533, "AGENT-2": 189.24006271468932, "AGENT-1": 273.57382187641235}, "custom_metrics": {"mean_ego_speed_mean": 39.80531499999999, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.357, "distance_travelled_mean": 84.6098625, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [14192.337395130946, -153.5024019691948, -430.2343367453275, -382.1467715280794, -786.3317384752007, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366], "episode_lengths": [619, 35, 21, 137, 408, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369], "policy_AGENT-0_reward": [3541.0383507276515, -8.293577636656421, -133.18166587215015, -156.86244611682017, -262.41215232734726, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299], "policy_AGENT-3_reward": [3512.277483651726, -68.4645453195638, -81.93723341937947, -115.00562220233142, -341.1285014574945, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996], "policy_AGENT-2_reward": [3511.953009643477, -8.845682501034721, -133.74266241863032, -55.46506604158461, -91.74704220615715, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655], "policy_AGENT-1_reward": [3627.068551108008, -67.89859651193987, -81.37277503516756, -54.81363716734292, -91.04404248420046, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508]}, "sampler_perf": {"mean_env_wait_ms": 46.743093645235966, "mean_raw_obs_processing_ms": 1.8657168815103842, "mean_inference_ms": 2.4110490367290502, "mean_action_processing_ms": 0.14797362995429222}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 54432, "timers": {"learn_time_ms": 12.382, "learn_throughput": 2584.395, "update_time_ms": 12.73}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 152.99957275390625, "min_q": -220.5005645751953, "max_q": 537.0706176757812, "mean_td_error": 1.2099170684814453, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 185.15487670898438, "min_q": -50.11786651611328, "max_q": 444.6881408691406, "mean_td_error": 9.164462089538574, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 110.66800689697266, "min_q": -58.61894607543945, "max_q": 341.86187744140625, "mean_td_error": -4.66851282119751, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 179.91009521484375, "min_q": -283.0638427734375, "max_q": 497.48455810546875, "mean_td_error": 15.642650604248047, "model": {}}}, "num_steps_sampled": 54432, "num_steps_trained": 142496, "last_target_update_ts": 54432, "num_target_updates": 107}, "done": false, "episodes_total": 244, "training_iteration": 54, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-08-56", "timestamp": 1624266536, "time_this_iter_s": 35.92977237701416, "time_total_s": 1575.4313249588013, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c62f830>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c62f8c0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c62fb00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c62f3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcef0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c47e0e0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c62fb00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c62f3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcef0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c47e0e0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c62fb00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c62f3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcef0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c47e0e0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c62fb00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c62f3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcef0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c47e0e0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c678680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1575.4313249588013, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 45.209803921568636, "ram_util_percent": 93.66666666666669}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 19566.579114412332, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 1577.4164305280233, "episode_len_mean": 307.67, "episodes_this_iter": 4, "policy_reward_min": {"AGENT-2": -552.396916831616, "AGENT-1": -357.6524258796918, "AGENT-0": -1887.6784051212405, "AGENT-3": -1917.8029490524984}, "policy_reward_max": {"AGENT-2": 3511.953009643477, "AGENT-1": 5974.29088858555, "AGENT-0": 9306.466775605351, "AGENT-3": 9311.39186054342}, "policy_reward_mean": {"AGENT-2": 261.7915813052071, "AGENT-1": 323.12419820470916, "AGENT-0": 598.7941313061991, "AGENT-3": 393.70651971190773}, "custom_metrics": {"mean_ego_speed_mean": 38.67025999999999, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.357, "distance_travelled_mean": 86.14955999999998, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, -640.4781093603292, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946], "episode_lengths": [999, 639, 210, 448, 149, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619], "policy_AGENT-2_reward": [474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 22.16551135064713, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477], "policy_AGENT-1_reward": [474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 22.917557807636626, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008], "policy_AGENT-0_reward": [9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, -362.8788055901146, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515], "policy_AGENT-3_reward": [9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, -322.6823729284985, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726]}, "sampler_perf": {"mean_env_wait_ms": 46.5798496089741, "mean_raw_obs_processing_ms": 1.8523731656709703, "mean_inference_ms": 2.402805358319227, "mean_action_processing_ms": 0.14794498114662688}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 55440, "timers": {"learn_time_ms": 12.205, "learn_throughput": 2621.87, "update_time_ms": 12.887}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 155.10638427734375, "min_q": -258.0931396484375, "max_q": 536.7657470703125, "mean_td_error": -8.455912590026855, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 137.346923828125, "min_q": -40.54111099243164, "max_q": 457.24993896484375, "mean_td_error": 15.866933822631836, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 94.74715423583984, "min_q": -189.0179443359375, "max_q": 377.8796081542969, "mean_td_error": -1.3447932004928589, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 186.70420837402344, "min_q": -59.0340461730957, "max_q": 506.5731506347656, "mean_td_error": 28.656463623046875, "model": {}}}, "num_steps_sampled": 55440, "num_steps_trained": 145184, "last_target_update_ts": 55440, "num_target_updates": 109}, "done": false, "episodes_total": 248, "training_iteration": 55, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-09-38", "timestamp": 1624266578, "time_this_iter_s": 41.91140913963318, "time_total_s": 1617.3427340984344, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c62f560>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c62f170>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bce60>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc830>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc560>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc7a0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bce60>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc830>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc560>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc7a0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bce60>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc830>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc560>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc7a0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bce60>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc830>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc560>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc7a0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c47e4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1617.3427340984344, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 50.7322033898305, "ram_util_percent": 93.92033898305085}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 19566.579114412332, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 1590.0902580343238, "episode_len_mean": 309.55, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-0": -1887.6784051212405, "AGENT-2": -552.396916831616, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9306.466775605351, "AGENT-2": 3511.953009643477, "AGENT-1": 5974.29088858555}, "policy_reward_mean": {"AGENT-3": 399.2393002653822, "AGENT-0": 603.4145593057568, "AGENT-2": 261.67934252688286, "AGENT-1": 325.7570559363014}, "custom_metrics": {"mean_ego_speed_mean": 38.6200075, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.357, "distance_travelled_mean": 86.41294750000003, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [626.9046412696962, -251.84652519557744, -648.1299490774692, -433.2136910585809, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619], "episode_lengths": [337, 28, 143, 23, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448], "policy_AGENT-3_reward": [230.5956824189529, -90.00796226076633, -276.6417250318054, -83.37415071085707, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914], "policy_AGENT-0_reward": [99.16399436565561, -35.91480670901123, -319.71893652113556, -133.22245251319737, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464], "policy_AGENT-2_reward": [10.94163351822625, -36.47695137353181, -26.139372066583192, -133.79795167609495, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029], "policy_AGENT-1_reward": [286.203330966861, -89.44680485226809, -25.629915457944833, -82.8191361584315, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201]}, "sampler_perf": {"mean_env_wait_ms": 46.570088935248016, "mean_raw_obs_processing_ms": 1.8484278439328536, "mean_inference_ms": 2.4015762162606538, "mean_action_processing_ms": 0.14800848092773383}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 56448, "timers": {"learn_time_ms": 12.727, "learn_throughput": 2514.307, "update_time_ms": 12.65}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 153.1126251220703, "min_q": -128.1577606201172, "max_q": 528.3265380859375, "mean_td_error": 30.001190185546875, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 158.37091064453125, "min_q": -52.0733757019043, "max_q": 423.0643310546875, "mean_td_error": 11.918578147888184, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 89.93519592285156, "min_q": -293.74609375, "max_q": 363.2256774902344, "mean_td_error": -4.015273571014404, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 127.3489990234375, "min_q": -238.50167846679688, "max_q": 506.0865173339844, "mean_td_error": -3.4322428703308105, "model": {}}}, "num_steps_sampled": 56448, "num_steps_trained": 147872, "last_target_update_ts": 56448, "num_target_updates": 111}, "done": false, "episodes_total": 249, "training_iteration": 56, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-10-18", "timestamp": 1624266618, "time_this_iter_s": 39.830204486846924, "time_total_s": 1657.1729385852814, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c62f950>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c62f7a0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c62fdd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1cb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c47e050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c47ecb0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c62fdd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1cb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c47e050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c47ecb0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c62fdd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1cb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c47e050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c47ecb0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c62fdd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1cb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c47e050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c47ecb0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c689a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1657.1729385852814, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 50.040350877192985, "ram_util_percent": 94.06666666666665}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 19566.579114412332, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 1882.5796190291494, "episode_len_mean": 321.6, "episodes_this_iter": 3, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-2": -552.396916831616, "AGENT-0": -1887.6784051212405, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-2": 3821.5996489337294, "AGENT-0": 9306.466775605351, "AGENT-1": 5974.29088858555}, "policy_reward_mean": {"AGENT-3": 457.47248359984354, "AGENT-2": 350.05954631037866, "AGENT-0": 693.0833506385964, "AGENT-1": 381.96423848033044}, "custom_metrics": {"mean_ego_speed_mean": 37.8279325, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.357, "distance_travelled_mean": 87.87138, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [5835.161379412621, 8146.136961155272, 13934.44759358303, -352.72516759979635, 927.518525847537, -356.15824043857504, 14681.206434419075, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962], "episode_lengths": [325, 523, 551, 648, 405, 112, 999, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337], "policy_AGENT-3_reward": [1600.3492516056829, 254.30930657563812, 3518.6359372613774, -89.11164218725354, 28.078440894058126, -142.99416211440274, 7427.78910568499, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529], "policy_AGENT-2_reward": [1349.0427552837643, 3821.5996489337294, 3470.963699015873, -192.45181567658244, 374.97748853642196, -41.48681662247509, -85.93717718715979, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625], "policy_AGENT-0_reward": [1284.8541874710156, 3739.883828105372, 3453.2849219642294, 17.383482802026712, 84.60596066119665, -40.930107024276744, 7424.590667165545, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561], "policy_AGENT-1_reward": [1600.9151850521516, 330.3441775405248, 3491.563035341582, -88.54519253798841, 439.8566357558604, -130.7471546774204, -85.23616124435213, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861]}, "sampler_perf": {"mean_env_wait_ms": 46.559970038590606, "mean_raw_obs_processing_ms": 1.836202322815991, "mean_inference_ms": 2.3981940386704337, "mean_action_processing_ms": 0.14818424667310567}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 57456, "timers": {"learn_time_ms": 11.788, "learn_throughput": 2714.568, "update_time_ms": 12.672}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 189.96224975585938, "min_q": -228.8019561767578, "max_q": 558.080322265625, "mean_td_error": 33.55487823486328, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 157.19171142578125, "min_q": -49.024261474609375, "max_q": 487.769775390625, "mean_td_error": 28.34296417236328, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 129.23684692382812, "min_q": -283.28778076171875, "max_q": 375.0745544433594, "mean_td_error": -0.9603317975997925, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 178.87619018554688, "min_q": -321.4301452636719, "max_q": 505.8967590332031, "mean_td_error": 32.066253662109375, "model": {}}}, "num_steps_sampled": 57456, "num_steps_trained": 150560, "last_target_update_ts": 57456, "num_target_updates": 113}, "done": false, "episodes_total": 252, "training_iteration": 57, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-10-57", "timestamp": 1624266657, "time_this_iter_s": 38.47627353668213, "time_total_s": 1695.6492121219635, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c74de60>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c5f1710>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6788c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689b90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6788c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689b90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6788c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689b90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c5f1dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6788c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c689b90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c47ed40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1695.6492121219635, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 53.36071428571429, "ram_util_percent": 93.8267857142857}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 19566.579114412332, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 1911.1653991435678, "episode_len_mean": 315.88, "episodes_this_iter": 4, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-0": -1887.6784051212405, "AGENT-2": -552.396916831616, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9306.466775605351, "AGENT-2": 3821.5996489337294, "AGENT-1": 5974.29088858555}, "policy_reward_mean": {"AGENT-3": 426.83202580568883, "AGENT-0": 662.5263737327291, "AGENT-2": 387.7579805684855, "AGENT-1": 434.0490190366646}, "custom_metrics": {"mean_ego_speed_mean": 37.435155, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.357, "distance_travelled_mean": 88.48366, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, -747.9773663182812, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303], "episode_lengths": [397, 99, 542, 554, 207, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551], "policy_AGENT-3_reward": [182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 153.90650866597616, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774], "policy_AGENT-0_reward": [398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, -503.958948183327, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294], "policy_AGENT-2_reward": [308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, -552.396916831616, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873], "policy_AGENT-1_reward": [613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 154.47199003068567, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582]}, "sampler_perf": {"mean_env_wait_ms": 46.54190416842532, "mean_raw_obs_processing_ms": 1.8236132671544527, "mean_inference_ms": 2.3940265956790503, "mean_action_processing_ms": 0.1484184974165451}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 58464, "timers": {"learn_time_ms": 12.787, "learn_throughput": 2502.484, "update_time_ms": 14.051}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 176.17276000976562, "min_q": -264.6339416503906, "max_q": 561.4359130859375, "mean_td_error": -6.05599308013916, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 198.09266662597656, "min_q": -95.23399353027344, "max_q": 460.9658508300781, "mean_td_error": 30.86767578125, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 154.58213806152344, "min_q": -107.67974853515625, "max_q": 387.15814208984375, "mean_td_error": 19.701507568359375, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 281.95404052734375, "min_q": -55.50978088378906, "max_q": 516.096923828125, "mean_td_error": 9.740243911743164, "model": {}}}, "num_steps_sampled": 58464, "num_steps_trained": 153248, "last_target_update_ts": 58464, "num_target_updates": 115}, "done": false, "episodes_total": 256, "training_iteration": 58, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-11-39", "timestamp": 1624266699, "time_this_iter_s": 41.24862599372864, "time_total_s": 1736.8978381156921, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c47ee60>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c47e200>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c47e8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c47e9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c47eb00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c47e3b0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c47e8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c47e9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c47eb00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c47e3b0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c47e8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c47e9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c47eb00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c47e3b0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c47e8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c47e9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c47eb00>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c47e3b0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c4bcef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1736.8978381156921, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 44.69152542372881, "ram_util_percent": 93.99661016949155}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 19566.579114412332, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 1964.1866364055156, "episode_len_mean": 316.48, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-0": -1887.6784051212405, "AGENT-2": -526.3264540039414, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9306.466775605351, "AGENT-2": 3821.5996489337294, "AGENT-1": 5974.29088858555}, "policy_reward_mean": {"AGENT-3": 428.2077665353523, "AGENT-0": 681.4758751271382, "AGENT-2": 406.7149158271532, "AGENT-1": 447.7880789158721}, "custom_metrics": {"mean_ego_speed_mean": 37.315205, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.357, "distance_travelled_mean": 88.28987999999998, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [4554.146359876497, -578.5039253347771, 876.4803962664561, -442.18079686111014, 1270.7463765443645, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694], "episode_lengths": [267, 120, 351, 24, 189, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554], "policy_AGENT-3_reward": [291.4805816323237, -80.61703813053805, 137.26545221884615, -85.64441601621488, 184.48299916696826, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797], "policy_AGENT-0_reward": [1390.9911912575838, -209.36459417047465, 250.3125942335711, -135.4435714533954, 130.78586149729904, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646], "policy_AGENT-2_reward": [1343.296609035159, -208.46491075641475, 351.07044258409394, -136.0080593544336, 444.217063763511, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193], "policy_AGENT-1_reward": [1528.3779779514327, -80.05738227734952, 137.83190722994306, -85.08475003706633, 511.2604521165872, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805]}, "sampler_perf": {"mean_env_wait_ms": 46.52699884500385, "mean_raw_obs_processing_ms": 1.8212803367623451, "mean_inference_ms": 2.392814196342051, "mean_action_processing_ms": 0.14847100916043895}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 59472, "timers": {"learn_time_ms": 12.731, "learn_throughput": 2513.624, "update_time_ms": 12.802}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 163.94451904296875, "min_q": -163.52120971679688, "max_q": 568.5833129882812, "mean_td_error": 21.996545791625977, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 218.78903198242188, "min_q": -56.84368133544922, "max_q": 499.2112731933594, "mean_td_error": 17.114614486694336, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 149.45806884765625, "min_q": -283.7620544433594, "max_q": 388.33477783203125, "mean_td_error": 11.207889556884766, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 263.34161376953125, "min_q": -39.348609924316406, "max_q": 527.4117431640625, "mean_td_error": 35.888023376464844, "model": {}}}, "num_steps_sampled": 59472, "num_steps_trained": 155936, "last_target_update_ts": 59472, "num_target_updates": 117}, "done": false, "episodes_total": 257, "training_iteration": 59, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-12-19", "timestamp": 1624266739, "time_this_iter_s": 39.99296808242798, "time_total_s": 1776.8908061981201, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c62f170>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c67a830>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6785f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bce60>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc7a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc050>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6785f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bce60>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc7a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc050>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6785f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bce60>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc7a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc050>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c6785f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bce60>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc7a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc050>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c4794d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1776.8908061981201, "timesteps_since_restore": 0, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 51.17368421052632, "ram_util_percent": 94.2298245614035}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 19566.579114412332, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 2157.3680888005006, "episode_len_mean": 322.7, "episodes_this_iter": 4, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-2": -526.3264540039414, "AGENT-0": -1887.6784051212405, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-2": 3821.5996489337294, "AGENT-0": 9306.466775605351, "AGENT-1": 5974.29088858555}, "policy_reward_mean": {"AGENT-3": 472.8622122679208, "AGENT-2": 452.9720974917863, "AGENT-0": 731.1165909759789, "AGENT-1": 500.41718806481515}, "custom_metrics": {"mean_ego_speed_mean": 36.864554999999996, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.357, "distance_travelled_mean": 88.98187, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, -215.94484774102983, 1027.233167690807, 976.7240208158286, 1207.243258718658, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497], "episode_lengths": [179, 134, 465, 528, 22, 689, 167, 461, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267], "policy_AGENT-3_reward": [534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, -79.51959886193174, 161.8548721380687, 118.08017733953756, 119.4675066912292, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237], "policy_AGENT-2_reward": [265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, -29.0145573962944, 480.82358640332154, 377.5158035692801, 369.9398949571427, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159], "policy_AGENT-0_reward": [213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, -28.45058288088569, 165.77590127220714, 305.29772600094293, 172.86475383156102, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838], "policy_AGENT-1_reward": [657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, -78.96010860191797, 218.778807877212, 175.83031390606752, 544.9711032387277, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327]}, "sampler_perf": {"mean_env_wait_ms": 46.56044163584161, "mean_raw_obs_processing_ms": 1.807585933577522, "mean_inference_ms": 2.3904295056107334, "mean_action_processing_ms": 0.1487983397601629}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 60480, "timers": {"learn_time_ms": 12.995, "learn_throughput": 2462.412, "update_time_ms": 12.118}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 256.0020446777344, "min_q": -239.40162658691406, "max_q": 574.9647827148438, "mean_td_error": 18.019371032714844, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 257.67156982421875, "min_q": -102.19482421875, "max_q": 517.5897216796875, "mean_td_error": 27.928354263305664, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 162.23390197753906, "min_q": -213.3092041015625, "max_q": 418.0050964355469, "mean_td_error": 15.04312801361084, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 151.35804748535156, "min_q": -219.17710876464844, "max_q": 545.3362426757812, "mean_td_error": 14.906587600708008, "model": {}}}, "num_steps_sampled": 60480, "num_steps_trained": 158624, "last_target_update_ts": 60480, "num_target_updates": 119}, "done": false, "episodes_total": 261, "training_iteration": 60, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-12-59", "timestamp": 1624266779, "time_this_iter_s": 40.578333139419556, "time_total_s": 1817.4691393375397, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c479050>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c479e60>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c479b00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4799e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4798c0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4797a0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c479b00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4799e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4798c0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4797a0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c479b00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4799e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4798c0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4797a0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c479b00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4799e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4798c0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4797a0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c479200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1817.4691393375397, "timesteps_since_restore": 0, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 47.47586206896552, "ram_util_percent": 94.38275862068967}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 19566.579114412332, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 2132.3166941939576, "episode_len_mean": 318.64, "episodes_this_iter": 4, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-2": -526.3264540039414, "AGENT-0": -1887.6784051212405, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-2": 3821.5996489337294, "AGENT-0": 9306.466775605351, "AGENT-1": 5974.29088858555}, "policy_reward_mean": {"AGENT-3": 469.9069110985474, "AGENT-2": 441.88311741175335, "AGENT-0": 722.4556278125389, "AGENT-1": 498.07103787111805}, "custom_metrics": {"mean_ego_speed_mean": 36.865384999999996, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 88.5572725, "distance_travelled_min": 19.163, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, -417.07724757632127, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435], "episode_lengths": [354, 122, 408, 49, 21, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528], "policy_AGENT-3_reward": [386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, -77.61759584464683, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559], "policy_AGENT-2_reward": [153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, -131.50265364196713, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066], "policy_AGENT-0_reward": [240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, -130.91454754200436, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422], "policy_AGENT-1_reward": [537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, -77.04245054770288, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405]}, "sampler_perf": {"mean_env_wait_ms": 46.53153265607028, "mean_raw_obs_processing_ms": 1.800702895782032, "mean_inference_ms": 2.388060043891495, "mean_action_processing_ms": 0.1490296603745773}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 61488, "timers": {"learn_time_ms": 13.891, "learn_throughput": 2303.728, "update_time_ms": 13.609}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 137.76663208007812, "min_q": -247.9294891357422, "max_q": 565.2139892578125, "mean_td_error": 29.474472045898438, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 171.08984375, "min_q": -86.77909088134766, "max_q": 503.065673828125, "mean_td_error": 4.808854579925537, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 136.36181640625, "min_q": -121.87528228759766, "max_q": 435.22784423828125, "mean_td_error": 0.4291238784790039, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 166.70521545410156, "min_q": -292.30218505859375, "max_q": 503.2529602050781, "mean_td_error": 27.146339416503906, "model": {}}}, "num_steps_sampled": 61488, "num_steps_trained": 161312, "last_target_update_ts": 61488, "num_target_updates": 121}, "done": false, "episodes_total": 265, "training_iteration": 61, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-13-40", "timestamp": 1624266820, "time_this_iter_s": 40.33197474479675, "time_total_s": 1857.8011140823364, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c47e4d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c6893b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c689b00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c689320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6899e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c689b00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c689320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6899e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c689b00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c689320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6899e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c689b00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c689320>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6899e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c47ec20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1857.8011140823364, "timesteps_since_restore": 0, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 46.81724137931034, "ram_util_percent": 94.22068965517241}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 19566.579114412332, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 2168.26143048654, "episode_len_mean": 322.0, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-2": -526.3264540039414, "AGENT-1": -357.6524258796918, "AGENT-0": -1887.6784051212405, "AGENT-3": -1917.8029490524984}, "policy_reward_max": {"AGENT-2": 3821.5996489337294, "AGENT-1": 5974.29088858555, "AGENT-0": 9306.466775605351, "AGENT-3": 9311.39186054342}, "policy_reward_mean": {"AGENT-2": 451.06979068012913, "AGENT-1": 503.9841820673061, "AGENT-0": 732.3220161183972, "AGENT-3": 480.8854416207077}, "custom_metrics": {"mean_ego_speed_mean": 36.63361, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 89.58381999999997, "distance_travelled_min": 19.174999999999997, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [3177.396381681887, -880.765990575195, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727], "episode_lengths": [357, 291, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49], "policy_AGENT-2_reward": [787.1646731956108, -394.63977129049465, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103], "policy_AGENT-1_reward": [514.2719690710962, -52.755008849460985, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634], "policy_AGENT-0_reward": [855.7242830438074, -380.06016302963326, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944], "policy_AGENT-3_reward": [1020.2354563713722, -53.31104740560585, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808]}, "sampler_perf": {"mean_env_wait_ms": 46.53426941689609, "mean_raw_obs_processing_ms": 1.7989770804797771, "mean_inference_ms": 2.3874415369972817, "mean_action_processing_ms": 0.14911173789578636}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 62496, "timers": {"learn_time_ms": 12.621, "learn_throughput": 2535.4, "update_time_ms": 12.782}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 185.6114959716797, "min_q": -165.14111328125, "max_q": 585.9085083007812, "mean_td_error": 8.06551742553711, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 189.98251342773438, "min_q": -92.9247055053711, "max_q": 518.5166015625, "mean_td_error": 23.60271453857422, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 132.21865844726562, "min_q": -284.6962585449219, "max_q": 411.953125, "mean_td_error": 18.09337615966797, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 139.62734985351562, "min_q": -387.45452880859375, "max_q": 547.9403686523438, "mean_td_error": 27.101970672607422, "model": {}}}, "num_steps_sampled": 62496, "num_steps_trained": 164000, "last_target_update_ts": 62496, "num_target_updates": 123}, "done": false, "episodes_total": 266, "training_iteration": 62, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-14-21", "timestamp": 1624266861, "time_this_iter_s": 41.23927164077759, "time_total_s": 1899.040385723114, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c47e320>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c47e3b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4795f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c479710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2320>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2200>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4795f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c479710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2320>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2200>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4795f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c479710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2320>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2200>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4795f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c479710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2320>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2200>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c4a20e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1899.040385723114, "timesteps_since_restore": 0, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 47.52203389830509, "ram_util_percent": 94.34915254237286}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 2489.8071894647132, "episode_len_mean": 329.08, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-0": -1887.6784051212405, "AGENT-3": -1917.8029490524984, "AGENT-2": -526.3264540039414, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-0": 9306.466775605351, "AGENT-3": 9311.39186054342, "AGENT-2": 7816.855740483498, "AGENT-1": 7821.321766695836}, "policy_reward_mean": {"AGENT-0": 814.2783871035243, "AGENT-3": 559.6191067405605, "AGENT-2": 533.1847457978691, "AGENT-1": 582.724949822759}, "custom_metrics": {"mean_ego_speed_mean": 36.317685, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 89.5473225, "distance_travelled_min": 19.174999999999997, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [31273.80990724214, -7.257863160367066, -412.2721233151127, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887], "episode_lengths": [999, 246, 20, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357], "policy_AGENT-0_reward": [7815.576935483085, -123.12445402838975, -127.97295918514567, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074], "policy_AGENT-3_reward": [7820.055464579678, -187.41226379287318, -78.15876543983234, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722], "policy_AGENT-2_reward": [7816.855740483498, 151.23865984681356, -128.53677537791992, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108], "policy_AGENT-1_reward": [7821.321766695836, 152.04019481408258, -77.60362331221476, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962]}, "sampler_perf": {"mean_env_wait_ms": 46.589970078076334, "mean_raw_obs_processing_ms": 1.7952587999926164, "mean_inference_ms": 2.387752230228306, "mean_action_processing_ms": 0.14925617192509463}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 63504, "timers": {"learn_time_ms": 12.429, "learn_throughput": 2574.54, "update_time_ms": 12.226}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 204.08621215820312, "min_q": -314.6558532714844, "max_q": 592.2752685546875, "mean_td_error": 34.6654167175293, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 176.84413146972656, "min_q": -52.541961669921875, "max_q": 509.48162841796875, "mean_td_error": 15.0774564743042, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 169.49240112304688, "min_q": -133.1680908203125, "max_q": 453.87335205078125, "mean_td_error": 4.396040916442871, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 187.63427734375, "min_q": -62.342262268066406, "max_q": 511.7139892578125, "mean_td_error": 28.778732299804688, "model": {}}}, "num_steps_sampled": 63504, "num_steps_trained": 166688, "last_target_update_ts": 63504, "num_target_updates": 125}, "done": false, "episodes_total": 267, "training_iteration": 63, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-15-02", "timestamp": 1624266902, "time_this_iter_s": 40.5173282623291, "time_total_s": 1939.5577139854431, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c62f200>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c62fb00>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c47e710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c47e830>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c47e200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc170>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c47e710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c47e830>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c47e200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc170>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c47e710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c47e830>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c47e200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc170>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c47e710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c47e830>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c47e200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc170>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c4a2680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1939.5577139854431, "timesteps_since_restore": 0, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 46.77068965517242, "ram_util_percent": 94.55172413793106}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 2680.360272051323, "episode_len_mean": 340.22, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-0": -1887.6784051212405, "AGENT-2": -526.3264540039414, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9306.466775605351, "AGENT-2": 7816.855740483498, "AGENT-1": 7821.321766695836}, "policy_reward_mean": {"AGENT-3": 568.3688262837223, "AGENT-0": 900.728262265735, "AGENT-2": 616.2205326701472, "AGENT-1": 595.0426508317186}, "custom_metrics": {"mean_ego_speed_mean": 35.865775, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.35880000000002, "distance_travelled_min": 19.174999999999997, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [2469.0474044870725, 16166.730867698443, -333.161410785067, -304.307286336853, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214], "episode_lengths": [381, 999, 109, 93, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999], "policy_AGENT-3_reward": [294.6951383995843, 314.7057866838869, -272.5297222449839, -134.52119475426076, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678], "policy_AGENT-0_reward": [767.2853261104539, 7626.604776897079, -326.8926542360459, -28.53298311293104, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085], "policy_AGENT-2_reward": [680.0949033019635, 7646.185668394739, 132.87022183288698, -29.099375888284182, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498], "policy_AGENT-1_reward": [726.972036675072, 579.2346357227531, 133.390743863076, -112.15373258137723, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836]}, "sampler_perf": {"mean_env_wait_ms": 46.59434967031481, "mean_raw_obs_processing_ms": 1.7874672204735316, "mean_inference_ms": 2.386938842654111, "mean_action_processing_ms": 0.1494330716501472}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 64512, "timers": {"learn_time_ms": 13.005, "learn_throughput": 2460.607, "update_time_ms": 12.623}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 211.27862548828125, "min_q": -212.54632568359375, "max_q": 602.5315551757812, "mean_td_error": 16.984161376953125, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 295.3537902832031, "min_q": -40.1402473449707, "max_q": 528.73193359375, "mean_td_error": 28.994104385375977, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 187.09625244140625, "min_q": -274.03460693359375, "max_q": 421.85845947265625, "mean_td_error": 6.619306564331055, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 222.44349670410156, "min_q": -346.4429931640625, "max_q": 574.0929565429688, "mean_td_error": 1.5413870811462402, "model": {}}}, "num_steps_sampled": 64512, "num_steps_trained": 169376, "last_target_update_ts": 64512, "num_target_updates": 127}, "done": false, "episodes_total": 269, "training_iteration": 64, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-15-43", "timestamp": 1624266943, "time_this_iter_s": 40.8616361618042, "time_total_s": 1980.4193501472473, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c47ef80>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c689440>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a20e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a23b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2e60>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a20e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a23b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2e60>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a20e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a23b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2e60>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a20e0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a23b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2e60>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c678680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 1980.4193501472473, "timesteps_since_restore": 0, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 53.82203389830509, "ram_util_percent": 94.6813559322034}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 2799.3614330356295, "episode_len_mean": 344.03, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-2": -526.3264540039414, "AGENT-0": -1887.6784051212405, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-2": 7816.855740483498, "AGENT-0": 9306.466775605351, "AGENT-1": 7821.321766695836}, "policy_reward_mean": {"AGENT-3": 601.0755380610532, "AGENT-2": 641.6581332869928, "AGENT-0": 930.6073256847027, "AGENT-1": 626.0204360028808}, "custom_metrics": {"mean_ego_speed_mean": 35.4646175, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.92298000000001, "distance_travelled_min": 19.174999999999997, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [10170.99199801668, 1091.6554032920737, 1017.8037397402185, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443], "episode_lengths": [374, 209, 462, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999], "policy_AGENT-3_reward": [2594.8726233269304, 268.74763740690923, 129.09520055208066, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869], "policy_AGENT-2_reward": [2421.925864772317, 225.60504285684587, 384.6954076368992, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739], "policy_AGENT-0_reward": [2367.8432248571685, 264.637479690625, 375.16708230847235, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079], "policy_AGENT-1_reward": [2786.3502850602385, 332.66524333769155, 128.84604924276437, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531]}, "sampler_perf": {"mean_env_wait_ms": 46.63867735347005, "mean_raw_obs_processing_ms": 1.7798185698569988, "mean_inference_ms": 2.386862904778244, "mean_action_processing_ms": 0.1496890130452131}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 65520, "timers": {"learn_time_ms": 13.326, "learn_throughput": 2401.273, "update_time_ms": 12.286}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 208.95748901367188, "min_q": -318.0186462402344, "max_q": 611.706787109375, "mean_td_error": 5.391359806060791, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 247.3578643798828, "min_q": -4.55928373336792, "max_q": 507.6854248046875, "mean_td_error": 35.23954772949219, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 168.02691650390625, "min_q": -302.35107421875, "max_q": 425.05328369140625, "mean_td_error": 7.035488128662109, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 203.62722778320312, "min_q": -355.2945556640625, "max_q": 567.9508666992188, "mean_td_error": 19.292943954467773, "model": {}}}, "num_steps_sampled": 65520, "num_steps_trained": 172064, "last_target_update_ts": 65520, "num_target_updates": 129}, "done": false, "episodes_total": 271, "training_iteration": 65, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-16-20", "timestamp": 1624266980, "time_this_iter_s": 36.159688234329224, "time_total_s": 2016.5790383815765, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c62ff80>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c47eb90>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c47e200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c479ef0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c479cb0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c47e200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c479ef0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c479cb0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c47e200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c479ef0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c479cb0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c47e200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c479ef0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c479cb0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c4a2cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2016.5790383815765, "timesteps_since_restore": 0, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 51.348076923076924, "ram_util_percent": 94.49807692307692}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 3059.7999603251556, "episode_len_mean": 349.4, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-0": -1887.6784051212405, "AGENT-3": -1917.8029490524984, "AGENT-2": -526.3264540039414, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-0": 9306.466775605351, "AGENT-3": 9311.39186054342, "AGENT-2": 7816.855740483498, "AGENT-1": 7821.321766695836}, "policy_reward_mean": {"AGENT-0": 1012.0971131268132, "AGENT-3": 685.0604200473971, "AGENT-2": 688.064682461297, "AGENT-1": 674.5777446896477}, "custom_metrics": {"mean_ego_speed_mean": 35.164125000000006, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.34938000000002, "distance_travelled_min": 19.174999999999997, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [27061.65646869279, 164.97612390320154, 672.0794835503924, -424.3369000476369, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737], "episode_lengths": [999, 527, 999, 26, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209], "policy_AGENT-0_reward": [8524.145826519532, -50.68575574815381, -1.1485638679071295, -131.17591947820839, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625], "policy_AGENT-3_reward": [8527.583399186491, 115.5860517463331, 143.71029225897985, -80.97973332714594, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923], "policy_AGENT-2_reward": [5025.350325067341, -47.35914300892605, 385.24109083108897, -131.76100460824247, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587], "policy_AGENT-1_reward": [4984.576917919443, 147.43497091394806, 144.27666432823037, -80.42024263404016, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155]}, "sampler_perf": {"mean_env_wait_ms": 46.721138378061696, "mean_raw_obs_processing_ms": 1.7769437474985184, "mean_inference_ms": 2.388278676774595, "mean_action_processing_ms": 0.14986553302802771}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 66528, "timers": {"learn_time_ms": 13.362, "learn_throughput": 2394.859, "update_time_ms": 12.247}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 259.7325744628906, "min_q": -73.99832153320312, "max_q": 618.2073974609375, "mean_td_error": 3.0618677139282227, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 262.40313720703125, "min_q": -35.8431396484375, "max_q": 539.6138916015625, "mean_td_error": -2.872114658355713, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 209.87120056152344, "min_q": -350.16961669921875, "max_q": 481.8209533691406, "mean_td_error": 38.93986892700195, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 208.19760131835938, "min_q": -315.5776672363281, "max_q": 570.823974609375, "mean_td_error": 42.57929611206055, "model": {}}}, "num_steps_sampled": 66528, "num_steps_trained": 174752, "last_target_update_ts": 66528, "num_target_updates": 131}, "done": false, "episodes_total": 272, "training_iteration": 66, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-16-55", "timestamp": 1624267015, "time_this_iter_s": 35.263806104660034, "time_total_s": 2051.8428444862366, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c4a2b00>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c4a2b90>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4445f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4440e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4444d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c444170>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4445f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4440e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4444d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c444170>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4445f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4440e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4444d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c444170>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4445f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4440e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4444d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c444170>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c4447a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2051.8428444862366, "timesteps_since_restore": 0, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 51.92941176470588, "ram_util_percent": 94.63529411764704}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 3420.3340509647096, "episode_len_mean": 352.72, "episodes_this_iter": 3, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-2": -526.3264540039414, "AGENT-0": -1887.6784051212405, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-2": 7925.388282994336, "AGENT-0": 9306.466775605351, "AGENT-1": 7821.321766695836}, "policy_reward_mean": {"AGENT-3": 693.787771679607, "AGENT-2": 827.2417169885983, "AGENT-0": 1153.70142598938, "AGENT-1": 745.6031363071255}, "custom_metrics": {"mean_ego_speed_mean": 34.411255000000004, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.730525, "distance_travelled_min": 19.174999999999997, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [13811.180251547887, 16893.673319350593, 5761.274200462976, 842.5714969155753, -416.0816130586026, 1567.8955781504922, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279], "episode_lengths": [529, 999, 356, 659, 23, 272, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999], "policy_AGENT-3_reward": [519.8072741521348, 259.2457661809863, 271.99873356601813, -6.211103706241417, -78.68163390440274, 227.84933765825616, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491], "policy_AGENT-2_reward": [4353.594409268832, 7925.388282994336, 1844.8417036808805, -6.110920939172936, -129.9102693196234, 227.82307588492424, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341], "policy_AGENT-0_reward": [4313.589877168614, 7891.870697655202, 1771.96047233858, 361.2078408922016, -129.36756891172126, 566.3194228207803, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532], "policy_AGENT-1_reward": [4624.188690958367, 817.1685725200525, 1872.4732908775018, 493.68568066879044, -78.12214092285511, 545.90374178653, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443]}, "sampler_perf": {"mean_env_wait_ms": 46.854591363108845, "mean_raw_obs_processing_ms": 1.7680680279494958, "mean_inference_ms": 2.3901015709518036, "mean_action_processing_ms": 0.15030352961857282}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 67536, "timers": {"learn_time_ms": 12.197, "learn_throughput": 2623.695, "update_time_ms": 12.742}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 301.625244140625, "min_q": -147.1819610595703, "max_q": 614.1389770507812, "mean_td_error": 51.4150505065918, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 216.49563598632812, "min_q": -62.33402633666992, "max_q": 543.5465698242188, "mean_td_error": 33.874759674072266, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 196.48495483398438, "min_q": -120.97300720214844, "max_q": 463.93499755859375, "mean_td_error": -9.374887466430664, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 147.00003051757812, "min_q": -77.83934020996094, "max_q": 590.087890625, "mean_td_error": 38.677276611328125, "model": {}}}, "num_steps_sampled": 67536, "num_steps_trained": 177440, "last_target_update_ts": 67536, "num_target_updates": 133}, "done": false, "episodes_total": 275, "training_iteration": 67, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-17-32", "timestamp": 1624267052, "time_this_iter_s": 36.59260654449463, "time_total_s": 2088.435451030731, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c4a2dd0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c4a2830>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2cb0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a24d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc710>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2cb0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a24d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc710>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2cb0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a24d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc710>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2cb0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a24d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc710>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c4448c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2088.435451030731, "timesteps_since_restore": 0, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 52.803846153846166, "ram_util_percent": 94.85192307692303}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 3497.8517235633353, "episode_len_mean": 351.2, "episodes_this_iter": 3, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-0": -1887.6784051212405, "AGENT-2": -526.3264540039414, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9306.466775605351, "AGENT-2": 7925.388282994336, "AGENT-1": 7821.321766695836}, "policy_reward_mean": {"AGENT-3": 712.2698762226178, "AGENT-0": 1170.7453090826948, "AGENT-2": 850.5303716750395, "AGENT-1": 764.3061665829845}, "custom_metrics": {"mean_ego_speed_mean": 34.0035725, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 91.954805, "distance_travelled_min": 19.174999999999997, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [2948.9419614335147, 1601.3553661109756, 5195.855394325519, 440.27179300326463, 673.041604912905, 1454.0116577404904, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976], "episode_lengths": [257, 215, 330, 999, 247, 217, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356], "policy_AGENT-3_reward": [295.6015525842424, 408.65603181234343, 1286.9094699521168, 102.23621986148906, 102.52659387718577, 237.6939561377783, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813], "policy_AGENT-0_reward": [877.5650182365541, 364.8292337822627, 1260.1537521139248, -85.4185132437963, 247.27135701516812, 489.01598354200786, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858], "policy_AGENT-2_reward": [840.6279391569639, 342.94994404035583, 1237.089471072911, 275.86180192022834, 103.0797605734496, 237.63958564196253, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805], "policy_AGENT-1_reward": [935.1474514557542, 484.92015647601374, 1411.7027011865803, 147.59228446534453, 220.1638934471012, 489.6621324187435, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018]}, "sampler_perf": {"mean_env_wait_ms": 47.03775574339082, "mean_raw_obs_processing_ms": 1.7621198953941848, "mean_inference_ms": 2.392794960896364, "mean_action_processing_ms": 0.150817875269036}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 68544, "timers": {"learn_time_ms": 13.281, "learn_throughput": 2409.416, "update_time_ms": 13.709}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 266.3944091796875, "min_q": -138.906005859375, "max_q": 640.2582397460938, "mean_td_error": -1.0635818243026733, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 221.59527587890625, "min_q": -14.540204048156738, "max_q": 548.5059814453125, "mean_td_error": 24.939651489257812, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 211.264404296875, "min_q": -138.64744567871094, "max_q": 480.0847473144531, "mean_td_error": 48.95188903808594, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 175.93960571289062, "min_q": -334.9080505371094, "max_q": 561.5283203125, "mean_td_error": -13.739686965942383, "model": {}}}, "num_steps_sampled": 68544, "num_steps_trained": 180128, "last_target_update_ts": 68544, "num_target_updates": 135}, "done": false, "episodes_total": 278, "training_iteration": 68, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-18-11", "timestamp": 1624267091, "time_this_iter_s": 39.41532516479492, "time_total_s": 2127.850776195526, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c47eef0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c4447a0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4444d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4440e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4445f0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4443b0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4444d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4440e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4445f0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4443b0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4444d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4440e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4445f0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4443b0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4444d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4440e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4445f0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4443b0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c479ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2127.850776195526, "timesteps_since_restore": 0, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 45.959649122807015, "ram_util_percent": 95.03684210526316}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 3505.7319902839918, "episode_len_mean": 344.99, "episodes_this_iter": 3, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-0": -1887.6784051212405, "AGENT-2": -526.3264540039414, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9306.466775605351, "AGENT-2": 7925.388282994336, "AGENT-1": 7821.321766695836}, "policy_reward_mean": {"AGENT-3": 712.6864671799863, "AGENT-0": 1175.1791874135988, "AGENT-2": 855.5821625803233, "AGENT-1": 762.2841731100843}, "custom_metrics": {"mean_ego_speed_mean": 33.9578925, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.86627499999999, "distance_travelled_min": 19.174999999999997, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [489.7228456989154, 3117.1671723646346, -251.53829034130246, -416.6326578753331, -1124.703775550179, 364.79020452426084, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519], "episode_lengths": [146, 602, 94, 22, 185, 177, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330], "policy_AGENT-3_reward": [174.7502600958562, 411.3248940195743, -101.95928850213049, -76.93002128457476, -46.78537962671452, -75.64638339005161, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168], "policy_AGENT-0_reward": [62.46058938164886, 1066.5168303543203, -34.72075933219986, -131.38748644634535, -505.3701028027561, 267.7348604505232, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248], "policy_AGENT-2_reward": [61.89641105633777, 1095.1686048053034, -35.30477719763629, -131.97501326087783, -526.3264540039414, 247.7582246428534, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911], "policy_AGENT-1_reward": [190.61558516507299, 544.1568431854403, -79.55346530933585, -76.3401368835352, -46.2218391167663, -75.05649717906434, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803]}, "sampler_perf": {"mean_env_wait_ms": 47.11087939318393, "mean_raw_obs_processing_ms": 1.7606745952279232, "mean_inference_ms": 2.39457213566308, "mean_action_processing_ms": 0.15119319544906445}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 69552, "timers": {"learn_time_ms": 12.749, "learn_throughput": 2509.934, "update_time_ms": 13.037}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 286.8763122558594, "min_q": -180.2369842529297, "max_q": 648.0479736328125, "mean_td_error": 0.9286251068115234, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 260.940185546875, "min_q": -85.69930267333984, "max_q": 567.0924682617188, "mean_td_error": 46.287689208984375, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 219.062255859375, "min_q": -107.10804748535156, "max_q": 484.0986633300781, "mean_td_error": 33.657371520996094, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 224.90794372558594, "min_q": -384.43756103515625, "max_q": 599.5366821289062, "mean_td_error": 35.69730758666992, "model": {}}}, "num_steps_sampled": 69552, "num_steps_trained": 182816, "last_target_update_ts": 69552, "num_target_updates": 137}, "done": false, "episodes_total": 281, "training_iteration": 69, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-18-52", "timestamp": 1624267132, "time_this_iter_s": 39.910141468048096, "time_total_s": 2167.760917663574, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c47e830>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c47e3b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c689950>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2cb0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c444950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c689950>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2cb0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c444950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c689950>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2cb0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c444950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c689950>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2cb0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c444950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c444cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2167.760917663574, "timesteps_since_restore": 0, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 46.694736842105264, "ram_util_percent": 94.67192982456139}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 3802.4961442460644, "episode_len_mean": 354.67, "episodes_this_iter": 3, "policy_reward_min": {"AGENT-2": -307.33075828169893, "AGENT-1": -357.6524258796918, "AGENT-0": -1887.6784051212405, "AGENT-3": -1917.8029490524984}, "policy_reward_max": {"AGENT-2": 7925.388282994336, "AGENT-1": 7821.321766695836, "AGENT-0": 9306.466775605351, "AGENT-3": 9311.39186054342}, "policy_reward_mean": {"AGENT-2": 933.7509413175326, "AGENT-1": 839.4457433442512, "AGENT-0": 1253.2933366084744, "AGENT-3": 776.0061229758068}, "custom_metrics": {"mean_ego_speed_mean": 33.19087, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 91.93796000000002, "distance_travelled_min": 19.91325, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [15065.545380374202, 5427.3647053232935, 8006.959081608567, 658.9352294443023, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246], "episode_lengths": [440, 307, 605, 186, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94], "policy_AGENT-2_reward": [3767.094485957348, 1701.7622511432303, 1937.4778939984017, 377.01216691110847, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629], "policy_AGENT-1_reward": [3741.4107795854106, 1666.0061687338412, 2111.121601918086, -53.29291344606382, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585], "policy_AGENT-0_reward": [3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 389.06838011842694, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986], "policy_AGENT-3_reward": [3789.377017268921, 357.24289445122935, 1985.9838835605467, -53.8524041391696, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049]}, "sampler_perf": {"mean_env_wait_ms": 47.26913765935121, "mean_raw_obs_processing_ms": 1.7538511761102882, "mean_inference_ms": 2.3971164531209452, "mean_action_processing_ms": 0.15166514408758233}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 70560, "timers": {"learn_time_ms": 12.336, "learn_throughput": 2594.076, "update_time_ms": 12.579}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 332.0286560058594, "min_q": -263.07025146484375, "max_q": 657.0664672851562, "mean_td_error": 21.627153396606445, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 265.5726623535156, "min_q": -1.4431042671203613, "max_q": 550.8300170898438, "mean_td_error": 25.17397689819336, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 243.628662109375, "min_q": -42.337703704833984, "max_q": 492.3830871582031, "mean_td_error": 23.185569763183594, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 193.21832275390625, "min_q": -374.05908203125, "max_q": 595.9740600585938, "mean_td_error": 12.139217376708984, "model": {}}}, "num_steps_sampled": 70560, "num_steps_trained": 185504, "last_target_update_ts": 70560, "num_target_updates": 139}, "done": false, "episodes_total": 284, "training_iteration": 70, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-19-31", "timestamp": 1624267171, "time_this_iter_s": 39.16811537742615, "time_total_s": 2206.9290330410004, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c444f80>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c3cb5f0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb4d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb050>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb4d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb050>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb4d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb050>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb4d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb050>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c3cb680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2206.9290330410004, "timesteps_since_restore": 0, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 49.158928571428575, "ram_util_percent": 94.81785714285714}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 3860.4429260237994, "episode_len_mean": 355.8, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-0": -1887.6784051212405, "AGENT-3": -1917.8029490524984, "AGENT-2": -307.33075828169893, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-0": 9306.466775605351, "AGENT-3": 9311.39186054342, "AGENT-2": 7925.388282994336, "AGENT-1": 7821.321766695836}, "policy_reward_mean": {"AGENT-0": 1265.453617461941, "AGENT-3": 792.5506163303521, "AGENT-2": 945.5018700843034, "AGENT-1": 856.9368221472042}, "custom_metrics": {"mean_ego_speed_mean": 32.915639999999996, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 91.9943275, "distance_travelled_min": 19.91325, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [6453.61340721784, 828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567], "episode_lengths": [299, 214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605], "policy_AGENT-0_reward": [1605.0964654650625, 286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118], "policy_AGENT-3_reward": [1600.5969313153403, 120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467], "policy_AGENT-2_reward": [1552.1050435881864, 274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017], "policy_AGENT-1_reward": [1695.8149668492338, 147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086]}, "sampler_perf": {"mean_env_wait_ms": 47.376923172864416, "mean_raw_obs_processing_ms": 1.7492663686119996, "mean_inference_ms": 2.399186246264852, "mean_action_processing_ms": 0.1518931706816362}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 71568, "timers": {"learn_time_ms": 11.624, "learn_throughput": 2752.817, "update_time_ms": 15.878}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 213.09967041015625, "min_q": -326.5750732421875, "max_q": 662.611328125, "mean_td_error": 11.694870948791504, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 337.16827392578125, "min_q": 8.2460355758667, "max_q": 584.1692504882812, "mean_td_error": 20.426319122314453, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 238.9512939453125, "min_q": -33.33204650878906, "max_q": 518.7356567382812, "mean_td_error": 4.027932643890381, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 259.08135986328125, "min_q": -309.4432373046875, "max_q": 603.0089111328125, "mean_td_error": 16.83709716796875, "model": {}}}, "num_steps_sampled": 71568, "num_steps_trained": 188192, "last_target_update_ts": 71568, "num_target_updates": 141}, "done": false, "episodes_total": 285, "training_iteration": 71, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-20-08", "timestamp": 1624267208, "time_this_iter_s": 36.33763861656189, "time_total_s": 2243.2666716575623, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c47e3b0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c47ee60>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc680>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc440>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc680>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc440>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc680>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc440>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc680>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc440>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c3cbb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2243.2666716575623, "timesteps_since_restore": 0, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 42.67115384615385, "ram_util_percent": 95.03846153846158}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 3860.4429260238, "episode_len_mean": 355.8, "episodes_this_iter": 0, "policy_reward_min": {"AGENT-0": -1887.6784051212405, "AGENT-3": -1917.8029490524984, "AGENT-2": -307.33075828169893, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-0": 9306.466775605351, "AGENT-3": 9311.39186054342, "AGENT-2": 7925.388282994336, "AGENT-1": 7821.321766695836}, "policy_reward_mean": {"AGENT-0": 1265.4536174619407, "AGENT-3": 792.5506163303519, "AGENT-2": 945.5018700843034, "AGENT-1": 856.9368221472043}, "custom_metrics": {"mean_ego_speed_mean": 32.915639999999996, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 91.9943275, "distance_travelled_min": 19.91325, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [828.1682284861971, 42.17359846131401, -1761.0572487911854, -433.75497860854693, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784], "episode_lengths": [214, 170, 148, 31, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299], "policy_AGENT-0_reward": [286.18527397124996, -217.2853951942532, -877.5287333117959, -137.6822752576336, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625], "policy_AGENT-3_reward": [120.55287499551294, 181.4558925319157, -815.8205249906721, -79.18847855041483, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403], "policy_AGENT-2_reward": [274.2991495848141, -158.0129684904038, -34.22395078464875, -138.25523694318943, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864], "policy_AGENT-1_reward": [147.13092993461953, 236.01606961405466, -33.48403970406926, -78.62898785730906, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338]}, "sampler_perf": {"mean_env_wait_ms": 47.37692317286441, "mean_raw_obs_processing_ms": 1.7492663686119996, "mean_inference_ms": 2.399186246264852, "mean_action_processing_ms": 0.15189317068163624}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 72576, "timers": {"learn_time_ms": 12.958, "learn_throughput": 2469.476, "update_time_ms": 13.375}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 194.41326904296875, "min_q": -42.4621467590332, "max_q": 645.42529296875, "mean_td_error": -26.409709930419922, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 270.01123046875, "min_q": 13.348414421081543, "max_q": 586.7310791015625, "mean_td_error": 11.830517768859863, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 246.1990966796875, "min_q": -168.09921264648438, "max_q": 535.605712890625, "mean_td_error": 33.400840759277344, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 239.46591186523438, "min_q": -51.79179382324219, "max_q": 623.193359375, "mean_td_error": 31.922073364257812, "model": {}}}, "num_steps_sampled": 72576, "num_steps_trained": 190880, "last_target_update_ts": 72576, "num_target_updates": 143}, "done": false, "episodes_total": 285, "training_iteration": 72, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-20-43", "timestamp": 1624267243, "time_this_iter_s": 35.48739957809448, "time_total_s": 2278.7540712356567, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c3cb050>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c3cb0e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb560>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb9e0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb560>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb9e0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb560>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb9e0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb560>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb9e0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c444320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2278.7540712356567, "timesteps_since_restore": 0, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 43.431372549019606, "ram_util_percent": 95.2686274509804}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 4129.159773041874, "episode_len_mean": 376.89, "episodes_this_iter": 4, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-0": -1887.6784051212405, "AGENT-2": -307.33075828169893, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9306.466775605351, "AGENT-2": 7925.388282994336, "AGENT-1": 7821.321766695836}, "policy_reward_mean": {"AGENT-3": 892.426307379897, "AGENT-0": 1309.3747470656774, "AGENT-2": 981.0662082846524, "AGENT-1": 946.2925103116484}, "custom_metrics": {"mean_ego_speed_mean": 32.4529225, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 91.52590249999999, "distance_travelled_min": 19.91325, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 1035.8561924795254, 527.3380511281126, -1270.3232750787975, -236.1193044948904, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784], "episode_lengths": [999, 999, 602, 72, 187, 197, 373, 22, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299], "policy_AGENT-3_reward": [5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 113.24819133106662, -78.49866106003333, -630.9959377913976, -84.58125829035478, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403], "policy_AGENT-0_reward": [-28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 340.30033055419716, 348.66375917829487, -569.4640279825139, -33.48493262955706, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625], "policy_AGENT-2_reward": [-29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 406.9745671180769, 335.11117305028876, -35.27930597060002, -34.02718118144996, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864], "policy_AGENT-1_reward": [5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 175.33310347618558, -77.93822004043723, -34.58400333428475, -84.0259323935286, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338]}, "sampler_perf": {"mean_env_wait_ms": 47.63116401772586, "mean_raw_obs_processing_ms": 1.7406902543836729, "mean_inference_ms": 2.4037330308254794, "mean_action_processing_ms": 0.1525800614474607}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 73584, "timers": {"learn_time_ms": 13.357, "learn_throughput": 2395.701, "update_time_ms": 18.933}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 178.81265258789062, "min_q": -317.7774658203125, "max_q": 672.5868530273438, "mean_td_error": -14.250679016113281, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 292.8183898925781, "min_q": -80.25627899169922, "max_q": 582.8682250976562, "mean_td_error": 16.60203742980957, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 195.28773498535156, "min_q": -227.4270782470703, "max_q": 546.33251953125, "mean_td_error": 15.404491424560547, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 315.83990478515625, "min_q": -14.625405311584473, "max_q": 621.1502075195312, "mean_td_error": 8.241636276245117, "model": {}}}, "num_steps_sampled": 73584, "num_steps_trained": 193568, "last_target_update_ts": 73584, "num_target_updates": 145}, "done": false, "episodes_total": 289, "training_iteration": 73, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-21-15", "timestamp": 1624267275, "time_this_iter_s": 31.12641978263855, "time_total_s": 2309.8804910182953, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c4a2170>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c4a2710>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a25f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2050>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2440>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb680>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a25f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2050>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2440>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb680>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a25f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2050>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2440>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb680>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a25f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2050>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2440>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3cb680>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c3cbcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2309.8804910182953, "timesteps_since_restore": 0, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 49.24666666666666, "ram_util_percent": 95.09555555555556}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 4142.389708134762, "episode_len_mean": 378.73, "episodes_this_iter": 4, "policy_reward_min": {"AGENT-2": -307.33075828169893, "AGENT-1": -357.6524258796918, "AGENT-0": -1887.6784051212405, "AGENT-3": -1917.8029490524984}, "policy_reward_max": {"AGENT-2": 7925.388282994336, "AGENT-1": 7821.321766695836, "AGENT-0": 9306.466775605351, "AGENT-3": 9311.39186054342}, "policy_reward_mean": {"AGENT-2": 974.1946873073659, "AGENT-1": 953.4222399377089, "AGENT-0": 1308.3939634037522, "AGENT-3": 906.3788174859354}, "custom_metrics": {"mean_ego_speed_mean": 32.522262500000004, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 91.446765, "distance_travelled_min": 19.91325, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 652.2383998438195, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952], "episode_lengths": [184, 175, 102, 502, 428, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72], "policy_AGENT-2_reward": [22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, 1.9129092746385719, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615], "policy_AGENT-1_reward": [336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 305.44934779064886, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001], "policy_AGENT-0_reward": [22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, 375.840876008469, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333], "policy_AGENT-3_reward": [279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, -30.964733229935955, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865]}, "sampler_perf": {"mean_env_wait_ms": 47.93099588188569, "mean_raw_obs_processing_ms": 1.7319504707084203, "mean_inference_ms": 2.410568555591603, "mean_action_processing_ms": 0.15341955610475236}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 74592, "timers": {"learn_time_ms": 11.058, "learn_throughput": 2893.771, "update_time_ms": 11.128}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 321.6392822265625, "min_q": -166.46759033203125, "max_q": 686.1231689453125, "mean_td_error": 15.540714263916016, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 228.7969207763672, "min_q": 6.443599700927734, "max_q": 562.7206420898438, "mean_td_error": 3.016693115234375, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 247.67991638183594, "min_q": -214.73866271972656, "max_q": 546.3212890625, "mean_td_error": 25.150390625, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 175.01251220703125, "min_q": -343.563232421875, "max_q": 614.761962890625, "mean_td_error": 49.80366516113281, "model": {}}}, "num_steps_sampled": 74592, "num_steps_trained": 196256, "last_target_update_ts": 74592, "num_target_updates": 147}, "done": false, "episodes_total": 293, "training_iteration": 74, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-21-41", "timestamp": 1624267301, "time_this_iter_s": 26.071468830108643, "time_total_s": 2335.951959848404, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c41b9e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c41b950>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c41b290>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c41b4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c41b320>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c41b5f0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c41b290>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c41b4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c41b320>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c41b5f0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c41b290>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c41b4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c41b320>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c41b5f0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c41b290>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c41b4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c41b320>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c41b5f0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c41bb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2335.951959848404, "timesteps_since_restore": 0, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 45.963157894736845, "ram_util_percent": 95.21315789473688}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -3850.4188048670617, "episode_reward_mean": 4138.13006496868, "episode_len_mean": 376.16, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-3": -1917.8029490524984, "AGENT-0": -1887.6784051212405, "AGENT-2": -307.33075828169893, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9306.466775605351, "AGENT-2": 7925.388282994336, "AGENT-1": 7821.321766695836}, "policy_reward_mean": {"AGENT-3": 907.8254129535846, "AGENT-0": 1304.3485259803683, "AGENT-2": 973.8828874341566, "AGENT-1": 952.0732386005707}, "custom_metrics": {"mean_ego_speed_mean": 32.623965000000005, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 91.13268750000003, "distance_travelled_min": 19.91325, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [226.2740832356053, 1716.2048911292202, -3850.4188048670617, 48.00492262006248, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497], "episode_lengths": [171, 194, 495, 98, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502], "policy_AGENT-3_reward": [113.69481353500137, 237.4610706054486, -1917.8029490524984, 50.75862544547641, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283], "policy_AGENT-0_reward": [-28.702866329907348, 548.0311478704114, -1887.6784051212405, -28.64579245788043, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078], "policy_AGENT-2_reward": [-29.267078046315504, 625.4441189084074, -22.742232969309715, -29.190972747828877, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867], "policy_AGENT-1_reward": [170.5492140768269, 305.2685537449548, -22.195217724013077, 55.08306238029538, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826]}, "sampler_perf": {"mean_env_wait_ms": 47.99246930664368, "mean_raw_obs_processing_ms": 1.7320286403812768, "mean_inference_ms": 2.4122357006076003, "mean_action_processing_ms": 0.1536144176389433}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 75600, "timers": {"learn_time_ms": 10.841, "learn_throughput": 2951.741, "update_time_ms": 14.253}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 252.03768920898438, "min_q": -133.07852172851562, "max_q": 652.2027587890625, "mean_td_error": 90.79113006591797, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 268.4046936035156, "min_q": -7.116374492645264, "max_q": 598.2128295898438, "mean_td_error": -7.701676368713379, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 275.0755615234375, "min_q": -338.35150146484375, "max_q": 550.4002685546875, "mean_td_error": 42.111083984375, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 206.2635498046875, "min_q": -112.98352813720703, "max_q": 650.2488403320312, "mean_td_error": 25.264469146728516, "model": {}}}, "num_steps_sampled": 75600, "num_steps_trained": 198944, "last_target_update_ts": 75600, "num_target_updates": 149}, "done": false, "episodes_total": 294, "training_iteration": 75, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-22-13", "timestamp": 1624267333, "time_this_iter_s": 31.816356658935547, "time_total_s": 2367.7683165073395, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c4a2170>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c47e710>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c479320>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc560>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c479320>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc560>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c479320>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc560>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c479320>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bcef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc560>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c41bd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2367.7683165073395, "timesteps_since_restore": 0, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 41.87777777777778, "ram_util_percent": 95.41999999999999}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 4402.347363110431, "episode_len_mean": 386.74, "episodes_this_iter": 3, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-2": -307.33075828169893, "AGENT-0": -434.50493179261696, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-2": 7925.388282994336, "AGENT-0": 9306.466775605351, "AGENT-1": 7821.321766695836}, "policy_reward_mean": {"AGENT-3": 987.4087950925062, "AGENT-2": 1028.408452830181, "AGENT-0": 1378.3089642863697, "AGENT-1": 1008.2211509013746}, "custom_metrics": {"mean_ego_speed_mean": 32.220175, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.582245, "distance_travelled_min": 19.91325, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [313.8039896473803, -238.14712720858753, 24259.863960618557, -874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053], "episode_lengths": [999, 104, 742, 335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171], "policy_AGENT-3_reward": [324.2570092396328, -77.668258306801, 6082.1662099577525, -422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137], "policy_AGENT-2_reward": [31.555753551095638, -40.66944823952906, 6035.1811474821525, -37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504], "policy_AGENT-0_reward": [32.116923223009685, -40.11739483647506, 6035.75125250488, -377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348], "policy_AGENT-1_reward": [-74.12569636635766, -79.69202582578242, 6106.765350673762, -37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269]}, "sampler_perf": {"mean_env_wait_ms": 48.09443244798938, "mean_raw_obs_processing_ms": 1.7262605988363438, "mean_inference_ms": 2.414284575368822, "mean_action_processing_ms": 0.15400087204593754}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 76608, "timers": {"learn_time_ms": 11.091, "learn_throughput": 2885.311, "update_time_ms": 11.491}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 304.60614013671875, "min_q": -318.2407531738281, "max_q": 704.380615234375, "mean_td_error": 1.5078229904174805, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 245.2169189453125, "min_q": -6.265516757965088, "max_q": 573.023193359375, "mean_td_error": 12.214284896850586, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 196.5847930908203, "min_q": -170.06332397460938, "max_q": 558.4110107421875, "mean_td_error": 11.800883293151855, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 254.62210083007812, "min_q": -85.36875915527344, "max_q": 664.660400390625, "mean_td_error": 25.46817970275879, "model": {}}}, "num_steps_sampled": 76608, "num_steps_trained": 201632, "last_target_update_ts": 76608, "num_target_updates": 151}, "done": false, "episodes_total": 297, "training_iteration": 76, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-22-46", "timestamp": 1624267366, "time_this_iter_s": 33.123414754867554, "time_total_s": 2400.891731262207, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c41b560>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c41b4d0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c41b950>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c41b0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c41b050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c41bc20>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c41b950>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c41b0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c41b050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c41bc20>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c41b950>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c41b0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c41b050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c41bc20>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c41b950>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c41b0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c41b050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c41bc20>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c3cbb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2400.891731262207, "timesteps_since_restore": 0, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 44.03333333333333, "ram_util_percent": 95.65208333333332}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 4402.347363110431, "episode_len_mean": 386.74, "episodes_this_iter": 0, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-2": -307.33075828169893, "AGENT-0": -434.50493179261696, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-2": 7925.388282994336, "AGENT-0": 9306.466775605351, "AGENT-1": 7821.321766695836}, "policy_reward_mean": {"AGENT-3": 987.4087950925062, "AGENT-2": 1028.408452830181, "AGENT-0": 1378.3089642863697, "AGENT-1": 1008.2211509013744}, "custom_metrics": {"mean_ego_speed_mean": 32.220175, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.58224499999999, "distance_travelled_min": 19.91325, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [-874.4918991366709, -273.13609530943023, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557], "episode_lengths": [335, 68, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742], "policy_AGENT-3_reward": [-422.00142551556706, -108.10050090975272, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525], "policy_AGENT-2_reward": [-37.63775051934959, -29.138935919751997, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525], "policy_AGENT-0_reward": [-377.6590481814646, -28.55049011844051, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488], "policy_AGENT-1_reward": [-37.193674920289936, -107.34616836148497, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762]}, "sampler_perf": {"mean_env_wait_ms": 48.094432447989384, "mean_raw_obs_processing_ms": 1.7262605988363438, "mean_inference_ms": 2.414284575368822, "mean_action_processing_ms": 0.15400087204593751}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 77616, "timers": {"learn_time_ms": 11.146, "learn_throughput": 2871.029, "update_time_ms": 11.52}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 313.9232482910156, "min_q": -177.98204040527344, "max_q": 662.91943359375, "mean_td_error": 16.44818878173828, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 315.1885986328125, "min_q": -4.709109783172607, "max_q": 615.0211791992188, "mean_td_error": 7.4527268409729, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 257.3067626953125, "min_q": -43.62535095214844, "max_q": 576.2058715820312, "mean_td_error": -7.003082275390625, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 247.22402954101562, "min_q": -167.81228637695312, "max_q": 658.3865356445312, "mean_td_error": 4.856616020202637, "model": {}}}, "num_steps_sampled": 77616, "num_steps_trained": 204320, "last_target_update_ts": 77616, "num_target_updates": 153}, "done": false, "episodes_total": 297, "training_iteration": 77, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-23-20", "timestamp": 1624267400, "time_this_iter_s": 33.37473225593567, "time_total_s": 2434.2664635181427, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c74d9e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c444290>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c444dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c47e3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c47ee60>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c47ea70>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c444dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c47e3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c47ee60>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c47ea70>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c444dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c47e3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c47ee60>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c47ea70>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c444dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c47e3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c47ee60>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c47ea70>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c41b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2434.2664635181427, "timesteps_since_restore": 0, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 51.50208333333333, "ram_util_percent": 95.60416666666667}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 4681.795040619687, "episode_len_mean": 398.84, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-2": -307.33075828169893, "AGENT-1": -357.6524258796918, "AGENT-0": -434.50493179261696, "AGENT-3": -507.5460381922926}, "policy_reward_max": {"AGENT-2": 7925.388282994336, "AGENT-1": 7821.321766695836, "AGENT-0": 9306.466775605351, "AGENT-3": 9311.39186054342}, "policy_reward_mean": {"AGENT-2": 1066.9248068429267, "AGENT-1": 1106.1503453605924, "AGENT-0": 1419.5098758109625, "AGENT-3": 1089.2100126052067}, "custom_metrics": {"mean_ego_speed_mean": 31.692247499999997, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.59985749999998, "distance_travelled_min": 19.91325, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [11739.639014324455, 15057.500742155107, -215.95276614075436, -790.561156212137, 604.6654605576658, 717.4260543279736, -231.5488187276277, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557], "episode_lengths": [999, 614, 375, 374, 408, 141, 353, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742], "policy_AGENT-2_reward": [20.878398363498096, 3763.980316471953, 104.4723991724407, -42.32639200385715, 119.01336922255678, 285.0091551207608, -307.33075828169893, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525], "policy_AGENT-1_reward": [5847.502511621161, 3800.8770910188746, -240.17540347939786, -41.67851815908655, 169.17989727934105, 133.3954006176239, 191.40861523989454, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762], "policy_AGENT-0_reward": [21.470260467193583, 3692.4113536921495, -184.78186760597004, -320.34687406954265, 147.85699918871094, 212.4124193721025, -295.2437700073097, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488], "policy_AGENT-3_reward": [5849.787843872602, 3800.2319809721193, 104.53210577217249, -386.2093719796503, 168.6151948670568, 86.60907921748698, 179.61709432148663, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525]}, "sampler_perf": {"mean_env_wait_ms": 48.278158891459036, "mean_raw_obs_processing_ms": 1.7191306361440974, "mean_inference_ms": 2.417920764069684, "mean_action_processing_ms": 0.1544480518233368}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 78624, "timers": {"learn_time_ms": 10.871, "learn_throughput": 2943.571, "update_time_ms": 12.217}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 236.996826171875, "min_q": -223.87594604492188, "max_q": 717.0540771484375, "mean_td_error": 48.251583099365234, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 263.35247802734375, "min_q": -15.316285133361816, "max_q": 593.0466918945312, "mean_td_error": 13.97391128540039, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 275.72271728515625, "min_q": -159.859130859375, "max_q": 586.3184814453125, "mean_td_error": 92.19859313964844, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 348.7280578613281, "min_q": -286.1795654296875, "max_q": 677.6146240234375, "mean_td_error": 22.45724105834961, "model": {}}}, "num_steps_sampled": 78624, "num_steps_trained": 207008, "last_target_update_ts": 78624, "num_target_updates": 155}, "done": false, "episodes_total": 299, "training_iteration": 78, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-23-52", "timestamp": 1624267432, "time_this_iter_s": 31.9840030670166, "time_total_s": 2466.2504665851593, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c391170>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c391200>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c391440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c391680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3917a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3915f0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c391440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c391680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3917a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3915f0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c391440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c391680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3917a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3915f0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c391440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c391680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3917a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3915f0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c391e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2466.2504665851593, "timesteps_since_restore": 0, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 48.7108695652174, "ram_util_percent": 95.80652173913042}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 4947.559502893556, "episode_len_mean": 400.92, "episodes_this_iter": 5, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-0": -434.50493179261696, "AGENT-2": -127.21751108869097, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9306.466775605351, "AGENT-2": 7925.388282994336, "AGENT-1": 7821.321766695836}, "policy_reward_mean": {"AGENT-3": 1130.7331887226294, "AGENT-0": 1501.2287612076761, "AGENT-2": 1142.240207225321, "AGENT-1": 1173.357345737929}, "custom_metrics": {"mean_ego_speed_mean": 31.407982499999992, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.535275, "distance_travelled_min": 19.91325, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107], "episode_lengths": [229, 133, 156, 999, 342, 263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614], "policy_AGENT-3_reward": [289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193], "policy_AGENT-0_reward": [281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495], "policy_AGENT-2_reward": [280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953], "policy_AGENT-1_reward": [389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746]}, "sampler_perf": {"mean_env_wait_ms": 48.57659381045871, "mean_raw_obs_processing_ms": 1.7122756283972274, "mean_inference_ms": 2.424583446235092, "mean_action_processing_ms": 0.15533622922339485}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 79632, "timers": {"learn_time_ms": 11.245, "learn_throughput": 2845.585, "update_time_ms": 11.892}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 284.0589599609375, "min_q": -198.6695556640625, "max_q": 707.2760620117188, "mean_td_error": 10.184797286987305, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 321.12176513671875, "min_q": -9.197084426879883, "max_q": 614.0445556640625, "mean_td_error": 8.099138259887695, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 313.34552001953125, "min_q": -70.34989166259766, "max_q": 587.5266723632812, "mean_td_error": 18.888141632080078, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 304.85430908203125, "min_q": -135.6979217529297, "max_q": 663.4710083007812, "mean_td_error": 15.471631050109863, "model": {}}}, "num_steps_sampled": 79632, "num_steps_trained": 209696, "last_target_update_ts": 79632, "num_target_updates": 157}, "done": false, "episodes_total": 304, "training_iteration": 79, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-24-25", "timestamp": 1624267465, "time_this_iter_s": 33.13682150840759, "time_total_s": 2499.387288093567, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c41bdd0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c6897a0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2b90>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a27a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2c20>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2b90>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a27a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2c20>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2b90>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a27a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2c20>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2b90>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a27a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2c20>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c391ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2499.387288093567, "timesteps_since_restore": 0, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 49.76170212765957, "ram_util_percent": 95.98723404255323}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 4947.559502893555, "episode_len_mean": 400.92, "episodes_this_iter": 0, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-0": -434.50493179261696, "AGENT-2": -127.21751108869097, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9306.466775605351, "AGENT-2": 7925.388282994336, "AGENT-1": 7821.321766695836}, "policy_reward_mean": {"AGENT-3": 1130.7331887226294, "AGENT-0": 1501.2287612076761, "AGENT-2": 1142.240207225321, "AGENT-1": 1173.3573457379293}, "custom_metrics": {"mean_ego_speed_mean": 31.407982500000003, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.53527500000001, "distance_travelled_min": 19.91325, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [1686.1937671508638, 1573.3743948995884, -407.05122671186257, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897], "episode_lengths": [263, 310, 26, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342], "policy_AGENT-3_reward": [196.6803902355693, 174.70413959548, -76.89058870724719, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167], "policy_AGENT-0_reward": [626.3602240821833, 632.6787756241563, -126.63910035507743, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586], "policy_AGENT-2_reward": [601.6446268908876, 590.7234963320302, -127.21751108869097, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963], "policy_AGENT-1_reward": [261.5085259422224, 175.26798334792028, -76.30402656084682, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329]}, "sampler_perf": {"mean_env_wait_ms": 48.57659381045869, "mean_raw_obs_processing_ms": 1.7122756283972271, "mean_inference_ms": 2.4245834462350917, "mean_action_processing_ms": 0.15533622922339485}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 80640, "timers": {"learn_time_ms": 10.547, "learn_throughput": 3034.129, "update_time_ms": 11.803}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 242.70077514648438, "min_q": -204.05259704589844, "max_q": 693.0492553710938, "mean_td_error": 17.939542770385742, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 322.1551513671875, "min_q": 1.9541480541229248, "max_q": 608.4115600585938, "mean_td_error": 11.038895606994629, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 329.15557861328125, "min_q": -38.09995651245117, "max_q": 578.9745483398438, "mean_td_error": 8.455766677856445, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 322.4822998046875, "min_q": -320.1158142089844, "max_q": 694.3458251953125, "mean_td_error": 48.76864242553711, "model": {}}}, "num_steps_sampled": 80640, "num_steps_trained": 212384, "last_target_update_ts": 80640, "num_target_updates": 159}, "done": false, "episodes_total": 304, "training_iteration": 80, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-24-58", "timestamp": 1624267498, "time_this_iter_s": 32.580395460128784, "time_total_s": 2531.9676835536957, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c391710>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c391680>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c391200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c391b00>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c391b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3919e0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c391200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c391b00>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c391b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3919e0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c391200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c391b00>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c391b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3919e0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c391200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c391b00>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c391b90>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3919e0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c47e3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2531.9676835536957, "timesteps_since_restore": 0, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 48.725531914893615, "ram_util_percent": 96.20000000000002}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 31273.80990724214, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 4953.523469124532, "episode_len_mean": 401.7, "episodes_this_iter": 3, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-2": -51.88198065094656, "AGENT-0": -434.50493179261696, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-2": 7925.388282994336, "AGENT-0": 9306.466775605351, "AGENT-1": 7821.321766695836}, "policy_reward_mean": {"AGENT-3": 1136.4325332122214, "AGENT-2": 1137.2886185609882, "AGENT-0": 1496.076004954353, "AGENT-1": 1183.7263123969713}, "custom_metrics": {"mean_ego_speed_mean": 31.24564, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.403535, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [1372.0286701674238, 1684.1022670957852, 392.7826211731642, 421.7654150927596, -930.3285013776364, -384.92081931540594, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897], "episode_lengths": [446, 142, 89, 151, 238, 270, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342], "policy_AGENT-3_reward": [436.0232934878875, 282.9322362783238, 145.47286031678016, -78.74001795112173, -470.2254890207935, -304.4816618070087, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167], "policy_AGENT-2_reward": [87.2106047501562, 432.4404130061322, 50.340727944655406, 324.18964770185863, -33.73764472908894, 74.15712058262372, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963], "policy_AGENT-0_reward": [133.20434497309685, 432.9898780540318, 50.93005099182474, 254.49631259943828, -393.3154197404889, -229.50325225594494, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586], "policy_AGENT-1_reward": [715.590426956285, 535.7397397572951, 146.0389819199035, -78.18052725741606, -33.04994788726492, 74.90697416492395, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329]}, "sampler_perf": {"mean_env_wait_ms": 48.76453585080689, "mean_raw_obs_processing_ms": 1.710050224690154, "mean_inference_ms": 2.4292407410738206, "mean_action_processing_ms": 0.15591423457028614}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 81648, "timers": {"learn_time_ms": 10.604, "learn_throughput": 3017.682, "update_time_ms": 11.037}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 407.5545349121094, "min_q": -312.66766357421875, "max_q": 731.6919555664062, "mean_td_error": 21.223018646240234, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 248.16151428222656, "min_q": -9.654877662658691, "max_q": 591.5554809570312, "mean_td_error": 12.325221061706543, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 325.41705322265625, "min_q": -18.106557846069336, "max_q": 596.4240112304688, "mean_td_error": 18.6784725189209, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 186.2579345703125, "min_q": -323.1968994140625, "max_q": 656.8526000976562, "mean_td_error": 49.14588165283203, "model": {}}}, "num_steps_sampled": 81648, "num_steps_trained": 215072, "last_target_update_ts": 81648, "num_target_updates": 161}, "done": false, "episodes_total": 307, "training_iteration": 81, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-25-32", "timestamp": 1624267532, "time_this_iter_s": 33.222885847091675, "time_total_s": 2565.1905694007874, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c479f80>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c3cbcb0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2d40>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2dd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a27a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9f80>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2d40>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2dd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a27a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9f80>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2d40>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2dd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a27a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9f80>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2d40>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2dd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a27a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9f80>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c2e99e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2565.1905694007874, "timesteps_since_restore": 0, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 48.93541666666667, "ram_util_percent": 95.82916666666667}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 5469.599067710295, "episode_len_mean": 416.32, "episodes_this_iter": 3, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-0": -434.50493179261696, "AGENT-2": -51.88198065094656, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9306.466775605351, "AGENT-2": 8958.253931464842, "AGENT-1": 8963.640732104383}, "policy_reward_mean": {"AGENT-3": 1241.1161778858827, "AGENT-0": 1653.6467613561417, "AGENT-2": 1287.554852700803, "AGENT-1": 1287.2812757674646}, "custom_metrics": {"mean_ego_speed_mean": 30.5962725, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.36507249999998, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [1485.7795939776192, 13385.910523994096, 35842.385835004054, 461.2219978024416, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642], "episode_lengths": [123, 999, 999, 415, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89], "policy_AGENT-3_reward": [372.1591583617757, 280.51989913896745, 8962.238241086483, 216.69566436042106, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016], "policy_AGENT-0_reward": [345.1991590120742, 6085.301191421704, 8958.252930348119, 6.715110435916458, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474], "policy_AGENT-2_reward": [344.76408835612006, 6088.214517715903, 8958.253931464842, -51.88198065094656, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406], "policy_AGENT-1_reward": [423.6571882476487, 931.8749157175558, 8963.640732104383, 289.69320365704954, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035]}, "sampler_perf": {"mean_env_wait_ms": 48.965629629569285, "mean_raw_obs_processing_ms": 1.703762220735999, "mean_inference_ms": 2.4336468496275403, "mean_action_processing_ms": 0.1564521075961182}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 82656, "timers": {"learn_time_ms": 11.409, "learn_throughput": 2804.874, "update_time_ms": 10.872}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 427.4272155761719, "min_q": -98.56964874267578, "max_q": 725.8834838867188, "mean_td_error": 9.2935209274292, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 247.44009399414062, "min_q": -103.2196044921875, "max_q": 631.3916625976562, "mean_td_error": 29.40900993347168, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 319.8216552734375, "min_q": -164.5670623779297, "max_q": 623.6380004882812, "mean_td_error": 1.3580141067504883, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 172.52880859375, "min_q": -345.66845703125, "max_q": 666.2354736328125, "mean_td_error": 16.73797035217285, "model": {}}}, "num_steps_sampled": 82656, "num_steps_trained": 217760, "last_target_update_ts": 82656, "num_target_updates": 163}, "done": false, "episodes_total": 310, "training_iteration": 82, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-26-06", "timestamp": 1624267566, "time_this_iter_s": 34.24813890457153, "time_total_s": 2599.438708305359, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c2e93b0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c2e9440>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9680>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2e98c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9a70>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c391950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9680>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2e98c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9a70>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c391950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9680>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2e98c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9a70>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c391950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9680>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2e98c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9a70>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c391950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c4bc050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2599.438708305359, "timesteps_since_restore": 0, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 52.27959183673468, "ram_util_percent": 96.05918367346942}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 5523.322813899362, "episode_len_mean": 415.81, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-2": -40.66944823952906, "AGENT-0": -434.50493179261696, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-2": 8958.253931464842, "AGENT-0": 9306.466775605351, "AGENT-1": 8963.640732104383}, "policy_reward_mean": {"AGENT-3": 1242.9246708826258, "AGENT-2": 1305.2209368392596, "AGENT-0": 1670.3219396811392, "AGENT-1": 1304.8552664963358}, "custom_metrics": {"mean_ego_speed_mean": 30.329702499999993, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.33958000000001, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.78875}, "hist_stats": {"episode_reward": [5833.596616709325, 1749.0903326197467, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054], "episode_lengths": [364, 467, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999], "policy_AGENT-3_reward": [397.5449640347583, 208.80235490062046, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483], "policy_AGENT-2_reward": [1714.7264331947183, 606.205477053206, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842], "policy_AGENT-0_reward": [1674.2329429356782, 652.1169039164746, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119], "policy_AGENT-1_reward": [2047.0922765441753, 281.9655967494474, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383]}, "sampler_perf": {"mean_env_wait_ms": 49.02410085667013, "mean_raw_obs_processing_ms": 1.703034218226295, "mean_inference_ms": 2.4347958129179172, "mean_action_processing_ms": 0.1566262826134821}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 83664, "timers": {"learn_time_ms": 10.746, "learn_throughput": 2977.904, "update_time_ms": 11.589}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 370.73931884765625, "min_q": -186.53811645507812, "max_q": 748.1708374023438, "mean_td_error": 11.793632507324219, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 320.25677490234375, "min_q": -19.88123321533203, "max_q": 651.1127319335938, "mean_td_error": 24.27414321899414, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 266.87890625, "min_q": -269.14727783203125, "max_q": 609.2307739257812, "mean_td_error": 8.3377685546875, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 332.7376708984375, "min_q": -215.7064208984375, "max_q": 717.403076171875, "mean_td_error": 15.73420524597168, "model": {}}}, "num_steps_sampled": 83664, "num_steps_trained": 220448, "last_target_update_ts": 83664, "num_target_updates": 165}, "done": false, "episodes_total": 311, "training_iteration": 83, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-26-39", "timestamp": 1624267599, "time_this_iter_s": 32.57144117355347, "time_total_s": 2632.0101494789124, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c479320>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c479cb0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc830>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc320>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc830>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc320>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc830>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc320>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc830>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc320>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c2c64d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2632.0101494789124, "timesteps_since_restore": 0, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 50.978260869565204, "ram_util_percent": 96.29999999999998}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 5598.534365520288, "episode_len_mean": 415.35, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-0": -434.50493179261696, "AGENT-2": -40.66944823952906, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9306.466775605351, "AGENT-2": 8958.253931464842, "AGENT-1": 8963.640732104383}, "policy_reward_mean": {"AGENT-3": 1243.464844064877, "AGENT-0": 1693.5332146538701, "AGENT-2": 1328.8854964285927, "AGENT-1": 1332.6508103729452}, "custom_metrics": {"mean_ego_speed_mean": 30.0666725, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 89.81195000000001, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.48975}, "hist_stats": {"episode_reward": [9270.245494712182, -81.60634403711293, -838.6888324496276, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325], "episode_lengths": [421, 482, 183, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364], "policy_AGENT-3_reward": [262.8196731257371, -55.62103407704742, -416.85258184010956, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583], "policy_AGENT-0_reward": [2973.2444011895586, 21.3628774174582, -363.31830902533306, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782], "policy_AGENT-2_reward": [2972.66143598652, 7.713636256324337, -29.608719087383378, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183], "policy_AGENT-1_reward": [3061.519984410381, -55.06182363384826, -28.90922249680152, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753]}, "sampler_perf": {"mean_env_wait_ms": 49.09817560566012, "mean_raw_obs_processing_ms": 1.7010502622636436, "mean_inference_ms": 2.436369349637376, "mean_action_processing_ms": 0.1568327148068323}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 84672, "timers": {"learn_time_ms": 10.497, "learn_throughput": 3048.574, "update_time_ms": 13.811}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 311.40350341796875, "min_q": -87.17640686035156, "max_q": 704.5940551757812, "mean_td_error": 47.13805389404297, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 332.0992431640625, "min_q": -24.44868278503418, "max_q": 644.9190063476562, "mean_td_error": 38.15357971191406, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 290.08203125, "min_q": -200.74813842773438, "max_q": 621.4031982421875, "mean_td_error": 36.351722717285156, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 284.4051513671875, "min_q": -299.12017822265625, "max_q": 720.96875, "mean_td_error": -1.0821342468261719, "model": {}}}, "num_steps_sampled": 84672, "num_steps_trained": 223136, "last_target_update_ts": 84672, "num_target_updates": 167}, "done": false, "episodes_total": 312, "training_iteration": 84, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-27-12", "timestamp": 1624267632, "time_this_iter_s": 32.74031853675842, "time_total_s": 2664.750468015671, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c2e9680>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c2e94d0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a27a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2c20>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6cb0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a27a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2c20>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6cb0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a27a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2c20>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6cb0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9200>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4a27a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4a2c20>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6cb0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c2c60e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2664.750468015671, "timesteps_since_restore": 0, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 50.112765957446804, "ram_util_percent": 96.55106382978728}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 6043.964767386583, "episode_len_mean": 428.53, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-2": -40.66944823952906, "AGENT-0": -434.50493179261696, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-2": 8958.253931464842, "AGENT-0": 9306.466775605351, "AGENT-1": 8963.640732104383}, "policy_reward_mean": {"AGENT-3": 1338.3266197518667, "AGENT-2": 1456.0456984846462, "AGENT-0": 1824.4679010799323, "AGENT-1": 1425.1245480701348}, "custom_metrics": {"mean_ego_speed_mean": 29.446645, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 89.95671250000001, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.48975}, "hist_stats": {"episode_reward": [9411.059092335705, 34211.68591780714, -81.6240851019203, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325, 9270.245494712182], "episode_lengths": [984, 999, 77, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364, 421], "policy_AGENT-3_reward": [459.40214937058136, 8554.301803411183, -12.656348356210536, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583, 262.8196731257371], "policy_AGENT-2_reward": [4143.584003368301, 8550.541119406005, -28.71747451248559, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183, 2972.66143598652], "policy_AGENT-0_reward": [4200.998247548772, 8550.514963449576, -28.162111239790384, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782, 2973.2444011895586], "policy_AGENT-1_reward": [607.0746920480364, 8556.328031540294, -12.088150993433786, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753, 3061.519984410381]}, "sampler_perf": {"mean_env_wait_ms": 49.24496247941192, "mean_raw_obs_processing_ms": 1.6969524375335001, "mean_inference_ms": 2.439623482018256, "mean_action_processing_ms": 0.15719171746838642}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 85680, "timers": {"learn_time_ms": 11.505, "learn_throughput": 2781.444, "update_time_ms": 13.667}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 325.3407287597656, "min_q": -79.07910919189453, "max_q": 736.9432983398438, "mean_td_error": 38.655433654785156, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 344.991943359375, "min_q": -0.2740870714187622, "max_q": 668.8787231445312, "mean_td_error": 31.17069435119629, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 341.203125, "min_q": -110.86711883544922, "max_q": 634.3349609375, "mean_td_error": 28.396984100341797, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 383.7929992675781, "min_q": -342.01373291015625, "max_q": 714.6991577148438, "mean_td_error": 1.64920973777771, "model": {}}}, "num_steps_sampled": 85680, "num_steps_trained": 225824, "last_target_update_ts": 85680, "num_target_updates": 169}, "done": false, "episodes_total": 314, "training_iteration": 85, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-27-50", "timestamp": 1624267670, "time_this_iter_s": 37.9199857711792, "time_total_s": 2702.67045378685, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c6897a0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c47eb00>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c47e710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c444710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c391cb0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c47e710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c444710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c391cb0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c47e710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c444710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c391cb0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c47e710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c444710>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c7c1200>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c391cb0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c2c6d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2702.67045378685, "timesteps_since_restore": 0, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 51.42363636363637, "ram_util_percent": 96.20363636363639}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 6175.066914582165, "episode_len_mean": 435.59, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-2": -40.66944823952906, "AGENT-0": -434.50493179261696, "AGENT-1": -357.6524258796918}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-2": 8958.253931464842, "AGENT-0": 9306.466775605351, "AGENT-1": 8963.640732104383}, "policy_reward_mean": {"AGENT-3": 1372.0528030710918, "AGENT-2": 1487.5155572751564, "AGENT-0": 1856.647906022073, "AGENT-1": 1458.850648213841}, "custom_metrics": {"mean_ego_speed_mean": 29.0463775, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.49649500000001, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.48975}, "hist_stats": {"episode_reward": [13028.590634456254, -826.8716016031685, 3970.5910558676283, -563.7912024926624, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325, 9270.245494712182, 9411.059092335705, 34211.68591780714], "episode_lengths": [783, 213, 357, 341, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364, 421, 984, 999], "policy_AGENT-3_reward": [3359.9619835662957, -412.6140373825411, 856.37092354151, 50.2864122557822, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583, 262.8196731257371, 459.40214937058136, 8554.301803411183], "policy_AGENT-2_reward": [3118.2684045385445, -34.67834496281314, 1054.350185154991, 50.50570769270446, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183, 2972.66143598652, 4143.584003368301, 8550.541119406005], "policy_AGENT-0_reward": [3189.8383829742834, -345.5890203169127, 1103.3909771098115, -306.93089656145673, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782, 2973.2444011895586, 4200.998247548772, 8550.514963449576], "policy_AGENT-1_reward": [3360.5218633771706, -33.99019894090169, 956.4789700613206, -357.6524258796918, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753, 3061.519984410381, 607.0746920480364, 8556.328031540294]}, "sampler_perf": {"mean_env_wait_ms": 49.30760942912109, "mean_raw_obs_processing_ms": 1.6960019619340696, "mean_inference_ms": 2.44086061613542, "mean_action_processing_ms": 0.15737208125786886}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 86688, "timers": {"learn_time_ms": 13.291, "learn_throughput": 2407.726, "update_time_ms": 16.958}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 291.1322937011719, "min_q": -273.4490051269531, "max_q": 752.0330810546875, "mean_td_error": 42.05781936645508, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 312.77325439453125, "min_q": -16.812776565551758, "max_q": 673.3150024414062, "mean_td_error": 12.611525535583496, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 312.37518310546875, "min_q": -167.08580017089844, "max_q": 643.0477905273438, "mean_td_error": 7.23524284362793, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 292.78179931640625, "min_q": -113.37256622314453, "max_q": 733.7152099609375, "mean_td_error": 60.21806335449219, "model": {}}}, "num_steps_sampled": 86688, "num_steps_trained": 228512, "last_target_update_ts": 86688, "num_target_updates": 171}, "done": false, "episodes_total": 315, "training_iteration": 86, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-28-16", "timestamp": 1624267696, "time_this_iter_s": 26.09315276145935, "time_total_s": 2728.7636065483093, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c2c68c0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c2c6950>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6320>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c31c320>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c31c200>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6320>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c31c320>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c31c200>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6320>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c31c320>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c31c200>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6320>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c31c320>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c31c200>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c31c560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2728.7636065483093, "timesteps_since_restore": 0, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 48.6972972972973, "ram_util_percent": 96.37027027027028}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 6245.006493784819, "episode_len_mean": 435.47, "episodes_this_iter": 3, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-0": -434.50493179261696, "AGENT-2": -40.66944823952906, "AGENT-1": -303.0152551308864}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9306.466775605351, "AGENT-2": 8958.253931464842, "AGENT-1": 8963.640732104383}, "policy_reward_mean": {"AGENT-3": 1388.146862741306, "AGENT-0": 1876.402134536913, "AGENT-2": 1498.8505775095484, "AGENT-1": 1481.6069189970492}, "custom_metrics": {"mean_ego_speed_mean": 28.898967500000005, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.0925475, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.48975}, "hist_stats": {"episode_reward": [2271.993482035765, 1090.0410168870833, 6211.851673114387, 206.22271789469164, 8556.088148581028, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325, 9270.245494712182, 9411.059092335705, 34211.68591780714, 13028.590634456254], "episode_lengths": [152, 455, 292, 113, 560, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364, 421, 984, 999, 783], "policy_AGENT-3_reward": [292.8816233366533, 218.7252931205793, 1591.8423489789695, 129.3265730410071, 69.53849395430328, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583, 262.8196731257371, 459.40214937058136, 8554.301803411183, 3359.9619835662957], "policy_AGENT-0_reward": [628.0489875479294, 274.35177277417864, 1523.8931513932946, -31.650284800254735, 4151.033313250751, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782, 2973.2444011895586, 4200.998247548772, 8550.514963449576, 3189.8383829742834], "policy_AGENT-2_reward": [627.4576258224816, 146.70362876696294, 1429.5183167346297, -32.190133423409875, 108.41790266866613, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183, 2972.66143598652, 4143.584003368301, 8550.541119406005, 3118.2684045385445], "policy_AGENT-1_reward": [723.6052453287012, 450.2603222253631, 1666.5978560074882, 140.73656307734922, 4227.098438707324, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753, 3061.519984410381, 607.0746920480364, 8556.328031540294, 3360.5218633771706]}, "sampler_perf": {"mean_env_wait_ms": 49.660765071117936, "mean_raw_obs_processing_ms": 1.6891363304688074, "mean_inference_ms": 2.448318837466527, "mean_action_processing_ms": 0.1581016870709205}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 87696, "timers": {"learn_time_ms": 11.134, "learn_throughput": 2874.084, "update_time_ms": 14.594}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 367.31854248046875, "min_q": -151.02130126953125, "max_q": 771.9584350585938, "mean_td_error": 30.837488174438477, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 377.577392578125, "min_q": -12.318402290344238, "max_q": 679.7823486328125, "mean_td_error": 12.603124618530273, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 350.1347961425781, "min_q": -47.28224182128906, "max_q": 651.0785522460938, "mean_td_error": 16.731351852416992, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 364.088623046875, "min_q": -38.900943756103516, "max_q": 720.17919921875, "mean_td_error": 64.46314239501953, "model": {}}}, "num_steps_sampled": 87696, "num_steps_trained": 231200, "last_target_update_ts": 87696, "num_target_updates": 173}, "done": false, "episodes_total": 318, "training_iteration": 87, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-28-50", "timestamp": 1624267730, "time_this_iter_s": 33.286319732666016, "time_total_s": 2762.0499262809753, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c6897a0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c41b710>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6d40>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c31c0e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c31c440>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6d40>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c31c0e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c31c440>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6d40>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c31c0e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c31c440>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6d40>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c31c0e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c31c440>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c31c8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2762.0499262809753, "timesteps_since_restore": 0, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 49.36041666666666, "ram_util_percent": 96.41250000000001}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 6285.008153826401, "episode_len_mean": 442.37, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-2": -319.9713200692588, "AGENT-0": -434.50493179261696, "AGENT-1": -303.0152551308864}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-2": 8958.253931464842, "AGENT-0": 9306.466775605351, "AGENT-1": 8963.640732104383}, "policy_reward_mean": {"AGENT-3": 1390.0134898961574, "AGENT-2": 1557.0857134189198, "AGENT-0": 1894.93607994684, "AGENT-1": 1442.9728705644823}, "custom_metrics": {"mean_ego_speed_mean": 28.844997500000005, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.51108500000002, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.48975}, "hist_stats": {"episode_reward": [-319.1743590551796, 13081.65122968914, 984.7269331196521, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325, 9270.245494712182, 9411.059092335705, 34211.68591780714, 13028.590634456254, 2271.993482035765, 1090.0410168870833, 6211.851673114387], "episode_lengths": [364, 999, 304, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364, 421, 984, 999, 783, 152, 455, 292], "policy_AGENT-3_reward": [107.37378687590919, 278.15399560452573, 144.65462883194616, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583, 262.8196731257371, 459.40214937058136, 8554.301803411183, 3359.9619835662957, 292.8816233366533, 218.7252931205793, 1591.8423489789695], "policy_AGENT-2_reward": [-319.9713200692588, 6219.712680251618, 336.5933419830226, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183, 2972.66143598652, 4143.584003368301, 8550.541119406005, 3118.2684045385445, 627.4576258224816, 146.70362876696294, 1429.5183167346297], "policy_AGENT-0_reward": [-214.51703063320798, 6187.294600076396, 358.2489100656159, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782, 2973.2444011895586, 4200.998247548772, 8550.514963449576, 3189.8383829742834, 628.0489875479294, 274.35177277417864, 1523.8931513932946], "policy_AGENT-1_reward": [107.94020477137774, 396.4899537566012, 145.2300522390685, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753, 3061.519984410381, 607.0746920480364, 8556.328031540294, 3360.5218633771706, 723.6052453287012, 450.2603222253631, 1666.5978560074882]}, "sampler_perf": {"mean_env_wait_ms": 49.746434011695165, "mean_raw_obs_processing_ms": 1.6850013745385033, "mean_inference_ms": 2.4502303636108955, "mean_action_processing_ms": 0.1584063389240346}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 88704, "timers": {"learn_time_ms": 10.809, "learn_throughput": 2960.459, "update_time_ms": 13.65}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 461.76275634765625, "min_q": -56.944488525390625, "max_q": 762.371337890625, "mean_td_error": 47.595176696777344, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 353.14306640625, "min_q": -97.3521957397461, "max_q": 693.1278686523438, "mean_td_error": 27.9718074798584, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 359.2195739746094, "min_q": -149.13510131835938, "max_q": 660.758544921875, "mean_td_error": 19.106163024902344, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 337.7513427734375, "min_q": 0.030894994735717773, "max_q": 744.5537719726562, "mean_td_error": 26.376100540161133, "model": {}}}, "num_steps_sampled": 88704, "num_steps_trained": 233888, "last_target_update_ts": 88704, "num_target_updates": 175}, "done": false, "episodes_total": 320, "training_iteration": 88, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-29-23", "timestamp": 1624267763, "time_this_iter_s": 33.76069688796997, "time_total_s": 2795.8106231689453, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c2c67a0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c2c6710>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c31c170>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c31c290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c31c3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c31c7a0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c31c170>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c31c290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c31c3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c31c7a0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c31c170>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c31c290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c31c3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c31c7a0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c31c170>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c31c290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c31c3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c31c7a0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c3915f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2795.8106231689453, "timesteps_since_restore": 0, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 45.977083333333326, "ram_util_percent": 96.52708333333334}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 6308.764295516553, "episode_len_mean": 441.22, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-0": -434.50493179261696, "AGENT-2": -319.9713200692588, "AGENT-1": -303.0152551308864}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9306.466775605351, "AGENT-2": 8958.253931464842, "AGENT-1": 8963.640732104383}, "policy_reward_mean": {"AGENT-3": 1391.4313108259098, "AGENT-0": 1901.286393911919, "AGENT-2": 1563.647148977393, "AGENT-1": 1452.3994418013299}, "custom_metrics": {"mean_ego_speed_mean": 28.796157500000003, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.16132499999999, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.48975}, "hist_stats": {"episode_reward": [3360.3411021348834, -265.9655923527992, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325, 9270.245494712182, 9411.059092335705, 34211.68591780714, 13028.590634456254, 2271.993482035765, 1090.0410168870833, 6211.851673114387, -319.1743590551796, 13081.65122968914], "episode_lengths": [189, 108, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364, 421, 984, 999, 783, 152, 455, 292, 364, 999], "policy_AGENT-3_reward": [286.4367218071854, -102.36327181605955, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583, 262.8196731257371, 459.40214937058136, 8554.301803411183, 3359.9619835662957, 292.8816233366533, 218.7252931205793, 1591.8423489789695, 107.37378687590919, 278.15399560452573], "policy_AGENT-0_reward": [993.2803065735391, -34.52374477228021, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782, 2973.2444011895586, 4200.998247548772, 8550.514963449576, 3189.8383829742834, 628.0489875479294, 274.35177277417864, 1523.8931513932946, -214.51703063320798, 6187.294600076396], "policy_AGENT-2_reward": [992.7368978303267, -35.097043905592805, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183, 2972.66143598652, 4143.584003368301, 8550.541119406005, 3118.2684045385445, 627.4576258224816, 146.70362876696294, 1429.5183167346297, -319.9713200692588, 6219.712680251618], "policy_AGENT-1_reward": [1087.8871759238295, -93.98153185886669, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753, 3061.519984410381, 607.0746920480364, 8556.328031540294, 3360.5218633771706, 723.6052453287012, 450.2603222253631, 1666.5978560074882, 107.94020477137774, 396.4899537566012]}, "sampler_perf": {"mean_env_wait_ms": 49.82578943230949, "mean_raw_obs_processing_ms": 1.6833260366276397, "mean_inference_ms": 2.4519933750521283, "mean_action_processing_ms": 0.15861333694843374}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 89712, "timers": {"learn_time_ms": 10.594, "learn_throughput": 3020.48, "update_time_ms": 13.116}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 361.58990478515625, "min_q": -327.0254821777344, "max_q": 766.6099853515625, "mean_td_error": 34.08448791503906, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 304.77178955078125, "min_q": -14.6155424118042, "max_q": 672.934326171875, "mean_td_error": 65.15097045898438, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 305.5428466796875, "min_q": -351.7125549316406, "max_q": 670.934326171875, "mean_td_error": -7.1402974128723145, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 342.728515625, "min_q": -39.08842086791992, "max_q": 732.2138671875, "mean_td_error": 35.273136138916016, "model": {}}}, "num_steps_sampled": 89712, "num_steps_trained": 236576, "last_target_update_ts": 89712, "num_target_updates": 177}, "done": false, "episodes_total": 321, "training_iteration": 89, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-29-58", "timestamp": 1624267798, "time_this_iter_s": 34.0226616859436, "time_total_s": 2829.833284854889, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c391950>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c2e9b90>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2e99e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9c20>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6ef0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2e99e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9c20>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6ef0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2e99e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9c20>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6ef0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2e99e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9c20>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6ef0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c31ccb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2829.833284854889, "timesteps_since_restore": 0, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 54.24081632653061, "ram_util_percent": 96.55714285714288}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 6643.302670801911, "episode_len_mean": 450.13, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-0": -434.50493179261696, "AGENT-3": -507.5460381922926, "AGENT-2": -319.9713200692588, "AGENT-1": -303.0152551308864}, "policy_reward_max": {"AGENT-0": 9306.466775605351, "AGENT-3": 9311.39186054342, "AGENT-2": 8958.253931464842, "AGENT-1": 8963.640732104383}, "policy_reward_mean": {"AGENT-0": 1988.7374143977186, "AGENT-3": 1479.8720074925568, "AGENT-2": 1642.1466422490746, "AGENT-1": 1532.5466066625586}, "custom_metrics": {"mean_ego_speed_mean": 28.34933, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.1284075, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.48975}, "hist_stats": {"episode_reward": [33187.871936182964, 11964.435468943962, 18990.27692727228, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325, 9270.245494712182, 9411.059092335705, 34211.68591780714, 13028.590634456254, 2271.993482035765, 1090.0410168870833, 6211.851673114387, -319.1743590551796, 13081.65122968914, 3360.3411021348834], "episode_lengths": [999, 999, 999, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364, 421, 984, 999, 783, 152, 455, 292, 364, 999, 189], "policy_AGENT-0_reward": [8710.578303807662, 6004.951576451219, 8981.751322892642, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782, 2973.2444011895586, 4200.998247548772, 8550.514963449576, 3189.8383829742834, 628.0489875479294, 274.35177277417864, 1523.8931513932946, -214.51703063320798, 6187.294600076396, 993.2803065735391], "policy_AGENT-3_reward": [8741.706394848676, -22.314087886500186, 8986.118090110682, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583, 262.8196731257371, 459.40214937058136, 8554.301803411183, 3359.9619835662957, 292.8816233366533, 218.7252931205793, 1591.8423489789695, 107.37378687590919, 278.15399560452573, 286.4367218071854], "policy_AGENT-2_reward": [7814.852283262563, 7.507091793726815, 469.3655550436909, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183, 2972.66143598652, 4143.584003368301, 8550.541119406005, 3118.2684045385445, 627.4576258224816, 146.70362876696294, 1429.5183167346297, -319.9713200692588, 6219.712680251618, 992.7368978303267], "policy_AGENT-1_reward": [7920.7349542640295, 5974.29088858555, 553.0419592252724, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753, 3061.519984410381, 607.0746920480364, 8556.328031540294, 3360.5218633771706, 723.6052453287012, 450.2603222253631, 1666.5978560074882, 107.94020477137774, 396.4899537566012, 1087.8871759238295]}, "sampler_perf": {"mean_env_wait_ms": 49.97780944327676, "mean_raw_obs_processing_ms": 1.6795732522962732, "mean_inference_ms": 2.455224759632157, "mean_action_processing_ms": 0.15888974538554868}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 90720, "timers": {"learn_time_ms": 10.57, "learn_throughput": 3027.395, "update_time_ms": 14.401}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 371.4124450683594, "min_q": -175.25006103515625, "max_q": 744.542724609375, "mean_td_error": 13.484769821166992, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 305.2028503417969, "min_q": -40.491031646728516, "max_q": 701.6836547851562, "mean_td_error": -4.0357160568237305, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 383.41021728515625, "min_q": -133.6260986328125, "max_q": 670.6000366210938, "mean_td_error": 29.937358856201172, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 353.56707763671875, "min_q": -97.22286987304688, "max_q": 749.930908203125, "mean_td_error": -0.11970901489257812, "model": {}}}, "num_steps_sampled": 90720, "num_steps_trained": 239264, "last_target_update_ts": 90720, "num_target_updates": 179}, "done": false, "episodes_total": 322, "training_iteration": 90, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-30-32", "timestamp": 1624267832, "time_this_iter_s": 34.29819416999817, "time_total_s": 2864.131479024887, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c31cf80>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c2b7830>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2b70e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2b73b0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2b70e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2b73b0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2b70e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2b73b0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7710>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7290>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2b70e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2b73b0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c2b78c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2864.131479024887, "timesteps_since_restore": 0, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 48.908, "ram_util_percent": 96.742}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 6497.113748589486, "episode_len_mean": 441.54, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-2": -319.9713200692588, "AGENT-0": -434.50493179261696, "AGENT-1": -303.0152551308864}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-2": 8958.253931464842, "AGENT-0": 9306.466775605351, "AGENT-1": 8963.640732104383}, "policy_reward_mean": {"AGENT-3": 1397.525017714452, "AGENT-2": 1702.279988936397, "AGENT-0": 1903.8910807533691, "AGENT-1": 1493.4176611852658}, "custom_metrics": {"mean_ego_speed_mean": 28.49860500000001, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.12169, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.48975}, "hist_stats": {"episode_reward": [15320.332794398382, 1015.4873805754371, 1992.6370605227469, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325, 9270.245494712182, 9411.059092335705, 34211.68591780714, 13028.590634456254, 2271.993482035765, 1090.0410168870833, 6211.851673114387, -319.1743590551796, 13081.65122968914, 3360.3411021348834, 33187.871936182964], "episode_lengths": [999, 140, 475, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364, 421, 984, 999, 783, 152, 455, 292, 364, 999, 189, 999], "policy_AGENT-3_reward": [541.4620050677707, 187.64301934587456, 391.23403993780437, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583, 262.8196731257371, 459.40214937058136, 8554.301803411183, 3359.9619835662957, 292.8816233366533, 218.7252931205793, 1591.8423489789695, 107.37378687590919, 278.15399560452573, 286.4367218071854, 8741.706394848676], "policy_AGENT-2_reward": [6319.1912453324185, 171.01607023728423, 365.8789995163216, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183, 2972.66143598652, 4143.584003368301, 8550.541119406005, 3118.2684045385445, 627.4576258224816, 146.70362876696294, 1429.5183167346297, -319.9713200692588, 6219.712680251618, 992.7368978303267, 7814.852283262563], "policy_AGENT-0_reward": [6330.5085231451485, 171.561011763775, 458.36413636018636, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782, 2973.2444011895586, 4200.998247548772, 8550.514963449576, 3189.8383829742834, 628.0489875479294, 274.35177277417864, 1523.8931513932946, -214.51703063320798, 6187.294600076396, 993.2803065735391, 8710.578303807662], "policy_AGENT-1_reward": [2129.1710208530476, 485.2672792285024, 777.1598847084296, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753, 3061.519984410381, 607.0746920480364, 8556.328031540294, 3360.5218633771706, 723.6052453287012, 450.2603222253631, 1666.5978560074882, 107.94020477137774, 396.4899537566012, 1087.8871759238295, 7920.7349542640295]}, "sampler_perf": {"mean_env_wait_ms": 50.13379262647547, "mean_raw_obs_processing_ms": 1.6758959917796303, "mean_inference_ms": 2.4588570795305227, "mean_action_processing_ms": 0.1592546913253282}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 91728, "timers": {"learn_time_ms": 10.74, "learn_throughput": 2979.478, "update_time_ms": 14.871}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 357.8665771484375, "min_q": -212.0617218017578, "max_q": 763.04296875, "mean_td_error": -12.975126266479492, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 306.4068908691406, "min_q": -39.066673278808594, "max_q": 706.9695434570312, "mean_td_error": 39.11766052246094, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 331.1339111328125, "min_q": -210.47677612304688, "max_q": 682.6480102539062, "mean_td_error": 30.09752655029297, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 333.1375732421875, "min_q": -152.6940460205078, "max_q": 740.7099609375, "mean_td_error": 104.72785949707031, "model": {}}}, "num_steps_sampled": 91728, "num_steps_trained": 241952, "last_target_update_ts": 91728, "num_target_updates": 181}, "done": false, "episodes_total": 324, "training_iteration": 91, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-31-07", "timestamp": 1624267867, "time_this_iter_s": 34.24549126625061, "time_total_s": 2898.3769702911377, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c3cbc20>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c41bd40>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c31ccb0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c31c950>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2b79e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2b74d0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c31ccb0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c31c950>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2b79e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2b74d0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c31ccb0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c31c950>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2b79e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2b74d0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c31ccb0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c31c950>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2b79e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2b74d0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c2b7d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2898.3769702911377, "timesteps_since_restore": 0, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 46.967346938775506, "ram_util_percent": 96.95510204081633}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 6796.484419673367, "episode_len_mean": 446.78, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-2": -319.9713200692588, "AGENT-0": -434.50493179261696, "AGENT-1": -303.0152551308864}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-2": 8958.253931464842, "AGENT-0": 9306.466775605351, "AGENT-1": 8963.640732104383}, "policy_reward_mean": {"AGENT-3": 1474.5084919610113, "AGENT-2": 1777.4244752812456, "AGENT-0": 1978.0020757205098, "AGENT-1": 1566.5493767105977}, "custom_metrics": {"mean_ego_speed_mean": 28.245045000000005, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.00151250000003, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.48975}, "hist_stats": {"episode_reward": [31929.704168910794, 3545.8706700607263, 252.27059029046936, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325, 9270.245494712182, 9411.059092335705, 34211.68591780714, 13028.590634456254, 2271.993482035765, 1090.0410168870833, 6211.851673114387, -319.1743590551796, 13081.65122968914, 3360.3411021348834, 33187.871936182964, 15320.332794398382, 1015.4873805754371], "episode_lengths": [999, 357, 142, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364, 421, 984, 999, 783, 152, 455, 292, 364, 999, 189, 999, 999, 140], "policy_AGENT-3_reward": [8089.581464593753, 36.63921675461524, 138.56996067297456, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583, 262.8196731257371, 459.40214937058136, 8554.301803411183, 3359.9619835662957, 292.8816233366533, 218.7252931205793, 1591.8423489789695, 107.37378687590919, 278.15399560452573, 286.4367218071854, 8741.706394848676, 541.4620050677707, 187.64301934587456], "policy_AGENT-2_reward": [7880.32763400115, 58.06465840597534, -29.355094151940108, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183, 2972.66143598652, 4143.584003368301, 8550.541119406005, 3118.2684045385445, 627.4576258224816, 146.70362876696294, 1429.5183167346297, -319.9713200692588, 6219.712680251618, 992.7368978303267, 7814.852283262563, 6319.1912453324185, 171.01607023728423], "policy_AGENT-0_reward": [7869.463633074263, 1694.7782736536706, -28.787383607569872, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782, 2973.2444011895586, 4200.998247548772, 8550.514963449576, 3189.8383829742834, 628.0489875479294, 274.35177277417864, 1523.8931513932946, -214.51703063320798, 6187.294600076396, 993.2803065735391, 8710.578303807662, 6330.5085231451485, 171.561011763775], "policy_AGENT-1_reward": [8090.331437241606, 1756.3885212464666, 171.84310737700494, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753, 3061.519984410381, 607.0746920480364, 8556.328031540294, 3360.5218633771706, 723.6052453287012, 450.2603222253631, 1666.5978560074882, 107.94020477137774, 396.4899537566012, 1087.8871759238295, 7920.7349542640295, 2129.1710208530476, 485.2672792285024]}, "sampler_perf": {"mean_env_wait_ms": 50.22252379318915, "mean_raw_obs_processing_ms": 1.6741382191605867, "mean_inference_ms": 2.4608158015385304, "mean_action_processing_ms": 0.1594775426200312}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 92736, "timers": {"learn_time_ms": 10.621, "learn_throughput": 3012.845, "update_time_ms": 17.64}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 467.0777587890625, "min_q": -60.632843017578125, "max_q": 794.1111450195312, "mean_td_error": 22.397445678710938, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 393.1436462402344, "min_q": -20.422779083251953, "max_q": 685.8401489257812, "mean_td_error": 36.284934997558594, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 321.0801696777344, "min_q": -99.83902740478516, "max_q": 689.0884399414062, "mean_td_error": 31.56549072265625, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 311.1078796386719, "min_q": -208.98812866210938, "max_q": 771.447998046875, "mean_td_error": 64.5835189819336, "model": {}}}, "num_steps_sampled": 92736, "num_steps_trained": 244640, "last_target_update_ts": 92736, "num_target_updates": 183}, "done": false, "episodes_total": 325, "training_iteration": 92, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-31-36", "timestamp": 1624267896, "time_this_iter_s": 28.971032857894897, "time_total_s": 2927.3480031490326, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c2b73b0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c2b7170>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7680>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2b77a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7c20>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7680>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2b77a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7c20>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7680>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2b77a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7c20>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7680>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2b77a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7050>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7c20>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c2c6ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2927.3480031490326, "timesteps_since_restore": 0, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 48.49268292682927, "ram_util_percent": 97.00731707317073}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 6871.596839495394, "episode_len_mean": 452.13, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-0": -434.50493179261696, "AGENT-2": -319.9713200692588, "AGENT-1": -303.0152551308864}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9306.466775605351, "AGENT-2": 8958.253931464842, "AGENT-1": 8963.640732104383}, "policy_reward_mean": {"AGENT-3": 1475.2347498729955, "AGENT-0": 1999.218873646544, "AGENT-2": 1814.3131618183647, "AGENT-1": 1582.830054157487}, "custom_metrics": {"mean_ego_speed_mean": 27.881450000000005, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.23808750000002, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.48975}, "hist_stats": {"episode_reward": [10239.49450023268, 1069.8887423212473, -219.13732034862412, -543.4554542678886, -221.8233316846136, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325, 9270.245494712182, 9411.059092335705, 34211.68591780714, 13028.590634456254, 2271.993482035765, 1090.0410168870833, 6211.851673114387, -319.1743590551796, 13081.65122968914, 3360.3411021348834, 33187.871936182964, 15320.332794398382, 1015.4873805754371, 31929.704168910794], "episode_lengths": [464, 570, 89, 216, 103, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364, 421, 984, 999, 783, 152, 455, 292, 364, 999, 189, 999, 999, 140, 999], "policy_AGENT-3_reward": [254.4466550476002, -6.611686421586233, -90.88506869165732, -314.954316121668, -77.03137120981295, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583, 262.8196731257371, 459.40214937058136, 8554.301803411183, 3359.9619835662957, 292.8816233366533, 218.7252931205793, 1591.8423489789695, 107.37378687590919, 278.15399560452573, 286.4367218071854, 8741.706394848676, 541.4620050677707, 187.64301934587456, 8089.581464593753], "policy_AGENT-0_reward": [3295.3291211937594, 492.341561455807, -29.013459808092392, -271.7070873897027, -33.685210755578005, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782, 2973.2444011895586, 4200.998247548772, 8550.514963449576, 3189.8383829742834, 628.0489875479294, 274.35177277417864, 1523.8931513932946, -214.51703063320798, 6187.294600076396, 993.2803065735391, 8710.578303807662, 6330.5085231451485, 171.561011763775, 7869.463633074263], "policy_AGENT-2_reward": [3294.747668755996, 422.8305492099743, -29.577796475005115, 21.30767995769113, -34.27518652227463, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183, 2972.66143598652, 4143.584003368301, 8550.541119406005, 3118.2684045385445, 627.4576258224816, 146.70362876696294, 1429.5183167346297, -319.9713200692588, 6219.712680251618, 992.7368978303267, 7814.852283262563, 6319.1912453324185, 171.01607023728423, 7880.32763400115], "policy_AGENT-1_reward": [3394.9710552353295, 161.3283180770502, -69.66099537386931, 21.898269285791827, -76.83156319694797, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753, 3061.519984410381, 607.0746920480364, 8556.328031540294, 3360.5218633771706, 723.6052453287012, 450.2603222253631, 1666.5978560074882, 107.94020477137774, 396.4899537566012, 1087.8871759238295, 7920.7349542640295, 2129.1710208530476, 485.2672792285024, 8090.331437241606]}, "sampler_perf": {"mean_env_wait_ms": 50.4375809736165, "mean_raw_obs_processing_ms": 1.6719085203883566, "mean_inference_ms": 2.4655983567877104, "mean_action_processing_ms": 0.15992326514750213}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 93744, "timers": {"learn_time_ms": 10.763, "learn_throughput": 2973.089, "update_time_ms": 16.847}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 478.058837890625, "min_q": 16.553546905517578, "max_q": 777.5599975585938, "mean_td_error": 2.5210587978363037, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 318.2288818359375, "min_q": -98.15038299560547, "max_q": 716.3362426757812, "mean_td_error": 50.255706787109375, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 324.87640380859375, "min_q": -143.28689575195312, "max_q": 689.2755126953125, "mean_td_error": 32.35878372192383, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 358.1849060058594, "min_q": -242.87290954589844, "max_q": 756.5296630859375, "mean_td_error": 96.68141174316406, "model": {}}}, "num_steps_sampled": 93744, "num_steps_trained": 247328, "last_target_update_ts": 93744, "num_target_updates": 185}, "done": false, "episodes_total": 327, "training_iteration": 93, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-32-10", "timestamp": 1624267930, "time_this_iter_s": 33.380433320999146, "time_total_s": 2960.7284364700317, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c2c6b90>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c2c63b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c444dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c391f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c31c710>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c444dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c391f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c31c710>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c444dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c391f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c31c710>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c444dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c391f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c6897a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c31c710>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c2b7b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2960.7284364700317, "timesteps_since_restore": 0, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 51.62708333333334, "ram_util_percent": 96.73541666666665}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 7263.767728099092, "episode_len_mean": 465.93, "episodes_this_iter": 3, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-2": -319.9713200692588, "AGENT-0": -434.50493179261696, "AGENT-1": -303.0152551308864}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-2": 8958.253931464842, "AGENT-0": 9306.466775605351, "AGENT-1": 9000.797411649222}, "policy_reward_mean": {"AGENT-3": 1517.2004445307455, "AGENT-2": 1909.0130440057394, "AGENT-0": 2126.464213259121, "AGENT-1": 1711.0900263034841}, "custom_metrics": {"mean_ego_speed_mean": 26.945077500000004, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.21688000000002, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.48975}, "hist_stats": {"episode_reward": [1797.171214876274, 24286.681784788496, 12148.819754403923, 6437.044989861819, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325, 9270.245494712182, 9411.059092335705, 34211.68591780714, 13028.590634456254, 2271.993482035765, 1090.0410168870833, 6211.851673114387, -319.1743590551796, 13081.65122968914, 3360.3411021348834, 33187.871936182964, 15320.332794398382, 1015.4873805754371, 31929.704168910794, 10239.49450023268, 1069.8887423212473], "episode_lengths": [322, 999, 467, 594, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364, 421, 984, 999, 783, 152, 455, 292, 364, 999, 189, 999, 999, 140, 999, 464, 570], "policy_AGENT-3_reward": [419.16360236066856, 263.88809201001175, 3030.6470153811856, 1388.5332242901225, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583, 262.8196731257371, 459.40214937058136, 8554.301803411183, 3359.9619835662957, 292.8816233366533, 218.7252931205793, 1591.8423489789695, 107.37378687590919, 278.15399560452573, 286.4367218071854, 8741.706394848676, 541.4620050677707, 187.64301934587456, 8089.581464593753, 254.4466550476002, -6.611686421586233], "policy_AGENT-2_reward": [435.0061329806446, 6026.934818903771, 2965.501963813467, 1722.4488033837736, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183, 2972.66143598652, 4143.584003368301, 8550.541119406005, 3118.2684045385445, 627.4576258224816, 146.70362876696294, 1429.5183167346297, -319.9713200692588, 6219.712680251618, 992.7368978303267, 7814.852283262563, 6319.1912453324185, 171.01607023728423, 7880.32763400115, 3294.747668755996, 422.8305492099743], "policy_AGENT-0_reward": [435.5842591847143, 8995.061462225516, 2959.482481894102, 1757.8586107110934, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782, 2973.2444011895586, 4200.998247548772, 8550.514963449576, 3189.8383829742834, 628.0489875479294, 274.35177277417864, 1523.8931513932946, -214.51703063320798, 6187.294600076396, 993.2803065735391, 8710.578303807662, 6330.5085231451485, 171.561011763775, 7869.463633074263, 3295.3291211937594, 492.341561455807], "policy_AGENT-1_reward": [507.4172203502464, 9000.797411649222, 3193.188293315189, 1568.2043514768468, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753, 3061.519984410381, 607.0746920480364, 8556.328031540294, 3360.5218633771706, 723.6052453287012, 450.2603222253631, 1666.5978560074882, 107.94020477137774, 396.4899537566012, 1087.8871759238295, 7920.7349542640295, 2129.1710208530476, 485.2672792285024, 8090.331437241606, 3394.9710552353295, 161.3283180770502]}, "sampler_perf": {"mean_env_wait_ms": 50.69890330387827, "mean_raw_obs_processing_ms": 1.6623706860912733, "mean_inference_ms": 2.4708967281648317, "mean_action_processing_ms": 0.1605419309683381}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 94752, "timers": {"learn_time_ms": 10.937, "learn_throughput": 2925.772, "update_time_ms": 18.759}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 480.80853271484375, "min_q": -155.18618774414062, "max_q": 772.848388671875, "mean_td_error": 23.059219360351562, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 392.73895263671875, "min_q": -99.63407135009766, "max_q": 714.2921142578125, "mean_td_error": 25.684326171875, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 339.0167236328125, "min_q": -116.24217987060547, "max_q": 695.2388916015625, "mean_td_error": 33.90393829345703, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 412.410888671875, "min_q": -50.686553955078125, "max_q": 776.0960083007812, "mean_td_error": 1.7067837715148926, "model": {}}}, "num_steps_sampled": 94752, "num_steps_trained": 250016, "last_target_update_ts": 94752, "num_target_updates": 187}, "done": false, "episodes_total": 330, "training_iteration": 94, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-32-40", "timestamp": 1624267960, "time_this_iter_s": 30.56913733482361, "time_total_s": 2991.2975738048553, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c357170>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c357200>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c357440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c357680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3577a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3575f0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c357440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c357680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3577a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3575f0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c357440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c357680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3577a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3575f0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c357440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c357680>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3577a0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3575f0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c3578c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 2991.2975738048553, "timesteps_since_restore": 0, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 49.02954545454545, "ram_util_percent": 96.95227272727274}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 7219.774497435374, "episode_len_mean": 463.6, "episodes_this_iter": 1, "policy_reward_min": {"AGENT-0": -434.50493179261696, "AGENT-3": -507.5460381922926, "AGENT-2": -319.9713200692588, "AGENT-1": -303.0152551308864}, "policy_reward_max": {"AGENT-0": 9306.466775605351, "AGENT-3": 9311.39186054342, "AGENT-2": 8958.253931464842, "AGENT-1": 9000.797411649222}, "policy_reward_mean": {"AGENT-0": 2115.002248094657, "AGENT-3": 1507.6777010067224, "AGENT-2": 1897.3180173458563, "AGENT-1": 1699.7765309881354}, "custom_metrics": {"mean_ego_speed_mean": 27.012375, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.023755, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.4785}, "hist_stats": {"episode_reward": [2037.7219234899026, 938.2804150638907, -303.9922512037695, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325, 9270.245494712182, 9411.059092335705, 34211.68591780714, 13028.590634456254, 2271.993482035765, 1090.0410168870833, 6211.851673114387, -319.1743590551796, 13081.65122968914, 3360.3411021348834, 33187.871936182964, 15320.332794398382, 1015.4873805754371, 31929.704168910794, 10239.49450023268, 1069.8887423212473, 1797.171214876274, 24286.681784788496, 12148.819754403923], "episode_lengths": [361, 316, 101, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364, 421, 984, 999, 783, 152, 455, 292, 364, 999, 189, 999, 999, 140, 999, 464, 570, 322, 999, 467], "policy_AGENT-0_reward": [611.6620942646209, 415.28550710282803, -35.79434916075682, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782, 2973.2444011895586, 4200.998247548772, 8550.514963449576, 3189.8383829742834, 628.0489875479294, 274.35177277417864, 1523.8931513932946, -214.51703063320798, 6187.294600076396, 993.2803065735391, 8710.578303807662, 6330.5085231451485, 171.561011763775, 7869.463633074263, 3295.3291211937594, 492.341561455807, 435.5842591847143, 8995.061462225516, 2959.482481894102], "policy_AGENT-3_reward": [436.258871887776, 77.44065504434514, -116.65496286627078, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583, 262.8196731257371, 459.40214937058136, 8554.301803411183, 3359.9619835662957, 292.8816233366533, 218.7252931205793, 1591.8423489789695, 107.37378687590919, 278.15399560452573, 286.4367218071854, 8741.706394848676, 541.4620050677707, 187.64301934587456, 8089.581464593753, 254.4466550476002, -6.611686421586233, 419.16360236066856, 263.88809201001175, 3030.6470153811856], "policy_AGENT-2_reward": [552.9461373954882, 367.5375009346923, -36.3445658105404, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183, 2972.66143598652, 4143.584003368301, 8550.541119406005, 3118.2684045385445, 627.4576258224816, 146.70362876696294, 1429.5183167346297, -319.9713200692588, 6219.712680251618, 992.7368978303267, 7814.852283262563, 6319.1912453324185, 171.01607023728423, 7880.32763400115, 3294.747668755996, 422.8305492099743, 435.0061329806446, 6026.934818903771, 2965.501963813467], "policy_AGENT-1_reward": [436.8548199420166, 78.01675198202545, -115.19837336620144, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753, 3061.519984410381, 607.0746920480364, 8556.328031540294, 3360.5218633771706, 723.6052453287012, 450.2603222253631, 1666.5978560074882, 107.94020477137774, 396.4899537566012, 1087.8871759238295, 7920.7349542640295, 2129.1710208530476, 485.2672792285024, 8090.331437241606, 3394.9710552353295, 161.3283180770502, 507.4172203502464, 9000.797411649222, 3193.188293315189]}, "sampler_perf": {"mean_env_wait_ms": 50.837811027099626, "mean_raw_obs_processing_ms": 1.6610732698335802, "mean_inference_ms": 2.474047098134772, "mean_action_processing_ms": 0.16078082284585207}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 95760, "timers": {"learn_time_ms": 10.468, "learn_throughput": 3056.878, "update_time_ms": 13.858}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 353.73590087890625, "min_q": -155.11744689941406, "max_q": 810.131103515625, "mean_td_error": 49.61429214477539, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 301.4943542480469, "min_q": -57.125587463378906, "max_q": 730.9410400390625, "mean_td_error": 15.618768692016602, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 373.8411865234375, "min_q": -311.87762451171875, "max_q": 691.2857055664062, "mean_td_error": 25.98284339904785, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 323.0975646972656, "min_q": -135.2678680419922, "max_q": 741.3865966796875, "mean_td_error": -14.924449920654297, "model": {}}}, "num_steps_sampled": 95760, "num_steps_trained": 252704, "last_target_update_ts": 95760, "num_target_updates": 189}, "done": false, "episodes_total": 331, "training_iteration": 95, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-33-10", "timestamp": 1624267990, "time_this_iter_s": 29.667280435562134, "time_total_s": 3020.9648542404175, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c479cb0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c2c63b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6290>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c357cb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c357d40>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3579e0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6290>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c357cb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c357d40>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3579e0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6290>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c357cb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c357d40>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3579e0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6290>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c357cb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c357d40>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c3579e0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c357ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 3020.9648542404175, "timesteps_since_restore": 0, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 46.32142857142857, "ram_util_percent": 97.1047619047619}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 7305.541847131927, "episode_len_mean": 468.8, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-2": -319.9713200692588, "AGENT-0": -434.50493179261696, "AGENT-1": -303.0152551308864}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-2": 8958.253931464842, "AGENT-0": 9306.466775605351, "AGENT-1": 9000.797411649222}, "policy_reward_mean": {"AGENT-3": 1527.6654208639052, "AGENT-2": 1920.246935366766, "AGENT-0": 2137.8744328941484, "AGENT-1": 1719.7550580071047}, "custom_metrics": {"mean_ego_speed_mean": 26.532985, "mean_ego_speed_min": 2.53925, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 90.0963825, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.4785}, "hist_stats": {"episode_reward": [1819.8906083371658, 7391.132525178352, 1355.3948383007964, 13849.946085063762, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325, 9270.245494712182, 9411.059092335705, 34211.68591780714, 13028.590634456254, 2271.993482035765, 1090.0410168870833, 6211.851673114387, -319.1743590551796, 13081.65122968914, 3360.3411021348834, 33187.871936182964, 15320.332794398382, 1015.4873805754371, 31929.704168910794, 10239.49450023268, 1069.8887423212473, 1797.171214876274, 24286.681784788496, 12148.819754403923, 2037.7219234899026], "episode_lengths": [597, 340, 419, 999, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364, 421, 984, 999, 783, 152, 455, 292, 364, 999, 189, 999, 999, 140, 999, 464, 570, 322, 999, 467, 361], "policy_AGENT-3_reward": [68.42444239914855, 1891.133235497228, 125.21949454914949, 6475.181676839524, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583, 262.8196731257371, 459.40214937058136, 8554.301803411183, 3359.9619835662957, 292.8816233366533, 218.7252931205793, 1591.8423489789695, 107.37378687590919, 278.15399560452573, 286.4367218071854, 8741.706394848676, 541.4620050677707, 187.64301934587456, 8089.581464593753, 254.4466550476002, -6.611686421586233, 419.16360236066856, 263.88809201001175, 3030.6470153811856, 436.258871887776], "policy_AGENT-2_reward": [786.9346476342544, 1837.1500895808367, 549.7021292595308, 402.04837880794406, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183, 2972.66143598652, 4143.584003368301, 8550.541119406005, 3118.2684045385445, 627.4576258224816, 146.70362876696294, 1429.5183167346297, -319.9713200692588, 6219.712680251618, 992.7368978303267, 7814.852283262563, 6319.1912453324185, 171.01607023728423, 7880.32763400115, 3294.747668755996, 422.8305492099743, 435.0061329806446, 6026.934818903771, 2965.501963813467, 552.9461373954882], "policy_AGENT-0_reward": [895.5402659164189, 1771.16937197487, 554.6790754029955, 6472.133917214968, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782, 2973.2444011895586, 4200.998247548772, 8550.514963449576, 3189.8383829742834, 628.0489875479294, 274.35177277417864, 1523.8931513932946, -214.51703063320798, 6187.294600076396, 993.2803065735391, 8710.578303807662, 6330.5085231451485, 171.561011763775, 7869.463633074263, 3295.3291211937594, 492.341561455807, 435.5842591847143, 8995.061462225516, 2959.482481894102, 611.6620942646209], "policy_AGENT-1_reward": [68.99125238734541, 1891.6798281254348, 125.79413908911883, 500.5821122012951, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753, 3061.519984410381, 607.0746920480364, 8556.328031540294, 3360.5218633771706, 723.6052453287012, 450.2603222253631, 1666.5978560074882, 107.94020477137774, 396.4899537566012, 1087.8871759238295, 7920.7349542640295, 2129.1710208530476, 485.2672792285024, 8090.331437241606, 3394.9710552353295, 161.3283180770502, 507.4172203502464, 9000.797411649222, 3193.188293315189, 436.8548199420166]}, "sampler_perf": {"mean_env_wait_ms": 51.00409674308239, "mean_raw_obs_processing_ms": 1.6530941035968818, "mean_inference_ms": 2.476559904407334, "mean_action_processing_ms": 0.16115656725077643}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 96768, "timers": {"learn_time_ms": 11.265, "learn_throughput": 2840.653, "update_time_ms": 14.723}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 470.081787109375, "min_q": -148.79148864746094, "max_q": 815.1195678710938, "mean_td_error": 88.82807922363281, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 286.3472900390625, "min_q": -67.53199005126953, "max_q": 698.9597778320312, "mean_td_error": -1.8251699209213257, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 311.5469055175781, "min_q": -375.7002258300781, "max_q": 698.931884765625, "mean_td_error": 46.397735595703125, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 304.063232421875, "min_q": -173.74005126953125, "max_q": 768.5899047851562, "mean_td_error": 71.21698760986328, "model": {}}}, "num_steps_sampled": 96768, "num_steps_trained": 255392, "last_target_update_ts": 96768, "num_target_updates": 191}, "done": false, "episodes_total": 333, "training_iteration": 96, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-33-43", "timestamp": 1624268023, "time_this_iter_s": 32.9953875541687, "time_total_s": 3053.960241794586, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c357290>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c357170>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c444dd0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c1e6290>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c444dd0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c1e6290>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c444dd0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c1e6290>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7f80>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2c6c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c444dd0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c1e6290>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c1e6e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 3053.960241794586, "timesteps_since_restore": 0, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 49.82083333333333, "ram_util_percent": 97.23333333333333}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 7485.05615597104, "episode_len_mean": 467.63, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-0": -434.50493179261696, "AGENT-2": -319.9713200692588, "AGENT-1": -303.0152551308864}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9336.44922418634, "AGENT-2": 9336.23812199138, "AGENT-1": 9342.070375129997}, "policy_reward_mean": {"AGENT-3": 1476.7371612649201, "AGENT-0": 2172.602055225883, "AGENT-2": 2016.4884759496601, "AGENT-1": 1819.2284635305737}, "custom_metrics": {"mean_ego_speed_mean": 26.5380775, "mean_ego_speed_min": 3.183, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 89.70277, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.4785}, "hist_stats": {"episode_reward": [28291.23514954064, 4865.536657735151, 214.6912039096064, 923.2967226512116, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325, 9270.245494712182, 9411.059092335705, 34211.68591780714, 13028.590634456254, 2271.993482035765, 1090.0410168870833, 6211.851673114387, -319.1743590551796, 13081.65122968914, 3360.3411021348834, 33187.871936182964, 15320.332794398382, 1015.4873805754371, 31929.704168910794, 10239.49450023268, 1069.8887423212473, 1797.171214876274, 24286.681784788496, 12148.819754403923, 2037.7219234899026, 1819.8906083371658, 7391.132525178352], "episode_lengths": [999, 302, 130, 352, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364, 421, 984, 999, 783, 152, 455, 292, 364, 999, 189, 999, 999, 140, 999, 464, 570, 322, 999, 467, 361, 597, 340], "policy_AGENT-3_reward": [276.4774282328419, 1231.0977832573064, 121.17561355394162, 85.47359485722211, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583, 262.8196731257371, 459.40214937058136, 8554.301803411183, 3359.9619835662957, 292.8816233366533, 218.7252931205793, 1591.8423489789695, 107.37378687590919, 278.15399560452573, 286.4367218071854, 8741.706394848676, 541.4620050677707, 187.64301934587456, 8089.581464593753, 254.4466550476002, -6.611686421586233, 419.16360236066856, 263.88809201001175, 3030.6470153811856, 436.258871887776, 68.42444239914855, 1891.133235497228], "policy_AGENT-0_reward": [9336.44922418634, 1163.1260016050621, -33.693470117353975, 395.7889294561415, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782, 2973.2444011895586, 4200.998247548772, 8550.514963449576, 3189.8383829742834, 628.0489875479294, 274.35177277417864, 1523.8931513932946, -214.51703063320798, 6187.294600076396, 993.2803065735391, 8710.578303807662, 6330.5085231451485, 171.561011763775, 7869.463633074263, 3295.3291211937594, 492.341561455807, 435.5842591847143, 8995.061462225516, 2959.482481894102, 611.6620942646209, 895.5402659164189, 1771.16937197487], "policy_AGENT-2_reward": [9336.23812199138, 1239.6664443655009, -34.259191962834734, 355.9758509246552, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183, 2972.66143598652, 4143.584003368301, 8550.541119406005, 3118.2684045385445, 627.4576258224816, 146.70362876696294, 1429.5183167346297, -319.9713200692588, 6219.712680251618, 992.7368978303267, 7814.852283262563, 6319.1912453324185, 171.01607023728423, 7880.32763400115, 3294.747668755996, 422.8305492099743, 435.0061329806446, 6026.934818903771, 2965.501963813467, 552.9461373954882, 786.9346476342544, 1837.1500895808367], "policy_AGENT-1_reward": [9342.070375129997, 1231.6464285072748, 161.46825243585357, 86.05834741319269, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753, 3061.519984410381, 607.0746920480364, 8556.328031540294, 3360.5218633771706, 723.6052453287012, 450.2603222253631, 1666.5978560074882, 107.94020477137774, 396.4899537566012, 1087.8871759238295, 7920.7349542640295, 2129.1710208530476, 485.2672792285024, 8090.331437241606, 3394.9710552353295, 161.3283180770502, 507.4172203502464, 9000.797411649222, 3193.188293315189, 436.8548199420166, 68.99125238734541, 1891.6798281254348]}, "sampler_perf": {"mean_env_wait_ms": 51.20887181713923, "mean_raw_obs_processing_ms": 1.6510545914039463, "mean_inference_ms": 2.4809539038727304, "mean_action_processing_ms": 0.16154322106948807}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 97776, "timers": {"learn_time_ms": 11.078, "learn_throughput": 2888.664, "update_time_ms": 15.206}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 532.225830078125, "min_q": -133.00669860839844, "max_q": 810.1583251953125, "mean_td_error": 70.464599609375, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 421.9582214355469, "min_q": -65.20011901855469, "max_q": 710.0938110351562, "mean_td_error": 46.15758514404297, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 432.3110656738281, "min_q": -40.972381591796875, "max_q": 712.4000244140625, "mean_td_error": 52.090614318847656, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 366.51202392578125, "min_q": -276.5364990234375, "max_q": 791.29638671875, "mean_td_error": 52.499454498291016, "model": {}}}, "num_steps_sampled": 97776, "num_steps_trained": 258080, "last_target_update_ts": 97776, "num_target_updates": 193}, "done": false, "episodes_total": 335, "training_iteration": 97, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-34-16", "timestamp": 1624268056, "time_this_iter_s": 32.612077951431274, "time_total_s": 3086.5723197460175, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c3cbc20>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c2e9b90>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2b74d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2b78c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7560>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7d40>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2b74d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2b78c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7560>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7d40>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2b74d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2b78c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7560>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7d40>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2b74d0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c2b78c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7560>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c2b7d40>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c1e6c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 3086.5723197460175, "timesteps_since_restore": 0, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 52.480851063829796, "ram_util_percent": 97.1851063829787}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 7738.461218844961, "episode_len_mean": 474.13, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-0": -434.50493179261696, "AGENT-2": -319.9713200692588, "AGENT-1": -303.0152551308864}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9336.44922418634, "AGENT-2": 9336.23812199138, "AGENT-1": 9342.070375129997}, "policy_reward_mean": {"AGENT-3": 1507.0038697416917, "AGENT-0": 2245.2936395080237, "AGENT-2": 2091.301685933303, "AGENT-1": 1894.862023661939}, "custom_metrics": {"mean_ego_speed_mean": 25.948949999999996, "mean_ego_speed_min": 3.183, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 89.46702499999998, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.4785}, "hist_stats": {"episode_reward": [14585.914497736723, 11892.5797162162, 6411.555295781114, -472.97994453906415, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325, 9270.245494712182, 9411.059092335705, 34211.68591780714, 13028.590634456254, 2271.993482035765, 1090.0410168870833, 6211.851673114387, -319.1743590551796, 13081.65122968914, 3360.3411021348834, 33187.871936182964, 15320.332794398382, 1015.4873805754371, 31929.704168910794, 10239.49450023268, 1069.8887423212473, 1797.171214876274, 24286.681784788496, 12148.819754403923, 2037.7219234899026, 1819.8906083371658, 7391.132525178352, 28291.23514954064, 4865.536657735151], "episode_lengths": [612, 520, 321, 157, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364, 421, 984, 999, 783, 152, 455, 292, 364, 999, 189, 999, 999, 140, 999, 464, 570, 322, 999, 467, 361, 597, 340, 999, 302], "policy_AGENT-3_reward": [251.81870569379367, 2981.501350394546, 1447.5375088989294, 83.85709149317319, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583, 262.8196731257371, 459.40214937058136, 8554.301803411183, 3359.9619835662957, 292.8816233366533, 218.7252931205793, 1591.8423489789695, 107.37378687590919, 278.15399560452573, 286.4367218071854, 8741.706394848676, 541.4620050677707, 187.64301934587456, 8089.581464593753, 254.4466550476002, -6.611686421586233, 419.16360236066856, 263.88809201001175, 3030.6470153811856, 436.258871887776, 68.42444239914855, 1891.133235497228, 276.4774282328419, 1231.0977832573064], "policy_AGENT-0_reward": [4717.9160985056715, 2913.337789047231, 1647.0182582603722, -337.6245133369953, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782, 2973.2444011895586, 4200.998247548772, 8550.514963449576, 3189.8383829742834, 628.0489875479294, 274.35177277417864, 1523.8931513932946, -214.51703063320798, 6187.294600076396, 993.2803065735391, 8710.578303807662, 6330.5085231451485, 171.561011763775, 7869.463633074263, 3295.3291211937594, 492.341561455807, 435.5842591847143, 8995.061462225516, 2959.482481894102, 611.6620942646209, 895.5402659164189, 1771.16937197487, 9336.44922418634, 1163.1260016050621], "policy_AGENT-2_reward": [4787.548529762532, 3015.489127563556, 1675.9669634011063, 83.8027324356442, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183, 2972.66143598652, 4143.584003368301, 8550.541119406005, 3118.2684045385445, 627.4576258224816, 146.70362876696294, 1429.5183167346297, -319.9713200692588, 6219.712680251618, 992.7368978303267, 7814.852283262563, 6319.1912453324185, 171.01607023728423, 7880.32763400115, 3294.747668755996, 422.8305492099743, 435.0061329806446, 6026.934818903771, 2965.501963813467, 552.9461373954882, 786.9346476342544, 1837.1500895808367, 9336.23812199138, 1239.6664443655009], "policy_AGENT-1_reward": [4828.631163774683, 2982.2514492108967, 1641.0325652207093, -303.0152551308864, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753, 3061.519984410381, 607.0746920480364, 8556.328031540294, 3360.5218633771706, 723.6052453287012, 450.2603222253631, 1666.5978560074882, 107.94020477137774, 396.4899537566012, 1087.8871759238295, 7920.7349542640295, 2129.1710208530476, 485.2672792285024, 8090.331437241606, 3394.9710552353295, 161.3283180770502, 507.4172203502464, 9000.797411649222, 3193.188293315189, 436.8548199420166, 68.99125238734541, 1891.6798281254348, 9342.070375129997, 1231.6464285072748]}, "sampler_perf": {"mean_env_wait_ms": 51.35894188045294, "mean_raw_obs_processing_ms": 1.6447047139494657, "mean_inference_ms": 2.483472841107403, "mean_action_processing_ms": 0.16185940514692604}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 98784, "timers": {"learn_time_ms": 10.917, "learn_throughput": 2931.126, "update_time_ms": 14.97}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 505.4281005859375, "min_q": -85.53988647460938, "max_q": 822.9042358398438, "mean_td_error": 55.48838806152344, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 311.4684143066406, "min_q": -70.26998138427734, "max_q": 732.562255859375, "mean_td_error": 27.904399871826172, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 354.52587890625, "min_q": -93.19573974609375, "max_q": 719.6381225585938, "mean_td_error": 29.237743377685547, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 372.1337890625, "min_q": -239.72117614746094, "max_q": 797.8423461914062, "mean_td_error": 18.217979431152344, "model": {}}}, "num_steps_sampled": 98784, "num_steps_trained": 260768, "last_target_update_ts": 98784, "num_target_updates": 195}, "done": false, "episodes_total": 337, "training_iteration": 98, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-34-49", "timestamp": 1624268089, "time_this_iter_s": 32.48154616355896, "time_total_s": 3119.0538659095764, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c1e6710>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c1e67a0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c1e6b00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c1e6a70>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1050>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c1e6b00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c1e6a70>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1050>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c1e6b00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c1e6a70>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1050>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c1e6b00>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c1e6a70>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1050>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c1d1200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 3119.0538659095764, "timesteps_since_restore": 0, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 52.06304347826086, "ram_util_percent": 97.37391304347824}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 7835.539798437988, "episode_len_mean": 477.59, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-0": -434.50493179261696, "AGENT-2": -319.9713200692588, "AGENT-1": -119.31060069405001}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9336.44922418634, "AGENT-2": 9336.23812199138, "AGENT-1": 9342.070375129997}, "policy_reward_mean": {"AGENT-3": 1495.8957937318028, "AGENT-0": 2282.0673696078575, "AGENT-2": 2122.97409354377, "AGENT-1": 1934.6025415545537}, "custom_metrics": {"mean_ego_speed_mean": 25.776887499999997, "mean_ego_speed_min": 3.183, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 88.851515, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.4785}, "hist_stats": {"episode_reward": [15522.852931384798, 123.58037915992995, -44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325, 9270.245494712182, 9411.059092335705, 34211.68591780714, 13028.590634456254, 2271.993482035765, 1090.0410168870833, 6211.851673114387, -319.1743590551796, 13081.65122968914, 3360.3411021348834, 33187.871936182964, 15320.332794398382, 1015.4873805754371, 31929.704168910794, 10239.49450023268, 1069.8887423212473, 1797.171214876274, 24286.681784788496, 12148.819754403923, 2037.7219234899026, 1819.8906083371658, 7391.132525178352, 28291.23514954064, 4865.536657735151, 14585.914497736723, 11892.5797162162], "episode_lengths": [691, 133, 85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364, 421, 984, 999, 783, 152, 455, 292, 364, 999, 189, 999, 999, 140, 999, 464, 570, 322, 999, 467, 361, 597, 340, 999, 302, 612, 520], "policy_AGENT-3_reward": [286.4045813146187, 134.18241808861652, 6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583, 262.8196731257371, 459.40214937058136, 8554.301803411183, 3359.9619835662957, 292.8816233366533, 218.7252931205793, 1591.8423489789695, 107.37378687590919, 278.15399560452573, 286.4367218071854, 8741.706394848676, 541.4620050677707, 187.64301934587456, 8089.581464593753, 254.4466550476002, -6.611686421586233, 419.16360236066856, 263.88809201001175, 3030.6470153811856, 436.258871887776, 68.42444239914855, 1891.133235497228, 276.4774282328419, 1231.0977832573064, 251.81870569379367, 2981.501350394546], "policy_AGENT-0_reward": [5059.169080494654, -72.40232558794305, -28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782, 2973.2444011895586, 4200.998247548772, 8550.514963449576, 3189.8383829742834, 628.0489875479294, 274.35177277417864, 1523.8931513932946, -214.51703063320798, 6187.294600076396, 993.2803065735391, 8710.578303807662, 6330.5085231451485, 171.561011763775, 7869.463633074263, 3295.3291211937594, 492.341561455807, 435.5842591847143, 8995.061462225516, 2959.482481894102, 611.6620942646209, 895.5402659164189, 1771.16937197487, 9336.44922418634, 1163.1260016050621, 4717.9160985056715, 2913.337789047231], "policy_AGENT-2_reward": [4999.973338614422, -72.96288173096616, -29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183, 2972.66143598652, 4143.584003368301, 8550.541119406005, 3118.2684045385445, 627.4576258224816, 146.70362876696294, 1429.5183167346297, -319.9713200692588, 6219.712680251618, 992.7368978303267, 7814.852283262563, 6319.1912453324185, 171.01607023728423, 7880.32763400115, 3294.747668755996, 422.8305492099743, 435.0061329806446, 6026.934818903771, 2965.501963813467, 552.9461373954882, 786.9346476342544, 1837.1500895808367, 9336.23812199138, 1239.6664443655009, 4787.548529762532, 3015.489127563556], "policy_AGENT-1_reward": [5177.305930961074, 134.763168390223, 6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753, 3061.519984410381, 607.0746920480364, 8556.328031540294, 3360.5218633771706, 723.6052453287012, 450.2603222253631, 1666.5978560074882, 107.94020477137774, 396.4899537566012, 1087.8871759238295, 7920.7349542640295, 2129.1710208530476, 485.2672792285024, 8090.331437241606, 3394.9710552353295, 161.3283180770502, 507.4172203502464, 9000.797411649222, 3193.188293315189, 436.8548199420166, 68.99125238734541, 1891.6798281254348, 9342.070375129997, 1231.6464285072748, 4828.631163774683, 2982.2514492108967]}, "sampler_perf": {"mean_env_wait_ms": 51.49183386124222, "mean_raw_obs_processing_ms": 1.6434813723053951, "mean_inference_ms": 2.4863267562700706, "mean_action_processing_ms": 0.16217188663180263}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 99792, "timers": {"learn_time_ms": 10.915, "learn_throughput": 2931.619, "update_time_ms": 13.57}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 429.35711669921875, "min_q": -125.55329895019531, "max_q": 809.82861328125, "mean_td_error": 11.684989929199219, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 281.22344970703125, "min_q": -60.05144500732422, "max_q": 712.7139282226562, "mean_td_error": 24.77336883544922, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 347.9064636230469, "min_q": -198.9656524658203, "max_q": 711.6908569335938, "mean_td_error": 43.61167907714844, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 311.27496337890625, "min_q": -195.09324645996094, "max_q": 763.5313720703125, "mean_td_error": 21.275060653686523, "model": {}}}, "num_steps_sampled": 99792, "num_steps_trained": 263456, "last_target_update_ts": 99792, "num_target_updates": 197}, "done": false, "episodes_total": 339, "training_iteration": 99, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-35-21", "timestamp": 1624268121, "time_this_iter_s": 32.22088003158569, "time_total_s": 3151.274745941162, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c1e6c20>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c1e6b90>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c357440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c3574d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3579e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c357d40>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c357440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c3574d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3579e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c357d40>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c357440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c3574d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3579e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c357d40>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c357440>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c3574d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c3579e0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c357d40>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c1d1680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 3151.274745941162, "timesteps_since_restore": 0, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 49.980434782608704, "ram_util_percent": 97.58478260869569}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 7835.539798437988, "episode_len_mean": 477.59, "episodes_this_iter": 0, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-0": -434.50493179261696, "AGENT-2": -319.9713200692588, "AGENT-1": -119.31060069405001}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-0": 9336.44922418634, "AGENT-2": 9336.23812199138, "AGENT-1": 9342.070375129997}, "policy_reward_mean": {"AGENT-3": 1495.8957937318028, "AGENT-0": 2282.0673696078575, "AGENT-2": 2122.97409354377, "AGENT-1": 1934.6025415545532}, "custom_metrics": {"mean_ego_speed_mean": 25.7768875, "mean_ego_speed_min": 3.183, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 88.851515, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.4785}, "hist_stats": {"episode_reward": [-44.83327407790307, 2720.3295226591417, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325, 9270.245494712182, 9411.059092335705, 34211.68591780714, 13028.590634456254, 2271.993482035765, 1090.0410168870833, 6211.851673114387, -319.1743590551796, 13081.65122968914, 3360.3411021348834, 33187.871936182964, 15320.332794398382, 1015.4873805754371, 31929.704168910794, 10239.49450023268, 1069.8887423212473, 1797.171214876274, 24286.681784788496, 12148.819754403923, 2037.7219234899026, 1819.8906083371658, 7391.132525178352, 28291.23514954064, 4865.536657735151, 14585.914497736723, 11892.5797162162, 15522.852931384798, 123.58037915992995], "episode_lengths": [85, 271, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364, 421, 984, 999, 783, 152, 455, 292, 364, 999, 189, 999, 999, 140, 999, 464, 570, 322, 999, 467, 361, 597, 340, 999, 302, 612, 520, 691, 133], "policy_AGENT-3_reward": [6.02810808552826, 171.2573258114042, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583, 262.8196731257371, 459.40214937058136, 8554.301803411183, 3359.9619835662957, 292.8816233366533, 218.7252931205793, 1591.8423489789695, 107.37378687590919, 278.15399560452573, 286.4367218071854, 8741.706394848676, 541.4620050677707, 187.64301934587456, 8089.581464593753, 254.4466550476002, -6.611686421586233, 419.16360236066856, 263.88809201001175, 3030.6470153811856, 436.258871887776, 68.42444239914855, 1891.133235497228, 276.4774282328419, 1231.0977832573064, 251.81870569379367, 2981.501350394546, 286.4045813146187, 134.18241808861652], "policy_AGENT-0_reward": [-28.440632786873756, 1101.5818854644951, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782, 2973.2444011895586, 4200.998247548772, 8550.514963449576, 3189.8383829742834, 628.0489875479294, 274.35177277417864, 1523.8931513932946, -214.51703063320798, 6187.294600076396, 993.2803065735391, 8710.578303807662, 6330.5085231451485, 171.561011763775, 7869.463633074263, 3295.3291211937594, 492.341561455807, 435.5842591847143, 8995.061462225516, 2959.482481894102, 611.6620942646209, 895.5402659164189, 1771.16937197487, 9336.44922418634, 1163.1260016050621, 4717.9160985056715, 2913.337789047231, 5059.169080494654, -72.40232558794305], "policy_AGENT-2_reward": [-29.016443975065908, 1179.4328949903447, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183, 2972.66143598652, 4143.584003368301, 8550.541119406005, 3118.2684045385445, 627.4576258224816, 146.70362876696294, 1429.5183167346297, -319.9713200692588, 6219.712680251618, 992.7368978303267, 7814.852283262563, 6319.1912453324185, 171.01607023728423, 7880.32763400115, 3294.747668755996, 422.8305492099743, 435.0061329806446, 6026.934818903771, 2965.501963813467, 552.9461373954882, 786.9346476342544, 1837.1500895808367, 9336.23812199138, 1239.6664443655009, 4787.548529762532, 3015.489127563556, 4999.973338614422, -72.96288173096616], "policy_AGENT-1_reward": [6.595694598508324, 268.05741639289215, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753, 3061.519984410381, 607.0746920480364, 8556.328031540294, 3360.5218633771706, 723.6052453287012, 450.2603222253631, 1666.5978560074882, 107.94020477137774, 396.4899537566012, 1087.8871759238295, 7920.7349542640295, 2129.1710208530476, 485.2672792285024, 8090.331437241606, 3394.9710552353295, 161.3283180770502, 507.4172203502464, 9000.797411649222, 3193.188293315189, 436.8548199420166, 68.99125238734541, 1891.6798281254348, 9342.070375129997, 1231.6464285072748, 4828.631163774683, 2982.2514492108967, 5177.305930961074, 134.763168390223]}, "sampler_perf": {"mean_env_wait_ms": 51.49183386124223, "mean_raw_obs_processing_ms": 1.6434813723053956, "mean_inference_ms": 2.4863267562700706, "mean_action_processing_ms": 0.16217188663180263}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 100800, "timers": {"learn_time_ms": 10.544, "learn_throughput": 3034.788, "update_time_ms": 17.713}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 536.6978759765625, "min_q": -170.72506713867188, "max_q": 825.29248046875, "mean_td_error": -13.194526672363281, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 409.98358154296875, "min_q": -43.551822662353516, "max_q": 742.8645629882812, "mean_td_error": 31.29424285888672, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 412.97174072265625, "min_q": -99.52989196777344, "max_q": 721.4407348632812, "mean_td_error": 101.58892822265625, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 318.87506103515625, "min_q": -233.25096130371094, "max_q": 791.446044921875, "mean_td_error": -15.187938690185547, "model": {}}}, "num_steps_sampled": 100800, "num_steps_trained": 266144, "last_target_update_ts": 100800, "num_target_updates": 199}, "done": false, "episodes_total": 339, "training_iteration": 100, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-35-47", "timestamp": 1624268147, "time_this_iter_s": 25.721304655075073, "time_total_s": 3176.996050596237, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c1e65f0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c1e60e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1050>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1e60>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1050>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1e60>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1050>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1e60>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c2e9ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1050>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c1d1e60>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c2b74d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 3176.996050596237, "timesteps_since_restore": 0, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 51.67297297297298, "ram_util_percent": 97.64594594594591}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 8146.059677357004, "episode_len_mean": 490.94, "episodes_this_iter": 2, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-2": -319.9713200692588, "AGENT-0": -434.50493179261696, "AGENT-1": -119.31060069405001}, "policy_reward_max": {"AGENT-3": 9311.39186054342, "AGENT-2": 9336.23812199138, "AGENT-0": 9336.44922418634, "AGENT-1": 9342.070375129997}, "policy_reward_mean": {"AGENT-3": 1502.4393114015518, "AGENT-2": 2255.772369132817, "AGENT-0": 2414.0540898176077, "AGENT-1": 1973.7939070050243}, "custom_metrics": {"mean_ego_speed_mean": 25.010602500000005, "mean_ego_speed_min": 3.183, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 88.9619125, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.4785}, "hist_stats": {"episode_reward": [21187.773128673398, 12539.71101180948, 4001.0091448281305, 766.2669960674366, 14192.337395130946, 19566.579114412332, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325, 9270.245494712182, 9411.059092335705, 34211.68591780714, 13028.590634456254, 2271.993482035765, 1090.0410168870833, 6211.851673114387, -319.1743590551796, 13081.65122968914, 3360.3411021348834, 33187.871936182964, 15320.332794398382, 1015.4873805754371, 31929.704168910794, 10239.49450023268, 1069.8887423212473, 1797.171214876274, 24286.681784788496, 12148.819754403923, 2037.7219234899026, 1819.8906083371658, 7391.132525178352, 28291.23514954064, 4865.536657735151, 14585.914497736723, 11892.5797162162, 15522.852931384798, 123.58037915992995], "episode_lengths": [946, 745, 351, 369, 619, 999, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364, 421, 984, 999, 783, 152, 455, 292, 364, 999, 189, 999, 999, 140, 999, 464, 570, 322, 999, 467, 361, 597, 340, 999, 302, 612, 520, 691, 133], "policy_AGENT-3_reward": [422.32096743147196, 409.3162334403645, 193.26531441847217, -59.77777319444996, 3512.277483651726, 9311.39186054342, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583, 262.8196731257371, 459.40214937058136, 8554.301803411183, 3359.9619835662957, 292.8816233366533, 218.7252931205793, 1591.8423489789695, 107.37378687590919, 278.15399560452573, 286.4367218071854, 8741.706394848676, 541.4620050677707, 187.64301934587456, 8089.581464593753, 254.4466550476002, -6.611686421586233, 419.16360236066856, 263.88809201001175, 3030.6470153811856, 436.258871887776, 68.42444239914855, 1891.133235497228, 276.4774282328419, 1231.0977832573064, 251.81870569379367, 2981.501350394546, 286.4045813146187, 134.18241808861652], "policy_AGENT-2_reward": [8529.428754582945, 5900.815255337058, 1727.7321038080192, 397.93332902560655, 3511.953009643477, 474.1416280884558, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183, 2972.66143598652, 4143.584003368301, 8550.541119406005, 3118.2684045385445, 627.4576258224816, 146.70362876696294, 1429.5183167346297, -319.9713200692588, 6219.712680251618, 992.7368978303267, 7814.852283262563, 6319.1912453324185, 171.01607023728423, 7880.32763400115, 3294.747668755996, 422.8305492099743, 435.0061329806446, 6026.934818903771, 2965.501963813467, 552.9461373954882, 786.9346476342544, 1837.1500895808367, 9336.23812199138, 1239.6664443655009, 4787.548529762532, 3015.489127563556, 4999.973338614422, -72.96288173096616], "policy_AGENT-0_reward": [8452.133344907345, 5819.679928745257, 1656.7311858532457, 29.7385665586299, 3541.0383507276515, 9306.466775605351, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782, 2973.2444011895586, 4200.998247548772, 8550.514963449576, 3189.8383829742834, 628.0489875479294, 274.35177277417864, 1523.8931513932946, -214.51703063320798, 6187.294600076396, 993.2803065735391, 8710.578303807662, 6330.5085231451485, 171.561011763775, 7869.463633074263, 3295.3291211937594, 492.341561455807, 435.5842591847143, 8995.061462225516, 2959.482481894102, 611.6620942646209, 895.5402659164189, 1771.16937197487, 9336.44922418634, 1163.1260016050621, 4717.9160985056715, 2913.337789047231, 5059.169080494654, -72.40232558794305], "policy_AGENT-1_reward": [3783.89006175166, 409.8995942868129, 423.2805407483927, 398.3728736776508, 3627.068551108008, 474.5788501751187, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753, 3061.519984410381, 607.0746920480364, 8556.328031540294, 3360.5218633771706, 723.6052453287012, 450.2603222253631, 1666.5978560074882, 107.94020477137774, 396.4899537566012, 1087.8871759238295, 7920.7349542640295, 2129.1710208530476, 485.2672792285024, 8090.331437241606, 3394.9710552353295, 161.3283180770502, 507.4172203502464, 9000.797411649222, 3193.188293315189, 436.8548199420166, 68.99125238734541, 1891.6798281254348, 9342.070375129997, 1231.6464285072748, 4828.631163774683, 2982.2514492108967, 5177.305930961074, 134.763168390223]}, "sampler_perf": {"mean_env_wait_ms": 51.63585687106239, "mean_raw_obs_processing_ms": 1.6360738765295144, "mean_inference_ms": 2.488720756862634, "mean_action_processing_ms": 0.16246364909257108}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 101808, "timers": {"learn_time_ms": 12.337, "learn_throughput": 2593.74, "update_time_ms": 22.564}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 477.22186279296875, "min_q": -155.27532958984375, "max_q": 821.1797485351562, "mean_td_error": 48.411216735839844, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 360.0854187011719, "min_q": -123.32504272460938, "max_q": 723.6005859375, "mean_td_error": 1.7240495681762695, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 439.2113037109375, "min_q": -246.7798614501953, "max_q": 731.2510375976562, "mean_td_error": 36.45399475097656, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 315.9872741699219, "min_q": -172.75794982910156, "max_q": 779.1717529296875, "mean_td_error": 53.910980224609375, "model": {}}}, "num_steps_sampled": 101808, "num_steps_trained": 268832, "last_target_update_ts": 101808, "num_target_updates": 201}, "done": false, "episodes_total": 341, "training_iteration": 101, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_09-36-19", "timestamp": 1624268179, "time_this_iter_s": 31.515573024749756, "time_total_s": 3208.511623620987, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c6898c0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c1e6dd0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc320>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc8c0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc320>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc8c0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc320>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc8c0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc320>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc200>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc170>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c4bc8c0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c1d1cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 3208.511623620987, "timesteps_since_restore": 0, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 48.91555555555555, "ram_util_percent": 97.12666666666668}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
{"episode_reward_max": 35842.385835004054, "episode_reward_min": -952.1266693901413, "episode_reward_mean": 8130.031567582082, "episode_len_mean": 488.62, "episodes_this_iter": 4, "policy_reward_min": {"AGENT-3": -507.5460381922926, "AGENT-0": -434.50493179261696, "AGENT-2": -319.9713200692588, "AGENT-1": -119.31060069405001}, "policy_reward_max": {"AGENT-3": 8962.238241086483, "AGENT-0": 9336.44922418634, "AGENT-2": 9336.23812199138, "AGENT-1": 9342.070375129997}, "policy_reward_mean": {"AGENT-3": 1385.2783848239837, "AGENT-0": 2392.300757222607, "AGENT-2": 2301.3068095690583, "AGENT-1": 2051.145615966428}, "custom_metrics": {"mean_ego_speed_mean": 25.1528675, "mean_ego_speed_min": 4.386, "mean_ego_speed_max": 53.5805, "distance_travelled_mean": 88.39155749999998, "distance_travelled_min": 43.3185, "distance_travelled_max": 124.4785}, "hist_stats": {"episode_reward": [14107.281346482852, 1785.7905026244134, 11443.274196328823, 9587.035627510342, 6073.063517142258, 4105.93814312078, 10363.72891366619, 626.9046412696962, 5835.161379412621, 8146.136961155272, 13934.44759358303, 1502.5103112745269, -504.3070852304793, 3829.2708336463256, 12930.945503979694, 4554.146359876497, 1670.6142025620065, 1322.1142712564879, 3348.424603690628, 14103.53421260435, 1318.7468841760337, 392.80193486829523, -952.1266693901413, -269.30601082425727, 3177.396381681887, 31273.80990724214, 2469.0474044870725, 16166.730867698443, 10170.99199801668, 1091.6554032920737, 27061.65646869279, 13811.180251547887, 16893.673319350593, 5761.274200462976, 2948.9419614335147, 1601.3553661109756, 5195.855394325519, 489.7228456989154, 3117.1671723646346, -251.53829034130246, 15065.545380374202, 5427.3647053232935, 8006.959081608567, 6453.61340721784, 11039.420765303, 204.63527074183767, 14600.606866929342, -297.448601618952, 660.6846880778712, 308.62819159059245, 362.8359598151288, 47.59633383906497, 226.2740832356053, 313.8039896473803, -238.14712720858753, 24259.863960618557, 11739.639014324455, 15057.500742155107, 1241.2855000821614, 330.37450021564325, 1265.488122133677, 15321.607699081553, 8501.719179678897, 1372.0286701674238, 1684.1022670957852, 392.7826211731642, 1485.7795939776192, 13385.910523994096, 35842.385835004054, 5833.596616709325, 9270.245494712182, 9411.059092335705, 34211.68591780714, 13028.590634456254, 2271.993482035765, 1090.0410168870833, 6211.851673114387, -319.1743590551796, 13081.65122968914, 3360.3411021348834, 33187.871936182964, 15320.332794398382, 1015.4873805754371, 31929.704168910794, 10239.49450023268, 1069.8887423212473, 1797.171214876274, 24286.681784788496, 12148.819754403923, 2037.7219234899026, 1819.8906083371658, 7391.132525178352, 28291.23514954064, 4865.536657735151, 14585.914497736723, 11892.5797162162, 15522.852931384798, 123.58037915992995, 21187.773128673398, 12539.71101180948], "episode_lengths": [922, 139, 539, 506, 639, 210, 448, 337, 325, 523, 551, 397, 99, 542, 554, 267, 179, 134, 465, 528, 354, 122, 408, 49, 357, 999, 381, 999, 374, 209, 999, 529, 999, 356, 257, 215, 330, 146, 602, 94, 440, 307, 605, 299, 999, 999, 602, 72, 184, 175, 102, 502, 171, 999, 104, 742, 999, 614, 229, 133, 156, 999, 342, 446, 142, 89, 123, 999, 999, 364, 421, 984, 999, 783, 152, 455, 292, 364, 999, 189, 999, 999, 140, 999, 464, 570, 322, 999, 467, 361, 597, 340, 999, 302, 612, 520, 691, 133, 946, 745], "policy_AGENT-3_reward": [274.04346935204734, 385.5394730730506, 259.01899556857114, 322.46228966867824, 284.42240136166095, 867.9091313146679, 2627.044523706914, 230.5956824189529, 1600.3492516056829, 254.30930657563812, 3518.6359372613774, 182.12238905125076, -264.80050751925586, 1044.44844275245, 3197.9456385774797, 291.4805816323237, 534.2893982733349, 294.36651689863476, 293.15747439539007, 3499.118180928559, 386.63080675405286, 251.31702383508446, -507.5460381922926, -106.0489520272808, 1020.2354563713722, 7820.055464579678, 294.6951383995843, 314.7057866838869, 2594.8726233269304, 268.74763740690923, 8527.583399186491, 519.8072741521348, 259.2457661809863, 271.99873356601813, 295.6015525842424, 408.65603181234343, 1286.9094699521168, 174.7502600958562, 411.3248940195743, -101.95928850213049, 3789.377017268921, 357.24289445122935, 1985.9838835605467, 1600.5969313153403, 5549.837996126815, 322.82350725152463, 3641.7829770113726, -119.87561144885865, 279.90948683256755, 172.13998724526752, 144.91050982237857, 117.46336089291283, 113.69481353500137, 324.2570092396328, -77.668258306801, 6082.1662099577525, 5849.787843872602, 3800.2319809721193, 289.52591723584237, 183.3900969288833, 293.7294221492453, 1460.1637231597376, 2078.6725544671167, 436.0232934878875, 282.9322362783238, 145.47286031678016, 372.1591583617757, 280.51989913896745, 8962.238241086483, 397.5449640347583, 262.8196731257371, 459.40214937058136, 8554.301803411183, 3359.9619835662957, 292.8816233366533, 218.7252931205793, 1591.8423489789695, 107.37378687590919, 278.15399560452573, 286.4367218071854, 8741.706394848676, 541.4620050677707, 187.64301934587456, 8089.581464593753, 254.4466550476002, -6.611686421586233, 419.16360236066856, 263.88809201001175, 3030.6470153811856, 436.258871887776, 68.42444239914855, 1891.133235497228, 276.4774282328419, 1231.0977832573064, 251.81870569379367, 2981.501350394546, 286.4045813146187, 134.18241808861652, 422.32096743147196, 409.3162334403645], "policy_AGENT-0_reward": [5233.9700883211435, 421.4985707064401, 3671.7090675974027, 3031.46389261984, 2756.0873290024474, 811.9498019466698, 2518.7778773450464, 99.16399436565561, 1284.8541874710156, 3739.883828105372, 3453.2849219642294, 398.5903522489906, -323.8547024119325, 1139.4889085820707, 3215.727754598646, 1390.9911912575838, 213.52234143112406, 296.1323987763419, 1064.2234817432613, 3426.4836530403422, 240.7032984648396, -28.192341866774186, -434.50493179261696, -28.614542925621944, 855.7242830438074, 7815.576935483085, 767.2853261104539, 7626.604776897079, 2367.8432248571685, 264.637479690625, 8524.145826519532, 4313.589877168614, 7891.870697655202, 1771.96047233858, 877.5650182365541, 364.8292337822627, 1260.1537521139248, 62.46058938164886, 1066.5168303543203, -34.72075933219986, 3767.6630975625208, 1702.3533909949833, 1972.3757021315118, 1605.0964654650625, -28.710153571925034, -28.63916913808043, 3531.994957763073, -28.843804471827333, 22.594643604714932, -28.64096136353106, 22.67889268555259, -28.695811998874078, -28.702866329907348, 32.116923223009685, -40.11739483647506, 6035.75125250488, 21.470260467193583, 3692.4113536921495, 281.4155380986324, -18.20012410505238, 289.19253061309786, 5124.946642527231, 2054.4308594154586, 133.20434497309685, 432.9898780540318, 50.93005099182474, 345.1991590120742, 6085.301191421704, 8958.252930348119, 1674.2329429356782, 2973.2444011895586, 4200.998247548772, 8550.514963449576, 3189.8383829742834, 628.0489875479294, 274.35177277417864, 1523.8931513932946, -214.51703063320798, 6187.294600076396, 993.2803065735391, 8710.578303807662, 6330.5085231451485, 171.561011763775, 7869.463633074263, 3295.3291211937594, 492.341561455807, 435.5842591847143, 8995.061462225516, 2959.482481894102, 611.6620942646209, 895.5402659164189, 1771.16937197487, 9336.44922418634, 1163.1260016050621, 4717.9160985056715, 2913.337789047231, 5059.169080494654, -72.40232558794305, 8452.133344907345, 5819.679928745257], "policy_AGENT-2_reward": [3398.781744944706, 421.029257875522, 3745.621354238971, 3099.771757130493, 2688.2474323616175, 1212.632981235271, 2590.329364199029, 10.94163351822625, 1349.0427552837643, 3821.5996489337294, 3470.963699015873, 308.6799203815163, 41.78255199251395, 306.631324630237, 3167.8513078566193, 1343.296609035159, 265.60032766731825, 347.0924963195603, 1000.5053011537748, 3463.3345775594066, 153.67196652129556, -28.772998403723875, -5.373322659511771, -29.158925927898103, 787.1646731956108, 7816.855740483498, 680.0949033019635, 7646.185668394739, 2421.925864772317, 225.60504285684587, 5025.350325067341, 4353.594409268832, 7925.388282994336, 1844.8417036808805, 840.6279391569639, 342.94994404035583, 1237.089471072911, 61.89641105633777, 1095.1686048053034, -35.30477719763629, 3767.094485957348, 1701.7622511432303, 1937.4778939984017, 1552.1050435881864, -29.27657844445623, -29.22928207156031, 3588.165258921706, -29.41858500421615, 22.015749752300508, -29.20517307993921, 22.095757841068366, -29.279179225766867, -29.267078046315504, 31.555753551095638, -40.66944823952906, 6035.1811474821525, 20.878398363498096, 3763.980316471953, 280.67490199263256, -18.769102197238013, 288.62829972214814, 5085.982687148133, 2053.8610248039963, 87.2106047501562, 432.4404130061322, 50.340727944655406, 344.76408835612006, 6088.214517715903, 8958.253931464842, 1714.7264331947183, 2972.66143598652, 4143.584003368301, 8550.541119406005, 3118.2684045385445, 627.4576258224816, 146.70362876696294, 1429.5183167346297, -319.9713200692588, 6219.712680251618, 992.7368978303267, 7814.852283262563, 6319.1912453324185, 171.01607023728423, 7880.32763400115, 3294.747668755996, 422.8305492099743, 435.0061329806446, 6026.934818903771, 2965.501963813467, 552.9461373954882, 786.9346476342544, 1837.1500895808367, 9336.23812199138, 1239.6664443655009, 4787.548529762532, 3015.489127563556, 4999.973338614422, -72.96288173096616, 8529.428754582945, 5900.815255337058], "policy_AGENT-1_reward": [5200.486043864969, 557.7232009694011, 3766.9247789238852, 3133.3376880912965, 344.30635441652845, 1213.4462286241812, 2627.577148415201, 286.203330966861, 1600.9151850521516, 330.3441775405248, 3491.563035341582, 613.1176495927697, 42.565572708195134, 1338.7021576815685, 3349.4208029469805, 1528.3779779514327, 657.202135190231, 384.5228592619499, 990.5383463982052, 3714.5978010760405, 537.7408124358452, 198.45025130370894, -4.702376745721338, -105.48358994345634, 514.2719690710962, 7821.321766695836, 726.972036675072, 579.2346357227531, 2786.3502850602385, 332.66524333769155, 4984.576917919443, 4624.188690958367, 817.1685725200525, 1872.4732908775018, 935.1474514557542, 484.92015647601374, 1411.7027011865803, 190.61558516507299, 544.1568431854403, -79.55346530933585, 3741.4107795854106, 1666.0061687338412, 2111.121601918086, 1695.8149668492338, 5547.569501192578, -60.319785300046696, 3838.6636732332126, -119.31060069405001, 336.164807888289, 194.3343387887951, 173.15079946612943, -11.892035829206826, 170.5492140768269, -74.12569636635766, -79.69202582578242, 6106.765350673762, 5847.502511621161, 3800.8770910188746, 389.66914275505354, 183.95362958905105, 393.93786964918576, 3650.5146462464118, 2314.754740992329, 715.590426956285, 535.7397397572951, 146.0389819199035, 423.6571882476487, 931.8749157175558, 8963.640732104383, 2047.0922765441753, 3061.519984410381, 607.0746920480364, 8556.328031540294, 3360.5218633771706, 723.6052453287012, 450.2603222253631, 1666.5978560074882, 107.94020477137774, 396.4899537566012, 1087.8871759238295, 7920.7349542640295, 2129.1710208530476, 485.2672792285024, 8090.331437241606, 3394.9710552353295, 161.3283180770502, 507.4172203502464, 9000.797411649222, 3193.188293315189, 436.8548199420166, 68.99125238734541, 1891.6798281254348, 9342.070375129997, 1231.6464285072748, 4828.631163774683, 2982.2514492108967, 5177.305930961074, 134.763168390223, 3783.89006175166, 409.8995942868129]}, "sampler_perf": {"mean_env_wait_ms": 53.96949257785277, "mean_raw_obs_processing_ms": 1.8912833784054301, "mean_inference_ms": 2.494852019338532, "mean_action_processing_ms": 0.16315930006319973}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 102816, "timers": {"learn_time_ms": 402.913, "learn_throughput": 79.422, "update_time_ms": 26.531}, "info": {"learner": {"AGENT-0": {"cur_lr": 0.0005000000237487257, "mean_q": 421.5511474609375, "min_q": -148.5009002685547, "max_q": 830.1514892578125, "mean_td_error": 88.51319885253906, "model": {}}, "AGENT-1": {"cur_lr": 0.0005000000237487257, "mean_q": 285.27838134765625, "min_q": -23.727005004882812, "max_q": 695.1099853515625, "mean_td_error": 27.916000366210938, "model": {}}, "AGENT-2": {"cur_lr": 0.0005000000237487257, "mean_q": 335.2610168457031, "min_q": -284.44000244140625, "max_q": 734.4257202148438, "mean_td_error": -1.2644472122192383, "model": {}}, "AGENT-3": {"cur_lr": 0.0005000000237487257, "mean_q": 315.14813232421875, "min_q": -11.469294548034668, "max_q": 775.3696899414062, "mean_td_error": 2.0118722915649414, "model": {}}}, "num_steps_sampled": 102816, "num_steps_trained": 271520, "last_target_update_ts": 102816, "num_target_updates": 203}, "done": true, "episodes_total": 345, "training_iteration": 102, "experiment_id": "709f2e80eca944069bd717b917b0c3cc", "date": "2021-06-21_10-22-08", "timestamp": 1624270928, "time_this_iter_s": 2749.318699121475, "time_total_s": 5957.830322742462, "pid": 29442, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 32, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7f897c1d1b00>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7f897c1d1b90>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7f899171d200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c1af5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c1af0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c1af4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c1af170>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c1af5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c1af0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c1af4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c1af170>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c1af5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c1af0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c1af4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c1af170>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7f897c1af5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7f897c1af0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7f897c1af4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7f897c1af170>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0005, "monitor": false, "log_level": "ERROR", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.02, "epsilon_timesteps": 10000}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 1, "timesteps_per_iteration": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7f897c1af3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "target_network_update_freq": 500, "buffer_size": 50000, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "worker_side_prioritization": false}, "time_since_restore": 5957.830322742462, "timesteps_since_restore": 0, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 84.02078651685393, "ram_util_percent": 97.19943820224724}, "trial_id": "8a9f6_00000", "experiment_tag": "0"}
