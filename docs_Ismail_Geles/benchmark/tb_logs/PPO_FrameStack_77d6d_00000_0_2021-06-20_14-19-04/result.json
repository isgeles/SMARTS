{"episode_reward_max": 1142.7591396997777, "episode_reward_min": -1201.7930004744865, "episode_reward_mean": -134.67495606595082, "episode_len_mean": 116.31428571428572, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-2": -296.2134999097596, "AGENT-1": -283.0170737752406, "AGENT-3": -294.78426523338385, "AGENT-0": -327.7781615561015}, "policy_reward_max": {"AGENT-2": 297.429361147885, "AGENT-1": 293.2864647946911, "AGENT-3": 300.0942396839879, "AGENT-0": 251.94907407321264}, "policy_reward_mean": {"AGENT-2": -27.030464518984864, "AGENT-1": -37.65885477274618, "AGENT-3": -21.81243536124633, "AGENT-0": -48.17320141297341}, "custom_metrics": {"mean_ego_speed_mean": 41.26411428571428, "mean_ego_speed_min": 37.484, "mean_ego_speed_max": 44.8365, "distance_travelled_mean": 104.07105714285713, "distance_travelled_min": 25.968249999999998, "distance_travelled_max": 124.92875000000001}, "hist_stats": {"episode_reward": [-979.0885488701074, -51.654801943040084, -727.5115897484015, -1201.7930004744865, -114.35281257645518, -707.1930148758895, 371.3870741398226, -704.690731308097, -0.3231049624271565, -469.24572535825695, -165.63806388528837, -1134.4013208245406, 476.04838484092755, -259.20840296639085, 662.8653679815305, 287.4436319129097, 577.6095159456347, 726.1241289128875, 605.9107458918946, 609.9351690963796, 317.7367772661385, 1142.7591396997777, 204.52763436389446, -435.5024610487471, -538.4036845132592, -257.9287509176021, -532.9863110416262, -212.08008208797173, -179.6039978863294, -377.38879079872464, -400.08093158283145, -458.82831302642967, -148.270297035942, -359.22824159229356, -280.56805303493945], "episode_lengths": [124, 125, 124, 127, 125, 122, 120, 106, 124, 86, 79, 131, 124, 93, 122, 109, 135, 113, 139, 115, 121, 131, 119, 124, 124, 118, 127, 122, 126, 110, 122, 112, 28, 125, 119], "policy_AGENT-2_reward": [-237.66732535379575, 8.626815169773344, -187.77351443456078, -296.2134999097596, -26.74177645691669, -164.5614351867244, 85.44104946050663, -213.4182646633246, -16.23763462733789, -100.73297592092429, -12.062954822896668, -285.4455540893593, 128.86689515952045, -37.98703646862251, 190.41059764603136, 75.68225894395098, 157.92213861736548, 173.6246114372492, 47.79070211802502, 173.54457558029083, 26.516141827324738, 297.429361147885, 65.46297560048535, -98.72410140297026, -107.92323908530913, -43.57716290477736, -120.63106806963643, -54.586170234478175, -18.32671871736909, -87.85842648808661, -61.47672622645558, -72.25403744620219, -8.791205026440752, -64.15149771653863, -60.242055620391966], "policy_AGENT-1_reward": [-227.4515490326986, 9.108028993064288, -187.19826870611888, -283.0170737752406, -26.31182063588901, -167.1939588125718, 98.73973558512334, -138.86829528690458, 27.538563584248337, -133.90326514636027, -70.7180919057285, -257.9183743326192, 135.37418945030475, -91.66329451540852, 146.80518834731467, 44.99405894189752, 155.88175108714006, 176.24347745807998, 48.35261820117408, 131.15055819149012, 134.60520140022777, 293.2864647946911, 59.08160742351532, -93.8048951008184, -173.24955983042622, -62.887731831036625, -124.32593526985255, -50.42821062543418, -70.09104907533369, -101.66821611360928, -133.62708662732257, -146.22348510144076, -65.34409652614822, -113.67149833723575, -59.655603916189435], "policy_AGENT-3_reward": [-238.64390001436823, -15.738224681157986, -124.51065626430452, -294.78426523338385, -34.924313588973874, -164.94996999546208, 67.00535961194423, -213.55522135011822, -16.232144088702686, -100.7068916055905, -12.156192634764622, -291.3586556767208, 125.98072324611785, -37.92278279180776, 179.99266582701554, 121.80348921598635, 144.78838319058258, 176.76974026755084, 273.9197153564847, 173.91834811334266, 129.672479125214, 300.0942396839879, 65.3155096402196, -99.97252548555439, -107.95919723319486, -43.621612645295826, -118.08985924002342, -54.84555979801337, -18.56426357588233, -86.2208937603994, -144.0503418334905, -168.64332254012078, -8.77737894882624, -67.87440287392248, -58.59331506198899], "policy_AGENT-0_reward": [-275.32577446924546, -53.651421424719715, -228.02915034341714, -327.7781615561015, -26.374901894675578, -210.48765088113072, 120.20092948224851, -138.84895000774935, 4.608110169365089, -133.90259268538182, -70.70082452189858, -299.67873672584227, 85.82657698498444, -91.63528919055219, 145.65691616116945, 44.96382481107458, 119.01724305054705, 199.4862997500078, 235.84771021621094, 131.3216872112573, 26.942954913371867, 251.94907407321264, 14.66754169967411, -143.0009390594043, -149.2716883643289, -107.8422435364923, -169.93944846211352, -52.22014143004617, -72.62196651774437, -101.64125443662931, -60.92677689556264, -71.7074679386657, -65.3576165345268, -113.5308426645962, -102.07707843636899]}, "sampler_perf": {"mean_env_wait_ms": 88.12170750725048, "mean_raw_obs_processing_ms": 3.419656122424885, "mean_inference_ms": 4.830089723515658, "mean_action_processing_ms": 0.21009869175340418}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 4200, "timers": {"sample_time_ms": 143838.172, "sample_throughput": 29.199, "load_time_ms": 944.345, "load_throughput": 4447.527, "learn_time_ms": 21468.012, "learn_throughput": 195.64, "update_time_ms": 10.275}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 18.847332000732422, "policy_loss": -0.023882823064923286, "vf_loss": 18.869762420654297, "vf_explained_var": 0.49798160791397095, "kl": 0.007270120549947023, "entropy": 1.3788440227508545, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 10.658313751220703, "policy_loss": -0.02004985883831978, "vf_loss": 10.676797866821289, "vf_explained_var": 0.7557169795036316, "kl": 0.007826989516615868, "entropy": 1.3785972595214844, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 8.265551567077637, "policy_loss": -0.02132362313568592, "vf_loss": 8.285412788391113, "vf_explained_var": 0.7865334749221802, "kl": 0.007315334863960743, "entropy": 1.3790534734725952, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 6.8975982666015625, "policy_loss": -0.025907713919878006, "vf_loss": 6.921637535095215, "vf_explained_var": 0.8429914712905884, "kl": 0.009347911924123764, "entropy": 1.377027153968811, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 4200, "num_steps_trained": 4200}, "done": false, "episodes_total": 35, "training_iteration": 1, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_14-22-31", "timestamp": 1624198951, "time_this_iter_s": 169.26691508293152, "time_total_s": 169.26691508293152, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f041bb00>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f041b9e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f041bd40>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f041bef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f041b950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9050>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f041bd40>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f041bef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f041b950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9050>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f041bd40>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f041bef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f041b950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9050>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f041bd40>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f041bef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f041b950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9050>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f041b830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 169.26691508293152, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 58.46280991735537, "ram_util_percent": 83.60867768595043}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1142.7591396997777, "episode_reward_min": -1201.7930004744865, "episode_reward_mean": -71.28692549004246, "episode_len_mean": 115.28169014084507, "episodes_this_iter": 36, "policy_reward_min": {"AGENT-2": -296.2134999097596, "AGENT-3": -294.78426523338385, "AGENT-0": -327.7781615561015, "AGENT-1": -283.0170737752406}, "policy_reward_max": {"AGENT-2": 297.429361147885, "AGENT-3": 300.0942396839879, "AGENT-0": 293.07892507177155, "AGENT-1": 293.2864647946911}, "policy_reward_mean": {"AGENT-2": -11.510639539394205, "AGENT-3": -13.064303949433603, "AGENT-0": -29.636866069102016, "AGENT-1": -17.075115932112613}, "custom_metrics": {"mean_ego_speed_mean": 41.437869718309855, "mean_ego_speed_min": 31.898, "mean_ego_speed_max": 44.8365, "distance_travelled_mean": 104.07995774647888, "distance_travelled_min": 25.968249999999998, "distance_travelled_max": 124.92875000000001}, "hist_stats": {"episode_reward": [-96.6311035521867, -824.3224678077427, 109.98269692889266, -724.7312571574417, 392.5707935906311, -8.195908258317047, 992.3004641309043, -839.1585789553942, 111.38846698314482, -358.6169090607483, 74.82063134247142, 592.0888297821649, 514.8789940944622, 882.7808304156068, 523.2406931637739, 603.0993036885143, 247.17600109537875, 425.9883837106894, 194.45783044544999, 330.7683603567962, 555.0235202486938, 248.25591021550414, -160.97292250947416, -495.7928489612264, -206.38192264665264, -479.67388868341965, -367.77183188522935, -92.45263368022239, -308.5708754158629, -306.11293479846444, -200.57019124746864, -565.8727084487982, -318.9720144778759, -233.31805482595303, -390.9538779270609, -167.4970273782735, -979.0885488701074, -51.654801943040084, -727.5115897484015, -1201.7930004744865, -114.35281257645518, -707.1930148758895, 371.3870741398226, -704.690731308097, -0.3231049624271565, -469.24572535825695, -165.63806388528837, -1134.4013208245406, 476.04838484092755, -259.20840296639085, 662.8653679815305, 287.4436319129097, 577.6095159456347, 726.1241289128875, 605.9107458918946, 609.9351690963796, 317.7367772661385, 1142.7591396997777, 204.52763436389446, -435.5024610487471, -538.4036845132592, -257.9287509176021, -532.9863110416262, -212.08008208797173, -179.6039978863294, -377.38879079872464, -400.08093158283145, -458.82831302642967, -148.270297035942, -359.22824159229356, -280.56805303493945], "episode_lengths": [107, 107, 125, 119, 124, 122, 144, 136, 123, 128, 119, 121, 122, 116, 110, 120, 107, 121, 123, 116, 124, 76, 141, 121, 70, 123, 72, 123, 110, 94, 79, 117, 106, 106, 122, 120, 124, 125, 124, 127, 125, 122, 120, 106, 124, 86, 79, 131, 124, 93, 122, 109, 135, 113, 139, 115, 121, 131, 119, 124, 124, 118, 127, 122, 126, 110, 122, 112, 28, 125, 119], "policy_AGENT-2_reward": [35.14918215262977, -227.8949376323667, -12.103584806131117, -191.07248099991517, 97.7953632400159, -35.68192141057825, 217.73944041198678, -206.86969003320561, -15.267876613374376, -120.53229901089686, 11.810970563599433, 196.41103605006487, 137.47526941850364, 213.54523917172767, 136.76891581067014, 172.3433824494042, 58.99311679044038, 121.60172510281188, 66.53501218666038, 96.65506021057325, 150.54763189227273, 41.66718978737956, -34.40635860838765, -112.86270237400112, -10.590320525673036, -19.889137185379653, -107.4707117323681, -0.12583204657745956, -93.43220258239313, -51.51800942531703, -25.220233760569855, -62.359293602658326, -113.61150876248624, -43.463133616749865, -88.43894588687596, -53.416503755353304, -237.66732535379575, 8.626815169773344, -187.77351443456078, -296.2134999097596, -26.74177645691669, -164.5614351867244, 85.44104946050663, -213.4182646633246, -16.23763462733789, -100.73297592092429, -12.062954822896668, -285.4455540893593, 128.86689515952045, -37.98703646862251, 190.41059764603136, 75.68225894395098, 157.92213861736548, 173.6246114372492, 47.79070211802502, 173.54457558029083, 26.516141827324738, 297.429361147885, 65.46297560048535, -98.72410140297026, -107.92323908530913, -43.57716290477736, -120.63106806963643, -54.586170234478175, -18.32671871736909, -87.85842648808661, -61.47672622645558, -72.25403744620219, -8.791205026440752, -64.15149771653863, -60.242055620391966], "policy_AGENT-3_reward": [11.35929405614112, -228.0258890641623, -12.148703200126011, -191.2939885448773, 97.65900629093846, -35.580641306082875, 217.60435724679488, -207.75152455820577, -15.319188054130606, -120.78182032783963, 12.278235850977396, 146.7117799784067, 138.59605860499934, 215.6262027464281, 136.6287844322829, 172.85245737363294, 107.27493472046463, 121.65845444129195, 66.37672042563725, 96.70701975514888, 139.40424011939297, 41.683190549146715, -34.4135340777085, -112.5009147901988, -10.626835894996017, -201.84437057506705, -107.42410767980988, -3.321366161346346, -44.55630796618347, -51.55706794864665, -25.172727965034568, -233.85938964613862, -65.34703223872371, -43.59889423983329, -87.34730469603029, -54.07947042270694, -238.64390001436823, -15.738224681157986, -124.51065626430452, -294.78426523338385, -34.924313588973874, -164.94996999546208, 67.00535961194423, -213.55522135011822, -16.232144088702686, -100.7068916055905, -12.156192634764622, -291.3586556767208, 125.98072324611785, -37.92278279180776, 179.99266582701554, 121.80348921598635, 144.78838319058258, 176.76974026755084, 273.9197153564847, 173.91834811334266, 129.672479125214, 300.0942396839879, 65.3155096402196, -99.97252548555439, -107.95919723319486, -43.621612645295826, -118.08985924002342, -54.84555979801337, -18.56426357588233, -86.2208937603994, -144.0503418334905, -168.64332254012078, -8.77737894882624, -67.87440287392248, -58.59331506198899], "policy_AGENT-0_reward": [-71.54293228067056, -184.05986278128518, 67.0511619531218, -171.11591225576524, 76.85221936732991, 7.531699807126948, 293.07892507177155, -215.493129536017, 49.0163737953643, -81.9916030212797, 38.49149437257482, 101.77161767860218, 94.9942608356674, 238.26214607324093, 124.92520946467499, 128.7304551692255, 40.48134900830684, 67.65744280849073, 29.966121151176885, 45.98226443398334, 108.56259454809609, 82.4362026479459, -49.393480000328665, -158.35889856971264, -92.60521022183389, -238.47120500188464, -76.44918581678021, -44.943160221191796, -85.30994767677535, -101.54702816225856, -75.0626639712048, -61.81409961848368, -69.89543601759013, -73.1035127637867, -131.9732498658092, -30.816461856215437, -275.32577446924546, -53.651421424719715, -228.02915034341714, -327.7781615561015, -26.374901894675578, -210.48765088113072, 120.20092948224851, -138.84895000774935, 4.608110169365089, -133.90259268538182, -70.70082452189858, -299.67873672584227, 85.82657698498444, -91.63528919055219, 145.65691616116945, 44.96382481107458, 119.01724305054705, 199.4862997500078, 235.84771021621094, 131.3216872112573, 26.942954913371867, 251.94907407321264, 14.66754169967411, -143.0009390594043, -149.2716883643289, -107.8422435364923, -169.93944846211352, -52.22014143004617, -72.62196651774437, -101.64125443662931, -60.92677689556264, -71.7074679386657, -65.3576165345268, -113.5308426645962, -102.07707843636899], "policy_AGENT-1_reward": [-71.59664748028699, -184.3417783299289, 67.18382298202795, -171.24887535688418, 120.2642046923468, 55.534954651217106, 263.877741400351, -209.04423482796514, 92.95915785528538, -35.31118670073238, 12.239930555319653, 147.1943960750907, 143.81340523529212, 215.34724242420984, 124.91778345614524, 129.17300869625163, 40.42660057616681, 115.07076135809464, 31.579976681975754, 91.42401595709077, 156.5090536889327, 82.46932723103174, -42.75954982304935, -112.07033322731341, -92.55955600414971, -19.46917592108842, -76.42782665627135, -44.06227525110683, -85.27241719051088, -101.49082926224213, -75.11456555065934, -207.83992558151712, -70.11803745907588, -73.15251420558322, -83.19437747834588, -29.184591343997873, -227.4515490326986, 9.108028993064288, -187.19826870611888, -283.0170737752406, -26.31182063588901, -167.1939588125718, 98.73973558512334, -138.86829528690458, 27.538563584248337, -133.90326514636027, -70.7180919057285, -257.9183743326192, 135.37418945030475, -91.66329451540852, 146.80518834731467, 44.99405894189752, 155.88175108714006, 176.24347745807998, 48.35261820117408, 131.15055819149012, 134.60520140022777, 293.2864647946911, 59.08160742351532, -93.8048951008184, -173.24955983042622, -62.887731831036625, -124.32593526985255, -50.42821062543418, -70.09104907533369, -101.66821611360928, -133.62708662732257, -146.22348510144076, -65.34409652614822, -113.67149833723575, -59.655603916189435]}, "sampler_perf": {"mean_env_wait_ms": 86.86578006360182, "mean_raw_obs_processing_ms": 3.3930570737215024, "mean_inference_ms": 4.445279908625053, "mean_action_processing_ms": 0.20760164237508955}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 8400, "timers": {"sample_time_ms": 139927.86, "sample_throughput": 30.015, "load_time_ms": 481.803, "load_throughput": 8717.257, "learn_time_ms": 21233.963, "learn_throughput": 197.796, "update_time_ms": 9.619}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 17.38992691040039, "policy_loss": -0.021695436909794807, "vf_loss": 17.410314559936523, "vf_explained_var": 0.7307633757591248, "kl": 0.00652390718460083, "entropy": 1.371867299079895, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 13.771503448486328, "policy_loss": -0.02345195598900318, "vf_loss": 13.793560028076172, "vf_explained_var": 0.7859117984771729, "kl": 0.00697517953813076, "entropy": 1.3716199398040771, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 15.062872886657715, "policy_loss": -0.024248691275715828, "vf_loss": 15.085782051086426, "vf_explained_var": 0.7695420980453491, "kl": 0.006687518674880266, "entropy": 1.3745354413986206, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 13.119422912597656, "policy_loss": -0.02374826744198799, "vf_loss": 13.141867637634277, "vf_explained_var": 0.7939580678939819, "kl": 0.006510359235107899, "entropy": 1.3685575723648071, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 8400, "num_steps_trained": 8400}, "done": false, "episodes_total": 71, "training_iteration": 2, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_14-25-09", "timestamp": 1624199109, "time_this_iter_s": 157.07017827033997, "time_total_s": 326.3370933532715, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f2ef5e60>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f2ef5dd0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f41e2d40>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f2ef5f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f06ac680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9cb0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f41e2d40>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f2ef5f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f06ac680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9cb0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f41e2d40>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f2ef5f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f06ac680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9cb0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f41e2d40>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f2ef5f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f06ac680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9cb0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f03d9320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 326.3370933532715, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 57.244196428571435, "ram_util_percent": 85.740625}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1142.7591396997777, "episode_reward_min": -1134.4013208245406, "episode_reward_mean": -49.10854365360362, "episode_len_mean": 114.12, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-2": -285.4455540893593, "AGENT-1": -257.9183743326192, "AGENT-3": -291.3586556767208, "AGENT-0": -299.67873672584227}, "policy_reward_max": {"AGENT-2": 297.429361147885, "AGENT-1": 293.2864647946911, "AGENT-3": 300.0942396839879, "AGENT-0": 293.07892507177155}, "policy_reward_mean": {"AGENT-2": -6.643730997026058, "AGENT-1": -13.735759125907522, "AGENT-3": -7.011873951041196, "AGENT-0": -21.717179579628848}, "custom_metrics": {"mean_ego_speed_mean": 41.6251925, "mean_ego_speed_min": 31.898, "mean_ego_speed_max": 45.61675, "distance_travelled_mean": 103.00849249999999, "distance_travelled_min": 25.968249999999998, "distance_travelled_max": 124.92875000000001}, "hist_stats": {"episode_reward": [-667.8981429761599, 131.773983545975, -687.0859390968865, 286.2604840128473, -753.0458817058088, -195.7138659208405, -956.0043129938346, -353.9420228250582, -212.19153911638264, -542.5993795963295, -98.85111135663229, 76.73730472996095, -20.66287858958289, 498.5053534954078, 286.61746285030506, -254.95901520444355, 120.29086911703982, -210.100136660833, 1059.3909319947923, -63.31667183705358, 889.7574180498927, 450.7750580089881, 232.1152934181275, -63.04257813842736, 921.0406872750092, -438.3872801353042, -282.0591529748742, -103.30001001541578, -333.7979012667156, -377.49422143857066, -184.3465505270003, -261.6123764931911, -290.15397226291947, -379.6305278946538, -500.3064480079991, -234.77739305405268, -452.3656176333782, -0.3231049624271565, -469.24572535825695, -165.63806388528837, -1134.4013208245406, 476.04838484092755, -259.20840296639085, 662.8653679815305, 287.4436319129097, 577.6095159456347, 726.1241289128875, 605.9107458918946, 609.9351690963796, 317.7367772661385, 1142.7591396997777, 204.52763436389446, -435.5024610487471, -538.4036845132592, -257.9287509176021, -532.9863110416262, -212.08008208797173, -179.6039978863294, -377.38879079872464, -400.08093158283145, -458.82831302642967, -148.270297035942, -359.22824159229356, -280.56805303493945, -96.6311035521867, -824.3224678077427, 109.98269692889266, -724.7312571574417, 392.5707935906311, -8.195908258317047, 992.3004641309043, -839.1585789553942, 111.38846698314482, -358.6169090607483, 74.82063134247142, 592.0888297821649, 514.8789940944622, 882.7808304156068, 523.2406931637739, 603.0993036885143, 247.17600109537875, 425.9883837106894, 194.45783044544999, 330.7683603567962, 555.0235202486938, 248.25591021550414, -160.97292250947416, -495.7928489612264, -206.38192264665264, -479.67388868341965, -367.77183188522935, -92.45263368022239, -308.5708754158629, -306.11293479846444, -200.57019124746864, -565.8727084487982, -318.9720144778759, -233.31805482595303, -390.9538779270609, -167.4970273782735], "episode_lengths": [120, 119, 123, 121, 121, 111, 102, 123, 111, 57, 110, 129, 87, 117, 111, 117, 95, 120, 122, 119, 118, 119, 106, 116, 116, 103, 89, 121, 120, 123, 120, 121, 118, 113, 124, 121, 117, 124, 86, 79, 131, 124, 93, 122, 109, 135, 113, 139, 115, 121, 131, 119, 124, 124, 118, 127, 122, 126, 110, 122, 112, 28, 125, 119, 107, 107, 125, 119, 124, 122, 144, 136, 123, 128, 119, 121, 122, 116, 110, 120, 107, 121, 123, 116, 124, 76, 141, 121, 70, 123, 72, 123, 110, 94, 79, 117, 106, 106, 122, 120], "policy_AGENT-2_reward": [-131.33099490477116, 29.12439937342766, -191.01720508323547, 51.827194906021134, -191.36902813065998, -57.01914037931384, -232.0242394236709, -38.36354502834641, -51.78410921351575, -163.6440233116893, -38.68600195871696, -30.936147862362013, 23.199456227711373, 137.466480898385, 72.62819669957787, -37.067810963714535, 28.35780384758757, -34.82610188886886, 254.27212038792058, 6.048467389481942, 210.57753461756315, 136.16376467117692, 88.16885669263671, -42.89917236494621, 222.8980153485992, -128.90808720047082, -76.7890070349047, -2.9477599338703437, -95.65547009692474, -85.04210707385477, -8.24069918541205, -35.093745765755585, -82.8253419807162, -102.76029325025831, -128.71818019931948, -36.20729579171999, -116.00242681348995, -16.23763462733789, -100.73297592092429, -12.062954822896668, -285.4455540893593, 128.86689515952045, -37.98703646862251, 190.41059764603136, 75.68225894395098, 157.92213861736548, 173.6246114372492, 47.79070211802502, 173.54457558029083, 26.516141827324738, 297.429361147885, 65.46297560048535, -98.72410140297026, -107.92323908530913, -43.57716290477736, -120.63106806963643, -54.586170234478175, -18.32671871736909, -87.85842648808661, -61.47672622645558, -72.25403744620219, -8.791205026440752, -64.15149771653863, -60.242055620391966, 35.14918215262977, -227.8949376323667, -12.103584806131117, -191.07248099991517, 97.7953632400159, -35.68192141057825, 217.73944041198678, -206.86969003320561, -15.267876613374376, -120.53229901089686, 11.810970563599433, 196.41103605006487, 137.47526941850364, 213.54523917172767, 136.76891581067014, 172.3433824494042, 58.99311679044038, 121.60172510281188, 66.53501218666038, 96.65506021057325, 150.54763189227273, 41.66718978737956, -34.40635860838765, -112.86270237400112, -10.590320525673036, -19.889137185379653, -107.4707117323681, -0.12583204657745956, -93.43220258239313, -51.51800942531703, -25.220233760569855, -62.359293602658326, -113.61150876248624, -43.463133616749865, -88.43894588687596, -53.416503755353304], "policy_AGENT-1_reward": [-200.31976295812703, 57.84010258905186, -152.51788254103704, 78.60935870661406, -184.63322006125065, -62.43941557725283, -257.89865346397573, -126.95578130584207, -55.59060015380726, -107.62175258910258, -22.491178216996886, 92.44527397164549, -33.45131029100285, 136.88042227429307, 47.19815553900062, -65.79960190573257, 31.762229993895307, -55.74449800867116, 274.61827201128574, -37.71193344446635, 234.41671151089332, 91.41479173293598, 27.914414177474494, -1.883985718658245, 223.4751583753234, -90.28432857476305, -64.28168198658891, -48.060981752820766, -71.72742312281655, -80.0108460927025, -83.49051313268517, -95.54975033331351, -61.735316386594064, -102.25436987387542, -117.61829644949314, -79.54464483881385, -120.39304518401586, 27.538563584248337, -133.90326514636027, -70.7180919057285, -257.9183743326192, 135.37418945030475, -91.66329451540852, 146.80518834731467, 44.99405894189752, 155.88175108714006, 176.24347745807998, 48.35261820117408, 131.15055819149012, 134.60520140022777, 293.2864647946911, 59.08160742351532, -93.8048951008184, -173.24955983042622, -62.887731831036625, -124.32593526985255, -50.42821062543418, -70.09104907533369, -101.66821611360928, -133.62708662732257, -146.22348510144076, -65.34409652614822, -113.67149833723575, -59.655603916189435, -71.59664748028699, -184.3417783299289, 67.18382298202795, -171.24887535688418, 120.2642046923468, 55.534954651217106, 263.877741400351, -209.04423482796514, 92.95915785528538, -35.31118670073238, 12.239930555319653, 147.1943960750907, 143.81340523529212, 215.34724242420984, 124.91778345614524, 129.17300869625163, 40.42660057616681, 115.07076135809464, 31.579976681975754, 91.42401595709077, 156.5090536889327, 82.46932723103174, -42.75954982304935, -112.07033322731341, -92.55955600414971, -19.46917592108842, -76.42782665627135, -44.06227525110683, -85.27241719051088, -101.49082926224213, -75.11456555065934, -207.83992558151712, -70.11803745907588, -73.15251420558322, -83.19437747834588, -29.184591343997873], "policy_AGENT-3_reward": [-205.48069745188172, 33.07787430193193, -191.1703023890504, 51.780497102698455, -191.6571681892518, -13.80537569555755, -208.4132642230702, -38.46234783817651, -49.399541232344475, -163.75595483051174, -23.056337956180403, -30.901223999695365, 23.09931902365244, 132.25739293931318, 119.59806998960818, -37.114175120553554, 28.391363173751152, -34.719982899088706, 255.5616032460059, 6.071432906736227, 210.77084431233177, 131.26341375458853, 88.03467777050199, -2.449656424064372, 223.36445303552372, -129.04086322019108, -76.73871978926185, -2.106831244649232, -94.68840073592033, -84.44840013988117, -8.179969506219834, -35.03740441141379, -83.1056338976306, -97.56528572836848, -136.3579221970656, -38.74903934594295, -120.5894493008302, -16.232144088702686, -100.7068916055905, -12.156192634764622, -291.3586556767208, 125.98072324611785, -37.92278279180776, 179.99266582701554, 121.80348921598635, 144.78838319058258, 176.76974026755084, 273.9197153564847, 173.91834811334266, 129.672479125214, 300.0942396839879, 65.3155096402196, -99.97252548555439, -107.95919723319486, -43.621612645295826, -118.08985924002342, -54.84555979801337, -18.56426357588233, -86.2208937603994, -144.0503418334905, -168.64332254012078, -8.77737894882624, -67.87440287392248, -58.59331506198899, 11.35929405614112, -228.0258890641623, -12.148703200126011, -191.2939885448773, 97.65900629093846, -35.580641306082875, 217.60435724679488, -207.75152455820577, -15.319188054130606, -120.78182032783963, 12.278235850977396, 146.7117799784067, 138.59605860499934, 215.6262027464281, 136.6287844322829, 172.85245737363294, 107.27493472046463, 121.65845444129195, 66.37672042563725, 96.70701975514888, 139.40424011939297, 41.683190549146715, -34.4135340777085, -112.5009147901988, -10.626835894996017, -201.84437057506705, -107.42410767980988, -3.321366161346346, -44.55630796618347, -51.55706794864665, -25.172727965034568, -233.85938964613862, -65.34703223872371, -43.59889423983329, -87.34730469603029, -54.07947042270694], "policy_AGENT-0_reward": [-130.76668766138025, 11.731607281563647, -152.3805490835641, 104.04343329751374, -185.38646532464625, -62.4499342687163, -257.668155883118, -150.16034865269356, -55.41728851671512, -107.57764886502596, -14.61759322473809, 46.12940262037269, -33.510343549944, 91.90105738341693, 47.193040622118616, -114.97742721444311, 31.779472101805865, -84.80955386420422, 274.9389363495801, -37.72463868880529, 233.9923276091043, 91.93308785028623, 27.997344777514314, -15.809763630758553, 251.30306051556315, -90.15400113987911, -64.24974416411881, -50.18443708407554, -71.72660731105383, -127.9928681321318, -84.43536870268323, -95.93147598270812, -62.48767999797833, -77.0505790421515, -117.61204916212039, -80.27641307757602, -95.38069633504249, 4.608110169365089, -133.90259268538182, -70.70082452189858, -299.67873672584227, 85.82657698498444, -91.63528919055219, 145.65691616116945, 44.96382481107458, 119.01724305054705, 199.4862997500078, 235.84771021621094, 131.3216872112573, 26.942954913371867, 251.94907407321264, 14.66754169967411, -143.0009390594043, -149.2716883643289, -107.8422435364923, -169.93944846211352, -52.22014143004617, -72.62196651774437, -101.64125443662931, -60.92677689556264, -71.7074679386657, -65.3576165345268, -113.5308426645962, -102.07707843636899, -71.54293228067056, -184.05986278128518, 67.0511619531218, -171.11591225576524, 76.85221936732991, 7.531699807126948, 293.07892507177155, -215.493129536017, 49.0163737953643, -81.9916030212797, 38.49149437257482, 101.77161767860218, 94.9942608356674, 238.26214607324093, 124.92520946467499, 128.7304551692255, 40.48134900830684, 67.65744280849073, 29.966121151176885, 45.98226443398334, 108.56259454809609, 82.4362026479459, -49.393480000328665, -158.35889856971264, -92.60521022183389, -238.47120500188464, -76.44918581678021, -44.943160221191796, -85.30994767677535, -101.54702816225856, -75.0626639712048, -61.81409961848368, -69.89543601759013, -73.1035127637867, -131.9732498658092, -30.816461856215437]}, "sampler_perf": {"mean_env_wait_ms": 86.00105459870144, "mean_raw_obs_processing_ms": 3.366550569051021, "mean_inference_ms": 4.190717747916557, "mean_action_processing_ms": 0.20579889139518515}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 12600, "timers": {"sample_time_ms": 138400.202, "sample_throughput": 30.347, "load_time_ms": 327.545, "load_throughput": 12822.65, "learn_time_ms": 20647.248, "learn_throughput": 203.417, "update_time_ms": 9.754}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 11.953893661499023, "policy_loss": -0.026377664878964424, "vf_loss": 11.978517532348633, "vf_explained_var": 0.8160845041275024, "kl": 0.008764474652707577, "entropy": 1.3630356788635254, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 11.5263671875, "policy_loss": -0.025603506714105606, "vf_loss": 11.550207138061523, "vf_explained_var": 0.8140371441841125, "kl": 0.008817801252007484, "entropy": 1.3616942167282104, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 12.666853904724121, "policy_loss": -0.02451363392174244, "vf_loss": 12.689765930175781, "vf_explained_var": 0.8243501782417297, "kl": 0.008003097027540207, "entropy": 1.3656196594238281, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 11.066658020019531, "policy_loss": -0.027205726131796837, "vf_loss": 11.092203140258789, "vf_explained_var": 0.8518968820571899, "kl": 0.008310554549098015, "entropy": 1.3570572137832642, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 12600, "num_steps_trained": 12600}, "done": false, "episodes_total": 108, "training_iteration": 3, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_14-27-45", "timestamp": 1624199265, "time_this_iter_s": 154.87505626678467, "time_total_s": 481.21214962005615, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f03d97a0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f03d98c0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9b90>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9050>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9170>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9b90>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9050>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9170>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9b90>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9050>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9170>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9b90>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9050>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9170>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f03d9ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 481.21214962005615, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 57.711711711711715, "ram_util_percent": 86.63153153153152}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1059.3909319947923, "episode_reward_min": -1004.5736593039753, "episode_reward_mean": -57.322462935372926, "episode_len_mean": 112.12, "episodes_this_iter": 38, "policy_reward_min": {"AGENT-2": -297.9853700327863, "AGENT-3": -236.55614609217426, "AGENT-0": -257.668155883118, "AGENT-1": -257.89865346397573}, "policy_reward_max": {"AGENT-2": 254.27212038792058, "AGENT-3": 255.5616032460059, "AGENT-0": 274.9389363495801, "AGENT-1": 274.61827201128574}, "policy_reward_mean": {"AGENT-2": -12.55576767524156, "AGENT-3": -9.187408906316374, "AGENT-0": -23.018939178283166, "AGENT-1": -12.5603471755318}, "custom_metrics": {"mean_ego_speed_mean": 41.843835, "mean_ego_speed_min": 31.898, "mean_ego_speed_max": 45.61675, "distance_travelled_mean": 102.78794250000001, "distance_travelled_min": 38.7325, "distance_travelled_max": 124.86699999999999}, "hist_stats": {"episode_reward": [28.932188931201843, -1004.5736593039753, -474.9740752332976, 141.28069903027293, -429.15700836332593, 73.31053337038458, 109.83040246616488, -421.92009180757657, -498.73914508434103, -265.5150477941448, -499.9338950785481, 67.3400780254229, -927.3642587477267, 504.08492057131997, 421.04823309824656, 299.084453380478, 473.7082606059203, 476.20197192576467, 461.6396275475503, 282.37508371270235, 463.1709931619726, 448.2513455644882, 736.6874971420375, 505.44414703291557, 516.7157883272715, -170.58705309505382, -335.80401368014407, -260.7844774141188, -456.179442938696, -374.2377576550442, -397.62472196410675, -415.7135436967049, -227.62851906789925, -298.0421068600291, -151.21475119195793, -364.8319490014996, -307.49982986555676, -317.49201269470905, 592.0888297821649, 514.8789940944622, 882.7808304156068, 523.2406931637739, 603.0993036885143, 247.17600109537875, 425.9883837106894, 194.45783044544999, 330.7683603567962, 555.0235202486938, 248.25591021550414, -160.97292250947416, -495.7928489612264, -206.38192264665264, -479.67388868341965, -367.77183188522935, -92.45263368022239, -308.5708754158629, -306.11293479846444, -200.57019124746864, -565.8727084487982, -318.9720144778759, -233.31805482595303, -390.9538779270609, -167.4970273782735, -667.8981429761599, 131.773983545975, -687.0859390968865, 286.2604840128473, -753.0458817058088, -195.7138659208405, -956.0043129938346, -353.9420228250582, -212.19153911638264, -542.5993795963295, -98.85111135663229, 76.73730472996095, -20.66287858958289, 498.5053534954078, 286.61746285030506, -254.95901520444355, 120.29086911703982, -210.100136660833, 1059.3909319947923, -63.31667183705358, 889.7574180498927, 450.7750580089881, 232.1152934181275, -63.04257813842736, 921.0406872750092, -438.3872801353042, -282.0591529748742, -103.30001001541578, -333.7979012667156, -377.49422143857066, -184.3465505270003, -261.6123764931911, -290.15397226291947, -379.6305278946538, -500.3064480079991, -234.77739305405268, -452.3656176333782], "episode_lengths": [125, 107, 110, 121, 115, 117, 123, 84, 104, 130, 124, 119, 121, 126, 114, 108, 120, 120, 112, 78, 120, 120, 113, 118, 117, 121, 122, 118, 121, 123, 107, 109, 108, 118, 39, 111, 109, 80, 121, 122, 116, 110, 120, 107, 121, 123, 116, 124, 76, 141, 121, 70, 123, 72, 123, 110, 94, 79, 117, 106, 106, 122, 120, 120, 119, 123, 121, 121, 111, 102, 123, 111, 57, 110, 129, 87, 117, 111, 117, 95, 120, 122, 119, 118, 119, 106, 116, 116, 103, 89, 121, 120, 123, 120, 121, 118, 113, 124, 121, 117], "policy_AGENT-2_reward": [16.309666513853102, -297.9853700327863, -69.04163602302042, 33.7209402745315, -74.74165983075007, 17.083070458115102, -44.6492303225339, -143.32736281711772, -141.60017783088085, -63.815862543001636, -146.48380163446123, -3.853265017404261, -235.87834718609614, 46.628502534599264, 103.4765501577169, 115.97624623988902, 78.62734048621421, 107.09488281300911, 37.52554265502859, 46.83084594259101, 130.57995507835446, 122.45996727131264, 177.96178821031043, 137.8781351311086, 61.23236542343383, -9.546355000264109, -62.44871328380677, -56.80386844288181, -102.31857817137822, -72.5881746216585, -98.8587970832282, -164.45167565852248, -38.40638517988273, -65.20390283702932, -11.380372144337407, -88.31859304849911, -101.30455057376213, -92.268928656219, 196.41103605006487, 137.47526941850364, 213.54523917172767, 136.76891581067014, 172.3433824494042, 58.99311679044038, 121.60172510281188, 66.53501218666038, 96.65506021057325, 150.54763189227273, 41.66718978737956, -34.40635860838765, -112.86270237400112, -10.590320525673036, -19.889137185379653, -107.4707117323681, -0.12583204657745956, -93.43220258239313, -51.51800942531703, -25.220233760569855, -62.359293602658326, -113.61150876248624, -43.463133616749865, -88.43894588687596, -53.416503755353304, -131.33099490477116, 29.12439937342766, -191.01720508323547, 51.827194906021134, -191.36902813065998, -57.01914037931384, -232.0242394236709, -38.36354502834641, -51.78410921351575, -163.6440233116893, -38.68600195871696, -30.936147862362013, 23.199456227711373, 137.466480898385, 72.62819669957787, -37.067810963714535, 28.35780384758757, -34.82610188886886, 254.27212038792058, 6.048467389481942, 210.57753461756315, 136.16376467117692, 88.16885669263671, -42.89917236494621, 222.8980153485992, -128.90808720047082, -76.7890070349047, -2.9477599338703437, -95.65547009692474, -85.04210707385477, -8.24069918541205, -35.093745765755585, -82.8253419807162, -102.76029325025831, -128.71818019931948, -36.20729579171999, -116.00242681348995], "policy_AGENT-3_reward": [16.170799071903232, -202.61403709005765, -181.6113305255221, 33.49321603490266, -74.74075616449109, 14.24424814707932, -44.774481518391696, -143.6487404409712, -167.11046024637537, -63.78256082887735, -146.47227840126934, -3.866375801699819, -236.55614609217426, 199.8354160154664, 103.4908771635771, 116.71383938932266, 155.2022653353617, 104.32847391885146, 180.44849726786052, 46.78244727572483, 130.37118388405165, 122.9494590909186, 178.37800030337576, 137.34918339849676, 184.38866340528455, -9.570586022159391, -60.54085617840257, -81.77077465079117, -102.33007901559169, -72.5311216785331, -98.99419573468208, -117.8299840199133, -37.98959219461904, -66.39827852313977, -11.360137785578548, -87.00345275896954, -52.95467887161949, -92.58406842423466, 146.7117799784067, 138.59605860499934, 215.6262027464281, 136.6287844322829, 172.85245737363294, 107.27493472046463, 121.65845444129195, 66.37672042563725, 96.70701975514888, 139.40424011939297, 41.683190549146715, -34.4135340777085, -112.5009147901988, -10.626835894996017, -201.84437057506705, -107.42410767980988, -3.321366161346346, -44.55630796618347, -51.55706794864665, -25.172727965034568, -233.85938964613862, -65.34703223872371, -43.59889423983329, -87.34730469603029, -54.07947042270694, -205.48069745188172, 33.07787430193193, -191.1703023890504, 51.780497102698455, -191.6571681892518, -13.80537569555755, -208.4132642230702, -38.46234783817651, -49.399541232344475, -163.75595483051174, -23.056337956180403, -30.901223999695365, 23.09931902365244, 132.25739293931318, 119.59806998960818, -37.114175120553554, 28.391363173751152, -34.719982899088706, 255.5616032460059, 6.071432906736227, 210.77084431233177, 131.26341375458853, 88.03467777050199, -2.449656424064372, 223.36445303552372, -129.04086322019108, -76.73871978926185, -2.106831244649232, -94.68840073592033, -84.44840013988117, -8.179969506219834, -35.03740441141379, -83.1056338976306, -97.56528572836848, -136.3579221970656, -38.74903934594295, -120.5894493008302], "policy_AGENT-0_reward": [22.227887768065685, -251.9894791046999, -155.74254184578012, 12.925297185282282, -156.63247775195092, 17.64021844781675, 112.2310608037608, -67.50958255650544, -95.01733118790756, -73.47501772041478, -101.75694411678613, 37.334696116551704, -227.39770421002407, 47.1824950563148, 118.83570800805052, 33.174386187311114, 79.19033232854663, 132.8069023021986, 38.077577321564775, 94.36415044540135, 79.61003179301358, 79.7303680435382, 201.41310116187515, 92.94846491866736, 209.37986585757733, -76.98796862351556, -106.38279914565024, -61.50665707908379, -114.87022260739708, -135.9392742230465, -99.91557532739853, -66.72552574127073, -75.61345268183055, -107.99918959880154, -64.15278453056251, -94.63841381686215, -76.58972908201459, -66.35436652647375, 101.77161767860218, 94.9942608356674, 238.26214607324093, 124.92520946467499, 128.7304551692255, 40.48134900830684, 67.65744280849073, 29.966121151176885, 45.98226443398334, 108.56259454809609, 82.4362026479459, -49.393480000328665, -158.35889856971264, -92.60521022183389, -238.47120500188464, -76.44918581678021, -44.943160221191796, -85.30994767677535, -101.54702816225856, -75.0626639712048, -61.81409961848368, -69.89543601759013, -73.1035127637867, -131.9732498658092, -30.816461856215437, -130.76668766138025, 11.731607281563647, -152.3805490835641, 104.04343329751374, -185.38646532464625, -62.4499342687163, -257.668155883118, -150.16034865269356, -55.41728851671512, -107.57764886502596, -14.61759322473809, 46.12940262037269, -33.510343549944, 91.90105738341693, 47.193040622118616, -114.97742721444311, 31.779472101805865, -84.80955386420422, 274.9389363495801, -37.72463868880529, 233.9923276091043, 91.93308785028623, 27.997344777514314, -15.809763630758553, 251.30306051556315, -90.15400113987911, -64.24974416411881, -50.18443708407554, -71.72660731105383, -127.9928681321318, -84.43536870268323, -95.93147598270812, -62.48767999797833, -77.0505790421515, -117.61204916212039, -80.27641307757602, -95.38069633504249], "policy_AGENT-1_reward": [-25.776164422620113, -251.98477307643114, -68.5785668389748, 61.14124553555656, -123.0421146161336, 24.342996317373405, 87.02305350332962, -67.43440599298228, -95.01117581917705, -64.441606701851, -105.22087092603127, 37.72502272797525, -227.53206125943177, 210.43850696493956, 95.24509776890176, 33.21998156395527, 160.68832245579793, 131.9717128917053, 205.58801030309635, 94.39764004898541, 122.60982240655262, 123.11155115871897, 178.93460746647702, 137.26836358464323, 61.714893640975774, -74.48214344911477, -106.4316450722846, -60.703177241362454, -136.6605631443287, -93.179187131806, -99.85615381879809, -66.70635827699813, -75.61908901156681, -58.44073590105885, -64.32145673147946, -94.8714893771686, -76.65087133816064, -66.2846490877818, 147.1943960750907, 143.81340523529212, 215.34724242420984, 124.91778345614524, 129.17300869625163, 40.42660057616681, 115.07076135809464, 31.579976681975754, 91.42401595709077, 156.5090536889327, 82.46932723103174, -42.75954982304935, -112.07033322731341, -92.55955600414971, -19.46917592108842, -76.42782665627135, -44.06227525110683, -85.27241719051088, -101.49082926224213, -75.11456555065934, -207.83992558151712, -70.11803745907588, -73.15251420558322, -83.19437747834588, -29.184591343997873, -200.31976295812703, 57.84010258905186, -152.51788254103704, 78.60935870661406, -184.63322006125065, -62.43941557725283, -257.89865346397573, -126.95578130584207, -55.59060015380726, -107.62175258910258, -22.491178216996886, 92.44527397164549, -33.45131029100285, 136.88042227429307, 47.19815553900062, -65.79960190573257, 31.762229993895307, -55.74449800867116, 274.61827201128574, -37.71193344446635, 234.41671151089332, 91.41479173293598, 27.914414177474494, -1.883985718658245, 223.4751583753234, -90.28432857476305, -64.28168198658891, -48.060981752820766, -71.72742312281655, -80.0108460927025, -83.49051313268517, -95.54975033331351, -61.735316386594064, -102.25436987387542, -117.61829644949314, -79.54464483881385, -120.39304518401586]}, "sampler_perf": {"mean_env_wait_ms": 84.30966574629574, "mean_raw_obs_processing_ms": 3.366897528385016, "mean_inference_ms": 3.8078955767287046, "mean_action_processing_ms": 0.20265868126164363}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 16800, "timers": {"sample_time_ms": 134122.304, "sample_throughput": 31.315, "load_time_ms": 250.969, "load_throughput": 16735.131, "learn_time_ms": 19440.755, "learn_throughput": 216.041, "update_time_ms": 9.406}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 11.222710609436035, "policy_loss": -0.030503781512379646, "vf_loss": 11.251266479492188, "vf_explained_var": 0.8536396622657776, "kl": 0.009738246910274029, "entropy": 1.3531690835952759, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 9.770636558532715, "policy_loss": -0.026276065036654472, "vf_loss": 9.795103073120117, "vf_explained_var": 0.8801704049110413, "kl": 0.00905686430633068, "entropy": 1.3555338382720947, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 12.004304885864258, "policy_loss": -0.028835738077759743, "vf_loss": 12.031132698059082, "vf_explained_var": 0.8530335426330566, "kl": 0.010037529282271862, "entropy": 1.3552350997924805, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 8.772934913635254, "policy_loss": -0.02911963313817978, "vf_loss": 8.79998779296875, "vf_explained_var": 0.8989563584327698, "kl": 0.010331940837204456, "entropy": 1.3509191274642944, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 16800, "num_steps_trained": 16800}, "done": false, "episodes_total": 146, "training_iteration": 4, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_14-30-02", "timestamp": 1624199402, "time_this_iter_s": 137.16173362731934, "time_total_s": 618.3738832473755, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f031a7a0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f031a440>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f031aa70>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f031ad40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a3b0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f031aa70>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f031ad40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a3b0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f031aa70>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f031ad40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a3b0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f031aa70>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f031ad40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a3b0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f041b8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 618.3738832473755, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 59.140816326530604, "ram_util_percent": 86.92244897959183}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1059.3909319947923, "episode_reward_min": -1004.5736593039753, "episode_reward_mean": -55.326892324407396, "episode_len_mean": 111.64, "episodes_this_iter": 39, "policy_reward_min": {"AGENT-2": -297.9853700327863, "AGENT-3": -240.46318039890193, "AGENT-0": -251.9894791046999, "AGENT-1": -251.98477307643114}, "policy_reward_max": {"AGENT-2": 254.27212038792058, "AGENT-3": 255.5616032460059, "AGENT-0": 274.9389363495801, "AGENT-1": 274.61827201128574}, "policy_reward_mean": {"AGENT-2": -11.203672627295152, "AGENT-3": -4.223265947042732, "AGENT-0": -23.971006756482467, "AGENT-1": -15.928946993587033}, "custom_metrics": {"mean_ego_speed_mean": 41.663075, "mean_ego_speed_min": 31.7055, "mean_ego_speed_max": 44.88225, "distance_travelled_mean": 100.69600249999999, "distance_travelled_min": 30.319, "distance_travelled_max": 124.86699999999999}, "hist_stats": {"episode_reward": [185.4939287382611, -955.9949229036419, 435.6254914330678, -217.96230795800213, 148.83571789169176, -24.07161291381924, 638.7258193571423, -596.3084236536235, -21.0828216519997, -847.6987646276806, 523.8417781244221, -669.9275862339415, 448.93095593995287, 63.595560940731076, 286.5370558653137, 788.8934136779374, 555.4995010092889, 442.42176281529294, -265.9294072366709, 646.0864255662032, -420.94407121919954, 317.3352919746344, -265.61589197249054, 822.8167768008327, -276.9467181617789, -440.43304521110224, -275.02907554960103, -293.78041384453, -430.16406865579967, -333.90196178641577, -479.05541260530094, -198.9425061290585, -275.32909787197383, -267.6143398460189, -367.5093727973633, -172.7967779462892, -219.27471632276874, -316.8432876952373, -143.79883830618436, 286.61746285030506, -254.95901520444355, 120.29086911703982, -210.100136660833, 1059.3909319947923, -63.31667183705358, 889.7574180498927, 450.7750580089881, 232.1152934181275, -63.04257813842736, 921.0406872750092, -438.3872801353042, -282.0591529748742, -103.30001001541578, -333.7979012667156, -377.49422143857066, -184.3465505270003, -261.6123764931911, -290.15397226291947, -379.6305278946538, -500.3064480079991, -234.77739305405268, -452.3656176333782, 28.932188931201843, -1004.5736593039753, -474.9740752332976, 141.28069903027293, -429.15700836332593, 73.31053337038458, 109.83040246616488, -421.92009180757657, -498.73914508434103, -265.5150477941448, -499.9338950785481, 67.3400780254229, -927.3642587477267, 504.08492057131997, 421.04823309824656, 299.084453380478, 473.7082606059203, 476.20197192576467, 461.6396275475503, 282.37508371270235, 463.1709931619726, 448.2513455644882, 736.6874971420375, 505.44414703291557, 516.7157883272715, -170.58705309505382, -335.80401368014407, -260.7844774141188, -456.179442938696, -374.2377576550442, -397.62472196410675, -415.7135436967049, -227.62851906789925, -298.0421068600291, -151.21475119195793, -364.8319490014996, -307.49982986555676, -317.49201269470905], "episode_lengths": [123, 120, 120, 67, 122, 124, 139, 81, 120, 115, 131, 119, 126, 120, 112, 105, 108, 122, 35, 118, 135, 108, 125, 124, 43, 125, 121, 119, 122, 123, 125, 120, 119, 121, 48, 102, 116, 109, 31, 111, 117, 95, 120, 122, 119, 118, 119, 106, 116, 116, 103, 89, 121, 120, 123, 120, 121, 118, 113, 124, 121, 117, 125, 107, 110, 121, 115, 117, 123, 84, 104, 130, 124, 119, 121, 126, 114, 108, 120, 120, 112, 78, 120, 120, 113, 118, 117, 121, 122, 118, 121, 123, 107, 109, 108, 118, 39, 111, 109, 80], "policy_AGENT-2_reward": [40.57364558594317, -241.99787390525546, 89.60183732476214, -33.51204797111188, 40.64029555734158, -90.6079126799719, 158.05988303922837, -109.0511439714021, -17.256909239089563, -187.67187055604987, 132.12669864371003, -153.82160764505056, 70.04055854616394, 36.75562329646361, 72.32012698098762, 209.89503647795829, 140.39055755157005, 63.01624509462134, -37.155728674593966, 172.37895904953405, -18.9950328024227, 130.3857134541541, -7.6426335469425695, 215.17094866172093, -36.129245801815784, -112.69875885936523, -28.773165515130227, -13.364131580260473, -97.06660679630839, -28.59626773504134, -112.31656037392682, -61.237167732917314, -79.48290669852918, -77.62912871933841, -116.30566056648428, -12.978039908257166, -12.66695584330746, -49.189357009628566, -8.818129222336, 72.62819669957787, -37.067810963714535, 28.35780384758757, -34.82610188886886, 254.27212038792058, 6.048467389481942, 210.57753461756315, 136.16376467117692, 88.16885669263671, -42.89917236494621, 222.8980153485992, -128.90808720047082, -76.7890070349047, -2.9477599338703437, -95.65547009692474, -85.04210707385477, -8.24069918541205, -35.093745765755585, -82.8253419807162, -102.76029325025831, -128.71818019931948, -36.20729579171999, -116.00242681348995, 16.309666513853102, -297.9853700327863, -69.04163602302042, 33.7209402745315, -74.74165983075007, 17.083070458115102, -44.6492303225339, -143.32736281711772, -141.60017783088085, -63.815862543001636, -146.48380163446123, -3.853265017404261, -235.87834718609614, 46.628502534599264, 103.4765501577169, 115.97624623988902, 78.62734048621421, 107.09488281300911, 37.52554265502859, 46.83084594259101, 130.57995507835446, 122.45996727131264, 177.96178821031043, 137.8781351311086, 61.23236542343383, -9.546355000264109, -62.44871328380677, -56.80386844288181, -102.31857817137822, -72.5881746216585, -98.8587970832282, -164.45167565852248, -38.40638517988273, -65.20390283702932, -11.380372144337407, -88.31859304849911, -101.30455057376213, -92.268928656219], "policy_AGENT-3_reward": [42.98432996475449, -240.46318039890193, 100.39328205645067, -33.513734998737846, 23.160965981157833, -90.6662621244705, 157.92670893525028, -189.6631531696275, -17.206061144417315, -191.04890023075035, 110.47413032058934, -185.2981934983223, 174.67632333900832, 36.59509242091721, 121.2676773858771, 226.2663192909616, 142.76162511821838, 154.32810713965037, -37.08957793832933, 172.27736963199405, -19.045220168939526, 130.56325481397306, -7.653854655594401, 215.42911454115952, -36.10819656822528, -112.80397923467228, -29.059900006770558, -13.567399273036619, -97.20782992258162, -28.57596148717667, -105.4023552896489, -61.55870228911873, -81.39200473672445, -78.89500534467687, -116.36350654998911, -37.37318721559218, -12.752003650574103, -49.13465107610392, -8.863795633331762, 119.59806998960818, -37.114175120553554, 28.391363173751152, -34.719982899088706, 255.5616032460059, 6.071432906736227, 210.77084431233177, 131.26341375458853, 88.03467777050199, -2.449656424064372, 223.36445303552372, -129.04086322019108, -76.73871978926185, -2.106831244649232, -94.68840073592033, -84.44840013988117, -8.179969506219834, -35.03740441141379, -83.1056338976306, -97.56528572836848, -136.3579221970656, -38.74903934594295, -120.5894493008302, 16.170799071903232, -202.61403709005765, -181.6113305255221, 33.49321603490266, -74.74075616449109, 14.24424814707932, -44.774481518391696, -143.6487404409712, -167.11046024637537, -63.78256082887735, -146.47227840126934, -3.866375801699819, -236.55614609217426, 199.8354160154664, 103.4908771635771, 116.71383938932266, 155.2022653353617, 104.32847391885146, 180.44849726786052, 46.78244727572483, 130.37118388405165, 122.9494590909186, 178.37800030337576, 137.34918339849676, 184.38866340528455, -9.570586022159391, -60.54085617840257, -81.77077465079117, -102.33007901559169, -72.5311216785331, -98.99419573468208, -117.8299840199133, -37.98959219461904, -66.39827852313977, -11.360137785578548, -87.00345275896954, -52.95467887161949, -92.58406842423466], "policy_AGENT-0_reward": [49.7431973228228, -236.69844286283347, 134.29330490049176, -75.48931360205738, 42.46794215197691, 91.40995291567144, 141.20875733064838, -108.50187705931481, 6.196256551933884, -234.3782106520727, 118.2332425970099, -153.264224336924, 133.69170936611673, -5.52982621379617, 46.46361727316407, 176.3388217893341, 136.1480547148628, 63.57056914783515, -95.81402469081749, 127.07802214765563, -212.82663793944033, 28.19227858003759, -114.55826053916866, 171.50158777413665, -102.34122436059998, -107.4950845118411, -108.64888831845677, -122.24530535553092, -139.25452629701658, -138.35615334342765, -154.8197354754679, -39.165794342490344, -57.42236196067732, -55.74925717919085, -67.38060757112929, -61.08180549165415, -120.57985332388293, -109.23821728564114, -63.00783006231447, 47.193040622118616, -114.97742721444311, 31.779472101805865, -84.80955386420422, 274.9389363495801, -37.72463868880529, 233.9923276091043, 91.93308785028623, 27.997344777514314, -15.809763630758553, 251.30306051556315, -90.15400113987911, -64.24974416411881, -50.18443708407554, -71.72660731105383, -127.9928681321318, -84.43536870268323, -95.93147598270812, -62.48767999797833, -77.0505790421515, -117.61204916212039, -80.27641307757602, -95.38069633504249, 22.227887768065685, -251.9894791046999, -155.74254184578012, 12.925297185282282, -156.63247775195092, 17.64021844781675, 112.2310608037608, -67.50958255650544, -95.01733118790756, -73.47501772041478, -101.75694411678613, 37.334696116551704, -227.39770421002407, 47.1824950563148, 118.83570800805052, 33.174386187311114, 79.19033232854663, 132.8069023021986, 38.077577321564775, 94.36415044540135, 79.61003179301358, 79.7303680435382, 201.41310116187515, 92.94846491866736, 209.37986585757733, -76.98796862351556, -106.38279914565024, -61.50665707908379, -114.87022260739708, -135.9392742230465, -99.91557532739853, -66.72552574127073, -75.61345268183055, -107.99918959880154, -64.15278453056251, -94.63841381686215, -76.58972908201459, -66.35436652647375], "policy_AGENT-1_reward": [52.19275586474067, -236.83542573665176, 111.33706715136327, -75.44721138609493, 42.56651420121556, 65.79260897495148, 181.53047005201515, -189.09224945327938, 7.183892179573276, -234.59978318880806, 163.00770656311306, -177.54356075364439, 70.52236468866425, -4.225328562854033, 46.485634225284755, 176.39323611968314, 136.19926362463812, 161.5068414331863, -95.87007593293015, 174.3520747370189, -170.07718030839695, 28.19404512646941, -135.76114323078502, 220.71512582381627, -102.36805143113777, -107.43522260522387, -108.54712170924337, -144.60357763570218, -96.63510563989293, -138.37357922077024, -106.51676146625776, -36.98084176453199, -57.03182447604294, -55.340948602812595, -67.4595981097606, -61.363745330785775, -73.27590350500418, -109.28106232386352, -63.10908338820212, 47.19815553900062, -65.79960190573257, 31.762229993895307, -55.74449800867116, 274.61827201128574, -37.71193344446635, 234.41671151089332, 91.41479173293598, 27.914414177474494, -1.883985718658245, 223.4751583753234, -90.28432857476305, -64.28168198658891, -48.060981752820766, -71.72742312281655, -80.0108460927025, -83.49051313268517, -95.54975033331351, -61.735316386594064, -102.25436987387542, -117.61829644949314, -79.54464483881385, -120.39304518401586, -25.776164422620113, -251.98477307643114, -68.5785668389748, 61.14124553555656, -123.0421146161336, 24.342996317373405, 87.02305350332962, -67.43440599298228, -95.01117581917705, -64.441606701851, -105.22087092603127, 37.72502272797525, -227.53206125943177, 210.43850696493956, 95.24509776890176, 33.21998156395527, 160.68832245579793, 131.9717128917053, 205.58801030309635, 94.39764004898541, 122.60982240655262, 123.11155115871897, 178.93460746647702, 137.26836358464323, 61.714893640975774, -74.48214344911477, -106.4316450722846, -60.703177241362454, -136.6605631443287, -93.179187131806, -99.85615381879809, -66.70635827699813, -75.61908901156681, -58.44073590105885, -64.32145673147946, -94.8714893771686, -76.65087133816064, -66.2846490877818]}, "sampler_perf": {"mean_env_wait_ms": 82.98301211470886, "mean_raw_obs_processing_ms": 3.377521578409519, "mean_inference_ms": 3.6164275658427227, "mean_action_processing_ms": 0.20044707030659675}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 21000, "timers": {"sample_time_ms": 134724.07, "sample_throughput": 31.175, "load_time_ms": 205.347, "load_throughput": 20453.226, "learn_time_ms": 19727.362, "learn_throughput": 212.902, "update_time_ms": 9.661}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 11.670865058898926, "policy_loss": -0.029677659273147583, "vf_loss": 11.698452949523926, "vf_explained_var": 0.9024376273155212, "kl": 0.010444064624607563, "entropy": 1.343131184577942, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 11.543551445007324, "policy_loss": -0.03005189448595047, "vf_loss": 11.571614265441895, "vf_explained_var": 0.8915933966636658, "kl": 0.009950610809028149, "entropy": 1.3442211151123047, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 9.073266983032227, "policy_loss": -0.032842423766851425, "vf_loss": 9.104183197021484, "vf_explained_var": 0.9171382784843445, "kl": 0.009627744555473328, "entropy": 1.3473259210586548, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 8.937095642089844, "policy_loss": -0.031155433505773544, "vf_loss": 8.966060638427734, "vf_explained_var": 0.9233915209770203, "kl": 0.010954180732369423, "entropy": 1.3415755033493042, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 21000, "num_steps_trained": 21000}, "done": false, "episodes_total": 185, "training_iteration": 5, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_14-32-40", "timestamp": 1624199560, "time_this_iter_s": 158.06729531288147, "time_total_s": 776.441178560257, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f041bb00>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f041b320>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd601a3ae60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a170>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a5f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a0e0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd601a3ae60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a170>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a5f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a0e0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd601a3ae60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a170>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a5f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a0e0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd601a3ae60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a170>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a5f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a0e0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f031acb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 776.441178560257, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 56.25, "ram_util_percent": 87.37654867256634}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 860.4955599968243, "episode_reward_min": -985.0706210713564, "episode_reward_mean": 1.2755719461878798, "episode_len_mean": 113.64, "episodes_this_iter": 34, "policy_reward_min": {"AGENT-2": -256.047885594404, "AGENT-3": -250.6521644150791, "AGENT-0": -239.5470048334608, "AGENT-1": -238.82356622841252}, "policy_reward_max": {"AGENT-2": 223.58096033474706, "AGENT-3": 230.4891472636751, "AGENT-0": 209.37986585757733, "AGENT-1": 234.06070393045556}, "policy_reward_mean": {"AGENT-2": 3.6701126778683233, "AGENT-3": 9.849131433818906, "AGENT-0": -12.22907040120717, "AGENT-1": -0.014601764292185635}, "custom_metrics": {"mean_ego_speed_mean": 41.578445, "mean_ego_speed_min": 31.7055, "mean_ego_speed_max": 45.22075, "distance_travelled_mean": 101.76180249999999, "distance_travelled_min": 30.319, "distance_travelled_max": 124.899}, "hist_stats": {"episode_reward": [28.909679890935067, -4.789971794284867, 790.979085156852, -985.0706210713564, 168.29241610540768, -829.2727345442236, 60.9183220197252, -722.7246174664199, 65.34169737072408, 106.94556067747483, 312.30303353075215, 791.0939749525843, -31.572541738104775, 505.09988725304504, 317.4584881089745, -34.41124109855932, 96.33802999264523, 763.9847671284454, 624.7647687521684, 860.4955599968243, 617.3861579970495, 672.9784674094805, 562.3992365987764, -190.84992503006703, 620.4797014231743, -693.9953036779218, -126.74096528915489, -507.9433881099806, -356.55454002380674, -308.8750996156754, -276.1035465897285, -328.9675475149517, -331.05360166394524, -288.11799377519304, 67.3400780254229, -927.3642587477267, 504.08492057131997, 421.04823309824656, 299.084453380478, 473.7082606059203, 476.20197192576467, 461.6396275475503, 282.37508371270235, 463.1709931619726, 448.2513455644882, 736.6874971420375, 505.44414703291557, 516.7157883272715, -170.58705309505382, -335.80401368014407, -260.7844774141188, -456.179442938696, -374.2377576550442, -397.62472196410675, -415.7135436967049, -227.62851906789925, -298.0421068600291, -151.21475119195793, -364.8319490014996, -307.49982986555676, -317.49201269470905, 185.4939287382611, -955.9949229036419, 435.6254914330678, -217.96230795800213, 148.83571789169176, -24.07161291381924, 638.7258193571423, -596.3084236536235, -21.0828216519997, -847.6987646276806, 523.8417781244221, -669.9275862339415, 448.93095593995287, 63.595560940731076, 286.5370558653137, 788.8934136779374, 555.4995010092889, 442.42176281529294, -265.9294072366709, 646.0864255662032, -420.94407121919954, 317.3352919746344, -265.61589197249054, 822.8167768008327, -276.9467181617789, -440.43304521110224, -275.02907554960103, -293.78041384453, -430.16406865579967, -333.90196178641577, -479.05541260530094, -198.9425061290585, -275.32909787197383, -267.6143398460189, -367.5093727973633, -172.7967779462892, -219.27471632276874, -316.8432876952373, -143.79883830618436], "episode_lengths": [121, 128, 142, 123, 120, 121, 119, 121, 115, 128, 116, 126, 121, 118, 117, 74, 119, 123, 125, 119, 119, 119, 116, 113, 165, 128, 109, 122, 124, 125, 120, 121, 118, 114, 119, 121, 126, 114, 108, 120, 120, 112, 78, 120, 120, 113, 118, 117, 121, 122, 118, 121, 123, 107, 109, 108, 118, 39, 111, 109, 80, 123, 120, 120, 67, 122, 124, 139, 81, 120, 115, 131, 119, 126, 120, 112, 105, 108, 122, 35, 118, 135, 108, 125, 124, 43, 125, 121, 119, 122, 123, 125, 120, 119, 121, 48, 102, 116, 109, 31], "policy_AGENT-2_reward": [-12.156639246590846, -46.58345089031399, 211.03940006617742, -256.047885594404, 34.05165361634473, -213.8150383205534, -6.960632171728081, -184.36036057485975, -6.977989493205895, -34.80924350823299, 71.78862975721823, 192.60398198623926, 19.38142854640776, 88.82181665671983, 26.310842479392228, -41.55352296301575, 18.236404468238042, 201.16342344182374, 172.76560996348752, 223.58096033474706, 165.16441684853348, 190.6070010480543, 131.9797240380226, -26.931710830660062, 163.1704594153169, -163.227928106061, -0.8104975755704068, -69.16443982099736, -67.1103237659589, -9.675929680760001, -13.048807662296399, -86.63024704686453, -51.17294105357815, -41.64979752245917, -3.853265017404261, -235.87834718609614, 46.628502534599264, 103.4765501577169, 115.97624623988902, 78.62734048621421, 107.09488281300911, 37.52554265502859, 46.83084594259101, 130.57995507835446, 122.45996727131264, 177.96178821031043, 137.8781351311086, 61.23236542343383, -9.546355000264109, -62.44871328380677, -56.80386844288181, -102.31857817137822, -72.5881746216585, -98.8587970832282, -164.45167565852248, -38.40638517988273, -65.20390283702932, -11.380372144337407, -88.31859304849911, -101.30455057376213, -92.268928656219, 40.57364558594317, -241.99787390525546, 89.60183732476214, -33.51204797111188, 40.64029555734158, -90.6079126799719, 158.05988303922837, -109.0511439714021, -17.256909239089563, -187.67187055604987, 132.12669864371003, -153.82160764505056, 70.04055854616394, 36.75562329646361, 72.32012698098762, 209.89503647795829, 140.39055755157005, 63.01624509462134, -37.155728674593966, 172.37895904953405, -18.9950328024227, 130.3857134541541, -7.6426335469425695, 215.17094866172093, -36.129245801815784, -112.69875885936523, -28.773165515130227, -13.364131580260473, -97.06660679630839, -28.59626773504134, -112.31656037392682, -61.237167732917314, -79.48290669852918, -77.62912871933841, -116.30566056648428, -12.978039908257166, -12.66695584330746, -49.189357009628566, -8.818129222336], "policy_AGENT-3_reward": [-12.28321180049744, -46.720138115774816, 152.11279036330427, -250.6521644150791, 33.99530841282034, -213.94615955118334, -7.113224257523563, -183.05671729942017, -7.195667733715062, -34.72761456551512, 71.65793097182275, 193.4572224192271, 19.296388615045743, 184.82630904401228, 130.12507637300385, -41.86536165959257, 18.10497839704545, 200.4475057530017, 143.28823636307666, 230.4891472636751, 156.77569321479123, 190.20445513678447, 135.9204224701656, -23.305924525329967, 121.42989877041765, -159.93230464665314, -0.09646997128396817, -191.34081693254703, -67.04858538283591, -9.778678117393746, -13.041429254003154, -57.85338728264165, -51.170364457450056, -82.44566324769562, -3.866375801699819, -236.55614609217426, 199.8354160154664, 103.4908771635771, 116.71383938932266, 155.2022653353617, 104.32847391885146, 180.44849726786052, 46.78244727572483, 130.37118388405165, 122.9494590909186, 178.37800030337576, 137.34918339849676, 184.38866340528455, -9.570586022159391, -60.54085617840257, -81.77077465079117, -102.33007901559169, -72.5311216785331, -98.99419573468208, -117.8299840199133, -37.98959219461904, -66.39827852313977, -11.360137785578548, -87.00345275896954, -52.95467887161949, -92.58406842423466, 42.98432996475449, -240.46318039890193, 100.39328205645067, -33.513734998737846, 23.160965981157833, -90.6662621244705, 157.92670893525028, -189.6631531696275, -17.206061144417315, -191.04890023075035, 110.47413032058934, -185.2981934983223, 174.67632333900832, 36.59509242091721, 121.2676773858771, 226.2663192909616, 142.76162511821838, 154.32810713965037, -37.08957793832933, 172.27736963199405, -19.045220168939526, 130.56325481397306, -7.653854655594401, 215.42911454115952, -36.10819656822528, -112.80397923467228, -29.059900006770558, -13.567399273036619, -97.20782992258162, -28.57596148717667, -105.4023552896489, -61.55870228911873, -81.39200473672445, -78.89500534467687, -116.36350654998911, -37.37318721559218, -12.752003650574103, -49.13465107610392, -8.863795633331762], "policy_AGENT-0_reward": [25.82762852815624, 20.873464367434565, 193.7661907969151, -239.5470048334608, 49.92698157332068, -201.10449620465343, 13.061183998408616, -178.15904707440438, 39.59132439191886, 67.11898102933343, 84.45824977921535, 203.85854411671346, -59.27783445318248, 142.09410388348664, 26.737852406377563, 24.454528186279518, 43.54650559469245, 156.9750681587719, 130.4073222311539, 182.4059488858133, 122.9434644346151, 145.8422246620542, 158.45590913869052, -70.24367558194685, 161.49575310623212, -208.26622287388238, -62.89070995843349, -68.62734054937197, -135.79113283413216, -130.40467076130753, -149.42584381623305, -127.1967766313326, -114.57013780216701, -122.90764415042332, 37.334696116551704, -227.39770421002407, 47.1824950563148, 118.83570800805052, 33.174386187311114, 79.19033232854663, 132.8069023021986, 38.077577321564775, 94.36415044540135, 79.61003179301358, 79.7303680435382, 201.41310116187515, 92.94846491866736, 209.37986585757733, -76.98796862351556, -106.38279914565024, -61.50665707908379, -114.87022260739708, -135.9392742230465, -99.91557532739853, -66.72552574127073, -75.61345268183055, -107.99918959880154, -64.15278453056251, -94.63841381686215, -76.58972908201459, -66.35436652647375, 49.7431973228228, -236.69844286283347, 134.29330490049176, -75.48931360205738, 42.46794215197691, 91.40995291567144, 141.20875733064838, -108.50187705931481, 6.196256551933884, -234.3782106520727, 118.2332425970099, -153.264224336924, 133.69170936611673, -5.52982621379617, 46.46361727316407, 176.3388217893341, 136.1480547148628, 63.57056914783515, -95.81402469081749, 127.07802214765563, -212.82663793944033, 28.19227858003759, -114.55826053916866, 171.50158777413665, -102.34122436059998, -107.4950845118411, -108.64888831845677, -122.24530535553092, -139.25452629701658, -138.35615334342765, -154.8197354754679, -39.165794342490344, -57.42236196067732, -55.74925717919085, -67.38060757112929, -61.08180549165415, -120.57985332388293, -109.23821728564114, -63.00783006231447], "policy_AGENT-1_reward": [27.521902409867145, 67.64015284436934, 234.06070393045556, -238.82356622841252, 50.3184725029219, -200.40704046783264, 61.930994450568214, -177.14849251773532, 39.92403020572618, 109.36343772188954, 84.3982230224959, 201.17422643040436, -10.972524446375692, 89.35765766882614, 134.28471685020088, 24.553115337769523, 16.450141532669193, 205.39876977484812, 178.30360019444973, 224.01950351258847, 172.50258349910973, 146.32478656258726, 136.04318095189774, -70.36861409213006, 174.38359013120754, -162.5688480513257, -62.943287783867035, -178.8107908070646, -86.60449804087986, -159.01582105621426, -100.58746585719592, -57.28713655411323, -114.1401583507501, -41.114888854614954, 37.72502272797525, -227.53206125943177, 210.43850696493956, 95.24509776890176, 33.21998156395527, 160.68832245579793, 131.9717128917053, 205.58801030309635, 94.39764004898541, 122.60982240655262, 123.11155115871897, 178.93460746647702, 137.26836358464323, 61.714893640975774, -74.48214344911477, -106.4316450722846, -60.703177241362454, -136.6605631443287, -93.179187131806, -99.85615381879809, -66.70635827699813, -75.61908901156681, -58.44073590105885, -64.32145673147946, -94.8714893771686, -76.65087133816064, -66.2846490877818, 52.19275586474067, -236.83542573665176, 111.33706715136327, -75.44721138609493, 42.56651420121556, 65.79260897495148, 181.53047005201515, -189.09224945327938, 7.183892179573276, -234.59978318880806, 163.00770656311306, -177.54356075364439, 70.52236468866425, -4.225328562854033, 46.485634225284755, 176.39323611968314, 136.19926362463812, 161.5068414331863, -95.87007593293015, 174.3520747370189, -170.07718030839695, 28.19404512646941, -135.76114323078502, 220.71512582381627, -102.36805143113777, -107.43522260522387, -108.54712170924337, -144.60357763570218, -96.63510563989293, -138.37357922077024, -106.51676146625776, -36.98084176453199, -57.03182447604294, -55.340948602812595, -67.4595981097606, -61.363745330785775, -73.27590350500418, -109.28106232386352, -63.10908338820212]}, "sampler_perf": {"mean_env_wait_ms": 83.16416083952369, "mean_raw_obs_processing_ms": 3.3956273394886467, "mean_inference_ms": 3.5595900907281464, "mean_action_processing_ms": 0.20106590053848258}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 25200, "timers": {"sample_time_ms": 139550.266, "sample_throughput": 30.097, "load_time_ms": 174.737, "load_throughput": 24036.159, "learn_time_ms": 20617.315, "learn_throughput": 203.712, "update_time_ms": 10.669}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 6.780175685882568, "policy_loss": -0.03958394005894661, "vf_loss": 6.817131519317627, "vf_explained_var": 0.9441075325012207, "kl": 0.01313979085534811, "entropy": 1.3406158685684204, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 4.9423394203186035, "policy_loss": -0.03832149878144264, "vf_loss": 4.978260517120361, "vf_explained_var": 0.9531143307685852, "kl": 0.011999867856502533, "entropy": 1.3315962553024292, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 5.15598726272583, "policy_loss": -0.042388949543237686, "vf_loss": 5.195443153381348, "vf_explained_var": 0.9557682275772095, "kl": 0.014665686525404453, "entropy": 1.3348995447158813, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 4.735873222351074, "policy_loss": -0.04303840920329094, "vf_loss": 4.77603816986084, "vf_explained_var": 0.9603221416473389, "kl": 0.014365745708346367, "entropy": 1.3257123231887817, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 25200, "num_steps_trained": 25200}, "done": false, "episodes_total": 219, "training_iteration": 6, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_14-35-49", "timestamp": 1624199749, "time_this_iter_s": 188.83023047447205, "time_total_s": 965.271409034729, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f03660e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f0366200>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0366440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0366560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0366680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03667a0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0366440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0366560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0366680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03667a0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0366440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0366560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0366680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03667a0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0366440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0366560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0366680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03667a0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f03d9710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 965.271409034729, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 55.22193308550186, "ram_util_percent": 87.54646840148699}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 860.4955599968243, "episode_reward_min": -1560.5739153913514, "episode_reward_mean": -12.466501894028228, "episode_len_mean": 117.04, "episodes_this_iter": 34, "policy_reward_min": {"AGENT-2": -394.11800177520684, "AGENT-1": -434.02634121152903, "AGENT-3": -338.8844101460644, "AGENT-0": -393.5451622585504}, "policy_reward_max": {"AGENT-2": 229.08714021529377, "AGENT-1": 234.06070393045556, "AGENT-3": 234.89929179144127, "AGENT-0": 254.16776528454142}, "policy_reward_mean": {"AGENT-2": 3.4871945937161035, "AGENT-1": -4.991776329261679, "AGENT-3": 6.362053414888985, "AGENT-0": -17.323973573371653}, "custom_metrics": {"mean_ego_speed_mean": 41.247600000000006, "mean_ego_speed_min": 26.223, "mean_ego_speed_max": 47.039500000000004, "distance_travelled_mean": 103.33338499999999, "distance_travelled_min": 30.319, "distance_travelled_max": 124.93475}, "hist_stats": {"episode_reward": [-1083.1291543452176, 346.9951648984347, -652.763962248791, 117.49696629003303, -178.7352294530074, -209.0188857661921, -1560.5739153913514, -142.36420858294292, 595.6196643682503, -50.400720908333994, 742.8477846802481, 712.089023865936, 553.2909654183417, 786.0468531191063, 422.2607676772697, 388.35372027539455, 484.164261391708, 409.8355872150108, 311.9715951106352, 554.4775572805006, 563.7407419194003, 582.8051296744388, -40.76830851123643, -587.5838508836346, -228.98575822995895, -406.91297297232074, -277.5194052300711, -348.32172453787643, -489.97842968956104, -360.91419694978345, -377.0500920233797, -438.7453818541608, -336.6296812234231, -314.40721253753316, -596.3084236536235, -21.0828216519997, -847.6987646276806, 523.8417781244221, -669.9275862339415, 448.93095593995287, 63.595560940731076, 286.5370558653137, 788.8934136779374, 555.4995010092889, 442.42176281529294, -265.9294072366709, 646.0864255662032, -420.94407121919954, 317.3352919746344, -265.61589197249054, 822.8167768008327, -276.9467181617789, -440.43304521110224, -275.02907554960103, -293.78041384453, -430.16406865579967, -333.90196178641577, -479.05541260530094, -198.9425061290585, -275.32909787197383, -267.6143398460189, -367.5093727973633, -172.7967779462892, -219.27471632276874, -316.8432876952373, -143.79883830618436, 28.909679890935067, -4.789971794284867, 790.979085156852, -985.0706210713564, 168.29241610540768, -829.2727345442236, 60.9183220197252, -722.7246174664199, 65.34169737072408, 106.94556067747483, 312.30303353075215, 791.0939749525843, -31.572541738104775, 505.09988725304504, 317.4584881089745, -34.41124109855932, 96.33802999264523, 763.9847671284454, 624.7647687521684, 860.4955599968243, 617.3861579970495, 672.9784674094805, 562.3992365987764, -190.84992503006703, 620.4797014231743, -693.9953036779218, -126.74096528915489, -507.9433881099806, -356.55454002380674, -308.8750996156754, -276.1035465897285, -328.9675475149517, -331.05360166394524, -288.11799377519304], "episode_lengths": [120, 123, 141, 121, 129, 134, 129, 124, 132, 126, 140, 114, 111, 116, 121, 108, 121, 112, 117, 119, 105, 120, 118, 158, 121, 116, 115, 119, 115, 124, 118, 115, 120, 125, 81, 120, 115, 131, 119, 126, 120, 112, 105, 108, 122, 35, 118, 135, 108, 125, 124, 43, 125, 121, 119, 122, 123, 125, 120, 119, 121, 48, 102, 116, 109, 31, 121, 128, 142, 123, 120, 121, 119, 121, 115, 128, 116, 126, 121, 118, 117, 74, 119, 123, 125, 119, 119, 119, 116, 113, 165, 128, 109, 122, 124, 125, 120, 121, 118, 114], "policy_AGENT-2_reward": [-277.23179680178026, 87.9560140114272, -190.34802983657377, -6.649160102389329, -101.91350969511137, 13.667704369965819, -394.11800177520684, -82.93081154204472, 139.67809803221382, -43.277021834586165, 216.8929252846294, 201.4431526362443, 102.81319967479703, 229.08714021529377, 159.67976534160974, 49.66424475505518, 112.93896485526417, 114.96508192696999, 36.9120369148576, 159.15190797526557, 140.52947844045903, 138.00020911913097, 1.0034544678698438, -108.4953866390417, -7.468933318768156, -128.21629746919146, -74.72579875067629, -79.71645312042631, -130.07441521421586, -9.096046786205513, -102.20194521612324, -121.12777270949043, -66.64075492281651, -73.04360871209344, -109.0511439714021, -17.256909239089563, -187.67187055604987, 132.12669864371003, -153.82160764505056, 70.04055854616394, 36.75562329646361, 72.32012698098762, 209.89503647795829, 140.39055755157005, 63.01624509462134, -37.155728674593966, 172.37895904953405, -18.9950328024227, 130.3857134541541, -7.6426335469425695, 215.17094866172093, -36.129245801815784, -112.69875885936523, -28.773165515130227, -13.364131580260473, -97.06660679630839, -28.59626773504134, -112.31656037392682, -61.237167732917314, -79.48290669852918, -77.62912871933841, -116.30566056648428, -12.978039908257166, -12.66695584330746, -49.189357009628566, -8.818129222336, -12.156639246590846, -46.58345089031399, 211.03940006617742, -256.047885594404, 34.05165361634473, -213.8150383205534, -6.960632171728081, -184.36036057485975, -6.977989493205895, -34.80924350823299, 71.78862975721823, 192.60398198623926, 19.38142854640776, 88.82181665671983, 26.310842479392228, -41.55352296301575, 18.236404468238042, 201.16342344182374, 172.76560996348752, 223.58096033474706, 165.16441684853348, 190.6070010480543, 131.9797240380226, -26.931710830660062, 163.1704594153169, -163.227928106061, -0.8104975755704068, -69.16443982099736, -67.1103237659589, -9.675929680760001, -13.048807662296399, -86.63024704686453, -51.17294105357815, -41.64979752245917], "policy_AGENT-1_reward": [-269.1780625546835, 99.49918730499208, -115.17849769438578, 66.0233418374091, 33.58139168159691, 14.266055521759952, -434.02634121152903, 12.512049299093967, 176.24963931561524, 41.57149902355282, 173.88840505549513, 155.51316513012307, 150.5535661319243, 67.8926558278298, 30.245546511995975, 155.33375520458642, 113.7534042922431, 115.40497171148043, 37.605352187384966, 117.93608177103535, 141.42064185160882, 138.42949076649234, -21.37265471345485, -165.9561848397949, -107.05299022758322, -54.07962432643802, -75.05806074265534, -73.12357645280868, -125.73619871360788, -147.4980505621389, -84.44450148786846, -33.88147711940575, -112.5674413594635, -87.93326365442819, -189.09224945327938, 7.183892179573276, -234.59978318880806, 163.00770656311306, -177.54356075364439, 70.52236468866425, -4.225328562854033, 46.485634225284755, 176.39323611968314, 136.19926362463812, 161.5068414331863, -95.87007593293015, 174.3520747370189, -170.07718030839695, 28.19404512646941, -135.76114323078502, 220.71512582381627, -102.36805143113777, -107.43522260522387, -108.54712170924337, -144.60357763570218, -96.63510563989293, -138.37357922077024, -106.51676146625776, -36.98084176453199, -57.03182447604294, -55.340948602812595, -67.4595981097606, -61.363745330785775, -73.27590350500418, -109.28106232386352, -63.10908338820212, 27.521902409867145, 67.64015284436934, 234.06070393045556, -238.82356622841252, 50.3184725029219, -200.40704046783264, 61.930994450568214, -177.14849251773532, 39.92403020572618, 109.36343772188954, 84.3982230224959, 201.17422643040436, -10.972524446375692, 89.35765766882614, 134.28471685020088, 24.553115337769523, 16.450141532669193, 205.39876977484812, 178.30360019444973, 224.01950351258847, 172.50258349910973, 146.32478656258726, 136.04318095189774, -70.36861409213006, 174.38359013120754, -162.5688480513257, -62.943287783867035, -178.8107908070646, -86.60449804087986, -159.01582105621426, -100.58746585719592, -57.28713655411323, -114.1401583507501, -41.114888854614954], "policy_AGENT-3_reward": [-261.29674676735914, 59.913814618560934, -190.40835616333192, -6.907495627389483, -102.09682545824279, -134.4401598554036, -338.8844101460644, -82.88512862373355, 144.9968982622285, -43.30925296506647, 155.83652795168481, 199.48922471404967, 149.42794241143835, 234.89929179144127, 202.04859598885298, 133.1303386280953, 149.21804350252054, 114.89897384483672, 140.20688061902615, 159.30790340990666, 140.39408025012995, 174.80465360801009, 0.9382205690124934, -108.63139404265132, -7.6098933295849465, -54.639585483839895, -75.09427838731096, -73.56584891099388, -130.20942219684915, -9.070545853589131, -106.7289625204058, -155.03450208617912, -66.60525552905675, -73.02104000404758, -189.6631531696275, -17.206061144417315, -191.04890023075035, 110.47413032058934, -185.2981934983223, 174.67632333900832, 36.59509242091721, 121.2676773858771, 226.2663192909616, 142.76162511821838, 154.32810713965037, -37.08957793832933, 172.27736963199405, -19.045220168939526, 130.56325481397306, -7.653854655594401, 215.42911454115952, -36.10819656822528, -112.80397923467228, -29.059900006770558, -13.567399273036619, -97.20782992258162, -28.57596148717667, -105.4023552896489, -61.55870228911873, -81.39200473672445, -78.89500534467687, -116.36350654998911, -37.37318721559218, -12.752003650574103, -49.13465107610392, -8.863795633331762, -12.28321180049744, -46.720138115774816, 152.11279036330427, -250.6521644150791, 33.99530841282034, -213.94615955118334, -7.113224257523563, -183.05671729942017, -7.195667733715062, -34.72761456551512, 71.65793097182275, 193.4572224192271, 19.296388615045743, 184.82630904401228, 130.12507637300385, -41.86536165959257, 18.10497839704545, 200.4475057530017, 143.28823636307666, 230.4891472636751, 156.77569321479123, 190.20445513678447, 135.9204224701656, -23.305924525329967, 121.42989877041765, -159.93230464665314, -0.09646997128396817, -191.34081693254703, -67.04858538283591, -9.778678117393746, -13.041429254003154, -57.85338728264165, -51.170364457450056, -82.44566324769562], "policy_AGENT-0_reward": [-275.4225482213945, 99.62614896345441, -156.82907855449906, 65.03028018240275, -8.306285981250191, -102.51248580251415, -393.5451622585504, 10.939682283741114, 134.69502875819265, -5.385945132234021, 196.22992638843846, 155.6434813855186, 150.49625720018196, 254.16776528454142, 30.28685983481101, 50.2253816876576, 108.25384874167986, 64.56655973172319, 97.24732538936645, 118.08166412429262, 141.39654137720274, 131.57077618080547, -21.337328834663982, -204.50088536214605, -106.85394135402274, -169.97746569285118, -52.641267349428574, -121.91584605364768, -103.95839356488796, -195.24955374785017, -83.67468279898202, -128.70162993908602, -90.81622941208659, -80.40930016696382, -108.50187705931481, 6.196256551933884, -234.3782106520727, 118.2332425970099, -153.264224336924, 133.69170936611673, -5.52982621379617, 46.46361727316407, 176.3388217893341, 136.1480547148628, 63.57056914783515, -95.81402469081749, 127.07802214765563, -212.82663793944033, 28.19227858003759, -114.55826053916866, 171.50158777413665, -102.34122436059998, -107.4950845118411, -108.64888831845677, -122.24530535553092, -139.25452629701658, -138.35615334342765, -154.8197354754679, -39.165794342490344, -57.42236196067732, -55.74925717919085, -67.38060757112929, -61.08180549165415, -120.57985332388293, -109.23821728564114, -63.00783006231447, 25.82762852815624, 20.873464367434565, 193.7661907969151, -239.5470048334608, 49.92698157332068, -201.10449620465343, 13.061183998408616, -178.15904707440438, 39.59132439191886, 67.11898102933343, 84.45824977921535, 203.85854411671346, -59.27783445318248, 142.09410388348664, 26.737852406377563, 24.454528186279518, 43.54650559469245, 156.9750681587719, 130.4073222311539, 182.4059488858133, 122.9434644346151, 145.8422246620542, 158.45590913869052, -70.24367558194685, 161.49575310623212, -208.26622287388238, -62.89070995843349, -68.62734054937197, -135.79113283413216, -130.40467076130753, -149.42584381623305, -127.1967766313326, -114.57013780216701, -122.90764415042332]}, "sampler_perf": {"mean_env_wait_ms": 84.66977103497955, "mean_raw_obs_processing_ms": 3.451096364111411, "mean_inference_ms": 3.5756552428252544, "mean_action_processing_ms": 0.2043835071263437}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 29400, "timers": {"sample_time_ms": 143976.715, "sample_throughput": 29.171, "load_time_ms": 152.361, "load_throughput": 27566.186, "learn_time_ms": 20469.931, "learn_throughput": 205.179, "update_time_ms": 10.567}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 6.283687591552734, "policy_loss": -0.040152765810489655, "vf_loss": 6.321266174316406, "vf_explained_var": 0.9502822756767273, "kl": 0.012868013232946396, "entropy": 1.3257113695144653, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 6.425195693969727, "policy_loss": -0.03666163608431816, "vf_loss": 6.459478378295898, "vf_explained_var": 0.9494102597236633, "kl": 0.011893657967448235, "entropy": 1.334225058555603, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 5.643929481506348, "policy_loss": -0.04460446909070015, "vf_loss": 5.685802936553955, "vf_explained_var": 0.9579954743385315, "kl": 0.013653963804244995, "entropy": 1.319080114364624, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 3.7744951248168945, "policy_loss": -0.04570600390434265, "vf_loss": 3.817481517791748, "vf_explained_var": 0.9676841497421265, "kl": 0.013599365949630737, "entropy": 1.3095351457595825, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 29400, "num_steps_trained": 29400}, "done": false, "episodes_total": 253, "training_iteration": 7, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_14-39-00", "timestamp": 1624199940, "time_this_iter_s": 190.18232321739197, "time_total_s": 1155.453732252121, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f031a290>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd601a3e5f0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d93b0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9b00>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9200>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d93b0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9b00>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9200>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d93b0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9b00>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9200>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d93b0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9b00>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9200>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f03669e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1155.453732252121, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 57.547426470588235, "ram_util_percent": 87.81838235294116}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 860.4955599968243, "episode_reward_min": -1560.5739153913514, "episode_reward_mean": -11.002311341969689, "episode_len_mean": 120.91, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-2": -394.11800177520684, "AGENT-1": -434.02634121152903, "AGENT-3": -338.8844101460644, "AGENT-0": -393.5451622585504}, "policy_reward_max": {"AGENT-2": 229.08714021529377, "AGENT-1": 224.01950351258847, "AGENT-3": 234.89929179144127, "AGENT-0": 254.16776528454142}, "policy_reward_mean": {"AGENT-2": 1.1653506258468804, "AGENT-1": -1.63881308736836, "AGENT-3": 7.5572270725061905, "AGENT-0": -18.086075952954417}, "custom_metrics": {"mean_ego_speed_mean": 41.147882499999994, "mean_ego_speed_min": 26.223, "mean_ego_speed_max": 47.039500000000004, "distance_travelled_mean": 105.50868499999999, "distance_travelled_min": 56.5535, "distance_travelled_max": 124.93475}, "hist_stats": {"episode_reward": [-871.1129050060883, 409.1521486908016, 6.659867688314755, 392.1576478513093, -547.6069400118978, 713.8364555170182, -439.2603912381985, -576.3151605581668, 5.453648248926648, -985.8542055749567, 492.1130445102013, -365.6929618171426, 485.3899390440942, 461.0551960816535, -391.5802809438795, 828.6542899996059, 487.819204355398, 126.67660734903075, 398.6580319436092, 442.3695427063436, 212.0663577653466, 602.5741217117655, 376.75057133702427, -359.0536807635164, 206.48913290238715, -228.7550092044037, -24.781896582013673, -213.61103341771252, -251.0339734392277, -387.5856123662128, -446.01279326448446, -380.84571436928996, -625.0745595101503, -501.32465946557653, -773.8242583209759, -985.0706210713564, 168.29241610540768, -829.2727345442236, 60.9183220197252, -722.7246174664199, 65.34169737072408, 106.94556067747483, 312.30303353075215, 791.0939749525843, -31.572541738104775, 505.09988725304504, 317.4584881089745, -34.41124109855932, 96.33802999264523, 763.9847671284454, 624.7647687521684, 860.4955599968243, 617.3861579970495, 672.9784674094805, 562.3992365987764, -190.84992503006703, 620.4797014231743, -693.9953036779218, -126.74096528915489, -507.9433881099806, -356.55454002380674, -308.8750996156754, -276.1035465897285, -328.9675475149517, -331.05360166394524, -288.11799377519304, -1083.1291543452176, 346.9951648984347, -652.763962248791, 117.49696629003303, -178.7352294530074, -209.0188857661921, -1560.5739153913514, -142.36420858294292, 595.6196643682503, -50.400720908333994, 742.8477846802481, 712.089023865936, 553.2909654183417, 786.0468531191063, 422.2607676772697, 388.35372027539455, 484.164261391708, 409.8355872150108, 311.9715951106352, 554.4775572805006, 563.7407419194003, 582.8051296744388, -40.76830851123643, -587.5838508836346, -228.98575822995895, -406.91297297232074, -277.5194052300711, -348.32172453787643, -489.97842968956104, -360.91419694978345, -377.0500920233797, -438.7453818541608, -336.6296812234231, -314.40721253753316], "episode_lengths": [120, 132, 124, 126, 122, 131, 94, 115, 164, 126, 134, 124, 107, 122, 130, 118, 117, 119, 127, 122, 111, 122, 101, 110, 139, 128, 117, 74, 121, 74, 119, 125, 124, 122, 165, 123, 120, 121, 119, 121, 115, 128, 116, 126, 121, 118, 117, 74, 119, 123, 125, 119, 119, 119, 116, 113, 165, 128, 109, 122, 124, 125, 120, 121, 118, 114, 120, 123, 141, 121, 129, 134, 129, 124, 132, 126, 140, 114, 111, 116, 121, 108, 121, 112, 117, 119, 105, 120, 118, 158, 121, 116, 115, 119, 115, 124, 118, 115, 120, 125], "policy_AGENT-2_reward": [-223.69108762700012, 88.53590682670136, -80.16630867451502, 94.90198243006395, -159.0416381047286, 142.14150686962083, -97.29463254031948, -113.78924531322136, -31.429473616642273, -262.91680776555785, 106.64647636418763, -35.57917418838558, 101.92683825274516, 43.3509438137811, -34.29681137962979, 195.65657118704652, 122.73836507606798, 28.25357824740089, 51.176315030717895, 46.70574487995938, 35.07917601597512, 171.45324748534483, 150.70373132758962, -66.01507354630724, 55.533886386955245, -8.021373618212992, 60.08014729137752, -13.540358056553437, -18.05774142897822, -122.40897385323518, -115.9325193273817, -50.1949526536638, -153.48541381227693, -114.13535070670943, -11.139109171179848, -256.047885594404, 34.05165361634473, -213.8150383205534, -6.960632171728081, -184.36036057485975, -6.977989493205895, -34.80924350823299, 71.78862975721823, 192.60398198623926, 19.38142854640776, 88.82181665671983, 26.310842479392228, -41.55352296301575, 18.236404468238042, 201.16342344182374, 172.76560996348752, 223.58096033474706, 165.16441684853348, 190.6070010480543, 131.9797240380226, -26.931710830660062, 163.1704594153169, -163.227928106061, -0.8104975755704068, -69.16443982099736, -67.1103237659589, -9.675929680760001, -13.048807662296399, -86.63024704686453, -51.17294105357815, -41.64979752245917, -277.23179680178026, 87.9560140114272, -190.34802983657377, -6.649160102389329, -101.91350969511137, 13.667704369965819, -394.11800177520684, -82.93081154204472, 139.67809803221382, -43.277021834586165, 216.8929252846294, 201.4431526362443, 102.81319967479703, 229.08714021529377, 159.67976534160974, 49.66424475505518, 112.93896485526417, 114.96508192696999, 36.9120369148576, 159.15190797526557, 140.52947844045903, 138.00020911913097, 1.0034544678698438, -108.4953866390417, -7.468933318768156, -128.21629746919146, -74.72579875067629, -79.71645312042631, -130.07441521421586, -9.096046786205513, -102.20194521612324, -121.12777270949043, -66.64075492281651, -73.04360871209344], "policy_AGENT-1_reward": [-217.29818252557706, 136.88470919341228, 70.2497984919079, 124.62461311772896, -91.95548784248173, 201.60842326426592, -96.83217301746255, -173.0290690869069, 107.64752394063952, -240.5728739669967, 142.05727297387796, -122.736023641269, 118.01546149373412, 192.7184186242168, -163.60748291696265, 218.4265576143822, 123.19151163665211, 24.543623185791628, 153.5244986623363, 179.02347325252177, 46.91799245487087, 129.20324673331731, 49.11154556238309, -113.82874871522208, 49.48866166798718, -112.03963516515688, -67.75671182800188, -93.26536812086826, -82.88492579279536, -71.28771445834772, -118.64731582636367, -154.1837135743795, -164.1875332337915, -110.63008041984085, -358.90677248206003, -238.82356622841252, 50.3184725029219, -200.40704046783264, 61.930994450568214, -177.14849251773532, 39.92403020572618, 109.36343772188954, 84.3982230224959, 201.17422643040436, -10.972524446375692, 89.35765766882614, 134.28471685020088, 24.553115337769523, 16.450141532669193, 205.39876977484812, 178.30360019444973, 224.01950351258847, 172.50258349910973, 146.32478656258726, 136.04318095189774, -70.36861409213006, 174.38359013120754, -162.5688480513257, -62.943287783867035, -178.8107908070646, -86.60449804087986, -159.01582105621426, -100.58746585719592, -57.28713655411323, -114.1401583507501, -41.114888854614954, -269.1780625546835, 99.49918730499208, -115.17849769438578, 66.0233418374091, 33.58139168159691, 14.266055521759952, -434.02634121152903, 12.512049299093967, 176.24963931561524, 41.57149902355282, 173.88840505549513, 155.51316513012307, 150.5535661319243, 67.8926558278298, 30.245546511995975, 155.33375520458642, 113.7534042922431, 115.40497171148043, 37.605352187384966, 117.93608177103535, 141.42064185160882, 138.42949076649234, -21.37265471345485, -165.9561848397949, -107.05299022758322, -54.07962432643802, -75.05806074265534, -73.12357645280868, -125.73619871360788, -147.4980505621389, -84.44450148786846, -33.88147711940575, -112.5674413594635, -87.93326365442819], "policy_AGENT-3_reward": [-212.90847055597987, 91.1488774565525, -80.11423032080253, 90.33400849858484, -158.99027033009145, 142.0150602543141, -75.58101491552145, -176.25934309859034, -6.902922201413671, -267.62561227635314, 73.36798731433511, -35.45915429236525, 147.48294413305516, 181.08662090992945, -34.52834198601197, 196.08678528247103, 162.02571213408865, 28.131222627078735, 142.22442843840903, 169.3817898941713, 83.03398573061301, 173.40762563673022, 127.84832641367436, -65.43600939305318, 59.25214632760683, -7.980524925840904, 50.8075443808757, -13.604408758771344, -18.03058896289773, -122.55418887250141, -118.06064693423039, -50.188600885101074, -164.37399679049255, -116.73306837859607, -11.101290426977812, -250.6521644150791, 33.99530841282034, -213.94615955118334, -7.113224257523563, -183.05671729942017, -7.195667733715062, -34.72761456551512, 71.65793097182275, 193.4572224192271, 19.296388615045743, 184.82630904401228, 130.12507637300385, -41.86536165959257, 18.10497839704545, 200.4475057530017, 143.28823636307666, 230.4891472636751, 156.77569321479123, 190.20445513678447, 135.9204224701656, -23.305924525329967, 121.42989877041765, -159.93230464665314, -0.09646997128396817, -191.34081693254703, -67.04858538283591, -9.778678117393746, -13.041429254003154, -57.85338728264165, -51.170364457450056, -82.44566324769562, -261.29674676735914, 59.913814618560934, -190.40835616333192, -6.907495627389483, -102.09682545824279, -134.4401598554036, -338.8844101460644, -82.88512862373355, 144.9968982622285, -43.30925296506647, 155.83652795168481, 199.48922471404967, 149.42794241143835, 234.89929179144127, 202.04859598885298, 133.1303386280953, 149.21804350252054, 114.89897384483672, 140.20688061902615, 159.30790340990666, 140.39408025012995, 174.80465360801009, 0.9382205690124934, -108.63139404265132, -7.6098933295849465, -54.639585483839895, -75.09427838731096, -73.56584891099388, -130.20942219684915, -9.070545853589131, -106.7289625204058, -155.03450208617912, -66.60525552905675, -73.02104000404758], "policy_AGENT-0_reward": [-217.21516429753146, 92.58265521413534, 96.69060819172425, 82.29704380493177, -137.6195437345968, 228.0714651288172, -169.55257076489477, -113.23750305944895, -63.86147987365706, -214.73891156604927, 170.04130785780055, -171.9186096951226, 117.96469516455983, 43.89921273372614, -159.14764466127477, 218.4843759157066, 79.8636155085893, 45.74818328875958, 51.73278981214622, 47.2585346796909, 47.035203563887634, 128.51000185637326, 49.08696803337735, -113.77384910893377, 42.21443851983786, -100.71347549519287, -67.91287642626506, -93.20089848151949, -132.06071725455655, -71.33473518212828, -93.3723111765083, -126.2784472561456, -143.02761567358942, -159.82615996043018, -392.67708624075794, -239.5470048334608, 49.92698157332068, -201.10449620465343, 13.061183998408616, -178.15904707440438, 39.59132439191886, 67.11898102933343, 84.45824977921535, 203.85854411671346, -59.27783445318248, 142.09410388348664, 26.737852406377563, 24.454528186279518, 43.54650559469245, 156.9750681587719, 130.4073222311539, 182.4059488858133, 122.9434644346151, 145.8422246620542, 158.45590913869052, -70.24367558194685, 161.49575310623212, -208.26622287388238, -62.89070995843349, -68.62734054937197, -135.79113283413216, -130.40467076130753, -149.42584381623305, -127.1967766313326, -114.57013780216701, -122.90764415042332, -275.4225482213945, 99.62614896345441, -156.82907855449906, 65.03028018240275, -8.306285981250191, -102.51248580251415, -393.5451622585504, 10.939682283741114, 134.69502875819265, -5.385945132234021, 196.22992638843846, 155.6434813855186, 150.49625720018196, 254.16776528454142, 30.28685983481101, 50.2253816876576, 108.25384874167986, 64.56655973172319, 97.24732538936645, 118.08166412429262, 141.39654137720274, 131.57077618080547, -21.337328834663982, -204.50088536214605, -106.85394135402274, -169.97746569285118, -52.641267349428574, -121.91584605364768, -103.95839356488796, -195.24955374785017, -83.67468279898202, -128.70162993908602, -90.81622941208659, -80.40930016696382]}, "sampler_perf": {"mean_env_wait_ms": 87.60378701883349, "mean_raw_obs_processing_ms": 3.5432694733778827, "mean_inference_ms": 3.669178174130824, "mean_action_processing_ms": 0.21039587092227113}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 33600, "timers": {"sample_time_ms": 150509.233, "sample_throughput": 27.905, "load_time_ms": 135.877, "load_throughput": 30910.373, "learn_time_ms": 21042.1, "learn_throughput": 199.6, "update_time_ms": 10.505}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 9.436366081237793, "policy_loss": -0.040939878672361374, "vf_loss": 9.474981307983398, "vf_explained_var": 0.9474455118179321, "kl": 0.011629389598965645, "entropy": 1.3104299306869507, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 9.155655860900879, "policy_loss": -0.041255950927734375, "vf_loss": 9.194412231445312, "vf_explained_var": 0.9484450221061707, "kl": 0.012500281445682049, "entropy": 1.3134771585464478, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 10.087092399597168, "policy_loss": -0.0405152253806591, "vf_loss": 10.124970436096191, "vf_explained_var": 0.9400734305381775, "kl": 0.013185255229473114, "entropy": 1.30286705493927, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 7.947651386260986, "policy_loss": -0.04448368772864342, "vf_loss": 7.989390850067139, "vf_explained_var": 0.9572595357894897, "kl": 0.013721536844968796, "entropy": 1.2854766845703125, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 33600, "num_steps_trained": 33600}, "done": false, "episodes_total": 288, "training_iteration": 8, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_14-42-41", "timestamp": 1624200161, "time_this_iter_s": 221.34646821022034, "time_total_s": 1376.8002004623413, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f041b290>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f041ba70>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0468e60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c80e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8320>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0468e60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c80e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8320>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0468e60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c80e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8320>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0468e60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c80e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8320>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f041b200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1376.8002004623413, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 55.06158730158731, "ram_util_percent": 87.89174603174601}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1428.0462692856433, "episode_reward_min": -1560.5739153913514, "episode_reward_mean": -5.8516399898068405, "episode_len_mean": 119.16, "episodes_this_iter": 36, "policy_reward_min": {"AGENT-2": -394.11800177520684, "AGENT-1": -434.02634121152903, "AGENT-3": -350.7446779754646, "AGENT-0": -393.5451622585504}, "policy_reward_max": {"AGENT-2": 385.4728988617497, "AGENT-1": 365.2118081278428, "AGENT-3": 353.0692911027645, "AGENT-0": 324.29227119328687}, "policy_reward_mean": {"AGENT-2": 5.62852492071957, "AGENT-1": -3.522984741209059, "AGENT-3": 10.932952950684992, "AGENT-0": -18.890133120002364}, "custom_metrics": {"mean_ego_speed_mean": 41.3140175, "mean_ego_speed_min": 26.223, "mean_ego_speed_max": 48.5955, "distance_travelled_mean": 105.96330250000001, "distance_travelled_min": 29.771749999999997, "distance_travelled_max": 124.93475}, "hist_stats": {"episode_reward": [-1161.8383767726918, 746.6784139616879, -267.34381411787365, 359.2892453774561, -835.3246647218833, 1428.0462692856433, -1277.7970177672146, 1005.22242336586, -914.7366456123289, 1074.501050710414, -785.983231306555, 705.734380330011, 671.7898971425441, 622.2910124644744, 799.928544096535, -337.54681683515037, 62.79137033554471, 497.3260923669902, 836.9524759502638, 674.8846176084277, -250.09257976004497, 650.4442654753251, 837.9319836934383, 473.75457587310785, -305.85431186511585, -574.5658195366179, -202.5313095137022, -802.6758528285014, -411.0599587730584, -519.7025398010632, -274.0882249909178, -267.1234458100357, -386.44222479276385, -574.5589347803101, -430.19447390718017, -669.1490520788152, -209.0188857661921, -1560.5739153913514, -142.36420858294292, 595.6196643682503, -50.400720908333994, 742.8477846802481, 712.089023865936, 553.2909654183417, 786.0468531191063, 422.2607676772697, 388.35372027539455, 484.164261391708, 409.8355872150108, 311.9715951106352, 554.4775572805006, 563.7407419194003, 582.8051296744388, -40.76830851123643, -587.5838508836346, -228.98575822995895, -406.91297297232074, -277.5194052300711, -348.32172453787643, -489.97842968956104, -360.91419694978345, -377.0500920233797, -438.7453818541608, -336.6296812234231, -314.40721253753316, -871.1129050060883, 409.1521486908016, 6.659867688314755, 392.1576478513093, -547.6069400118978, 713.8364555170182, -439.2603912381985, -576.3151605581668, 5.453648248926648, -985.8542055749567, 492.1130445102013, -365.6929618171426, 485.3899390440942, 461.0551960816535, -391.5802809438795, 828.6542899996059, 487.819204355398, 126.67660734903075, 398.6580319436092, 442.3695427063436, 212.0663577653466, 602.5741217117655, 376.75057133702427, -359.0536807635164, 206.48913290238715, -228.7550092044037, -24.781896582013673, -213.61103341771252, -251.0339734392277, -387.5856123662128, -446.01279326448446, -380.84571436928996, -625.0745595101503, -501.32465946557653, -773.8242583209759], "episode_lengths": [114, 144, 32, 142, 115, 174, 134, 145, 122, 165, 118, 112, 119, 121, 118, 118, 58, 119, 115, 119, 29, 99, 116, 118, 122, 130, 77, 127, 118, 119, 119, 114, 127, 129, 123, 106, 134, 129, 124, 132, 126, 140, 114, 111, 116, 121, 108, 121, 112, 117, 119, 105, 120, 118, 158, 121, 116, 115, 119, 115, 124, 118, 115, 120, 125, 120, 132, 124, 126, 122, 131, 94, 115, 164, 126, 134, 124, 107, 122, 130, 118, 117, 119, 127, 122, 111, 122, 101, 110, 139, 128, 117, 74, 121, 74, 119, 125, 124, 122, 165], "policy_AGENT-2_reward": [-295.0518983826631, 200.23795117203423, -39.13710074349575, 107.42355893121622, -215.72833404546418, 385.4728988617497, -350.62006633273336, 254.60340810383414, -223.7601724769371, 274.32868885946607, -199.35512898105603, 196.4405680227363, 190.16313712209606, 171.1648527876589, 211.9466173489512, -35.644540933820345, -5.289640443155626, 106.95437336776922, 196.7128611518059, 156.52253386607916, -34.60378179616913, 162.17169387428183, 197.7636842509531, 127.6810055613363, -76.81335370211492, -133.2330609698495, -15.206237133749418, -210.39380650249802, -112.29266865362428, -120.7868694944388, -10.697612419033971, -34.0855882305688, -8.238713017523821, -128.5086751174595, -94.65346521472671, -211.6771147187049, 13.667704369965819, -394.11800177520684, -82.93081154204472, 139.67809803221382, -43.277021834586165, 216.8929252846294, 201.4431526362443, 102.81319967479703, 229.08714021529377, 159.67976534160974, 49.66424475505518, 112.93896485526417, 114.96508192696999, 36.9120369148576, 159.15190797526557, 140.52947844045903, 138.00020911913097, 1.0034544678698438, -108.4953866390417, -7.468933318768156, -128.21629746919146, -74.72579875067629, -79.71645312042631, -130.07441521421586, -9.096046786205513, -102.20194521612324, -121.12777270949043, -66.64075492281651, -73.04360871209344, -223.69108762700012, 88.53590682670136, -80.16630867451502, 94.90198243006395, -159.0416381047286, 142.14150686962083, -97.29463254031948, -113.78924531322136, -31.429473616642273, -262.91680776555785, 106.64647636418763, -35.57917418838558, 101.92683825274516, 43.3509438137811, -34.29681137962979, 195.65657118704652, 122.73836507606798, 28.25357824740089, 51.176315030717895, 46.70574487995938, 35.07917601597512, 171.45324748534483, 150.70373132758962, -66.01507354630724, 55.533886386955245, -8.021373618212992, 60.08014729137752, -13.540358056553437, -18.05774142897822, -122.40897385323518, -115.9325193273817, -50.1949526536638, -153.48541381227693, -114.13535070670943, -11.139109171179848], "policy_AGENT-1_reward": [-271.57097880664503, 229.14718305173415, -94.48702705943035, 107.8953526160821, -215.30792844001436, 365.2118081278428, -301.636650850155, 282.7150579738261, -215.87153253889628, 296.2378088466003, -194.12687945038053, 195.69340065628933, 146.37732008164383, 170.01535776411424, 211.9937087669259, -110.93623029304733, 36.678243396924216, 107.39805832891737, 220.89194786821565, 181.81323211414423, -90.32312102330204, 163.12050440137963, 220.88908756708358, 128.11949664557486, -83.6021569172713, -134.8552510396003, -86.05727372221062, -210.01613863421574, -91.7694110306531, -150.50471657105686, -105.36361677875617, -86.66409807699733, -163.370889481055, -136.25331519373793, -96.00633052593962, -211.20592934142599, 14.266055521759952, -434.02634121152903, 12.512049299093967, 176.24963931561524, 41.57149902355282, 173.88840505549513, 155.51316513012307, 150.5535661319243, 67.8926558278298, 30.245546511995975, 155.33375520458642, 113.7534042922431, 115.40497171148043, 37.605352187384966, 117.93608177103535, 141.42064185160882, 138.42949076649234, -21.37265471345485, -165.9561848397949, -107.05299022758322, -54.07962432643802, -75.05806074265534, -73.12357645280868, -125.73619871360788, -147.4980505621389, -84.44450148786846, -33.88147711940575, -112.5674413594635, -87.93326365442819, -217.29818252557706, 136.88470919341228, 70.2497984919079, 124.62461311772896, -91.95548784248173, 201.60842326426592, -96.83217301746255, -173.0290690869069, 107.64752394063952, -240.5728739669967, 142.05727297387796, -122.736023641269, 118.01546149373412, 192.7184186242168, -163.60748291696265, 218.4265576143822, 123.19151163665211, 24.543623185791628, 153.5244986623363, 179.02347325252177, 46.91799245487087, 129.20324673331731, 49.11154556238309, -113.82874871522208, 49.48866166798718, -112.03963516515688, -67.75671182800188, -93.26536812086826, -82.88492579279536, -71.28771445834772, -118.64731582636367, -154.1837135743795, -164.1875332337915, -110.63008041984085, -358.90677248206003], "policy_AGENT-3_reward": [-301.35687872537, 127.55340187349655, -39.261136178044644, 89.24737736233524, -217.3118387237675, 353.0692911027645, -350.7446779754646, 225.25229805452707, -213.71589142562397, 263.4582864897196, -198.25665999536486, 167.10470297530722, 190.00875999039448, 153.29352313532308, 212.74780897991326, -35.53665545039043, -5.284981975484186, 161.4279725970887, 198.48084285639703, 156.38901229629496, -34.71734301158038, 162.04233499069954, 198.47389787013844, 129.97349447436866, -83.5368544117613, -125.35602462724466, -15.191064854988062, -196.68070454416463, -115.364379091124, -120.75445626780855, -10.602211989820075, -59.727935349735915, -8.280417887995023, -127.35233673898168, -94.7808803533865, -162.4846571455236, -134.4401598554036, -338.8844101460644, -82.88512862373355, 144.9968982622285, -43.30925296506647, 155.83652795168481, 199.48922471404967, 149.42794241143835, 234.89929179144127, 202.04859598885298, 133.1303386280953, 149.21804350252054, 114.89897384483672, 140.20688061902615, 159.30790340990666, 140.39408025012995, 174.80465360801009, 0.9382205690124934, -108.63139404265132, -7.6098933295849465, -54.639585483839895, -75.09427838731096, -73.56584891099388, -130.20942219684915, -9.070545853589131, -106.7289625204058, -155.03450208617912, -66.60525552905675, -73.02104000404758, -212.90847055597987, 91.1488774565525, -80.11423032080253, 90.33400849858484, -158.99027033009145, 142.0150602543141, -75.58101491552145, -176.25934309859034, -6.902922201413671, -267.62561227635314, 73.36798731433511, -35.45915429236525, 147.48294413305516, 181.08662090992945, -34.52834198601197, 196.08678528247103, 162.02571213408865, 28.131222627078735, 142.22442843840903, 169.3817898941713, 83.03398573061301, 173.40762563673022, 127.84832641367436, -65.43600939305318, 59.25214632760683, -7.980524925840904, 50.8075443808757, -13.604408758771344, -18.03058896289773, -122.55418887250141, -118.06064693423039, -50.188600885101074, -164.37399679049255, -116.73306837859607, -11.101290426977812], "policy_AGENT-0_reward": [-293.85862085801244, 189.7398778644229, -94.45855013690286, 54.72295646782224, -186.97656351263748, 324.29227119328687, -274.7956226088615, 242.65165923367206, -261.38904917087206, 240.47626651462764, -194.2445628797542, 146.49570867567797, 145.24067994840976, 127.81727877737829, 163.2404090007439, -155.4293901578926, 36.687749357260245, 121.5456880732153, 220.86682407384444, 180.1598393319098, -90.44833392899343, 163.10973220896454, 220.80531400526314, 87.98057919182767, -61.90194683396833, -181.1214828999235, -86.07673380275406, -185.58520314762302, -91.63349999765666, -127.65649746775827, -147.42478380330766, -86.64582415273364, -206.55220440619024, -182.44460773013085, -144.75379781312765, -83.78135087316116, -102.51248580251415, -393.5451622585504, 10.939682283741114, 134.69502875819265, -5.385945132234021, 196.22992638843846, 155.6434813855186, 150.49625720018196, 254.16776528454142, 30.28685983481101, 50.2253816876576, 108.25384874167986, 64.56655973172319, 97.24732538936645, 118.08166412429262, 141.39654137720274, 131.57077618080547, -21.337328834663982, -204.50088536214605, -106.85394135402274, -169.97746569285118, -52.641267349428574, -121.91584605364768, -103.95839356488796, -195.24955374785017, -83.67468279898202, -128.70162993908602, -90.81622941208659, -80.40930016696382, -217.21516429753146, 92.58265521413534, 96.69060819172425, 82.29704380493177, -137.6195437345968, 228.0714651288172, -169.55257076489477, -113.23750305944895, -63.86147987365706, -214.73891156604927, 170.04130785780055, -171.9186096951226, 117.96469516455983, 43.89921273372614, -159.14764466127477, 218.4843759157066, 79.8636155085893, 45.74818328875958, 51.73278981214622, 47.2585346796909, 47.035203563887634, 128.51000185637326, 49.08696803337735, -113.77384910893377, 42.21443851983786, -100.71347549519287, -67.91287642626506, -93.20089848151949, -132.06071725455655, -71.33473518212828, -93.3723111765083, -126.2784472561456, -143.02761567358942, -159.82615996043018, -392.67708624075794]}, "sampler_perf": {"mean_env_wait_ms": 88.87840876849238, "mean_raw_obs_processing_ms": 3.58380612359442, "mean_inference_ms": 3.7030144001258862, "mean_action_processing_ms": 0.2125767946353473}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 37800, "timers": {"sample_time_ms": 145942.999, "sample_throughput": 28.778, "load_time_ms": 122.567, "load_throughput": 34267.086, "learn_time_ms": 20441.304, "learn_throughput": 205.466, "update_time_ms": 10.209}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 9.920954704284668, "policy_loss": -0.03988596424460411, "vf_loss": 9.958247184753418, "vf_explained_var": 0.9591984748840332, "kl": 0.01297328807413578, "entropy": 1.2963844537734985, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 9.510068893432617, "policy_loss": -0.04153669625520706, "vf_loss": 9.548995971679688, "vf_explained_var": 0.9605335593223572, "kl": 0.013055096380412579, "entropy": 1.2948634624481201, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 8.732288360595703, "policy_loss": -0.04608270898461342, "vf_loss": 8.775459289550781, "vf_explained_var": 0.9622124433517456, "kl": 0.014559907838702202, "entropy": 1.2782710790634155, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 6.372313022613525, "policy_loss": -0.04801251366734505, "vf_loss": 6.417388439178467, "vf_explained_var": 0.9752773642539978, "kl": 0.014682109467685223, "entropy": 1.2569652795791626, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 37800, "num_steps_trained": 37800}, "done": false, "episodes_total": 324, "training_iteration": 9, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_14-44-47", "timestamp": 1624200287, "time_this_iter_s": 125.0900719165802, "time_total_s": 1501.8902723789215, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f0366b90>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f0366ef0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0366cb0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd601a3e8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd601a3ed40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031acb0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0366cb0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd601a3e8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd601a3ed40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031acb0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0366cb0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd601a3e8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd601a3ed40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031acb0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0366cb0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd601a3e8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd601a3ed40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031acb0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f03d94d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1501.8902723789215, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 56.820111731843575, "ram_util_percent": 87.70558659217879}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1465.233948962873, "episode_reward_min": -1277.7970177672146, "episode_reward_mean": 43.02492867646431, "episode_len_mean": 119.09, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-2": -350.62006633273336, "AGENT-3": -350.7446779754646, "AGENT-0": -392.67708624075794, "AGENT-1": -358.90677248206003}, "policy_reward_max": {"AGENT-2": 385.4728988617497, "AGENT-3": 376.8265005702436, "AGENT-0": 382.02711042778594, "AGENT-1": 365.2118081278428}, "policy_reward_mean": {"AGENT-2": 14.01199510503547, "AGENT-3": 19.557540781205923, "AGENT-0": -5.361235567069559, "AGENT-1": 14.816628357292462}, "custom_metrics": {"mean_ego_speed_mean": 41.61878750000001, "mean_ego_speed_min": 23.61825, "mean_ego_speed_max": 48.5955, "distance_travelled_mean": 103.77302749999998, "distance_travelled_min": 26.8455, "distance_travelled_max": 124.898}, "hist_stats": {"episode_reward": [666.0705660597023, -48.61082403465858, 531.7199984329687, -20.459359169741774, 585.7336629398476, -227.01432514284448, 646.409791216527, -1074.4417825420069, 897.1587925177204, -866.7171757761732, 850.9679366910875, 594.0540245490901, 1109.3025106606447, 700.5004352189112, 533.7238624696507, 1251.951693215708, 686.6653535031419, 1465.233948962873, 584.9138695530587, 820.5636437897131, 738.8894412474431, 334.31181218396796, -355.90047562181087, -823.7525927293007, -156.01741018853713, -479.43804048373744, -314.3742744223437, -416.8637911387664, -325.25389871076754, -524.091980671669, -328.68077051776464, -371.7618227139131, -419.31340022875224, -155.25787104262844, -162.1495000155866, -439.2603912381985, -576.3151605581668, 5.453648248926648, -985.8542055749567, 492.1130445102013, -365.6929618171426, 485.3899390440942, 461.0551960816535, -391.5802809438795, 828.6542899996059, 487.819204355398, 126.67660734903075, 398.6580319436092, 442.3695427063436, 212.0663577653466, 602.5741217117655, 376.75057133702427, -359.0536807635164, 206.48913290238715, -228.7550092044037, -24.781896582013673, -213.61103341771252, -251.0339734392277, -387.5856123662128, -446.01279326448446, -380.84571436928996, -625.0745595101503, -501.32465946557653, -773.8242583209759, -1161.8383767726918, 746.6784139616879, -267.34381411787365, 359.2892453774561, -835.3246647218833, 1428.0462692856433, -1277.7970177672146, 1005.22242336586, -914.7366456123289, 1074.501050710414, -785.983231306555, 705.734380330011, 671.7898971425441, 622.2910124644744, 799.928544096535, -337.54681683515037, 62.79137033554471, 497.3260923669902, 836.9524759502638, 674.8846176084277, -250.09257976004497, 650.4442654753251, 837.9319836934383, 473.75457587310785, -305.85431186511585, -574.5658195366179, -202.5313095137022, -802.6758528285014, -411.0599587730584, -519.7025398010632, -274.0882249909178, -267.1234458100357, -386.44222479276385, -574.5589347803101, -430.19447390718017, -669.1490520788152], "episode_lengths": [148, 131, 141, 122, 148, 53, 153, 124, 192, 117, 125, 115, 124, 112, 130, 133, 122, 146, 116, 120, 115, 117, 107, 174, 30, 125, 119, 121, 141, 124, 124, 120, 119, 32, 121, 94, 115, 164, 126, 134, 124, 107, 122, 130, 118, 117, 119, 127, 122, 111, 122, 101, 110, 139, 128, 117, 74, 121, 74, 119, 125, 124, 122, 165, 114, 144, 32, 142, 115, 174, 134, 145, 122, 165, 118, 112, 119, 121, 118, 118, 58, 119, 115, 119, 29, 99, 116, 118, 122, 130, 77, 127, 118, 119, 119, 114, 127, 129, 123, 106], "policy_AGENT-2_reward": [6.568513359553199, -63.25980112038365, 36.90651654501028, -29.89750867167029, -8.038416040552539, -29.62921107686755, 20.49461488618161, -264.22747194540386, 230.77853381979926, -226.4685433078942, 219.59205542143062, 161.721888149604, 270.50644213218015, 130.86288773573176, 50.02641761464074, 304.622508313333, 184.66719852058114, 359.3670164049071, 155.6834831976163, 214.73695630217236, 188.24044145570647, 67.51775837755024, -128.0499669678113, -146.79093602901932, -9.930508817072795, -30.050666243395717, -59.642281431531664, -51.532071976435766, -71.39404018645394, -122.63358955096069, -71.8846130287283, -79.38841516034456, -94.41414026714345, -9.263576985228607, -9.47597727862768, -97.29463254031948, -113.78924531322136, -31.429473616642273, -262.91680776555785, 106.64647636418763, -35.57917418838558, 101.92683825274516, 43.3509438137811, -34.29681137962979, 195.65657118704652, 122.73836507606798, 28.25357824740089, 51.176315030717895, 46.70574487995938, 35.07917601597512, 171.45324748534483, 150.70373132758962, -66.01507354630724, 55.533886386955245, -8.021373618212992, 60.08014729137752, -13.540358056553437, -18.05774142897822, -122.40897385323518, -115.9325193273817, -50.1949526536638, -153.48541381227693, -114.13535070670943, -11.139109171179848, -295.0518983826631, 200.23795117203423, -39.13710074349575, 107.42355893121622, -215.72833404546418, 385.4728988617497, -350.62006633273336, 254.60340810383414, -223.7601724769371, 274.32868885946607, -199.35512898105603, 196.4405680227363, 190.16313712209606, 171.1648527876589, 211.9466173489512, -35.644540933820345, -5.289640443155626, 106.95437336776922, 196.7128611518059, 156.52253386607916, -34.60378179616913, 162.17169387428183, 197.7636842509531, 127.6810055613363, -76.81335370211492, -133.2330609698495, -15.206237133749418, -210.39380650249802, -112.29266865362428, -120.7868694944388, -10.697612419033971, -34.0855882305688, -8.238713017523821, -128.5086751174595, -94.65346521472671, -211.6771147187049], "policy_AGENT-3_reward": [6.572510548843953, -63.464085717882185, 36.915918754992994, -29.911293693050947, -8.00187625576749, -29.65756735490075, 20.5458716533902, -249.01899917341825, 250.977175592388, -214.54383944746388, 228.24807812774947, 161.58379659935684, 277.08564911019835, 222.75431393881863, 210.10279195674644, 339.315052890955, 177.37093252710378, 376.8265005702436, 159.20142252737014, 217.43976660449906, 149.36632319416847, 94.44876018193588, -105.96126268096411, -161.29634125131028, -9.875320628371723, -30.133875117915874, -59.82649594403249, -138.86252363978286, -72.50055066887975, -119.67768291022142, -71.55534266727707, -79.36557587937885, -92.57044699663366, -9.257574914336415, -9.462556166043898, -75.58101491552145, -176.25934309859034, -6.902922201413671, -267.62561227635314, 73.36798731433511, -35.45915429236525, 147.48294413305516, 181.08662090992945, -34.52834198601197, 196.08678528247103, 162.02571213408865, 28.131222627078735, 142.22442843840903, 169.3817898941713, 83.03398573061301, 173.40762563673022, 127.84832641367436, -65.43600939305318, 59.25214632760683, -7.980524925840904, 50.8075443808757, -13.604408758771344, -18.03058896289773, -122.55418887250141, -118.06064693423039, -50.188600885101074, -164.37399679049255, -116.73306837859607, -11.101290426977812, -301.35687872537, 127.55340187349655, -39.261136178044644, 89.24737736233524, -217.3118387237675, 353.0692911027645, -350.7446779754646, 225.25229805452707, -213.71589142562397, 263.4582864897196, -198.25665999536486, 167.10470297530722, 190.00875999039448, 153.29352313532308, 212.74780897991326, -35.53665545039043, -5.284981975484186, 161.4279725970887, 198.48084285639703, 156.38901229629496, -34.71734301158038, 162.04233499069954, 198.47389787013844, 129.97349447436866, -83.5368544117613, -125.35602462724466, -15.191064854988062, -196.68070454416463, -115.364379091124, -120.75445626780855, -10.602211989820075, -59.727935349735915, -8.280417887995023, -127.35233673898168, -94.7808803533865, -162.4846571455236], "policy_AGENT-0_reward": [341.3950719409132, 16.28064697489711, 209.44497151561666, -2.5953800507532065, 281.4744273232307, -83.88474186296469, 283.2055375241039, -302.21838718081824, 184.1981086438222, -201.3629293275711, 177.588124010096, 111.86445728521278, 295.3870311479998, 173.50590718318585, 50.57178386423093, 317.4115902608347, 140.76483956791034, 382.02711042778594, 112.61763628078442, 169.77091980372447, 212.4592694798774, 68.07297172682732, -60.93244182949976, -274.2225110067427, -68.18491296634691, -194.84674658492384, -97.07983209570413, -175.37298000267276, -93.34297819376559, -165.2947756970924, -117.22462051340615, -130.74943890174637, -140.74658123658025, -68.41982748187641, -71.54351952959087, -169.55257076489477, -113.23750305944895, -63.86147987365706, -214.73891156604927, 170.04130785780055, -171.9186096951226, 117.96469516455983, 43.89921273372614, -159.14764466127477, 218.4843759157066, 79.8636155085893, 45.74818328875958, 51.73278981214622, 47.2585346796909, 47.035203563887634, 128.51000185637326, 49.08696803337735, -113.77384910893377, 42.21443851983786, -100.71347549519287, -67.91287642626506, -93.20089848151949, -132.06071725455655, -71.33473518212828, -93.3723111765083, -126.2784472561456, -143.02761567358942, -159.82615996043018, -392.67708624075794, -293.85862085801244, 189.7398778644229, -94.45855013690286, 54.72295646782224, -186.97656351263748, 324.29227119328687, -274.7956226088615, 242.65165923367206, -261.38904917087206, 240.47626651462764, -194.2445628797542, 146.49570867567797, 145.24067994840976, 127.81727877737829, 163.2404090007439, -155.4293901578926, 36.687749357260245, 121.5456880732153, 220.86682407384444, 180.1598393319098, -90.44833392899343, 163.10973220896454, 220.80531400526314, 87.98057919182767, -61.90194683396833, -181.1214828999235, -86.07673380275406, -185.58520314762302, -91.63349999765666, -127.65649746775827, -147.42478380330766, -86.64582415273364, -206.55220440619024, -182.44460773013085, -144.75379781312765, -83.78135087316116], "policy_AGENT-1_reward": [311.5344702103915, 61.83241582871018, 248.45259161734865, 41.94482324573263, 320.2995279129366, -83.84280484811143, 322.16376715285134, -258.9769242423671, 231.20497446170975, -224.34186369324476, 225.53967913181165, 158.88388251491625, 266.323388270267, 173.37732636117462, 223.02286903403254, 290.6025417505863, 183.8623828875466, 347.01332155993697, 157.41132754728858, 218.61600107931793, 188.82340711769066, 104.2723218976548, -60.95680414353602, -241.44280444222804, -68.02666777674571, -224.40675253750237, -97.82566495107517, -51.0962155198751, -88.01632966166802, -116.48593251339462, -68.01619430835302, -82.25839277244302, -91.58223172839516, -68.31689166118703, -71.66744704132424, -96.83217301746255, -173.0290690869069, 107.64752394063952, -240.5728739669967, 142.05727297387796, -122.736023641269, 118.01546149373412, 192.7184186242168, -163.60748291696265, 218.4265576143822, 123.19151163665211, 24.543623185791628, 153.5244986623363, 179.02347325252177, 46.91799245487087, 129.20324673331731, 49.11154556238309, -113.82874871522208, 49.48866166798718, -112.03963516515688, -67.75671182800188, -93.26536812086826, -82.88492579279536, -71.28771445834772, -118.64731582636367, -154.1837135743795, -164.1875332337915, -110.63008041984085, -358.90677248206003, -271.57097880664503, 229.14718305173415, -94.48702705943035, 107.8953526160821, -215.30792844001436, 365.2118081278428, -301.636650850155, 282.7150579738261, -215.87153253889628, 296.2378088466003, -194.12687945038053, 195.69340065628933, 146.37732008164383, 170.01535776411424, 211.9937087669259, -110.93623029304733, 36.678243396924216, 107.39805832891737, 220.89194786821565, 181.81323211414423, -90.32312102330204, 163.12050440137963, 220.88908756708358, 128.11949664557486, -83.6021569172713, -134.8552510396003, -86.05727372221062, -210.01613863421574, -91.7694110306531, -150.50471657105686, -105.36361677875617, -86.66409807699733, -163.370889481055, -136.25331519373793, -96.00633052593962, -211.20592934142599]}, "sampler_perf": {"mean_env_wait_ms": 87.72605131934162, "mean_raw_obs_processing_ms": 3.542801026775042, "mean_inference_ms": 3.649511235778159, "mean_action_processing_ms": 0.20990152035474716}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 42000, "timers": {"sample_time_ms": 140083.891, "sample_throughput": 29.982, "load_time_ms": 111.768, "load_throughput": 37577.805, "learn_time_ms": 19826.123, "learn_throughput": 211.842, "update_time_ms": 9.873}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 8.25687313079834, "policy_loss": -0.04171934351325035, "vf_loss": 8.295629501342773, "vf_explained_var": 0.9707985520362854, "kl": 0.014811430126428604, "entropy": 1.2807748317718506, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 6.685146808624268, "policy_loss": -0.047073133289813995, "vf_loss": 6.728970050811768, "vf_explained_var": 0.9774888753890991, "kl": 0.01624646969139576, "entropy": 1.2826316356658936, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 6.1628642082214355, "policy_loss": -0.05312148109078407, "vf_loss": 6.2125654220581055, "vf_explained_var": 0.972529411315918, "kl": 0.017101852223277092, "entropy": 1.2605760097503662, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 3.1347439289093018, "policy_loss": -0.06207196041941643, "vf_loss": 3.1932432651519775, "vf_explained_var": 0.9880854487419128, "kl": 0.01786523498594761, "entropy": 1.2390450239181519, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 42000, "num_steps_trained": 42000}, "done": false, "episodes_total": 359, "training_iteration": 10, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_14-46-29", "timestamp": 1624200389, "time_this_iter_s": 101.68288230895996, "time_total_s": 1603.5731546878815, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f02c8c20>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f02c8b00>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c88c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c87a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8440>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c88c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c87a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8440>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c88c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c87a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8440>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c88c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c87a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8440>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f03d9170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1603.5731546878815, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 54.20342465753424, "ram_util_percent": 87.71438356164384}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1465.233948962873, "episode_reward_min": -1277.7970177672146, "episode_reward_mean": 96.49847188636453, "episode_len_mean": 120.74, "episodes_this_iter": 34, "policy_reward_min": {"AGENT-2": -350.62006633273336, "AGENT-3": -350.7446779754646, "AGENT-0": -302.21838718081824, "AGENT-1": -301.636650850155}, "policy_reward_max": {"AGENT-2": 385.4728988617497, "AGENT-3": 376.8265005702436, "AGENT-0": 476.7683570233988, "AGENT-1": 445.60497352035213}, "policy_reward_mean": {"AGENT-2": 16.74228286437002, "AGENT-3": 23.944397106992298, "AGENT-0": 20.364545967472395, "AGENT-1": 35.447245947529815}, "custom_metrics": {"mean_ego_speed_mean": 42.141537500000005, "mean_ego_speed_min": 23.61825, "mean_ego_speed_max": 49.92175, "distance_travelled_mean": 106.80212250000002, "distance_travelled_min": 26.8455, "distance_travelled_max": 124.898}, "hist_stats": {"episode_reward": [930.165195157274, -732.3268555687226, 992.8203046327393, -575.6823826548792, 642.0348299049613, -976.0814245604699, 833.4220487809632, -1083.700780593852, 571.7202115538435, -698.0907161821003, 466.6819182021982, 740.1950613855604, 394.79154992806696, 788.2902872901558, 572.0428232336031, 833.3715884616693, 450.37442751761733, 830.6504281099521, 528.6917853828597, 64.54245813380754, 432.64901778649596, 836.6544893775823, 624.3803758612097, -579.0342376078115, -140.3342440673577, -457.39747061673563, -761.5381993250649, -486.96543267547975, -670.8966219708296, -453.51564018482344, -497.6539176243051, -212.02121196570744, -479.4299447284463, -364.53109853777954, 1428.0462692856433, -1277.7970177672146, 1005.22242336586, -914.7366456123289, 1074.501050710414, -785.983231306555, 705.734380330011, 671.7898971425441, 622.2910124644744, 799.928544096535, -337.54681683515037, 62.79137033554471, 497.3260923669902, 836.9524759502638, 674.8846176084277, -250.09257976004497, 650.4442654753251, 837.9319836934383, 473.75457587310785, -305.85431186511585, -574.5658195366179, -202.5313095137022, -802.6758528285014, -411.0599587730584, -519.7025398010632, -274.0882249909178, -267.1234458100357, -386.44222479276385, -574.5589347803101, -430.19447390718017, -669.1490520788152, 666.0705660597023, -48.61082403465858, 531.7199984329687, -20.459359169741774, 585.7336629398476, -227.01432514284448, 646.409791216527, -1074.4417825420069, 897.1587925177204, -866.7171757761732, 850.9679366910875, 594.0540245490901, 1109.3025106606447, 700.5004352189112, 533.7238624696507, 1251.951693215708, 686.6653535031419, 1465.233948962873, 584.9138695530587, 820.5636437897131, 738.8894412474431, 334.31181218396796, -355.90047562181087, -823.7525927293007, -156.01741018853713, -479.43804048373744, -314.3742744223437, -416.8637911387664, -325.25389871076754, -524.091980671669, -328.68077051776464, -371.7618227139131, -419.31340022875224, -155.25787104262844, -162.1495000155866], "episode_lengths": [161, 126, 160, 108, 135, 120, 158, 124, 154, 78, 139, 118, 129, 126, 125, 119, 99, 124, 115, 73, 121, 117, 118, 120, 121, 130, 130, 136, 105, 120, 121, 130, 126, 97, 174, 134, 145, 122, 165, 118, 112, 119, 121, 118, 118, 58, 119, 115, 119, 29, 99, 116, 118, 122, 130, 77, 127, 118, 119, 119, 114, 127, 129, 123, 106, 148, 131, 141, 122, 148, 53, 153, 124, 192, 117, 125, 115, 124, 112, 130, 133, 122, 146, 116, 120, 115, 117, 107, 174, 30, 125, 119, 121, 141, 124, 124, 120, 119, 32, 121], "policy_AGENT-2_reward": [3.9406672151266484, -196.7436782294702, 261.0157677169142, -184.18585209849985, 152.97726412699663, -224.4284043908043, -11.295796181121746, -287.2786907815767, 1.4709983454618663, -149.46884409660478, 52.681604497244386, 174.2503379690818, 114.95595805438157, 107.77964743115531, 157.1707832939961, 227.95937477396845, 155.6728163440068, 219.22185707143626, 127.71467537923645, -3.886432547734465, 66.73402923845839, 219.41698814199825, 145.26175583238089, -132.58138825527018, -47.08377573343121, -105.51266428185565, -177.27972631233973, -9.320186542568036, -213.45914318963548, -116.36361785946724, -114.75814470703214, -47.75492837883494, -130.00503605436992, -84.97725254525157, 385.4728988617497, -350.62006633273336, 254.60340810383414, -223.7601724769371, 274.32868885946607, -199.35512898105603, 196.4405680227363, 190.16313712209606, 171.1648527876589, 211.9466173489512, -35.644540933820345, -5.289640443155626, 106.95437336776922, 196.7128611518059, 156.52253386607916, -34.60378179616913, 162.17169387428183, 197.7636842509531, 127.6810055613363, -76.81335370211492, -133.2330609698495, -15.206237133749418, -210.39380650249802, -112.29266865362428, -120.7868694944388, -10.697612419033971, -34.0855882305688, -8.238713017523821, -128.5086751174595, -94.65346521472671, -211.6771147187049, 6.568513359553199, -63.25980112038365, 36.90651654501028, -29.89750867167029, -8.038416040552539, -29.62921107686755, 20.49461488618161, -264.22747194540386, 230.77853381979926, -226.4685433078942, 219.59205542143062, 161.721888149604, 270.50644213218015, 130.86288773573176, 50.02641761464074, 304.622508313333, 184.66719852058114, 359.3670164049071, 155.6834831976163, 214.73695630217236, 188.24044145570647, 67.51775837755024, -128.0499669678113, -146.79093602901932, -9.930508817072795, -30.050666243395717, -59.642281431531664, -51.532071976435766, -71.39404018645394, -122.63358955096069, -71.8846130287283, -79.38841516034456, -94.41414026714345, -9.263576985228607, -9.47597727862768], "policy_AGENT-3_reward": [3.8511973983958354, -196.69408065499104, 246.11462724972043, -182.95154886964085, 137.44285679882066, -265.0092488566186, -11.255105765904654, -277.21786075518486, 1.4762672810170387, -149.41699273240738, 52.60385215918655, 181.82720652284343, 152.90555958727617, 305.0516689206683, 157.04340320539055, 232.96640328457707, 131.714224006084, 220.2276234267607, 156.56900404056213, -3.8754478900638247, 169.64215452955548, 219.28997514714658, 141.5510481157907, -135.47005155583926, -47.04271618896597, -77.28336837576346, -182.54175769477231, -9.374867181598253, -118.46496971954129, -119.34527762428301, -114.13245585727259, -6.25298544626818, -121.48869997628556, -85.18567221678782, 353.0692911027645, -350.7446779754646, 225.25229805452707, -213.71589142562397, 263.4582864897196, -198.25665999536486, 167.10470297530722, 190.00875999039448, 153.29352313532308, 212.74780897991326, -35.53665545039043, -5.284981975484186, 161.4279725970887, 198.48084285639703, 156.38901229629496, -34.71734301158038, 162.04233499069954, 198.47389787013844, 129.97349447436866, -83.5368544117613, -125.35602462724466, -15.191064854988062, -196.68070454416463, -115.364379091124, -120.75445626780855, -10.602211989820075, -59.727935349735915, -8.280417887995023, -127.35233673898168, -94.7808803533865, -162.4846571455236, 6.572510548843953, -63.464085717882185, 36.915918754992994, -29.911293693050947, -8.00187625576749, -29.65756735490075, 20.5458716533902, -249.01899917341825, 250.977175592388, -214.54383944746388, 228.24807812774947, 161.58379659935684, 277.08564911019835, 222.75431393881863, 210.10279195674644, 339.315052890955, 177.37093252710378, 376.8265005702436, 159.20142252737014, 217.43976660449906, 149.36632319416847, 94.44876018193588, -105.96126268096411, -161.29634125131028, -9.875320628371723, -30.133875117915874, -59.82649594403249, -138.86252363978286, -72.50055066887975, -119.67768291022142, -71.55534266727707, -79.36557587937885, -92.57044699663366, -9.257574914336415, -9.462556166043898], "policy_AGENT-0_reward": [476.7683570233988, -170.4953416158535, 224.05449913468235, -104.28219882057184, 155.9697552851058, -264.121714781073, 443.2343784319982, -248.3627904752307, 265.1286201610188, -199.4926229657724, 160.14245075403673, 209.4281777824066, 63.497725700049564, 267.18959247791844, 108.60043629676517, 186.2896410213936, 81.48781606686566, 172.87743349292228, 116.27235443755575, 36.233593034007356, 129.1044659582321, 174.3730326169477, 167.9636786010831, -179.03815707436922, -24.154499086329192, -159.53498940206683, -221.30511810505323, -255.49067957040637, -169.50479773618025, -97.47054581141592, -158.33532571781302, -79.0310497174043, -113.9196234212222, -97.12486563875764, 324.29227119328687, -274.7956226088615, 242.65165923367206, -261.38904917087206, 240.47626651462764, -194.2445628797542, 146.49570867567797, 145.24067994840976, 127.81727877737829, 163.2404090007439, -155.4293901578926, 36.687749357260245, 121.5456880732153, 220.86682407384444, 180.1598393319098, -90.44833392899343, 163.10973220896454, 220.80531400526314, 87.98057919182767, -61.90194683396833, -181.1214828999235, -86.07673380275406, -185.58520314762302, -91.63349999765666, -127.65649746775827, -147.42478380330766, -86.64582415273364, -206.55220440619024, -182.44460773013085, -144.75379781312765, -83.78135087316116, 341.3950719409132, 16.28064697489711, 209.44497151561666, -2.5953800507532065, 281.4744273232307, -83.88474186296469, 283.2055375241039, -302.21838718081824, 184.1981086438222, -201.3629293275711, 177.588124010096, 111.86445728521278, 295.3870311479998, 173.50590718318585, 50.57178386423093, 317.4115902608347, 140.76483956791034, 382.02711042778594, 112.61763628078442, 169.77091980372447, 212.4592694798774, 68.07297172682732, -60.93244182949976, -274.2225110067427, -68.18491296634691, -194.84674658492384, -97.07983209570413, -175.37298000267276, -93.34297819376559, -165.2947756970924, -117.22462051340615, -130.74943890174637, -140.74658123658025, -68.41982748187641, -71.54351952959087], "policy_AGENT-1_reward": [445.60497352035213, -168.3937550684072, 261.6354105314222, -104.26278286616667, 195.6449536940387, -222.52205653197325, 412.7385722959917, -270.8414385818593, 303.6443257663457, -199.71225638731582, 201.25401079173048, 174.68933911122886, 63.432306586359886, 108.26937846041389, 149.22820043745142, 186.15616938172906, 81.49957110066119, 218.32351411883334, 128.1357515255051, 36.070745537598434, 67.16836806025006, 223.5744934714899, 169.60389331195537, -131.94464072233262, -22.053253058631462, -115.06644855704974, -180.41159721289955, -212.779699380907, -169.46771132547315, -120.33619888965715, -110.42799134218731, -78.98224842319998, -114.01658527656807, -97.2433081369827, 365.2118081278428, -301.636650850155, 282.7150579738261, -215.87153253889628, 296.2378088466003, -194.12687945038053, 195.69340065628933, 146.37732008164383, 170.01535776411424, 211.9937087669259, -110.93623029304733, 36.678243396924216, 107.39805832891737, 220.89194786821565, 181.81323211414423, -90.32312102330204, 163.12050440137963, 220.88908756708358, 128.11949664557486, -83.6021569172713, -134.8552510396003, -86.05727372221062, -210.01613863421574, -91.7694110306531, -150.50471657105686, -105.36361677875617, -86.66409807699733, -163.370889481055, -136.25331519373793, -96.00633052593962, -211.20592934142599, 311.5344702103915, 61.83241582871018, 248.45259161734865, 41.94482324573263, 320.2995279129366, -83.84280484811143, 322.16376715285134, -258.9769242423671, 231.20497446170975, -224.34186369324476, 225.53967913181165, 158.88388251491625, 266.323388270267, 173.37732636117462, 223.02286903403254, 290.6025417505863, 183.8623828875466, 347.01332155993697, 157.41132754728858, 218.61600107931793, 188.82340711769066, 104.2723218976548, -60.95680414353602, -241.44280444222804, -68.02666777674571, -224.40675253750237, -97.82566495107517, -51.0962155198751, -88.01632966166802, -116.48593251339462, -68.01619430835302, -82.25839277244302, -91.58223172839516, -68.31689166118703, -71.66744704132424]}, "sampler_perf": {"mean_env_wait_ms": 84.72035481005949, "mean_raw_obs_processing_ms": 3.424274489002436, "mean_inference_ms": 3.5320350753182157, "mean_action_processing_ms": 0.20379431206760582}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 46200, "timers": {"sample_time_ms": 134554.524, "sample_throughput": 31.214, "load_time_ms": 18.91, "load_throughput": 222102.714, "learn_time_ms": 19234.474, "learn_throughput": 218.358, "update_time_ms": 9.482}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 7.486884117126465, "policy_loss": -0.04287426173686981, "vf_loss": 7.526757717132568, "vf_explained_var": 0.9794806241989136, "kl": 0.015002424828708172, "entropy": 1.2653025388717651, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 6.614619255065918, "policy_loss": -0.04870424419641495, "vf_loss": 6.660248279571533, "vf_explained_var": 0.9809830188751221, "kl": 0.015376517549157143, "entropy": 1.2701776027679443, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 8.129595756530762, "policy_loss": -0.04255335032939911, "vf_loss": 8.168696403503418, "vf_explained_var": 0.9738744497299194, "kl": 0.017264174297451973, "entropy": 1.240788459777832, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 6.002878665924072, "policy_loss": -0.04296010732650757, "vf_loss": 6.042738914489746, "vf_explained_var": 0.9828997850418091, "kl": 0.01550067588686943, "entropy": 1.2242953777313232, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 46200, "num_steps_trained": 46200}, "done": false, "episodes_total": 393, "training_iteration": 11, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_14-48-13", "timestamp": 1624200493, "time_this_iter_s": 104.1411144733429, "time_total_s": 1707.7142691612244, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f03d9050>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f03d90e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9560>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d94d0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9560>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d94d0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9560>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d94d0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9560>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d94d0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f02c83b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1707.7142691612244, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 55.851351351351354, "ram_util_percent": 87.91824324324323}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1465.233948962873, "episode_reward_min": -1238.337462747028, "episode_reward_mean": 91.84026803654, "episode_len_mean": 123.93, "episodes_this_iter": 33, "policy_reward_min": {"AGENT-2": -287.2786907815767, "AGENT-1": -358.6741090888179, "AGENT-3": -289.7973217677156, "AGENT-0": -393.77885230016284}, "policy_reward_max": {"AGENT-2": 359.3670164049071, "AGENT-1": 445.60497352035213, "AGENT-3": 376.8265005702436, "AGENT-0": 476.7683570233988}, "policy_reward_mean": {"AGENT-2": 17.398307405911027, "AGENT-1": 33.082478259868886, "AGENT-3": 25.953420551006065, "AGENT-0": 15.406061819754111}, "custom_metrics": {"mean_ego_speed_mean": 41.57119000000001, "mean_ego_speed_min": 19.109750000000002, "mean_ego_speed_max": 49.92175, "distance_travelled_mean": 106.18313499999998, "distance_travelled_min": 26.8455, "distance_travelled_max": 124.89575}, "hist_stats": {"episode_reward": [-1195.7770736400141, -441.76700998341016, 758.3934999604347, -259.902201564105, 1252.2396808184715, -275.4311270054221, 571.5529026687273, -348.9946018165878, 500.3163820112607, -14.370819328298793, 893.8219175230921, 456.9389329167421, 761.7866801949887, -387.31814241586903, 1012.2113893825119, 602.0531799527972, 750.4653148816734, 751.5613696045007, 687.7465162422914, 1079.8229100370775, -548.7798408315964, 1108.2756595407052, -535.0913791949052, -374.4447576462781, -617.3310306838549, -667.6661354000483, -601.7547998148221, -168.3061258172777, -1238.337462747028, -374.0601548561729, -420.46351697401485, -1229.4706140289147, 21.216333795145196, 531.7199984329687, -20.459359169741774, 585.7336629398476, -227.01432514284448, 646.409791216527, -1074.4417825420069, 897.1587925177204, -866.7171757761732, 850.9679366910875, 594.0540245490901, 1109.3025106606447, 700.5004352189112, 533.7238624696507, 1251.951693215708, 686.6653535031419, 1465.233948962873, 584.9138695530587, 820.5636437897131, 738.8894412474431, 334.31181218396796, -355.90047562181087, -823.7525927293007, -156.01741018853713, -479.43804048373744, -314.3742744223437, -416.8637911387664, -325.25389871076754, -524.091980671669, -328.68077051776464, -371.7618227139131, -419.31340022875224, -155.25787104262844, -162.1495000155866, 930.165195157274, -732.3268555687226, 992.8203046327393, -575.6823826548792, 642.0348299049613, -976.0814245604699, 833.4220487809632, -1083.700780593852, 571.7202115538435, -698.0907161821003, 466.6819182021982, 740.1950613855604, 394.79154992806696, 788.2902872901558, 572.0428232336031, 833.3715884616693, 450.37442751761733, 830.6504281099521, 528.6917853828597, 64.54245813380754, 432.64901778649596, 836.6544893775823, 624.3803758612097, -579.0342376078115, -140.3342440673577, -457.39747061673563, -761.5381993250649, -486.96543267547975, -670.8966219708296, -453.51564018482344, -497.6539176243051, -212.02121196570744, -479.4299447284463, -364.53109853777954], "episode_lengths": [127, 117, 171, 31, 226, 131, 147, 128, 155, 129, 118, 120, 121, 96, 120, 115, 118, 119, 123, 131, 130, 143, 132, 124, 138, 136, 134, 36, 187, 121, 135, 157, 112, 141, 122, 148, 53, 153, 124, 192, 117, 125, 115, 124, 112, 130, 133, 122, 146, 116, 120, 115, 117, 107, 174, 30, 125, 119, 121, 141, 124, 124, 120, 119, 32, 121, 161, 126, 160, 108, 135, 120, 158, 124, 154, 78, 139, 118, 129, 126, 125, 119, 99, 124, 115, 73, 121, 117, 118, 120, 121, 130, 130, 136, 105, 120, 121, 130, 126, 97], "policy_AGENT-2_reward": [-285.84610708986213, -120.95506825531746, 210.52016844360014, -36.642768716479104, 311.73008744430194, -106.19269540256361, 4.573797268482628, -133.09551817684462, 9.152697505661498, -71.13527185385945, 234.20455690022712, 63.034583561884546, 199.06444583338114, -33.737090565940754, 251.7671865554971, 134.1946972927993, 181.55760410411412, 209.6929233938578, 188.8405651180435, 276.6284043068298, -32.05302734711269, 286.0721776257467, -116.64013471938306, -10.525598408319935, -130.49098289309148, -115.83273501136503, -113.93330358279105, -11.971778647775512, -225.67650094114626, -91.81913344363886, -81.14400141982479, -231.10349836608907, 22.738312920801093, 36.90651654501028, -29.89750867167029, -8.038416040552539, -29.62921107686755, 20.49461488618161, -264.22747194540386, 230.77853381979926, -226.4685433078942, 219.59205542143062, 161.721888149604, 270.50644213218015, 130.86288773573176, 50.02641761464074, 304.622508313333, 184.66719852058114, 359.3670164049071, 155.6834831976163, 214.73695630217236, 188.24044145570647, 67.51775837755024, -128.0499669678113, -146.79093602901932, -9.930508817072795, -30.050666243395717, -59.642281431531664, -51.532071976435766, -71.39404018645394, -122.63358955096069, -71.8846130287283, -79.38841516034456, -94.41414026714345, -9.263576985228607, -9.47597727862768, 3.9406672151266484, -196.7436782294702, 261.0157677169142, -184.18585209849985, 152.97726412699663, -224.4284043908043, -11.295796181121746, -287.2786907815767, 1.4709983454618663, -149.46884409660478, 52.681604497244386, 174.2503379690818, 114.95595805438157, 107.77964743115531, 157.1707832939961, 227.95937477396845, 155.6728163440068, 219.22185707143626, 127.71467537923645, -3.886432547734465, 66.73402923845839, 219.41698814199825, 145.26175583238089, -132.58138825527018, -47.08377573343121, -105.51266428185565, -177.27972631233973, -9.320186542568036, -213.45914318963548, -116.36361785946724, -114.75814470703214, -47.75492837883494, -130.00503605436992, -84.97725254525157], "policy_AGENT-1_reward": [-289.0480968844692, -99.29081829887151, 210.96133910666606, -93.39591108660538, 344.06027628963886, -9.731399125550919, 300.76207975761935, -53.922391254830046, 260.6732284338405, 50.98977379078605, 234.32573081562592, 63.4601615996246, 204.63938323542425, -159.96378315147348, 242.56772490155117, 134.81208420543047, 200.8331141206631, 164.50128592248163, 187.4849430965546, 275.05754199154273, -220.26825398570566, 270.8376427018484, -128.2101298011584, -156.33738380509973, -178.71237936843937, -195.69753640241106, -201.9127333249558, -72.14860358449624, -358.6741090888179, -75.12871602211102, -102.61565130384203, -343.25774443028297, -12.169060706386304, 248.45259161734865, 41.94482324573263, 320.2995279129366, -83.84280484811143, 322.16376715285134, -258.9769242423671, 231.20497446170975, -224.34186369324476, 225.53967913181165, 158.88388251491625, 266.323388270267, 173.37732636117462, 223.02286903403254, 290.6025417505863, 183.8623828875466, 347.01332155993697, 157.41132754728858, 218.61600107931793, 188.82340711769066, 104.2723218976548, -60.95680414353602, -241.44280444222804, -68.02666777674571, -224.40675253750237, -97.82566495107517, -51.0962155198751, -88.01632966166802, -116.48593251339462, -68.01619430835302, -82.25839277244302, -91.58223172839516, -68.31689166118703, -71.66744704132424, 445.60497352035213, -168.3937550684072, 261.6354105314222, -104.26278286616667, 195.6449536940387, -222.52205653197325, 412.7385722959917, -270.8414385818593, 303.6443257663457, -199.71225638731582, 201.25401079173048, 174.68933911122886, 63.432306586359886, 108.26937846041389, 149.22820043745142, 186.15616938172906, 81.49957110066119, 218.32351411883334, 128.1357515255051, 36.070745537598434, 67.16836806025006, 223.5744934714899, 169.60389331195537, -131.94464072233262, -22.053253058631462, -115.06644855704974, -180.41159721289955, -212.779699380907, -169.46771132547315, -120.33619888965715, -110.42799134218731, -78.98224842319998, -114.01658527656807, -97.2433081369827], "policy_AGENT-3_reward": [-289.7973217677156, -120.93968240701531, 185.08189802438955, -36.69580727339938, 346.16200450167656, -106.2298418342502, 4.633923582533075, -133.18589964805201, 9.088065605690185, -71.0786027395625, 236.5578465736103, 185.8736526122421, 202.6695755154011, -33.61121238891811, 253.53421157241576, 174.44236844393964, 167.1801526306466, 212.44604452045849, 172.7234267719212, 291.29621421493925, -32.107073400268106, 318.6428865786359, -118.73686388024034, -10.642915062634017, -129.38380353900027, -115.79247665068371, -113.89260637705868, -12.056850925754867, -260.20800041689995, -75.69478770428276, -87.8402207082252, -277.59688511764193, 22.5234426419362, 36.915918754992994, -29.911293693050947, -8.00187625576749, -29.65756735490075, 20.5458716533902, -249.01899917341825, 250.977175592388, -214.54383944746388, 228.24807812774947, 161.58379659935684, 277.08564911019835, 222.75431393881863, 210.10279195674644, 339.315052890955, 177.37093252710378, 376.8265005702436, 159.20142252737014, 217.43976660449906, 149.36632319416847, 94.44876018193588, -105.96126268096411, -161.29634125131028, -9.875320628371723, -30.133875117915874, -59.82649594403249, -138.86252363978286, -72.50055066887975, -119.67768291022142, -71.55534266727707, -79.36557587937885, -92.57044699663366, -9.257574914336415, -9.462556166043898, 3.8511973983958354, -196.69408065499104, 246.11462724972043, -182.95154886964085, 137.44285679882066, -265.0092488566186, -11.255105765904654, -277.21786075518486, 1.4762672810170387, -149.41699273240738, 52.60385215918655, 181.82720652284343, 152.90555958727617, 305.0516689206683, 157.04340320539055, 232.96640328457707, 131.714224006084, 220.2276234267607, 156.56900404056213, -3.8754478900638247, 169.64215452955548, 219.28997514714658, 141.5510481157907, -135.47005155583926, -47.04271618896597, -77.28336837576346, -182.54175769477231, -9.374867181598253, -118.46496971954129, -119.34527762428301, -114.13245585727259, -6.25298544626818, -121.48869997628556, -85.18567221678782], "policy_AGENT-0_reward": [-331.085547897968, -100.58144102220618, 151.83009438577898, -93.1677144876211, 250.28731258285487, -53.27719064305749, 261.5831020600917, -28.790792736861277, 221.40239046606834, 76.853281474337, 188.7337832336286, 144.57053514299088, 155.41327561078236, -160.0060563095368, 264.3422663530482, 158.6040300106276, 200.89444402624977, 164.92111576770344, 138.69758125577232, 236.8407495237657, -264.3514860985097, 232.72295263447563, -171.50425079412338, -196.93886037022463, -178.74386488332362, -240.34338733558877, -172.0161565300163, -72.12889265925106, -393.77885230016284, -131.4175176861404, -148.86364354212304, -377.5124861149002, -11.876361061205735, 209.44497151561666, -2.5953800507532065, 281.4744273232307, -83.88474186296469, 283.2055375241039, -302.21838718081824, 184.1981086438222, -201.3629293275711, 177.588124010096, 111.86445728521278, 295.3870311479998, 173.50590718318585, 50.57178386423093, 317.4115902608347, 140.76483956791034, 382.02711042778594, 112.61763628078442, 169.77091980372447, 212.4592694798774, 68.07297172682732, -60.93244182949976, -274.2225110067427, -68.18491296634691, -194.84674658492384, -97.07983209570413, -175.37298000267276, -93.34297819376559, -165.2947756970924, -117.22462051340615, -130.74943890174637, -140.74658123658025, -68.41982748187641, -71.54351952959087, 476.7683570233988, -170.4953416158535, 224.05449913468235, -104.28219882057184, 155.9697552851058, -264.121714781073, 443.2343784319982, -248.3627904752307, 265.1286201610188, -199.4926229657724, 160.14245075403673, 209.4281777824066, 63.497725700049564, 267.18959247791844, 108.60043629676517, 186.2896410213936, 81.48781606686566, 172.87743349292228, 116.27235443755575, 36.233593034007356, 129.1044659582321, 174.3730326169477, 167.9636786010831, -179.03815707436922, -24.154499086329192, -159.53498940206683, -221.30511810505323, -255.49067957040637, -169.50479773618025, -97.47054581141592, -158.33532571781302, -79.0310497174043, -113.9196234212222, -97.12486563875764]}, "sampler_perf": {"mean_env_wait_ms": 81.76014239920296, "mean_raw_obs_processing_ms": 3.309667780032723, "mean_inference_ms": 3.420728584439421, "mean_action_processing_ms": 0.1979663872784821}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 50400, "timers": {"sample_time_ms": 129502.206, "sample_throughput": 32.432, "load_time_ms": 18.335, "load_throughput": 229067.296, "learn_time_ms": 18540.066, "learn_throughput": 226.536, "update_time_ms": 9.384}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 10.783092498779297, "policy_loss": -0.04486006125807762, "vf_loss": 10.824742317199707, "vf_explained_var": 0.975852370262146, "kl": 0.016047459095716476, "entropy": 1.228677749633789, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 13.109633445739746, "policy_loss": -0.04749634861946106, "vf_loss": 13.154073715209961, "vf_explained_var": 0.9703751802444458, "kl": 0.015284433960914612, "entropy": 1.245564579963684, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 12.233076095581055, "policy_loss": -0.05128326267004013, "vf_loss": 12.281462669372559, "vf_explained_var": 0.9661039710044861, "kl": 0.014481747522950172, "entropy": 1.2353698015213013, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 7.430919170379639, "policy_loss": -0.050195176154375076, "vf_loss": 7.477668762207031, "vf_explained_var": 0.9811872839927673, "kl": 0.01722983457148075, "entropy": 1.1983765363693237, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 50400, "num_steps_trained": 50400}, "done": false, "episodes_total": 426, "training_iteration": 12, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_14-49-53", "timestamp": 1624200593, "time_this_iter_s": 99.59051728248596, "time_total_s": 1807.3047864437103, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f024b0e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f024b200>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b7a0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b7a0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b7a0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b7a0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f031ae60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1807.3047864437103, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 53.57342657342657, "ram_util_percent": 88.0}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1485.700625519546, "episode_reward_min": -1238.337462747028, "episode_reward_mean": 69.72986350109481, "episode_len_mean": 128.74, "episodes_this_iter": 30, "policy_reward_min": {"AGENT-2": -287.2786907815767, "AGENT-3": -298.7371405211438, "AGENT-0": -393.77885230016284, "AGENT-1": -358.6741090888179}, "policy_reward_max": {"AGENT-2": 382.67487441141367, "AGENT-3": 386.64844274663494, "AGENT-0": 476.7683570233988, "AGENT-1": 445.60497352035213}, "policy_reward_mean": {"AGENT-2": 13.418500144989318, "AGENT-3": 20.819350232329683, "AGENT-0": 10.315193819437189, "AGENT-1": 25.176819304338693}, "custom_metrics": {"mean_ego_speed_mean": 41.120960000000004, "mean_ego_speed_min": 19.109750000000002, "mean_ego_speed_max": 49.92175, "distance_travelled_mean": 107.48967999999999, "distance_travelled_min": 27.789500000000004, "distance_travelled_max": 124.93674999999999}, "hist_stats": {"episode_reward": [1485.700625519546, -1098.677519393372, 851.9438496733561, 561.7921332239629, 752.6545032948866, -893.5547998038329, 233.60373399055138, 220.72220587432122, 950.528924043376, 835.4217846170847, 563.0031867433172, 500.92596739767725, 577.7094249954616, 970.3497576654065, 1395.0141345646896, 613.7308407847407, 374.3670150730792, 453.42683799181333, 901.7195614799459, 659.0469416782372, -576.6332569295179, -255.38285889082573, -775.6272398607272, -866.4757012675701, -432.2751984844475, -654.9399219410419, -1069.6836945790826, -935.4733425391001, -791.6124197659516, -715.0328513775296, -419.31340022875224, -155.25787104262844, -162.1495000155866, 930.165195157274, -732.3268555687226, 992.8203046327393, -575.6823826548792, 642.0348299049613, -976.0814245604699, 833.4220487809632, -1083.700780593852, 571.7202115538435, -698.0907161821003, 466.6819182021982, 740.1950613855604, 394.79154992806696, 788.2902872901558, 572.0428232336031, 833.3715884616693, 450.37442751761733, 830.6504281099521, 528.6917853828597, 64.54245813380754, 432.64901778649596, 836.6544893775823, 624.3803758612097, -579.0342376078115, -140.3342440673577, -457.39747061673563, -761.5381993250649, -486.96543267547975, -670.8966219708296, -453.51564018482344, -497.6539176243051, -212.02121196570744, -479.4299447284463, -364.53109853777954, -1195.7770736400141, -441.76700998341016, 758.3934999604347, -259.902201564105, 1252.2396808184715, -275.4311270054221, 571.5529026687273, -348.9946018165878, 500.3163820112607, -14.370819328298793, 893.8219175230921, 456.9389329167421, 761.7866801949887, -387.31814241586903, 1012.2113893825119, 602.0531799527972, 750.4653148816734, 751.5613696045007, 687.7465162422914, 1079.8229100370775, -548.7798408315964, 1108.2756595407052, -535.0913791949052, -374.4447576462781, -617.3310306838549, -667.6661354000483, -601.7547998148221, -168.3061258172777, -1238.337462747028, -374.0601548561729, -420.46351697401485, -1229.4706140289147, 21.216333795145196], "episode_lengths": [185, 144, 176, 203, 162, 128, 171, 137, 180, 119, 125, 120, 102, 132, 131, 118, 132, 117, 130, 120, 135, 122, 159, 142, 128, 130, 140, 139, 134, 130, 119, 32, 121, 161, 126, 160, 108, 135, 120, 158, 124, 154, 78, 139, 118, 129, 126, 125, 119, 99, 124, 115, 73, 121, 117, 118, 120, 121, 130, 130, 136, 105, 120, 121, 130, 126, 97, 127, 117, 171, 31, 226, 131, 147, 128, 155, 129, 118, 120, 121, 96, 120, 115, 118, 119, 123, 131, 130, 143, 132, 124, 138, 136, 134, 36, 187, 121, 135, 157, 112], "policy_AGENT-2_reward": [382.67487441141367, -285.5937774504364, 246.10143759522938, -39.54404847620238, 28.96452809009765, -222.25889252536535, 131.1627081543475, -30.770893789903173, 75.79538167739793, 230.68108755600917, 199.37744548491554, 80.34159037484926, 131.90193095601512, 259.4966016043606, 348.1398589584662, 165.97720078292738, 107.93115595769365, 137.64480611615474, 232.86547926314068, 83.60546371358693, -97.288096864409, -20.47501159138692, -123.42319105955703, -191.5302779352356, -42.803661251255384, -120.57276990428319, -247.0679740657671, -206.37219155698685, -188.40408511341607, -158.37092676226928, -94.41414026714345, -9.263576985228607, -9.47597727862768, 3.9406672151266484, -196.7436782294702, 261.0157677169142, -184.18585209849985, 152.97726412699663, -224.4284043908043, -11.295796181121746, -287.2786907815767, 1.4709983454618663, -149.46884409660478, 52.681604497244386, 174.2503379690818, 114.95595805438157, 107.77964743115531, 157.1707832939961, 227.95937477396845, 155.6728163440068, 219.22185707143626, 127.71467537923645, -3.886432547734465, 66.73402923845839, 219.41698814199825, 145.26175583238089, -132.58138825527018, -47.08377573343121, -105.51266428185565, -177.27972631233973, -9.320186542568036, -213.45914318963548, -116.36361785946724, -114.75814470703214, -47.75492837883494, -130.00503605436992, -84.97725254525157, -285.84610708986213, -120.95506825531746, 210.52016844360014, -36.642768716479104, 311.73008744430194, -106.19269540256361, 4.573797268482628, -133.09551817684462, 9.152697505661498, -71.13527185385945, 234.20455690022712, 63.034583561884546, 199.06444583338114, -33.737090565940754, 251.7671865554971, 134.1946972927993, 181.55760410411412, 209.6929233938578, 188.8405651180435, 276.6284043068298, -32.05302734711269, 286.0721776257467, -116.64013471938306, -10.525598408319935, -130.49098289309148, -115.83273501136503, -113.93330358279105, -11.971778647775512, -225.67650094114626, -91.81913344363886, -81.14400141982479, -231.10349836608907, 22.738312920801093], "policy_AGENT-3_reward": [386.64844274663494, -298.7371405211438, 164.73759996919105, -39.50684856938515, 28.99039666974349, -204.34458970978162, 3.968160212468174, -30.732401069755856, 75.84258033208116, 227.17498651158914, 168.87315802693595, 189.3112467553641, 181.6039406398358, 202.79510301490652, 369.50892260127216, 160.80114183088622, 143.7616490595752, 134.84721702248717, 248.51363416818185, 231.0939526362302, -97.33523848839313, -20.42100912723246, -140.57111784608827, -166.12227677098116, -42.76063361564501, -120.55212324069606, -218.65836632453573, -165.11575101283145, -197.50252378658647, -147.52533706478454, -92.57044699663366, -9.257574914336415, -9.462556166043898, 3.8511973983958354, -196.69408065499104, 246.11462724972043, -182.95154886964085, 137.44285679882066, -265.0092488566186, -11.255105765904654, -277.21786075518486, 1.4762672810170387, -149.41699273240738, 52.60385215918655, 181.82720652284343, 152.90555958727617, 305.0516689206683, 157.04340320539055, 232.96640328457707, 131.714224006084, 220.2276234267607, 156.56900404056213, -3.8754478900638247, 169.64215452955548, 219.28997514714658, 141.5510481157907, -135.47005155583926, -47.04271618896597, -77.28336837576346, -182.54175769477231, -9.374867181598253, -118.46496971954129, -119.34527762428301, -114.13245585727259, -6.25298544626818, -121.48869997628556, -85.18567221678782, -289.7973217677156, -120.93968240701531, 185.08189802438955, -36.69580727339938, 346.16200450167656, -106.2298418342502, 4.633923582533075, -133.18589964805201, 9.088065605690185, -71.0786027395625, 236.5578465736103, 185.8736526122421, 202.6695755154011, -33.61121238891811, 253.53421157241576, 174.44236844393964, 167.1801526306466, 212.44604452045849, 172.7234267719212, 291.29621421493925, -32.107073400268106, 318.6428865786359, -118.73686388024034, -10.642915062634017, -129.38380353900027, -115.79247665068371, -113.89260637705868, -12.056850925754867, -260.20800041689995, -75.69478770428276, -87.8402207082252, -277.59688511764193, 22.5234426419362], "policy_AGENT-0_reward": [333.02600034925786, -276.76507888078805, 194.36316015686546, 303.7529072675444, 327.27010891593477, -263.17272295914086, -33.44166883945255, 120.97307513097195, 376.3575302980963, 188.76431412524965, 97.40355375871181, 150.50024290936443, 132.0764152392236, 267.0605016732457, 352.72516040837917, 121.21765713164802, 61.351971775543646, 40.987541815913325, 187.52500565636615, 260.30757693146273, -177.77409767279755, -131.6751409483141, -275.1676251864256, -273.7759247901501, -161.07822369486513, -226.64069802164585, -322.3474392879309, -284.194150594643, -190.87011864881632, -204.79462421926593, -140.74658123658025, -68.41982748187641, -71.54351952959087, 476.7683570233988, -170.4953416158535, 224.05449913468235, -104.28219882057184, 155.9697552851058, -264.121714781073, 443.2343784319982, -248.3627904752307, 265.1286201610188, -199.4926229657724, 160.14245075403673, 209.4281777824066, 63.497725700049564, 267.18959247791844, 108.60043629676517, 186.2896410213936, 81.48781606686566, 172.87743349292228, 116.27235443755575, 36.233593034007356, 129.1044659582321, 174.3730326169477, 167.9636786010831, -179.03815707436922, -24.154499086329192, -159.53498940206683, -221.30511810505323, -255.49067957040637, -169.50479773618025, -97.47054581141592, -158.33532571781302, -79.0310497174043, -113.9196234212222, -97.12486563875764, -331.085547897968, -100.58144102220618, 151.83009438577898, -93.1677144876211, 250.28731258285487, -53.27719064305749, 261.5831020600917, -28.790792736861277, 221.40239046606834, 76.853281474337, 188.7337832336286, 144.57053514299088, 155.41327561078236, -160.0060563095368, 264.3422663530482, 158.6040300106276, 200.89444402624977, 164.92111576770344, 138.69758125577232, 236.8407495237657, -264.3514860985097, 232.72295263447563, -171.50425079412338, -196.93886037022463, -178.74386488332362, -240.34338733558877, -172.0161565300163, -72.12889265925106, -393.77885230016284, -131.4175176861404, -148.86364354212304, -377.5124861149002, -11.876361061205735], "policy_AGENT-1_reward": [383.3513080122401, -237.58152254100366, 246.7416519520698, 337.0901230020061, 367.42946961911053, -203.77859460954437, 131.91453446318855, 161.25242560300816, 422.53343173579987, 188.8013964242366, 97.34902947275411, 80.77288735809944, 132.127138160387, 240.99755137289355, 324.64019259657147, 165.73484103927964, 61.32223828026679, 139.947273037258, 232.8154423922585, 84.03994839695736, -204.23582390391869, -82.81169722389211, -236.46530576865598, -235.04722177120328, -185.63267992268194, -187.17433077441694, -281.6099149008485, -279.79124937463916, -214.8356922171321, -204.3419633312104, -91.58223172839516, -68.31689166118703, -71.66744704132424, 445.60497352035213, -168.3937550684072, 261.6354105314222, -104.26278286616667, 195.6449536940387, -222.52205653197325, 412.7385722959917, -270.8414385818593, 303.6443257663457, -199.71225638731582, 201.25401079173048, 174.68933911122886, 63.432306586359886, 108.26937846041389, 149.22820043745142, 186.15616938172906, 81.49957110066119, 218.32351411883334, 128.1357515255051, 36.070745537598434, 67.16836806025006, 223.5744934714899, 169.60389331195537, -131.94464072233262, -22.053253058631462, -115.06644855704974, -180.41159721289955, -212.779699380907, -169.46771132547315, -120.33619888965715, -110.42799134218731, -78.98224842319998, -114.01658527656807, -97.2433081369827, -289.0480968844692, -99.29081829887151, 210.96133910666606, -93.39591108660538, 344.06027628963886, -9.731399125550919, 300.76207975761935, -53.922391254830046, 260.6732284338405, 50.98977379078605, 234.32573081562592, 63.4601615996246, 204.63938323542425, -159.96378315147348, 242.56772490155117, 134.81208420543047, 200.8331141206631, 164.50128592248163, 187.4849430965546, 275.05754199154273, -220.26825398570566, 270.8376427018484, -128.2101298011584, -156.33738380509973, -178.71237936843937, -195.69753640241106, -201.9127333249558, -72.14860358449624, -358.6741090888179, -75.12871602211102, -102.61565130384203, -343.25774443028297, -12.169060706386304]}, "sampler_perf": {"mean_env_wait_ms": 79.37095290287203, "mean_raw_obs_processing_ms": 3.2132595236901396, "mean_inference_ms": 3.32914637317229, "mean_action_processing_ms": 0.1932207536943597}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 54600, "timers": {"sample_time_ms": 124393.566, "sample_throughput": 33.764, "load_time_ms": 17.81, "load_throughput": 235824.006, "learn_time_ms": 17912.549, "learn_throughput": 234.472, "update_time_ms": 9.246}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 11.418708801269531, "policy_loss": -0.04817588999867439, "vf_loss": 11.463666915893555, "vf_explained_var": 0.9771604537963867, "kl": 0.016086162999272346, "entropy": 1.2199177742004395, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 11.271990776062012, "policy_loss": -0.050320833921432495, "vf_loss": 11.318953514099121, "vf_explained_var": 0.9796044230461121, "kl": 0.01678411476314068, "entropy": 1.2436188459396362, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 9.666940689086914, "policy_loss": -0.05191923677921295, "vf_loss": 9.715385437011719, "vf_explained_var": 0.9766094088554382, "kl": 0.01737193949520588, "entropy": 1.221434473991394, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 8.507766723632812, "policy_loss": -0.0516175739467144, "vf_loss": 8.556014060974121, "vf_explained_var": 0.9824755787849426, "kl": 0.0168582983314991, "entropy": 1.1831817626953125, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 54600, "num_steps_trained": 54600}, "done": false, "episodes_total": 456, "training_iteration": 13, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_14-51-31", "timestamp": 1624200691, "time_this_iter_s": 97.50219488143921, "time_total_s": 1904.8069813251495, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f0366f80>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f0366ef0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a050>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a050>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a050>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a050>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f024b9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1904.8069813251495, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 51.58776978417266, "ram_util_percent": 88.0791366906475}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1710.4797429853863, "episode_reward_min": -1238.337462747028, "episode_reward_mean": 39.48518606105094, "episode_len_mean": 131.36, "episodes_this_iter": 32, "policy_reward_min": {"AGENT-2": -285.84610708986213, "AGENT-1": -358.6741090888179, "AGENT-3": -338.48845406522264, "AGENT-0": -393.77885230016284}, "policy_reward_max": {"AGENT-2": 394.7649723862703, "AGENT-1": 488.95842735795054, "AGENT-3": 404.8882972396771, "AGENT-0": 421.8680460014869}, "policy_reward_mean": {"AGENT-2": 9.27080858922855, "AGENT-1": 18.29703175310707, "AGENT-3": 12.97470687139022, "AGENT-0": -1.0573611526748252}, "custom_metrics": {"mean_ego_speed_mean": 40.40074, "mean_ego_speed_min": 19.109750000000002, "mean_ego_speed_max": 49.587999999999994, "distance_travelled_mean": 108.0404225, "distance_travelled_min": 26.68775, "distance_travelled_max": 124.93674999999999}, "hist_stats": {"episode_reward": [142.63618142305563, 1710.4797429853863, -774.6716039069177, 729.0742031699625, -723.5887827049563, -810.793069247216, -508.83659930032167, 863.3103479947879, -1071.9500318643982, -606.4987978889254, 1018.1274076932665, 609.5037622256693, 964.1948510835621, 798.1148464712973, 555.7405784552349, 662.2676962637656, -370.77232875167863, 1375.4181516020078, 693.9524826090486, 1031.9841762804767, 545.1777356712447, -222.07510196708216, -366.8476184677753, -758.7425272829444, -1057.8787917618074, -721.6955982604578, -728.2132876598544, -689.2598676219104, -146.2881304472709, -768.681724302722, -373.0223249729676, -389.92405793365714, -453.51564018482344, -497.6539176243051, -212.02121196570744, -479.4299447284463, -364.53109853777954, -1195.7770736400141, -441.76700998341016, 758.3934999604347, -259.902201564105, 1252.2396808184715, -275.4311270054221, 571.5529026687273, -348.9946018165878, 500.3163820112607, -14.370819328298793, 893.8219175230921, 456.9389329167421, 761.7866801949887, -387.31814241586903, 1012.2113893825119, 602.0531799527972, 750.4653148816734, 751.5613696045007, 687.7465162422914, 1079.8229100370775, -548.7798408315964, 1108.2756595407052, -535.0913791949052, -374.4447576462781, -617.3310306838549, -667.6661354000483, -601.7547998148221, -168.3061258172777, -1238.337462747028, -374.0601548561729, -420.46351697401485, -1229.4706140289147, 21.216333795145196, 1485.700625519546, -1098.677519393372, 851.9438496733561, 561.7921332239629, 752.6545032948866, -893.5547998038329, 233.60373399055138, 220.72220587432122, 950.528924043376, 835.4217846170847, 563.0031867433172, 500.92596739767725, 577.7094249954616, 970.3497576654065, 1395.0141345646896, 613.7308407847407, 374.3670150730792, 453.42683799181333, 901.7195614799459, 659.0469416782372, -576.6332569295179, -255.38285889082573, -775.6272398607272, -866.4757012675701, -432.2751984844475, -654.9399219410419, -1069.6836945790826, -935.4733425391001, -791.6124197659516, -715.0328513775296], "episode_lengths": [138, 224, 124, 156, 129, 168, 43, 156, 128, 121, 121, 116, 144, 117, 106, 125, 121, 137, 127, 143, 124, 124, 118, 145, 145, 131, 134, 131, 29, 130, 143, 125, 120, 121, 130, 126, 97, 127, 117, 171, 31, 226, 131, 147, 128, 155, 129, 118, 120, 121, 96, 120, 115, 118, 119, 123, 131, 130, 143, 132, 124, 138, 136, 134, 36, 187, 121, 135, 157, 112, 185, 144, 176, 203, 162, 128, 171, 137, 180, 119, 125, 120, 102, 132, 131, 118, 132, 117, 130, 120, 135, 122, 159, 142, 128, 130, 140, 139, 134, 130], "policy_AGENT-2_reward": [-41.32787438051604, 394.7649723862703, -219.1637071432462, -12.203651122152007, -216.51489799052462, -49.893671012784864, -150.89179026435016, 35.446651571241944, -251.17353070718116, -173.79627157359144, 255.64109487661815, 101.72765231777707, 252.64944489034767, 199.33221012867128, 72.42440542650229, 174.27049947086968, -34.75332573168491, 342.54466377290845, 192.61689710802477, 261.4802811908845, 69.16787799701386, -65.0145106875019, -102.1622243274164, -182.91843579858266, -138.20963787263793, -167.20587668972053, -171.2634625783503, -166.91152296823455, -8.640323817419185, -177.90045610368944, -8.062283051420746, -96.28210463226952, -116.36361785946724, -114.75814470703214, -47.75492837883494, -130.00503605436992, -84.97725254525157, -285.84610708986213, -120.95506825531746, 210.52016844360014, -36.642768716479104, 311.73008744430194, -106.19269540256361, 4.573797268482628, -133.09551817684462, 9.152697505661498, -71.13527185385945, 234.20455690022712, 63.034583561884546, 199.06444583338114, -33.737090565940754, 251.7671865554971, 134.1946972927993, 181.55760410411412, 209.6929233938578, 188.8405651180435, 276.6284043068298, -32.05302734711269, 286.0721776257467, -116.64013471938306, -10.525598408319935, -130.49098289309148, -115.83273501136503, -113.93330358279105, -11.971778647775512, -225.67650094114626, -91.81913344363886, -81.14400141982479, -231.10349836608907, 22.738312920801093, 382.67487441141367, -285.5937774504364, 246.10143759522938, -39.54404847620238, 28.96452809009765, -222.25889252536535, 131.1627081543475, -30.770893789903173, 75.79538167739793, 230.68108755600917, 199.37744548491554, 80.34159037484926, 131.90193095601512, 259.4966016043606, 348.1398589584662, 165.97720078292738, 107.93115595769365, 137.64480611615474, 232.86547926314068, 83.60546371358693, -97.288096864409, -20.47501159138692, -123.42319105955703, -191.5302779352356, -42.803661251255384, -120.57276990428319, -247.0679740657671, -206.37219155698685, -188.40408511341607, -158.37092676226928], "policy_AGENT-1_reward": [133.04133910433887, 488.95842735795054, -167.86466704875994, 396.21485035954737, -157.63284868113195, -49.46451560858271, -103.39029473822988, 415.7867588304379, -261.0385715793638, -107.06627201465474, 237.79845254744367, 102.16960726616385, 227.69264181644525, 199.34385390572072, 217.7697268631487, 175.17439858582722, -125.99873408699341, 342.97527410578925, 184.29726809320812, 257.74188467020883, 69.88809689080144, -46.632160394515374, -81.52512215936659, -202.55838463758153, -342.50961024424856, -172.6765671003098, -202.38037432302366, -169.9617432599442, -64.5250016728978, -186.500115929188, -191.22163596046957, -106.23294850149736, -120.33619888965715, -110.42799134218731, -78.98224842319998, -114.01658527656807, -97.2433081369827, -289.0480968844692, -99.29081829887151, 210.96133910666606, -93.39591108660538, 344.06027628963886, -9.731399125550919, 300.76207975761935, -53.922391254830046, 260.6732284338405, 50.98977379078605, 234.32573081562592, 63.4601615996246, 204.63938323542425, -159.96378315147348, 242.56772490155117, 134.81208420543047, 200.8331141206631, 164.50128592248163, 187.4849430965546, 275.05754199154273, -220.26825398570566, 270.8376427018484, -128.2101298011584, -156.33738380509973, -178.71237936843937, -195.69753640241106, -201.9127333249558, -72.14860358449624, -358.6741090888179, -75.12871602211102, -102.61565130384203, -343.25774443028297, -12.169060706386304, 383.3513080122401, -237.58152254100366, 246.7416519520698, 337.0901230020061, 367.42946961911053, -203.77859460954437, 131.91453446318855, 161.25242560300816, 422.53343173579987, 188.8013964242366, 97.34902947275411, 80.77288735809944, 132.127138160387, 240.99755137289355, 324.64019259657147, 165.73484103927964, 61.32223828026679, 139.947273037258, 232.8154423922585, 84.03994839695736, -204.23582390391869, -82.81169722389211, -236.46530576865598, -235.04722177120328, -185.63267992268194, -187.17433077441694, -281.6099149008485, -279.79124937463916, -214.8356922171321, -204.3419633312104], "policy_AGENT-3_reward": [-41.59990852764086, 404.8882972396771, -219.32134894082824, -12.370564306941713, -216.4741631326343, -338.48845406522264, -151.16524044909377, 35.50552056582252, -261.6058445223344, -173.74558002875608, 263.9707303384836, 188.99485964897352, 294.59011798212305, 175.05214750934343, 192.5675543737366, 137.9954904540606, -34.794188009453485, 363.50931435180524, 179.1560608219861, 292.8354099739847, 222.9667717188616, -64.24712144979307, -101.66137202646905, -132.76085207608367, -268.28497089604423, -162.8928367975284, -175.55072080427237, -142.93984536675757, -8.551719730006033, -176.74823782643395, -8.058560616461179, -102.84660414455983, -119.34527762428301, -114.13245585727259, -6.25298544626818, -121.48869997628556, -85.18567221678782, -289.7973217677156, -120.93968240701531, 185.08189802438955, -36.69580727339938, 346.16200450167656, -106.2298418342502, 4.633923582533075, -133.18589964805201, 9.088065605690185, -71.0786027395625, 236.5578465736103, 185.8736526122421, 202.6695755154011, -33.61121238891811, 253.53421157241576, 174.44236844393964, 167.1801526306466, 212.44604452045849, 172.7234267719212, 291.29621421493925, -32.107073400268106, 318.6428865786359, -118.73686388024034, -10.642915062634017, -129.38380353900027, -115.79247665068371, -113.89260637705868, -12.056850925754867, -260.20800041689995, -75.69478770428276, -87.8402207082252, -277.59688511764193, 22.5234426419362, 386.64844274663494, -298.7371405211438, 164.73759996919105, -39.50684856938515, 28.99039666974349, -204.34458970978162, 3.968160212468174, -30.732401069755856, 75.84258033208116, 227.17498651158914, 168.87315802693595, 189.3112467553641, 181.6039406398358, 202.79510301490652, 369.50892260127216, 160.80114183088622, 143.7616490595752, 134.84721702248717, 248.51363416818185, 231.0939526362302, -97.33523848839313, -20.42100912723246, -140.57111784608827, -166.12227677098116, -42.76063361564501, -120.55212324069606, -218.65836632453573, -165.11575101283145, -197.50252378658647, -147.52533706478454], "policy_AGENT-0_reward": [92.52262522687359, 421.8680460014869, -168.32188077408304, 357.43356823950944, -132.96687290066487, -372.94642856062507, -103.389273848648, 376.5714170272855, -298.1320850555186, -151.89067427192242, 260.71712993072106, 216.61164299275543, 189.26264639464472, 224.38663492756197, 72.9788917918474, 174.82730775300922, -175.226080923547, 326.3888993715042, 137.88225658582942, 219.92660044540003, 183.15498906456787, -46.18130943527204, -81.4988999545232, -240.5048547706966, -308.8745727488764, -218.92031767289905, -179.01872995420803, -209.44675602697424, -64.5710852269479, -227.5329144434102, -165.679845344616, -84.56240065533089, -97.47054581141592, -158.33532571781302, -79.0310497174043, -113.9196234212222, -97.12486563875764, -331.085547897968, -100.58144102220618, 151.83009438577898, -93.1677144876211, 250.28731258285487, -53.27719064305749, 261.5831020600917, -28.790792736861277, 221.40239046606834, 76.853281474337, 188.7337832336286, 144.57053514299088, 155.41327561078236, -160.0060563095368, 264.3422663530482, 158.6040300106276, 200.89444402624977, 164.92111576770344, 138.69758125577232, 236.8407495237657, -264.3514860985097, 232.72295263447563, -171.50425079412338, -196.93886037022463, -178.74386488332362, -240.34338733558877, -172.0161565300163, -72.12889265925106, -393.77885230016284, -131.4175176861404, -148.86364354212304, -377.5124861149002, -11.876361061205735, 333.02600034925786, -276.76507888078805, 194.36316015686546, 303.7529072675444, 327.27010891593477, -263.17272295914086, -33.44166883945255, 120.97307513097195, 376.3575302980963, 188.76431412524965, 97.40355375871181, 150.50024290936443, 132.0764152392236, 267.0605016732457, 352.72516040837917, 121.21765713164802, 61.351971775543646, 40.987541815913325, 187.52500565636615, 260.30757693146273, -177.77409767279755, -131.6751409483141, -275.1676251864256, -273.7759247901501, -161.07822369486513, -226.64069802164585, -322.3474392879309, -284.194150594643, -190.87011864881632, -204.79462421926593]}, "sampler_perf": {"mean_env_wait_ms": 77.03784846927674, "mean_raw_obs_processing_ms": 3.1202400458444672, "mean_inference_ms": 3.23765246374135, "mean_action_processing_ms": 0.18848321048030653}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 58800, "timers": {"sample_time_ms": 120464.17, "sample_throughput": 34.865, "load_time_ms": 17.12, "load_throughput": 245325.0, "learn_time_ms": 17724.248, "learn_throughput": 236.964, "update_time_ms": 9.107}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 8.776501655578613, "policy_loss": -0.054627224802970886, "vf_loss": 8.827201843261719, "vf_explained_var": 0.9842472076416016, "kl": 0.019630005583167076, "entropy": 1.1796337366104126, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 9.422247886657715, "policy_loss": -0.053513627499341965, "vf_loss": 9.472262382507324, "vf_explained_var": 0.9843778014183044, "kl": 0.017496822401881218, "entropy": 1.225060224533081, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 9.720784187316895, "policy_loss": -0.04709170386195183, "vf_loss": 9.764585494995117, "vf_explained_var": 0.9824427366256714, "kl": 0.01645064726471901, "entropy": 1.218443512916565, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 8.279481887817383, "policy_loss": -0.04981398209929466, "vf_loss": 8.325289726257324, "vf_explained_var": 0.9861789345741272, "kl": 0.0200321227312088, "entropy": 1.1857081651687622, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 58800, "num_steps_trained": 58800}, "done": false, "episodes_total": 488, "training_iteration": 14, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_14-53-07", "timestamp": 1624200787, "time_this_iter_s": 95.97677946090698, "time_total_s": 2000.7837607860565, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f041b950>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f024be60>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f024bb00>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02463b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246290>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f024bb00>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02463b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246290>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f024bb00>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02463b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246290>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f024bb00>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f024b8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02463b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246290>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f03d94d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2000.7837607860565, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 54.44306569343066, "ram_util_percent": 87.95401459854014}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2081.259705275066, "episode_reward_min": -1600.7924011511175, "episode_reward_mean": 50.30495551822889, "episode_len_mean": 134.96, "episodes_this_iter": 30, "policy_reward_min": {"AGENT-2": -450.2958458143081, "AGENT-3": -418.98375459767664, "AGENT-0": -519.5186822763613, "AGENT-1": -481.7897732875779}, "policy_reward_max": {"AGENT-2": 522.3911423875529, "AGENT-3": 461.1366255845217, "AGENT-0": 534.4032202230046, "AGENT-1": 587.9352150000288}, "policy_reward_mean": {"AGENT-2": 10.60855391210218, "AGENT-3": 16.167094310163247, "AGENT-0": 4.149491526428229, "AGENT-1": 19.37981576953532}, "custom_metrics": {"mean_ego_speed_mean": 39.552205, "mean_ego_speed_min": 19.109750000000002, "mean_ego_speed_max": 49.587999999999994, "distance_travelled_mean": 107.60422249999999, "distance_travelled_min": 26.68775, "distance_travelled_max": 124.93674999999999}, "hist_stats": {"episode_reward": [974.9872956486527, -1600.7924011511175, 2081.259705275066, -570.7023169598209, 765.4576198304378, -270.1385673362668, 854.2929104154534, -979.0053891542831, 1487.1685104492187, 742.569729280066, 653.0844760506125, 493.8662078013728, 1559.117271128255, 942.0685916690474, 593.0566926701772, 917.6235950072421, 740.7795567163323, 784.9458491035626, 856.061116826219, -705.2083390352801, -229.170434216992, -369.6465890883651, -607.3638686843751, -449.558383848151, -303.5260498589627, -373.50565894658774, -1114.5507017867803, -86.85073083931928, -1259.1226851280583, -264.3935275356884, -667.6661354000483, -601.7547998148221, -168.3061258172777, -1238.337462747028, -374.0601548561729, -420.46351697401485, -1229.4706140289147, 21.216333795145196, 1485.700625519546, -1098.677519393372, 851.9438496733561, 561.7921332239629, 752.6545032948866, -893.5547998038329, 233.60373399055138, 220.72220587432122, 950.528924043376, 835.4217846170847, 563.0031867433172, 500.92596739767725, 577.7094249954616, 970.3497576654065, 1395.0141345646896, 613.7308407847407, 374.3670150730792, 453.42683799181333, 901.7195614799459, 659.0469416782372, -576.6332569295179, -255.38285889082573, -775.6272398607272, -866.4757012675701, -432.2751984844475, -654.9399219410419, -1069.6836945790826, -935.4733425391001, -791.6124197659516, -715.0328513775296, 142.63618142305563, 1710.4797429853863, -774.6716039069177, 729.0742031699625, -723.5887827049563, -810.793069247216, -508.83659930032167, 863.3103479947879, -1071.9500318643982, -606.4987978889254, 1018.1274076932665, 609.5037622256693, 964.1948510835621, 798.1148464712973, 555.7405784552349, 662.2676962637656, -370.77232875167863, 1375.4181516020078, 693.9524826090486, 1031.9841762804767, 545.1777356712447, -222.07510196708216, -366.8476184677753, -758.7425272829444, -1057.8787917618074, -721.6955982604578, -728.2132876598544, -689.2598676219104, -146.2881304472709, -768.681724302722, -373.0223249729676, -389.92405793365714], "episode_lengths": [207, 152, 242, 99, 161, 143, 217, 117, 137, 109, 114, 123, 152, 143, 120, 116, 122, 118, 126, 179, 101, 133, 132, 130, 124, 53, 163, 147, 174, 110, 136, 134, 36, 187, 121, 135, 157, 112, 185, 144, 176, 203, 162, 128, 171, 137, 180, 119, 125, 120, 102, 132, 131, 118, 132, 117, 130, 120, 135, 122, 159, 142, 128, 130, 140, 139, 134, 130, 138, 224, 124, 156, 129, 168, 43, 156, 128, 121, 121, 116, 144, 117, 106, 125, 121, 137, 127, 143, 124, 124, 118, 145, 145, 131, 134, 131, 29, 130, 143, 125], "policy_AGENT-2_reward": [-8.394133140397622, -450.2958458143081, 522.3911423875529, -181.496320727939, 5.374810196966136, -147.1197856641722, 245.90838478154507, -251.7522550492148, 365.33151755028894, 141.61671606047497, 144.20284737696238, 65.67515187411797, 408.69980393656886, 269.8478460496327, 54.867896356618424, 235.13342798155026, 205.1053033328497, 220.09463464518072, 218.15075810196822, -76.74073234875412, -7.966895711395901, -80.11814545945636, -129.5290234328841, -100.94777179619078, -49.175741352451915, -121.19772526036373, -119.32872939385462, 0.6435072604281231, -128.8324495803773, -126.51300849288472, -115.83273501136503, -113.93330358279105, -11.971778647775512, -225.67650094114626, -91.81913344363886, -81.14400141982479, -231.10349836608907, 22.738312920801093, 382.67487441141367, -285.5937774504364, 246.10143759522938, -39.54404847620238, 28.96452809009765, -222.25889252536535, 131.1627081543475, -30.770893789903173, 75.79538167739793, 230.68108755600917, 199.37744548491554, 80.34159037484926, 131.90193095601512, 259.4966016043606, 348.1398589584662, 165.97720078292738, 107.93115595769365, 137.64480611615474, 232.86547926314068, 83.60546371358693, -97.288096864409, -20.47501159138692, -123.42319105955703, -191.5302779352356, -42.803661251255384, -120.57276990428319, -247.0679740657671, -206.37219155698685, -188.40408511341607, -158.37092676226928, -41.32787438051604, 394.7649723862703, -219.1637071432462, -12.203651122152007, -216.51489799052462, -49.893671012784864, -150.89179026435016, 35.446651571241944, -251.17353070718116, -173.79627157359144, 255.64109487661815, 101.72765231777707, 252.64944489034767, 199.33221012867128, 72.42440542650229, 174.27049947086968, -34.75332573168491, 342.54466377290845, 192.61689710802477, 261.4802811908845, 69.16787799701386, -65.0145106875019, -102.1622243274164, -182.91843579858266, -138.20963787263793, -167.20587668972053, -171.2634625783503, -166.91152296823455, -8.640323817419185, -177.90045610368944, -8.062283051420746, -96.28210463226952], "policy_AGENT-3_reward": [-8.569325627077276, -418.98375459767664, 436.5301276644807, -181.4744531013856, 5.301467496210702, -147.3433788847007, 213.24448179785034, -251.88083763779886, 396.8254259249095, 224.35862958973433, 189.118195430111, 200.81291279334013, 461.1366255845217, 201.7254735064204, 227.46400580941773, 187.47597127895915, 204.97839302290728, 221.28087122934252, 181.87148300384362, -76.83182425232536, -8.01967851903959, -80.14888915781883, -135.3518997594804, -91.57431398525785, -49.11959369050491, -121.41952166892204, -119.42632778024631, 37.807269744237324, -128.9817799837413, -20.048855266460897, -115.79247665068371, -113.89260637705868, -12.056850925754867, -260.20800041689995, -75.69478770428276, -87.8402207082252, -277.59688511764193, 22.5234426419362, 386.64844274663494, -298.7371405211438, 164.73759996919105, -39.50684856938515, 28.99039666974349, -204.34458970978162, 3.968160212468174, -30.732401069755856, 75.84258033208116, 227.17498651158914, 168.87315802693595, 189.3112467553641, 181.6039406398358, 202.79510301490652, 369.50892260127216, 160.80114183088622, 143.7616490595752, 134.84721702248717, 248.51363416818185, 231.0939526362302, -97.33523848839313, -20.42100912723246, -140.57111784608827, -166.12227677098116, -42.76063361564501, -120.55212324069606, -218.65836632453573, -165.11575101283145, -197.50252378658647, -147.52533706478454, -41.59990852764086, 404.8882972396771, -219.32134894082824, -12.370564306941713, -216.4741631326343, -338.48845406522264, -151.16524044909377, 35.50552056582252, -261.6058445223344, -173.74558002875608, 263.9707303384836, 188.99485964897352, 294.59011798212305, 175.05214750934343, 192.5675543737366, 137.9954904540606, -34.794188009453485, 363.50931435180524, 179.1560608219861, 292.8354099739847, 222.9667717188616, -64.24712144979307, -101.66137202646905, -132.76085207608367, -268.28497089604423, -162.8928367975284, -175.55072080427237, -142.93984536675757, -8.551719730006033, -176.74823782643395, -8.058560616461179, -102.84660414455983], "policy_AGENT-0_reward": [499.599310023269, -350.75972807702163, 534.4032202230046, -103.93292430149477, 357.0314919731114, 25.633595122562063, 148.7928534480887, -237.75091162523788, 359.25505405066514, 188.27316391056914, 175.01537431352932, 161.2733775913795, 326.7573799105694, 216.58987473804484, 255.33448015595079, 259.31870294282993, 164.73512172037053, 171.84953818136535, 239.20841266578813, -292.769271798179, -106.6071691752843, -101.80047963074297, -190.9337417885735, -150.7969561938011, -102.54916015369152, -65.48777930057906, -455.0928518615291, -62.67022740672284, -519.5186822763613, -98.34750049344362, -240.34338733558877, -172.0161565300163, -72.12889265925106, -393.77885230016284, -131.4175176861404, -148.86364354212304, -377.5124861149002, -11.876361061205735, 333.02600034925786, -276.76507888078805, 194.36316015686546, 303.7529072675444, 327.27010891593477, -263.17272295914086, -33.44166883945255, 120.97307513097195, 376.3575302980963, 188.76431412524965, 97.40355375871181, 150.50024290936443, 132.0764152392236, 267.0605016732457, 352.72516040837917, 121.21765713164802, 61.351971775543646, 40.987541815913325, 187.52500565636615, 260.30757693146273, -177.77409767279755, -131.6751409483141, -275.1676251864256, -273.7759247901501, -161.07822369486513, -226.64069802164585, -322.3474392879309, -284.194150594643, -190.87011864881632, -204.79462421926593, 92.52262522687359, 421.8680460014869, -168.32188077408304, 357.43356823950944, -132.96687290066487, -372.94642856062507, -103.389273848648, 376.5714170272855, -298.1320850555186, -151.89067427192242, 260.71712993072106, 216.61164299275543, 189.26264639464472, 224.38663492756197, 72.9788917918474, 174.82730775300922, -175.226080923547, 326.3888993715042, 137.88225658582942, 219.92660044540003, 183.15498906456787, -46.18130943527204, -81.4988999545232, -240.5048547706966, -308.8745727488764, -218.92031767289905, -179.01872995420803, -209.44675602697424, -64.5710852269479, -227.5329144434102, -165.679845344616, -84.56240065533089], "policy_AGENT-1_reward": [492.3514443928591, -380.7530726621127, 587.9352150000288, -103.79861882900127, 397.7498501641498, -1.3089979099562394, 246.3471903879681, -237.62138484203166, 365.75651292335664, 188.32121971928723, 144.74805893000982, 66.10476554253479, 362.5234616965954, 253.90539737494944, 55.390310348189985, 235.69549280390243, 165.9607386402053, 171.72080504767374, 216.83046305461903, -258.8665106360218, -106.5766908112721, -107.57907484034715, -151.54920370343729, -106.23934187290124, -102.68155466231443, -65.40063271672288, -420.7027927511487, -62.631280437262056, -481.7897732875779, -19.48416328289915, -195.69753640241106, -201.9127333249558, -72.14860358449624, -358.6741090888179, -75.12871602211102, -102.61565130384203, -343.25774443028297, -12.169060706386304, 383.3513080122401, -237.58152254100366, 246.7416519520698, 337.0901230020061, 367.42946961911053, -203.77859460954437, 131.91453446318855, 161.25242560300816, 422.53343173579987, 188.8013964242366, 97.34902947275411, 80.77288735809944, 132.127138160387, 240.99755137289355, 324.64019259657147, 165.73484103927964, 61.32223828026679, 139.947273037258, 232.8154423922585, 84.03994839695736, -204.23582390391869, -82.81169722389211, -236.46530576865598, -235.04722177120328, -185.63267992268194, -187.17433077441694, -281.6099149008485, -279.79124937463916, -214.8356922171321, -204.3419633312104, 133.04133910433887, 488.95842735795054, -167.86466704875994, 396.21485035954737, -157.63284868113195, -49.46451560858271, -103.39029473822988, 415.7867588304379, -261.0385715793638, -107.06627201465474, 237.79845254744367, 102.16960726616385, 227.69264181644525, 199.34385390572072, 217.7697268631487, 175.17439858582722, -125.99873408699341, 342.97527410578925, 184.29726809320812, 257.74188467020883, 69.88809689080144, -46.632160394515374, -81.52512215936659, -202.55838463758153, -342.50961024424856, -172.6765671003098, -202.38037432302366, -169.9617432599442, -64.5250016728978, -186.500115929188, -191.22163596046957, -106.23294850149736]}, "sampler_perf": {"mean_env_wait_ms": 75.03774927224583, "mean_raw_obs_processing_ms": 3.039049183647179, "mean_inference_ms": 3.159497378734899, "mean_action_processing_ms": 0.18436071456083825}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 63000, "timers": {"sample_time_ms": 114661.404, "sample_throughput": 36.63, "load_time_ms": 16.131, "load_throughput": 260361.377, "learn_time_ms": 16947.619, "learn_throughput": 247.822, "update_time_ms": 8.787}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 14.917704582214355, "policy_loss": -0.04963245242834091, "vf_loss": 14.96368408203125, "vf_explained_var": 0.9783098101615906, "kl": 0.018271073698997498, "entropy": 1.1301088333129883, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 15.600549697875977, "policy_loss": -0.05109941214323044, "vf_loss": 15.64831256866455, "vf_explained_var": 0.9804033041000366, "kl": 0.016670074313879013, "entropy": 1.2017035484313965, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 18.604284286499023, "policy_loss": -0.04943816736340523, "vf_loss": 18.650157928466797, "vf_explained_var": 0.969567596912384, "kl": 0.01782432571053505, "entropy": 1.1652989387512207, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 12.29643440246582, "policy_loss": -0.05335857346653938, "vf_loss": 12.345105171203613, "vf_explained_var": 0.9824004173278809, "kl": 0.015627378597855568, "entropy": 1.159792184829712, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 63000, "num_steps_trained": 63000}, "done": false, "episodes_total": 518, "training_iteration": 15, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_14-54-39", "timestamp": 1624200879, "time_this_iter_s": 92.2548131942749, "time_total_s": 2093.0385739803314, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f0366f80>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f03669e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8d40>, action_adapter=<function AgentSpec.<lambda> at 0x7fd601a3e5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd601a3ed40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f02464d0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8d40>, action_adapter=<function AgentSpec.<lambda> at 0x7fd601a3e5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd601a3ed40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f02464d0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8d40>, action_adapter=<function AgentSpec.<lambda> at 0x7fd601a3e5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd601a3ed40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f02464d0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8d40>, action_adapter=<function AgentSpec.<lambda> at 0x7fd601a3e5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd601a3ed40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f02464d0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f02465f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2093.0385739803314, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 52.20757575757575, "ram_util_percent": 87.9840909090909}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2081.259705275066, "episode_reward_min": -1600.7924011511175, "episode_reward_mean": 97.52723586552503, "episode_len_mean": 137.25, "episodes_this_iter": 30, "policy_reward_min": {"AGENT-2": -450.2958458143081, "AGENT-3": -418.98375459767664, "AGENT-0": -519.5186822763613, "AGENT-1": -481.7897732875779}, "policy_reward_max": {"AGENT-2": 522.3911423875529, "AGENT-3": 533.4277756029952, "AGENT-0": 534.4032202230046, "AGENT-1": 627.5685549645716}, "policy_reward_mean": {"AGENT-2": 17.222723130897883, "AGENT-3": 30.93801981532488, "AGENT-0": 14.274905675008224, "AGENT-1": 35.0915872442942}, "custom_metrics": {"mean_ego_speed_mean": 39.7673025, "mean_ego_speed_min": 19.4165, "mean_ego_speed_max": 49.889250000000004, "distance_travelled_mean": 107.75877999999999, "distance_travelled_min": 26.68775, "distance_travelled_max": 124.93674999999999}, "hist_stats": {"episode_reward": [1071.6185163663813, -535.9099660622334, 1775.89126416078, 680.326331117852, 1557.1050306215589, -586.1264738294449, 2010.414628529356, -902.4962627637144, 640.4814898967675, 614.7162787413918, 1531.8168020116393, 883.2075086192945, 1129.0316389160198, 878.3501894107685, 1217.1836003151473, 686.3401966258695, 1141.4298449147798, 547.6690566383908, 1122.0723372122445, -637.819455115041, -385.84311833381093, -284.5762734018316, -438.4362588728087, -461.06843382324615, -583.4971659712003, -760.8054681322271, -641.3916526313712, -284.43368142855394, -226.94425734509332, -637.5076939072765, -775.6272398607272, -866.4757012675701, -432.2751984844475, -654.9399219410419, -1069.6836945790826, -935.4733425391001, -791.6124197659516, -715.0328513775296, 142.63618142305563, 1710.4797429853863, -774.6716039069177, 729.0742031699625, -723.5887827049563, -810.793069247216, -508.83659930032167, 863.3103479947879, -1071.9500318643982, -606.4987978889254, 1018.1274076932665, 609.5037622256693, 964.1948510835621, 798.1148464712973, 555.7405784552349, 662.2676962637656, -370.77232875167863, 1375.4181516020078, 693.9524826090486, 1031.9841762804767, 545.1777356712447, -222.07510196708216, -366.8476184677753, -758.7425272829444, -1057.8787917618074, -721.6955982604578, -728.2132876598544, -689.2598676219104, -146.2881304472709, -768.681724302722, -373.0223249729676, -389.92405793365714, 974.9872956486527, -1600.7924011511175, 2081.259705275066, -570.7023169598209, 765.4576198304378, -270.1385673362668, 854.2929104154534, -979.0053891542831, 1487.1685104492187, 742.569729280066, 653.0844760506125, 493.8662078013728, 1559.117271128255, 942.0685916690474, 593.0566926701772, 917.6235950072421, 740.7795567163323, 784.9458491035626, 856.061116826219, -705.2083390352801, -229.170434216992, -369.6465890883651, -607.3638686843751, -449.558383848151, -303.5260498589627, -373.50565894658774, -1114.5507017867803, -86.85073083931928, -1259.1226851280583, -264.3935275356884], "episode_lengths": [192, 66, 264, 197, 240, 122, 277, 133, 100, 117, 191, 126, 127, 124, 142, 116, 146, 121, 151, 136, 118, 100, 121, 124, 127, 149, 127, 118, 120, 144, 159, 142, 128, 130, 140, 139, 134, 130, 138, 224, 124, 156, 129, 168, 43, 156, 128, 121, 121, 116, 144, 117, 106, 125, 121, 137, 127, 143, 124, 124, 118, 145, 145, 131, 134, 131, 29, 130, 143, 125, 207, 152, 242, 99, 161, 143, 217, 117, 137, 109, 114, 123, 152, 143, 120, 116, 122, 118, 126, 179, 101, 133, 132, 130, 124, 53, 163, 147, 174, 110], "policy_AGENT-2_reward": [-9.261797140140711, -165.27527097084294, 398.04619949288406, -40.0907792275268, 288.8410794914807, -168.7138373944875, 520.6728844991105, -237.3622758724224, 138.18387173288156, 124.88150726347406, 259.6399038553404, 235.09948904555748, 298.82077419625733, 238.48892009671212, 289.6524693123338, 169.09406006708386, 172.2813477876061, 200.58820249409433, 216.79782678450988, -131.44491698723257, -51.410912590130074, -59.966609180788204, -79.55637324861793, -88.04513005529229, -100.36033159948398, -138.98573392226203, -151.85366971775065, -35.444080312806946, -9.411733561921746, -124.49997095097608, -123.42319105955703, -191.5302779352356, -42.803661251255384, -120.57276990428319, -247.0679740657671, -206.37219155698685, -188.40408511341607, -158.37092676226928, -41.32787438051604, 394.7649723862703, -219.1637071432462, -12.203651122152007, -216.51489799052462, -49.893671012784864, -150.89179026435016, 35.446651571241944, -251.17353070718116, -173.79627157359144, 255.64109487661815, 101.72765231777707, 252.64944489034767, 199.33221012867128, 72.42440542650229, 174.27049947086968, -34.75332573168491, 342.54466377290845, 192.61689710802477, 261.4802811908845, 69.16787799701386, -65.0145106875019, -102.1622243274164, -182.91843579858266, -138.20963787263793, -167.20587668972053, -171.2634625783503, -166.91152296823455, -8.640323817419185, -177.90045610368944, -8.062283051420746, -96.28210463226952, -8.394133140397622, -450.2958458143081, 522.3911423875529, -181.496320727939, 5.374810196966136, -147.1197856641722, 245.90838478154507, -251.7522550492148, 365.33151755028894, 141.61671606047497, 144.20284737696238, 65.67515187411797, 408.69980393656886, 269.8478460496327, 54.867896356618424, 235.13342798155026, 205.1053033328497, 220.09463464518072, 218.15075810196822, -76.74073234875412, -7.966895711395901, -80.11814545945636, -129.5290234328841, -100.94777179619078, -49.175741352451915, -121.19772526036373, -119.32872939385462, 0.6435072604281231, -128.8324495803773, -126.51300849288472], "policy_AGENT-3_reward": [-9.159186748130274, -165.28016566768673, 425.9720875059928, -40.39705655019153, 398.4127613663399, -168.83639709228186, 423.3009828630162, -219.96105952521717, 182.20536214139344, 193.25729699972317, 533.4277756029952, 232.49671018647342, 305.67579052354364, 210.74818485317968, 337.04053044848735, 193.58581509932543, 416.5916646124743, 170.81301052655633, 433.24985129579966, -146.44792040496463, -51.45495456374689, -87.30036398710351, -79.77472190976818, -151.13082286863744, -100.36983693140678, -139.10502268401345, -138.1365414237744, -35.423234593510614, -9.31243604320068, -130.75903306242174, -140.57111784608827, -166.12227677098116, -42.76063361564501, -120.55212324069606, -218.65836632453573, -165.11575101283145, -197.50252378658647, -147.52533706478454, -41.59990852764086, 404.8882972396771, -219.32134894082824, -12.370564306941713, -216.4741631326343, -338.48845406522264, -151.16524044909377, 35.50552056582252, -261.6058445223344, -173.74558002875608, 263.9707303384836, 188.99485964897352, 294.59011798212305, 175.05214750934343, 192.5675543737366, 137.9954904540606, -34.794188009453485, 363.50931435180524, 179.1560608219861, 292.8354099739847, 222.9667717188616, -64.24712144979307, -101.66137202646905, -132.76085207608367, -268.28497089604423, -162.8928367975284, -175.55072080427237, -142.93984536675757, -8.551719730006033, -176.74823782643395, -8.058560616461179, -102.84660414455983, -8.569325627077276, -418.98375459767664, 436.5301276644807, -181.4744531013856, 5.301467496210702, -147.3433788847007, 213.24448179785034, -251.88083763779886, 396.8254259249095, 224.35862958973433, 189.118195430111, 200.81291279334013, 461.1366255845217, 201.7254735064204, 227.46400580941773, 187.47597127895915, 204.97839302290728, 221.28087122934252, 181.87148300384362, -76.83182425232536, -8.01967851903959, -80.14888915781883, -135.3518997594804, -91.57431398525785, -49.11959369050491, -121.41952166892204, -119.42632778024631, 37.807269744237324, -128.9817799837413, -20.048855266460897], "policy_AGENT-0_reward": [521.904045335818, -102.6651199438098, 337.16944733206003, 395.52722300490734, 242.28263479916865, -146.1432975354091, 443.2685199622153, -225.80014800709787, 160.08531529085974, 151.85233526387464, 293.3316319039595, 183.8787333672105, 242.4843163546414, 193.35170071122442, 300.1808108745618, 154.07174775351208, 379.50274210900545, 88.15556314299688, 248.5806547028983, -202.472244453464, -163.15480684197954, -68.72865390237862, -126.28203269057745, -107.01766798974543, -214.7724103371064, -261.33548921670155, -197.39307312061408, -106.92371523796376, -104.98576475672063, -210.51486600344845, -275.1676251864256, -273.7759247901501, -161.07822369486513, -226.64069802164585, -322.3474392879309, -284.194150594643, -190.87011864881632, -204.79462421926593, 92.52262522687359, 421.8680460014869, -168.32188077408304, 357.43356823950944, -132.96687290066487, -372.94642856062507, -103.389273848648, 376.5714170272855, -298.1320850555186, -151.89067427192242, 260.71712993072106, 216.61164299275543, 189.26264639464472, 224.38663492756197, 72.9788917918474, 174.82730775300922, -175.226080923547, 326.3888993715042, 137.88225658582942, 219.92660044540003, 183.15498906456787, -46.18130943527204, -81.4988999545232, -240.5048547706966, -308.8745727488764, -218.92031767289905, -179.01872995420803, -209.44675602697424, -64.5710852269479, -227.5329144434102, -165.679845344616, -84.56240065533089, 499.599310023269, -350.75972807702163, 534.4032202230046, -103.93292430149477, 357.0314919731114, 25.633595122562063, 148.7928534480887, -237.75091162523788, 359.25505405066514, 188.27316391056914, 175.01537431352932, 161.2733775913795, 326.7573799105694, 216.58987473804484, 255.33448015595079, 259.31870294282993, 164.73512172037053, 171.84953818136535, 239.20841266578813, -292.769271798179, -106.6071691752843, -101.80047963074297, -190.9337417885735, -150.7969561938011, -102.54916015369152, -65.48777930057906, -455.0928518615291, -62.67022740672284, -519.5186822763613, -98.34750049344362], "policy_AGENT-1_reward": [568.1354549188351, -102.68940947989378, 614.7035298298451, 365.28694389066317, 627.5685549645716, -102.4329418072669, 623.1722412050156, -219.37277935897566, 160.00694073163285, 144.72513921432034, 445.41749064934385, 231.73257602005205, 282.05075784157765, 235.76138374965197, 290.30978967976506, 169.5885737059481, 173.05409040569356, 88.11228047474322, 223.4440044290388, -157.45437326938026, -119.82244433795442, -68.58064633156131, -152.82313102384543, -114.87481290957072, -167.99458710320297, -221.3792223092498, -154.00836836923227, -106.6426512842728, -103.23432298325005, -171.7338238904297, -236.46530576865598, -235.04722177120328, -185.63267992268194, -187.17433077441694, -281.6099149008485, -279.79124937463916, -214.8356922171321, -204.3419633312104, 133.04133910433887, 488.95842735795054, -167.86466704875994, 396.21485035954737, -157.63284868113195, -49.46451560858271, -103.39029473822988, 415.7867588304379, -261.0385715793638, -107.06627201465474, 237.79845254744367, 102.16960726616385, 227.69264181644525, 199.34385390572072, 217.7697268631487, 175.17439858582722, -125.99873408699341, 342.97527410578925, 184.29726809320812, 257.74188467020883, 69.88809689080144, -46.632160394515374, -81.52512215936659, -202.55838463758153, -342.50961024424856, -172.6765671003098, -202.38037432302366, -169.9617432599442, -64.5250016728978, -186.500115929188, -191.22163596046957, -106.23294850149736, 492.3514443928591, -380.7530726621127, 587.9352150000288, -103.79861882900127, 397.7498501641498, -1.3089979099562394, 246.3471903879681, -237.62138484203166, 365.75651292335664, 188.32121971928723, 144.74805893000982, 66.10476554253479, 362.5234616965954, 253.90539737494944, 55.390310348189985, 235.69549280390243, 165.9607386402053, 171.72080504767374, 216.83046305461903, -258.8665106360218, -106.5766908112721, -107.57907484034715, -151.54920370343729, -106.23934187290124, -102.68155466231443, -65.40063271672288, -420.7027927511487, -62.631280437262056, -481.7897732875779, -19.48416328289915]}, "sampler_perf": {"mean_env_wait_ms": 73.1952152968448, "mean_raw_obs_processing_ms": 2.964878324718076, "mean_inference_ms": 3.0894074408218852, "mean_action_processing_ms": 0.18063931562303823}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 67200, "timers": {"sample_time_ms": 105832.16, "sample_throughput": 39.685, "load_time_ms": 15.287, "load_throughput": 274746.354, "learn_time_ms": 15758.019, "learn_throughput": 266.531, "update_time_ms": 7.951}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 11.413167953491211, "policy_loss": -0.045345187187194824, "vf_loss": 11.455018043518066, "vf_explained_var": 0.9872167110443115, "kl": 0.017479075118899345, "entropy": 1.1010035276412964, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 17.81431007385254, "policy_loss": -0.048872970044612885, "vf_loss": 17.859447479248047, "vf_explained_var": 0.9814340472221375, "kl": 0.018674887716770172, "entropy": 1.189595341682434, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 27.61019515991211, "policy_loss": -0.05096793547272682, "vf_loss": 27.657642364501953, "vf_explained_var": 0.9652971029281616, "kl": 0.01760018989443779, "entropy": 1.1848844289779663, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 9.82773494720459, "policy_loss": -0.05557120218873024, "vf_loss": 9.877610206604004, "vf_explained_var": 0.9883252382278442, "kl": 0.018986854702234268, "entropy": 1.113445520401001, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 67200, "num_steps_trained": 67200}, "done": false, "episodes_total": 548, "training_iteration": 16, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_14-56-08", "timestamp": 1624200968, "time_this_iter_s": 88.60082483291626, "time_total_s": 2181.6393988132477, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f0246950>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f0246830>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f02460e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246200>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c320>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f02460e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246200>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c320>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f02460e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246200>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c320>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f02460e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246200>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c320>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f03d9b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2181.6393988132477, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 54.591338582677174, "ram_util_percent": 87.96220472440945}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2081.259705275066, "episode_reward_min": -1600.7924011511175, "episode_reward_mean": 142.76923436539977, "episode_len_mean": 140.98, "episodes_this_iter": 29, "policy_reward_min": {"AGENT-2": -450.2958458143081, "AGENT-3": -418.98375459767664, "AGENT-0": -519.5186822763613, "AGENT-1": -481.7897732875779}, "policy_reward_max": {"AGENT-2": 522.3911423875529, "AGENT-3": 533.4277756029952, "AGENT-0": 534.4032202230046, "AGENT-1": 637.5776461472475}, "policy_reward_mean": {"AGENT-2": 27.996959568866725, "AGENT-3": 44.95031306193574, "AGENT-0": 24.806904521896822, "AGENT-1": 45.01505721270061}, "custom_metrics": {"mean_ego_speed_mean": 39.594210000000004, "mean_ego_speed_min": 19.4165, "mean_ego_speed_max": 50.02825, "distance_travelled_mean": 109.072095, "distance_travelled_min": 26.68775, "distance_travelled_max": 124.90400000000001}, "hist_stats": {"episode_reward": [1690.2708337098104, -880.9734039766956, 1718.3581178632287, -680.523118270253, 963.7582086306641, -1132.6425737801135, 1168.9582875040028, 719.8715958519633, 1129.779369945647, 703.3572557669634, 1703.4502167852813, 854.3691228690682, 1234.4094121351216, 818.4784619075867, 1467.2289262173629, 531.6551863980676, -472.879373378597, -928.6772640177612, -692.2638293931901, -177.08832555911349, -421.28597651258326, -740.479653180073, -454.6625533899939, -177.22296472751685, -882.6867691862747, -184.3664546705661, -502.9986601562806, -554.4930952065351, -704.7505497428447, -222.07510196708216, -366.8476184677753, -758.7425272829444, -1057.8787917618074, -721.6955982604578, -728.2132876598544, -689.2598676219104, -146.2881304472709, -768.681724302722, -373.0223249729676, -389.92405793365714, 974.9872956486527, -1600.7924011511175, 2081.259705275066, -570.7023169598209, 765.4576198304378, -270.1385673362668, 854.2929104154534, -979.0053891542831, 1487.1685104492187, 742.569729280066, 653.0844760506125, 493.8662078013728, 1559.117271128255, 942.0685916690474, 593.0566926701772, 917.6235950072421, 740.7795567163323, 784.9458491035626, 856.061116826219, -705.2083390352801, -229.170434216992, -369.6465890883651, -607.3638686843751, -449.558383848151, -303.5260498589627, -373.50565894658774, -1114.5507017867803, -86.85073083931928, -1259.1226851280583, -264.3935275356884, 1071.6185163663813, -535.9099660622334, 1775.89126416078, 680.326331117852, 1557.1050306215589, -586.1264738294449, 2010.414628529356, -902.4962627637144, 640.4814898967675, 614.7162787413918, 1531.8168020116393, 883.2075086192945, 1129.0316389160198, 878.3501894107685, 1217.1836003151473, 686.3401966258695, 1141.4298449147798, 547.6690566383908, 1122.0723372122445, -637.819455115041, -385.84311833381093, -284.5762734018316, -438.4362588728087, -461.06843382324615, -583.4971659712003, -760.8054681322271, -641.3916526313712, -284.43368142855394, -226.94425734509332, -637.5076939072765], "episode_lengths": [230, 100, 221, 125, 234, 214, 273, 130, 180, 127, 158, 123, 169, 126, 199, 117, 122, 134, 134, 100, 128, 127, 121, 34, 137, 105, 127, 122, 126, 124, 118, 145, 145, 131, 134, 131, 29, 130, 143, 125, 207, 152, 242, 99, 161, 143, 217, 117, 137, 109, 114, 123, 152, 143, 120, 116, 122, 118, 126, 179, 101, 133, 132, 130, 124, 53, 163, 147, 174, 110, 192, 66, 264, 197, 240, 122, 277, 133, 100, 117, 191, 126, 127, 124, 142, 116, 146, 121, 151, 136, 118, 100, 121, 124, 127, 149, 127, 118, 120, 144], "policy_AGENT-2_reward": [351.21622048872496, -254.82310967931824, 492.2364160285956, -171.16800859073072, 319.7119881591211, -286.8826950522983, 22.997691180159006, 197.3820050636003, 209.9502940265951, 173.84750930745514, 376.10994141464533, 210.71713218774863, 135.59489224642417, 215.86600301538266, 320.45344418638865, 97.29542954961114, -94.74098316784129, -194.98867847952317, -176.87422483595657, -12.919675679700017, -45.61423291782537, -174.0767850027375, -79.64555677454871, -18.854185006984356, -202.10535266640215, -24.89007804552063, -73.52402143470506, -130.52545872571483, -180.5194234354331, -65.0145106875019, -102.1622243274164, -182.91843579858266, -138.20963787263793, -167.20587668972053, -171.2634625783503, -166.91152296823455, -8.640323817419185, -177.90045610368944, -8.062283051420746, -96.28210463226952, -8.394133140397622, -450.2958458143081, 522.3911423875529, -181.496320727939, 5.374810196966136, -147.1197856641722, 245.90838478154507, -251.7522550492148, 365.33151755028894, 141.61671606047497, 144.20284737696238, 65.67515187411797, 408.69980393656886, 269.8478460496327, 54.867896356618424, 235.13342798155026, 205.1053033328497, 220.09463464518072, 218.15075810196822, -76.74073234875412, -7.966895711395901, -80.11814545945636, -129.5290234328841, -100.94777179619078, -49.175741352451915, -121.19772526036373, -119.32872939385462, 0.6435072604281231, -128.8324495803773, -126.51300849288472, -9.261797140140711, -165.27527097084294, 398.04619949288406, -40.0907792275268, 288.8410794914807, -168.7138373944875, 520.6728844991105, -237.3622758724224, 138.18387173288156, 124.88150726347406, 259.6399038553404, 235.09948904555748, 298.82077419625733, 238.48892009671212, 289.6524693123338, 169.09406006708386, 172.2813477876061, 200.58820249409433, 216.79782678450988, -131.44491698723257, -51.410912590130074, -59.966609180788204, -79.55637324861793, -88.04513005529229, -100.36033159948398, -138.98573392226203, -151.85366971775065, -35.444080312806946, -9.411733561921746, -124.49997095097608], "policy_AGENT-3_reward": [327.81503942974734, -208.6459751064124, 305.5616384086464, -171.172215862158, 196.19926752432778, -294.7833356076254, 23.023502731669527, 181.39825704792997, 406.5984826409647, 156.74275124679204, 498.7683557574729, 212.8309969021696, 504.26172115005556, 214.49810042477276, 462.84676125019826, 188.50694421766545, -94.87458425372742, -239.366756439327, -186.5402830995843, -35.317847577404734, -45.62771994987342, -183.6216490939735, -79.63982308096486, -18.965148258811514, -196.2336570502657, -24.937918491198072, -73.77513379456977, -150.14762251676586, -170.51397055486092, -64.24712144979307, -101.66137202646905, -132.76085207608367, -268.28497089604423, -162.8928367975284, -175.55072080427237, -142.93984536675757, -8.551719730006033, -176.74823782643395, -8.058560616461179, -102.84660414455983, -8.569325627077276, -418.98375459767664, 436.5301276644807, -181.4744531013856, 5.301467496210702, -147.3433788847007, 213.24448179785034, -251.88083763779886, 396.8254259249095, 224.35862958973433, 189.118195430111, 200.81291279334013, 461.1366255845217, 201.7254735064204, 227.46400580941773, 187.47597127895915, 204.97839302290728, 221.28087122934252, 181.87148300384362, -76.83182425232536, -8.01967851903959, -80.14888915781883, -135.3518997594804, -91.57431398525785, -49.11959369050491, -121.41952166892204, -119.42632778024631, 37.807269744237324, -128.9817799837413, -20.048855266460897, -9.159186748130274, -165.28016566768673, 425.9720875059928, -40.39705655019153, 398.4127613663399, -168.83639709228186, 423.3009828630162, -219.96105952521717, 182.20536214139344, 193.25729699972317, 533.4277756029952, 232.49671018647342, 305.67579052354364, 210.74818485317968, 337.04053044848735, 193.58581509932543, 416.5916646124743, 170.81301052655633, 433.24985129579966, -146.44792040496463, -51.45495456374689, -87.30036398710351, -79.77472190976818, -151.13082286863744, -100.36983693140678, -139.10502268401345, -138.1365414237744, -35.423234593510614, -9.31243604320068, -130.75903306242174], "policy_AGENT-0_reward": [373.66192764408896, -208.66159834422174, 427.72346541051843, -192.3792318030987, 127.50550628731318, -295.0706237487561, 517.1166357332401, 147.73032303110796, 175.87672786761726, 196.68178100228766, 409.7580182956061, 225.98737351276853, 458.3995161198878, 169.27760428596656, 282.5252997744453, 148.118542383837, -141.5918319895383, -233.91307733548473, -152.47803259842595, -64.29304424828764, -189.37932384397578, -178.43633579687804, -172.10906279237724, -69.75782721781867, -228.66965934737465, -67.14271097797554, -199.42020709705668, -124.4222694519802, -176.64744509233049, -46.18130943527204, -81.4988999545232, -240.5048547706966, -308.8745727488764, -218.92031767289905, -179.01872995420803, -209.44675602697424, -64.5710852269479, -227.5329144434102, -165.679845344616, -84.56240065533089, 499.599310023269, -350.75972807702163, 534.4032202230046, -103.93292430149477, 357.0314919731114, 25.633595122562063, 148.7928534480887, -237.75091162523788, 359.25505405066514, 188.27316391056914, 175.01537431352932, 161.2733775913795, 326.7573799105694, 216.58987473804484, 255.33448015595079, 259.31870294282993, 164.73512172037053, 171.84953818136535, 239.20841266578813, -292.769271798179, -106.6071691752843, -101.80047963074297, -190.9337417885735, -150.7969561938011, -102.54916015369152, -65.48777930057906, -455.0928518615291, -62.67022740672284, -519.5186822763613, -98.34750049344362, 521.904045335818, -102.6651199438098, 337.16944733206003, 395.52722300490734, 242.28263479916865, -146.1432975354091, 443.2685199622153, -225.80014800709787, 160.08531529085974, 151.85233526387464, 293.3316319039595, 183.8787333672105, 242.4843163546414, 193.35170071122442, 300.1808108745618, 154.07174775351208, 379.50274210900545, 88.15556314299688, 248.5806547028983, -202.472244453464, -163.15480684197954, -68.72865390237862, -126.28203269057745, -107.01766798974543, -214.7724103371064, -261.33548921670155, -197.39307312061408, -106.92371523796376, -104.98576475672063, -210.51486600344845], "policy_AGENT-1_reward": [637.5776461472475, -208.8427208467437, 492.83659801546946, -145.80366201426472, 320.34144665990283, -255.9059193714331, 605.8204578589332, 193.36101070932486, 337.353865410469, 176.08521421042832, 418.8139013175577, 204.8336202663813, 136.15328261875217, 218.83675418146393, 401.4034210063319, 97.73427024695377, -141.6719739674901, -260.4087517634263, -176.3712888592234, -64.55775805372107, -140.66469980090875, -204.34488328648393, -123.26811074210289, -69.64580424390232, -255.67810012223185, -67.39574715587182, -156.27929782994875, -149.3977445120741, -177.06971066022058, -46.632160394515374, -81.52512215936659, -202.55838463758153, -342.50961024424856, -172.6765671003098, -202.38037432302366, -169.9617432599442, -64.5250016728978, -186.500115929188, -191.22163596046957, -106.23294850149736, 492.3514443928591, -380.7530726621127, 587.9352150000288, -103.79861882900127, 397.7498501641498, -1.3089979099562394, 246.3471903879681, -237.62138484203166, 365.75651292335664, 188.32121971928723, 144.74805893000982, 66.10476554253479, 362.5234616965954, 253.90539737494944, 55.390310348189985, 235.69549280390243, 165.9607386402053, 171.72080504767374, 216.83046305461903, -258.8665106360218, -106.5766908112721, -107.57907484034715, -151.54920370343729, -106.23934187290124, -102.68155466231443, -65.40063271672288, -420.7027927511487, -62.631280437262056, -481.7897732875779, -19.48416328289915, 568.1354549188351, -102.68940947989378, 614.7035298298451, 365.28694389066317, 627.5685549645716, -102.4329418072669, 623.1722412050156, -219.37277935897566, 160.00694073163285, 144.72513921432034, 445.41749064934385, 231.73257602005205, 282.05075784157765, 235.76138374965197, 290.30978967976506, 169.5885737059481, 173.05409040569356, 88.11228047474322, 223.4440044290388, -157.45437326938026, -119.82244433795442, -68.58064633156131, -152.82313102384543, -114.87481290957072, -167.99458710320297, -221.3792223092498, -154.00836836923227, -106.6426512842728, -103.23432298325005, -171.7338238904297]}, "sampler_perf": {"mean_env_wait_ms": 71.66101563996986, "mean_raw_obs_processing_ms": 2.907681361026424, "mean_inference_ms": 3.0310636858865236, "mean_action_processing_ms": 0.17735496229774372}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 71400, "timers": {"sample_time_ms": 96959.203, "sample_throughput": 43.317, "load_time_ms": 14.943, "load_throughput": 281067.99, "learn_time_ms": 15142.373, "learn_throughput": 277.367, "update_time_ms": 7.761}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 18.415874481201172, "policy_loss": -0.04117421433329582, "vf_loss": 18.453737258911133, "vf_explained_var": 0.9814077019691467, "kl": 0.0165532436221838, "entropy": 1.0802011489868164, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 18.391355514526367, "policy_loss": -0.04830360412597656, "vf_loss": 18.43581771850586, "vf_explained_var": 0.9833975434303284, "kl": 0.01920575648546219, "entropy": 1.1971887350082397, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 24.36648941040039, "policy_loss": -0.0485495962202549, "vf_loss": 24.411584854125977, "vf_explained_var": 0.9758745431900024, "kl": 0.017270484939217567, "entropy": 1.19979727268219, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 14.694968223571777, "policy_loss": -0.05114370584487915, "vf_loss": 14.741291046142578, "vf_explained_var": 0.9857613444328308, "kl": 0.016073986887931824, "entropy": 1.1217924356460571, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 71400, "num_steps_trained": 71400}, "done": false, "episodes_total": 577, "training_iteration": 17, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_14-57-43", "timestamp": 1624201063, "time_this_iter_s": 95.2778639793396, "time_total_s": 2276.9172627925873, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f024b9e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f0366cb0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd601a3e5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9290>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd601a3e5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9290>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd601a3e5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9290>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd601a3e5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9290>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f0246560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2276.9172627925873, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 53.21492537313432, "ram_util_percent": 87.97388059701493}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2010.414628529356, "episode_reward_min": -1409.3423906930502, "episode_reward_mean": 148.69475157872813, "episode_len_mean": 143.87, "episodes_this_iter": 28, "policy_reward_min": {"AGENT-2": -353.82555823568316, "AGENT-1": -481.7897732875779, "AGENT-3": -358.37509836103027, "AGENT-0": -519.5186822763613}, "policy_reward_max": {"AGENT-2": 520.6728844991105, "AGENT-1": 637.5776461472475, "AGENT-3": 546.5639907682897, "AGENT-0": 521.904045335818}, "policy_reward_mean": {"AGENT-2": 34.97885804878553, "AGENT-1": 40.56316410133672, "AGENT-3": 60.833929312643086, "AGENT-0": 12.318800115962913}, "custom_metrics": {"mean_ego_speed_mean": 39.729040000000005, "mean_ego_speed_min": 19.4165, "mean_ego_speed_max": 50.02825, "distance_travelled_mean": 108.64105500000001, "distance_travelled_min": 37.61024999999999, "distance_travelled_max": 124.90400000000001}, "hist_stats": {"episode_reward": [-1001.4603731966636, 805.7967364988202, -929.4480262120602, 236.40362680336546, -1409.3423906930502, 1570.9463405015624, -1153.8621034188702, 1332.4718502115447, 1161.5316798899241, 618.4591006359896, 1781.6166668825986, 866.2134833493417, 1259.6321074033108, 962.1932539440077, 1036.2411741677984, 873.0854157097157, 1391.724909773425, 754.9022704836891, -372.9292754193483, -359.5010500107102, -1313.4266008598122, -573.0281302326341, -788.5389170086655, -310.06069883275, -754.2780028750386, -750.624294035761, -564.8671261124348, -615.2354493524657, 784.9458491035626, 856.061116826219, -705.2083390352801, -229.170434216992, -369.6465890883651, -607.3638686843751, -449.558383848151, -303.5260498589627, -373.50565894658774, -1114.5507017867803, -86.85073083931928, -1259.1226851280583, -264.3935275356884, 1071.6185163663813, -535.9099660622334, 1775.89126416078, 680.326331117852, 1557.1050306215589, -586.1264738294449, 2010.414628529356, -902.4962627637144, 640.4814898967675, 614.7162787413918, 1531.8168020116393, 883.2075086192945, 1129.0316389160198, 878.3501894107685, 1217.1836003151473, 686.3401966258695, 1141.4298449147798, 547.6690566383908, 1122.0723372122445, -637.819455115041, -385.84311833381093, -284.5762734018316, -438.4362588728087, -461.06843382324615, -583.4971659712003, -760.8054681322271, -641.3916526313712, -284.43368142855394, -226.94425734509332, -637.5076939072765, 1690.2708337098104, -880.9734039766956, 1718.3581178632287, -680.523118270253, 963.7582086306641, -1132.6425737801135, 1168.9582875040028, 719.8715958519633, 1129.779369945647, 703.3572557669634, 1703.4502167852813, 854.3691228690682, 1234.4094121351216, 818.4784619075867, 1467.2289262173629, 531.6551863980676, -472.879373378597, -928.6772640177612, -692.2638293931901, -177.08832555911349, -421.28597651258326, -740.479653180073, -454.6625533899939, -177.22296472751685, -882.6867691862747, -184.3664546705661, -502.9986601562806, -554.4930952065351, -704.7505497428447], "episode_lengths": [135, 205, 152, 200, 138, 225, 138, 208, 157, 132, 165, 113, 180, 135, 131, 144, 154, 138, 67, 67, 161, 159, 132, 114, 146, 149, 127, 146, 118, 126, 179, 101, 133, 132, 130, 124, 53, 163, 147, 174, 110, 192, 66, 264, 197, 240, 122, 277, 133, 100, 117, 191, 126, 127, 124, 142, 116, 146, 121, 151, 136, 118, 100, 121, 124, 127, 149, 127, 118, 120, 144, 230, 100, 221, 125, 234, 214, 273, 130, 180, 127, 158, 123, 169, 126, 199, 117, 122, 134, 134, 100, 128, 127, 121, 34, 137, 105, 127, 122, 126], "policy_AGENT-2_reward": [-250.2257928786051, 244.2726115807166, -252.30890455299456, 160.88408109201694, -353.82555823568316, 264.29289840832297, -317.1433391110218, 222.78502324568603, 220.37902037813163, 154.43240058573375, 365.1169195359187, 195.0904486306537, 116.60461456046934, 245.70377231126628, 271.81832420353567, 278.7255076228796, 314.2458237751582, 217.2128050001598, -116.02892941208195, -113.3408263008798, -249.6321540499632, -134.19272714779348, -180.17405648768798, -102.80503430980875, -9.7492772984832, -8.593188677019581, -131.4308422100656, -13.398103304826929, 220.09463464518072, 218.15075810196822, -76.74073234875412, -7.966895711395901, -80.11814545945636, -129.5290234328841, -100.94777179619078, -49.175741352451915, -121.19772526036373, -119.32872939385462, 0.6435072604281231, -128.8324495803773, -126.51300849288472, -9.261797140140711, -165.27527097084294, 398.04619949288406, -40.0907792275268, 288.8410794914807, -168.7138373944875, 520.6728844991105, -237.3622758724224, 138.18387173288156, 124.88150726347406, 259.6399038553404, 235.09948904555748, 298.82077419625733, 238.48892009671212, 289.6524693123338, 169.09406006708386, 172.2813477876061, 200.58820249409433, 216.79782678450988, -131.44491698723257, -51.410912590130074, -59.966609180788204, -79.55637324861793, -88.04513005529229, -100.36033159948398, -138.98573392226203, -151.85366971775065, -35.444080312806946, -9.411733561921746, -124.49997095097608, 351.21622048872496, -254.82310967931824, 492.2364160285956, -171.16800859073072, 319.7119881591211, -286.8826950522983, 22.997691180159006, 197.3820050636003, 209.9502940265951, 173.84750930745514, 376.10994141464533, 210.71713218774863, 135.59489224642417, 215.86600301538266, 320.45344418638865, 97.29542954961114, -94.74098316784129, -194.98867847952317, -176.87422483595657, -12.919675679700017, -45.61423291782537, -174.0767850027375, -79.64555677454871, -18.854185006984356, -202.10535266640215, -24.89007804552063, -73.52402143470506, -130.52545872571483, -180.5194234354331], "policy_AGENT-1_reward": [-230.1073421422188, 244.87482508078008, -221.51266694475692, 161.40275643294808, -327.42175338241316, 612.215078090129, -299.5344019952572, 600.8308638125251, 262.7261971178489, 173.4893186057953, 365.5476217353225, 217.58420294700386, 117.0330639014172, 255.5647251684875, 259.55975636532634, 15.776714095369258, 362.2809596656409, 183.94722336789744, -70.55796592315708, -66.31259804172379, -381.4493342601536, -144.62395063442304, -225.29994739934634, -74.57749802839604, -348.33215971837717, -382.3155980481178, -157.1687501955648, -276.22473131108273, 171.72080504767374, 216.83046305461903, -258.8665106360218, -106.5766908112721, -107.57907484034715, -151.54920370343729, -106.23934187290124, -102.68155466231443, -65.40063271672288, -420.7027927511487, -62.631280437262056, -481.7897732875779, -19.48416328289915, 568.1354549188351, -102.68940947989378, 614.7035298298451, 365.28694389066317, 627.5685549645716, -102.4329418072669, 623.1722412050156, -219.37277935897566, 160.00694073163285, 144.72513921432034, 445.41749064934385, 231.73257602005205, 282.05075784157765, 235.76138374965197, 290.30978967976506, 169.5885737059481, 173.05409040569356, 88.11228047474322, 223.4440044290388, -157.45437326938026, -119.82244433795442, -68.58064633156131, -152.82313102384543, -114.87481290957072, -167.99458710320297, -221.3792223092498, -154.00836836923227, -106.6426512842728, -103.23432298325005, -171.7338238904297, 637.5776461472475, -208.8427208467437, 492.83659801546946, -145.80366201426472, 320.34144665990283, -255.9059193714331, 605.8204578589332, 193.36101070932486, 337.353865410469, 176.08521421042832, 418.8139013175577, 204.8336202663813, 136.15328261875217, 218.83675418146393, 401.4034210063319, 97.73427024695377, -141.6719739674901, -260.4087517634263, -176.3712888592234, -64.55775805372107, -140.66469980090875, -204.34488328648393, -123.26811074210289, -69.64580424390232, -255.67810012223185, -67.39574715587182, -156.27929782994875, -149.3977445120741, -177.06971066022058], "policy_AGENT-3_reward": [-242.73882434503457, 187.30436806774844, -234.06413447209945, -45.294098098886565, -358.37509836103027, 466.56785331759727, -264.2986553629845, 320.71528098718323, 425.85246736627033, 174.4999993692827, 546.5639907682897, 235.84955672915487, 538.0673760957745, 204.6025020094392, 284.23500992216606, 337.60094827460887, 435.35187936293613, 214.7903608524408, -116.09219060858126, -113.39627029417733, -266.06101408080576, -135.05230467553181, -180.11488904724118, -58.18675557940196, -9.823576620121926, -8.56890375184329, -142.01539953323226, -13.380734905372142, 221.28087122934252, 181.87148300384362, -76.83182425232536, -8.01967851903959, -80.14888915781883, -135.3518997594804, -91.57431398525785, -49.11959369050491, -121.41952166892204, -119.42632778024631, 37.807269744237324, -128.9817799837413, -20.048855266460897, -9.159186748130274, -165.28016566768673, 425.9720875059928, -40.39705655019153, 398.4127613663399, -168.83639709228186, 423.3009828630162, -219.96105952521717, 182.20536214139344, 193.25729699972317, 533.4277756029952, 232.49671018647342, 305.67579052354364, 210.74818485317968, 337.04053044848735, 193.58581509932543, 416.5916646124743, 170.81301052655633, 433.24985129579966, -146.44792040496463, -51.45495456374689, -87.30036398710351, -79.77472190976818, -151.13082286863744, -100.36983693140678, -139.10502268401345, -138.1365414237744, -35.423234593510614, -9.31243604320068, -130.75903306242174, 327.81503942974734, -208.6459751064124, 305.5616384086464, -171.172215862158, 196.19926752432778, -294.7833356076254, 23.023502731669527, 181.39825704792997, 406.5984826409647, 156.74275124679204, 498.7683557574729, 212.8309969021696, 504.26172115005556, 214.49810042477276, 462.84676125019826, 188.50694421766545, -94.87458425372742, -239.366756439327, -186.5402830995843, -35.317847577404734, -45.62771994987342, -183.6216490939735, -79.63982308096486, -18.965148258811514, -196.2336570502657, -24.937918491198072, -73.77513379456977, -150.14762251676586, -170.51397055486092], "policy_AGENT-0_reward": [-278.3884138308046, 129.34493176957577, -221.5623202422105, -40.58911262271299, -369.7199807139239, 227.87051068551324, -272.8857069496083, 188.14068216615104, 252.57399502767242, 116.0373820751781, 504.3881348430664, 217.68927504252946, 487.92705284565005, 256.32225445481487, 220.62808367676965, 240.98224571685878, 279.8462469696914, 138.95188126319113, -70.25018947552779, -66.45135537392903, -416.284098468889, -159.15914777488575, -202.95002407439054, -74.49141091514315, -386.3729892380563, -351.1466035587806, -134.25213417357196, -312.23187983118356, 171.84953818136535, 239.20841266578813, -292.769271798179, -106.6071691752843, -101.80047963074297, -190.9337417885735, -150.7969561938011, -102.54916015369152, -65.48777930057906, -455.0928518615291, -62.67022740672284, -519.5186822763613, -98.34750049344362, 521.904045335818, -102.6651199438098, 337.16944733206003, 395.52722300490734, 242.28263479916865, -146.1432975354091, 443.2685199622153, -225.80014800709787, 160.08531529085974, 151.85233526387464, 293.3316319039595, 183.8787333672105, 242.4843163546414, 193.35170071122442, 300.1808108745618, 154.07174775351208, 379.50274210900545, 88.15556314299688, 248.5806547028983, -202.472244453464, -163.15480684197954, -68.72865390237862, -126.28203269057745, -107.01766798974543, -214.7724103371064, -261.33548921670155, -197.39307312061408, -106.92371523796376, -104.98576475672063, -210.51486600344845, 373.66192764408896, -208.66159834422174, 427.72346541051843, -192.3792318030987, 127.50550628731318, -295.0706237487561, 517.1166357332401, 147.73032303110796, 175.87672786761726, 196.68178100228766, 409.7580182956061, 225.98737351276853, 458.3995161198878, 169.27760428596656, 282.5252997744453, 148.118542383837, -141.5918319895383, -233.91307733548473, -152.47803259842595, -64.29304424828764, -189.37932384397578, -178.43633579687804, -172.10906279237724, -69.75782721781867, -228.66965934737465, -67.14271097797554, -199.42020709705668, -124.4222694519802, -176.64744509233049]}, "sampler_perf": {"mean_env_wait_ms": 70.22388727442662, "mean_raw_obs_processing_ms": 2.851800908508066, "mean_inference_ms": 2.981647389676117, "mean_action_processing_ms": 0.17452439903185243}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 75600, "timers": {"sample_time_ms": 85037.415, "sample_throughput": 49.39, "load_time_ms": 14.167, "load_throughput": 296468.127, "learn_time_ms": 13930.57, "learn_throughput": 301.495, "update_time_ms": 7.542}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 16.76471710205078, "policy_loss": -0.050355177372694016, "vf_loss": 16.81129264831543, "vf_explained_var": 0.9855951070785522, "kl": 0.01889769919216633, "entropy": 1.0341168642044067, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 22.49393653869629, "policy_loss": -0.04896054416894913, "vf_loss": 22.53905487060547, "vf_explained_var": 0.9815194606781006, "kl": 0.0192127525806427, "entropy": 1.183971643447876, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 30.44099235534668, "policy_loss": -0.04585037752985954, "vf_loss": 30.48341941833496, "vf_explained_var": 0.9761951565742493, "kl": 0.01709727942943573, "entropy": 1.1726151704788208, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 24.46726417541504, "policy_loss": -0.05091419443488121, "vf_loss": 24.5131893157959, "vf_explained_var": 0.9807308316230774, "kl": 0.016625327989459038, "entropy": 1.0631352663040161, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 75600, "num_steps_trained": 75600}, "done": false, "episodes_total": 605, "training_iteration": 18, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_14-59-14", "timestamp": 1624201154, "time_this_iter_s": 89.99001550674438, "time_total_s": 2366.9072782993317, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f023cb00>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f023c9e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c7a0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c440>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c0e0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c7a0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c440>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c0e0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c7a0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c440>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c0e0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c7a0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c440>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f023c0e0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f0246b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2366.9072782993317, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 54.64573643410853, "ram_util_percent": 87.99922480620155}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1781.6166668825986, "episode_reward_min": -1409.3423906930502, "episode_reward_mean": 115.58252649680992, "episode_len_mean": 146.53, "episodes_this_iter": 25, "policy_reward_min": {"AGENT-2": -376.5041902766156, "AGENT-1": -402.41012793616125, "AGENT-3": -376.4768516567872, "AGENT-0": -445.4729325542436}, "policy_reward_max": {"AGENT-2": 492.2364160285956, "AGENT-1": 637.5776461472475, "AGENT-3": 590.944987394549, "AGENT-0": 552.2011164492878}, "policy_reward_mean": {"AGENT-2": 21.747719257521826, "AGENT-1": 22.461576520344096, "AGENT-3": 57.142039703266875, "AGENT-0": 14.231191015677082}, "custom_metrics": {"mean_ego_speed_mean": 39.95220750000001, "mean_ego_speed_min": 11.98, "mean_ego_speed_max": 50.02825, "distance_travelled_mean": 109.67152750000002, "distance_travelled_min": 37.61024999999999, "distance_travelled_max": 124.90400000000001}, "hist_stats": {"episode_reward": [-1372.178255975438, 1293.1777045171134, -1208.706794094283, 1241.7778419109345, -674.2346626008086, 1346.318723309752, -1378.3853379946343, 1204.8113079808727, 881.1388249560222, 1563.7680217237064, 1055.9032475070192, 1185.2778486904112, 1016.0587139550637, 1136.7455328003775, 783.9548633430051, -1101.666881261192, -298.09467420462454, -479.0134700623799, -1032.0561144321455, 165.93866293616315, -302.41937141727624, -843.9039999914951, -968.5900458717014, -951.1205193505713, -956.5685301948629, 1129.0316389160198, 878.3501894107685, 1217.1836003151473, 686.3401966258695, 1141.4298449147798, 547.6690566383908, 1122.0723372122445, -637.819455115041, -385.84311833381093, -284.5762734018316, -438.4362588728087, -461.06843382324615, -583.4971659712003, -760.8054681322271, -641.3916526313712, -284.43368142855394, -226.94425734509332, -637.5076939072765, 1690.2708337098104, -880.9734039766956, 1718.3581178632287, -680.523118270253, 963.7582086306641, -1132.6425737801135, 1168.9582875040028, 719.8715958519633, 1129.779369945647, 703.3572557669634, 1703.4502167852813, 854.3691228690682, 1234.4094121351216, 818.4784619075867, 1467.2289262173629, 531.6551863980676, -472.879373378597, -928.6772640177612, -692.2638293931901, -177.08832555911349, -421.28597651258326, -740.479653180073, -454.6625533899939, -177.22296472751685, -882.6867691862747, -184.3664546705661, -502.9986601562806, -554.4930952065351, -704.7505497428447, -1001.4603731966636, 805.7967364988202, -929.4480262120602, 236.40362680336546, -1409.3423906930502, 1570.9463405015624, -1153.8621034188702, 1332.4718502115447, 1161.5316798899241, 618.4591006359896, 1781.6166668825986, 866.2134833493417, 1259.6321074033108, 962.1932539440077, 1036.2411741677984, 873.0854157097157, 1391.724909773425, 754.9022704836891, -372.9292754193483, -359.5010500107102, -1313.4266008598122, -573.0281302326341, -788.5389170086655, -310.06069883275, -754.2780028750386, -750.624294035761, -564.8671261124348, -615.2354493524657], "episode_lengths": [147, 244, 135, 231, 100, 211, 165, 171, 147, 164, 132, 217, 139, 213, 145, 153, 106, 136, 148, 130, 122, 135, 202, 141, 147, 127, 124, 142, 116, 146, 121, 151, 136, 118, 100, 121, 124, 127, 149, 127, 118, 120, 144, 230, 100, 221, 125, 234, 214, 273, 130, 180, 127, 158, 123, 169, 126, 199, 117, 122, 134, 134, 100, 128, 127, 121, 34, 137, 105, 127, 122, 126, 135, 205, 152, 200, 138, 225, 138, 208, 157, 132, 165, 113, 180, 135, 131, 144, 154, 138, 67, 67, 161, 159, 132, 114, 146, 149, 127, 146], "policy_AGENT-2_reward": [-376.5041902766156, 60.79391953701522, -228.73039415816476, 33.72279576507968, -144.9532460817672, 199.1591347463962, -313.3227636730629, 74.28746235483021, 228.01701942197568, 355.7098980640858, 276.02741438203645, 37.71393917308801, 286.96289234484897, 53.92290690799578, 224.78774185776453, -199.00392506958653, -33.674923554970555, -97.12753159808867, -355.1768929779138, 32.3756353444824, -8.781200597277373, -166.81055100725902, -60.34201016459104, -202.72371259306496, -156.24364531933395, 298.82077419625733, 238.48892009671212, 289.6524693123338, 169.09406006708386, 172.2813477876061, 200.58820249409433, 216.79782678450988, -131.44491698723257, -51.410912590130074, -59.966609180788204, -79.55637324861793, -88.04513005529229, -100.36033159948398, -138.98573392226203, -151.85366971775065, -35.444080312806946, -9.411733561921746, -124.49997095097608, 351.21622048872496, -254.82310967931824, 492.2364160285956, -171.16800859073072, 319.7119881591211, -286.8826950522983, 22.997691180159006, 197.3820050636003, 209.9502940265951, 173.84750930745514, 376.10994141464533, 210.71713218774863, 135.59489224642417, 215.86600301538266, 320.45344418638865, 97.29542954961114, -94.74098316784129, -194.98867847952317, -176.87422483595657, -12.919675679700017, -45.61423291782537, -174.0767850027375, -79.64555677454871, -18.854185006984356, -202.10535266640215, -24.89007804552063, -73.52402143470506, -130.52545872571483, -180.5194234354331, -250.2257928786051, 244.2726115807166, -252.30890455299456, 160.88408109201694, -353.82555823568316, 264.29289840832297, -317.1433391110218, 222.78502324568603, 220.37902037813163, 154.43240058573375, 365.1169195359187, 195.0904486306537, 116.60461456046934, 245.70377231126628, 271.81832420353567, 278.7255076228796, 314.2458237751582, 217.2128050001598, -116.02892941208195, -113.3408263008798, -249.6321540499632, -134.19272714779348, -180.17405648768798, -102.80503430980875, -9.7492772984832, -8.593188677019581, -131.4308422100656, -13.398103304826929], "policy_AGENT-1_reward": [-315.253714741694, 625.3191290031455, -228.3079690278908, 622.1401474096742, -192.2709091144965, 597.7016241157664, -312.85311767584716, 74.7197021790956, 216.89181435517082, 331.5165607919426, 280.01424712730295, 38.44326743687995, 281.51614928205055, 54.34149160176425, 208.09220031644693, -331.04913190505584, -115.39178234867273, -141.13049492776747, -323.71244301199914, 24.31437492986884, -118.21394825724599, -234.81819274322217, -402.41012793616125, -249.60780353380133, -338.8458415459849, 282.05075784157765, 235.76138374965197, 290.30978967976506, 169.5885737059481, 173.05409040569356, 88.11228047474322, 223.4440044290388, -157.45437326938026, -119.82244433795442, -68.58064633156131, -152.82313102384543, -114.87481290957072, -167.99458710320297, -221.3792223092498, -154.00836836923227, -106.6426512842728, -103.23432298325005, -171.7338238904297, 637.5776461472475, -208.8427208467437, 492.83659801546946, -145.80366201426472, 320.34144665990283, -255.9059193714331, 605.8204578589332, 193.36101070932486, 337.353865410469, 176.08521421042832, 418.8139013175577, 204.8336202663813, 136.15328261875217, 218.83675418146393, 401.4034210063319, 97.73427024695377, -141.6719739674901, -260.4087517634263, -176.3712888592234, -64.55775805372107, -140.66469980090875, -204.34488328648393, -123.26811074210289, -69.64580424390232, -255.67810012223185, -67.39574715587182, -156.27929782994875, -149.3977445120741, -177.06971066022058, -230.1073421422188, 244.87482508078008, -221.51266694475692, 161.40275643294808, -327.42175338241316, 612.215078090129, -299.5344019952572, 600.8308638125251, 262.7261971178489, 173.4893186057953, 365.5476217353225, 217.58420294700386, 117.0330639014172, 255.5647251684875, 259.55975636532634, 15.776714095369258, 362.2809596656409, 183.94722336789744, -70.55796592315708, -66.31259804172379, -381.4493342601536, -144.62395063442304, -225.29994739934634, -74.57749802839604, -348.33215971837717, -382.3155980481178, -157.1687501955648, -276.22473131108273], "policy_AGENT-3_reward": [-376.4768516567872, 60.81501887805723, -357.54672474179586, 33.71378228689194, -144.92382006088744, 315.5847937421352, -369.5893465815849, 518.3284029516566, 207.2943503047974, 510.4753790211509, 267.27711160020704, 590.944987394549, 211.5720697401713, 551.4501537049246, 187.1933216889477, -199.09763447521792, -33.86736992622547, -98.8101086340107, -289.7500578196254, 39.48256082135017, -8.78637009062614, -166.75437130036357, -60.364975216705375, -205.68992750056066, -156.1872840720154, 305.67579052354364, 210.74818485317968, 337.04053044848735, 193.58581509932543, 416.5916646124743, 170.81301052655633, 433.24985129579966, -146.44792040496463, -51.45495456374689, -87.30036398710351, -79.77472190976818, -151.13082286863744, -100.36983693140678, -139.10502268401345, -138.1365414237744, -35.423234593510614, -9.31243604320068, -130.75903306242174, 327.81503942974734, -208.6459751064124, 305.5616384086464, -171.172215862158, 196.19926752432778, -294.7833356076254, 23.023502731669527, 181.39825704792997, 406.5984826409647, 156.74275124679204, 498.7683557574729, 212.8309969021696, 504.26172115005556, 214.49810042477276, 462.84676125019826, 188.50694421766545, -94.87458425372742, -239.366756439327, -186.5402830995843, -35.317847577404734, -45.62771994987342, -183.6216490939735, -79.63982308096486, -18.965148258811514, -196.2336570502657, -24.937918491198072, -73.77513379456977, -150.14762251676586, -170.51397055486092, -242.73882434503457, 187.30436806774844, -234.06413447209945, -45.294098098886565, -358.37509836103027, 466.56785331759727, -264.2986553629845, 320.71528098718323, 425.85246736627033, 174.4999993692827, 546.5639907682897, 235.84955672915487, 538.0673760957745, 204.6025020094392, 284.23500992216606, 337.60094827460887, 435.35187936293613, 214.7903608524408, -116.09219060858126, -113.39627029417733, -266.06101408080576, -135.05230467553181, -180.11488904724118, -58.18675557940196, -9.823576620121926, -8.56890375184329, -142.01539953323226, -13.380734905372142], "policy_AGENT-0_reward": [-303.94349930034116, 546.2496370988941, -394.1217061664325, 552.2011164492878, -192.08668734365736, 233.8731707054543, -382.6201100641378, 537.47574049529, 228.93564087407944, 366.0661838465263, 232.5844743974734, 518.175654685894, 236.00760258799193, 477.03098058569185, 163.8815994798449, -372.5161898113319, -115.16059837475574, -141.94533490251288, -63.416720622608715, 69.76609184046168, -166.63785247212655, -275.52088494065094, -445.4729325542436, -293.09907572314376, -305.29175925752907, 242.4843163546414, 193.35170071122442, 300.1808108745618, 154.07174775351208, 379.50274210900545, 88.15556314299688, 248.5806547028983, -202.472244453464, -163.15480684197954, -68.72865390237862, -126.28203269057745, -107.01766798974543, -214.7724103371064, -261.33548921670155, -197.39307312061408, -106.92371523796376, -104.98576475672063, -210.51486600344845, 373.66192764408896, -208.66159834422174, 427.72346541051843, -192.3792318030987, 127.50550628731318, -295.0706237487561, 517.1166357332401, 147.73032303110796, 175.87672786761726, 196.68178100228766, 409.7580182956061, 225.98737351276853, 458.3995161198878, 169.27760428596656, 282.5252997744453, 148.118542383837, -141.5918319895383, -233.91307733548473, -152.47803259842595, -64.29304424828764, -189.37932384397578, -178.43633579687804, -172.10906279237724, -69.75782721781867, -228.66965934737465, -67.14271097797554, -199.42020709705668, -124.4222694519802, -176.64744509233049, -278.3884138308046, 129.34493176957577, -221.5623202422105, -40.58911262271299, -369.7199807139239, 227.87051068551324, -272.8857069496083, 188.14068216615104, 252.57399502767242, 116.0373820751781, 504.3881348430664, 217.68927504252946, 487.92705284565005, 256.32225445481487, 220.62808367676965, 240.98224571685878, 279.8462469696914, 138.95188126319113, -70.25018947552779, -66.45135537392903, -416.284098468889, -159.15914777488575, -202.95002407439054, -74.49141091514315, -386.3729892380563, -351.1466035587806, -134.25213417357196, -312.23187983118356]}, "sampler_perf": {"mean_env_wait_ms": 69.05762078792809, "mean_raw_obs_processing_ms": 2.8053362438080076, "mean_inference_ms": 2.9404014439561497, "mean_action_processing_ms": 0.1721789799532449}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 79800, "timers": {"sample_time_ms": 81380.105, "sample_throughput": 51.61, "load_time_ms": 13.988, "load_throughput": 300255.953, "learn_time_ms": 13590.61, "learn_throughput": 309.037, "update_time_ms": 7.488}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 15.974902153015137, "policy_loss": -0.042626429349184036, "vf_loss": 16.013662338256836, "vf_explained_var": 0.9891776442527771, "kl": 0.019331954419612885, "entropy": 0.988369882106781, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 20.278295516967773, "policy_loss": -0.05204877629876137, "vf_loss": 20.326385498046875, "vf_explained_var": 0.9874191284179688, "kl": 0.019800322130322456, "entropy": 1.1724932193756104, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 22.723600387573242, "policy_loss": -0.050667643547058105, "vf_loss": 22.771108627319336, "vf_explained_var": 0.9795930981636047, "kl": 0.015803270041942596, "entropy": 1.1928797960281372, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 13.62591552734375, "policy_loss": -0.0603473074734211, "vf_loss": 13.679569244384766, "vf_explained_var": 0.99040687084198, "kl": 0.02231757529079914, "entropy": 1.04535973072052, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 79800, "num_steps_trained": 79800}, "done": false, "episodes_total": 630, "training_iteration": 19, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-00-39", "timestamp": 1624201239, "time_this_iter_s": 85.1193675994873, "time_total_s": 2452.026645898819, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f0366e60>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f031ab90>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8f80>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02465f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246b90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8f80>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02465f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246b90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8f80>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02465f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246b90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8f80>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02c8ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f02465f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246b90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f023c050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2452.026645898819, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 51.65491803278688, "ram_util_percent": 88.02622950819672}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1781.6166668825986, "episode_reward_min": -1409.3423906930502, "episode_reward_mean": 126.92965818881918, "episode_len_mean": 150.13, "episodes_this_iter": 27, "policy_reward_min": {"AGENT-2": -376.5041902766156, "AGENT-3": -376.4768516567872, "AGENT-0": -445.4729325542436, "AGENT-1": -402.41012793616125}, "policy_reward_max": {"AGENT-2": 384.86746806118134, "AGENT-3": 590.944987394549, "AGENT-0": 552.2011164492878, "AGENT-1": 633.8509793824428}, "policy_reward_mean": {"AGENT-2": 13.141571877550478, "AGENT-3": 58.299286362984205, "AGENT-0": 29.642445913983103, "AGENT-1": 25.846354034301374}, "custom_metrics": {"mean_ego_speed_mean": 40.140417500000005, "mean_ego_speed_min": 11.98, "mean_ego_speed_max": 51.30525, "distance_travelled_mean": 107.26170999999998, "distance_travelled_min": 37.61024999999999, "distance_travelled_max": 124.90400000000001}, "hist_stats": {"episode_reward": [1318.5885462830875, -530.3728928051034, 1115.515736651734, -818.0875836852138, 1166.9249005721642, -625.8204275219916, 1131.4008013086952, -802.2951816447646, 1423.3352057928014, 693.3760011436397, 1702.4612514344117, 706.0909181263436, 1272.9314642340105, 1053.4284845396794, 783.9173200438406, 1475.2691836859972, 799.3504739186951, -682.028565762292, -739.5550456870277, -120.83203849597254, -528.3104787623973, 353.74456090460853, -1180.347763788574, -86.3054711070549, 287.06819676382554, -870.6072327923064, -1087.5164716008956, 703.3572557669634, 1703.4502167852813, 854.3691228690682, 1234.4094121351216, 818.4784619075867, 1467.2289262173629, 531.6551863980676, -472.879373378597, -928.6772640177612, -692.2638293931901, -177.08832555911349, -421.28597651258326, -740.479653180073, -454.6625533899939, -177.22296472751685, -882.6867691862747, -184.3664546705661, -502.9986601562806, -554.4930952065351, -704.7505497428447, -1001.4603731966636, 805.7967364988202, -929.4480262120602, 236.40362680336546, -1409.3423906930502, 1570.9463405015624, -1153.8621034188702, 1332.4718502115447, 1161.5316798899241, 618.4591006359896, 1781.6166668825986, 866.2134833493417, 1259.6321074033108, 962.1932539440077, 1036.2411741677984, 873.0854157097157, 1391.724909773425, 754.9022704836891, -372.9292754193483, -359.5010500107102, -1313.4266008598122, -573.0281302326341, -788.5389170086655, -310.06069883275, -754.2780028750386, -750.624294035761, -564.8671261124348, -615.2354493524657, -1372.178255975438, 1293.1777045171134, -1208.706794094283, 1241.7778419109345, -674.2346626008086, 1346.318723309752, -1378.3853379946343, 1204.8113079808727, 881.1388249560222, 1563.7680217237064, 1055.9032475070192, 1185.2778486904112, 1016.0587139550637, 1136.7455328003775, 783.9548633430051, -1101.666881261192, -298.09467420462454, -479.0134700623799, -1032.0561144321455, 165.93866293616315, -302.41937141727624, -843.9039999914951, -968.5900458717014, -951.1205193505713, -956.5685301948629], "episode_lengths": [305, 104, 259, 127, 225, 100, 259, 96, 240, 129, 169, 133, 171, 166, 132, 186, 152, 127, 137, 108, 134, 155, 154, 139, 180, 138, 153, 127, 158, 123, 169, 126, 199, 117, 122, 134, 134, 100, 128, 127, 121, 34, 137, 105, 127, 122, 126, 135, 205, 152, 200, 138, 225, 138, 208, 157, 132, 165, 113, 180, 135, 131, 144, 154, 138, 67, 67, 161, 159, 132, 114, 146, 149, 127, 146, 147, 244, 135, 231, 100, 211, 165, 171, 147, 164, 132, 217, 139, 213, 145, 153, 106, 136, 148, 130, 122, 135, 202, 141, 147], "policy_AGENT-2_reward": [84.65154899825231, -157.3068779518662, -3.474386071505712, -204.34845883039586, 302.4335531411839, -182.58898870576596, -4.253770738963578, -168.44503949950737, 184.04563504255566, 133.59807825061648, 330.34854742945345, 181.01095255889317, 290.60003091669404, 54.82321044444775, 215.76598470744167, 384.86746806118134, 246.59483384425366, -150.14212104677765, -170.19621003844017, -27.811217362544834, -12.481623607157239, -7.966494333762882, -284.5043397975646, -9.166533286828152, -11.453841421563775, -189.19523116661028, -190.65450729707146, 173.84750930745514, 376.10994141464533, 210.71713218774863, 135.59489224642417, 215.86600301538266, 320.45344418638865, 97.29542954961114, -94.74098316784129, -194.98867847952317, -176.87422483595657, -12.919675679700017, -45.61423291782537, -174.0767850027375, -79.64555677454871, -18.854185006984356, -202.10535266640215, -24.89007804552063, -73.52402143470506, -130.52545872571483, -180.5194234354331, -250.2257928786051, 244.2726115807166, -252.30890455299456, 160.88408109201694, -353.82555823568316, 264.29289840832297, -317.1433391110218, 222.78502324568603, 220.37902037813163, 154.43240058573375, 365.1169195359187, 195.0904486306537, 116.60461456046934, 245.70377231126628, 271.81832420353567, 278.7255076228796, 314.2458237751582, 217.2128050001598, -116.02892941208195, -113.3408263008798, -249.6321540499632, -134.19272714779348, -180.17405648768798, -102.80503430980875, -9.7492772984832, -8.593188677019581, -131.4308422100656, -13.398103304826929, -376.5041902766156, 60.79391953701522, -228.73039415816476, 33.72279576507968, -144.9532460817672, 199.1591347463962, -313.3227636730629, 74.28746235483021, 228.01701942197568, 355.7098980640858, 276.02741438203645, 37.71393917308801, 286.96289234484897, 53.92290690799578, 224.78774185776453, -199.00392506958653, -33.674923554970555, -97.12753159808867, -355.1768929779138, 32.3756353444824, -8.781200597277373, -166.81055100725902, -60.34201016459104, -202.72371259306496, -156.24364531933395], "policy_AGENT-3_reward": [84.63424692921174, -158.06092770707343, -3.668334971940321, -212.15666280859625, 334.0688800422874, -182.68372641148005, -4.263111172764343, -216.05617821921166, 540.0342165799949, 232.03625811193228, 511.4418202143355, 199.46439493337556, 317.03415401846587, 492.9199512243056, 199.87414991595472, 538.8047346248816, 208.5096253783655, -157.3980054991981, -146.431365125928, -27.809295604739933, -12.492780767194164, -7.900747907527475, -236.77865899131194, -9.425285270155156, -11.439744433698424, -201.37778891843752, -190.6705320982139, 156.74275124679204, 498.7683557574729, 212.8309969021696, 504.26172115005556, 214.49810042477276, 462.84676125019826, 188.50694421766545, -94.87458425372742, -239.366756439327, -186.5402830995843, -35.317847577404734, -45.62771994987342, -183.6216490939735, -79.63982308096486, -18.965148258811514, -196.2336570502657, -24.937918491198072, -73.77513379456977, -150.14762251676586, -170.51397055486092, -242.73882434503457, 187.30436806774844, -234.06413447209945, -45.294098098886565, -358.37509836103027, 466.56785331759727, -264.2986553629845, 320.71528098718323, 425.85246736627033, 174.4999993692827, 546.5639907682897, 235.84955672915487, 538.0673760957745, 204.6025020094392, 284.23500992216606, 337.60094827460887, 435.35187936293613, 214.7903608524408, -116.09219060858126, -113.39627029417733, -266.06101408080576, -135.05230467553181, -180.11488904724118, -58.18675557940196, -9.823576620121926, -8.56890375184329, -142.01539953323226, -13.380734905372142, -376.4768516567872, 60.81501887805723, -357.54672474179586, 33.71378228689194, -144.92382006088744, 315.5847937421352, -369.5893465815849, 518.3284029516566, 207.2943503047974, 510.4753790211509, 267.27711160020704, 590.944987394549, 211.5720697401713, 551.4501537049246, 187.1933216889477, -199.09763447521792, -33.86736992622547, -98.8101086340107, -289.7500578196254, 39.48256082135017, -8.78637009062614, -166.75437130036357, -60.364975216705375, -205.68992750056066, -156.1872840720154], "policy_AGENT-0_reward": [515.451770973181, -107.55653305470015, 519.9189515384792, -203.48859610863747, 227.4278484089984, -130.28046461884477, 527.7022152381812, -167.8837164155994, 514.7720267317169, 193.49810625130397, 529.6430661042953, 143.99319930627274, 325.40759034126495, 450.1557453900259, 161.52412947356277, 257.0323773794285, 148.8903309590271, -211.1433299792763, -235.19647627512217, -60.19842959736302, -273.74076175788036, 178.18384120098, -323.58294490832554, -38.80912831891982, 147.58915674872233, -260.60594475957606, -371.328597244643, 196.68178100228766, 409.7580182956061, 225.98737351276853, 458.3995161198878, 169.27760428596656, 282.5252997744453, 148.118542383837, -141.5918319895383, -233.91307733548473, -152.47803259842595, -64.29304424828764, -189.37932384397578, -178.43633579687804, -172.10906279237724, -69.75782721781867, -228.66965934737465, -67.14271097797554, -199.42020709705668, -124.4222694519802, -176.64744509233049, -278.3884138308046, 129.34493176957577, -221.5623202422105, -40.58911262271299, -369.7199807139239, 227.87051068551324, -272.8857069496083, 188.14068216615104, 252.57399502767242, 116.0373820751781, 504.3881348430664, 217.68927504252946, 487.92705284565005, 256.32225445481487, 220.62808367676965, 240.98224571685878, 279.8462469696914, 138.95188126319113, -70.25018947552779, -66.45135537392903, -416.284098468889, -159.15914777488575, -202.95002407439054, -74.49141091514315, -386.3729892380563, -351.1466035587806, -134.25213417357196, -312.23187983118356, -303.94349930034116, 546.2496370988941, -394.1217061664325, 552.2011164492878, -192.08668734365736, 233.8731707054543, -382.6201100641378, 537.47574049529, 228.93564087407944, 366.0661838465263, 232.5844743974734, 518.175654685894, 236.00760258799193, 477.03098058569185, 163.8815994798449, -372.5161898113319, -115.16059837475574, -141.94533490251288, -63.416720622608715, 69.76609184046168, -166.63785247212655, -275.52088494065094, -445.4729325542436, -293.09907572314376, -305.29175925752907], "policy_AGENT-1_reward": [633.8509793824428, -107.44855409146334, 602.7395061567028, -198.0938659375842, 302.99461897969536, -130.26724778590082, 612.2154679822422, -249.91024751044645, 184.4833274385342, 134.2435585297873, 331.02781768632696, 181.6223713278016, 339.88968895758455, 55.529577480900386, 206.7530559468815, 294.5646036205035, 195.3556837370489, -163.34510923704013, -187.73099424753715, -5.01309593132469, -229.5953126301656, 191.42796194491862, -335.48182009137105, -28.904524231151694, 162.37262587036562, -219.42826794768217, -334.862834960967, 176.08521421042832, 418.8139013175577, 204.8336202663813, 136.15328261875217, 218.83675418146393, 401.4034210063319, 97.73427024695377, -141.6719739674901, -260.4087517634263, -176.3712888592234, -64.55775805372107, -140.66469980090875, -204.34488328648393, -123.26811074210289, -69.64580424390232, -255.67810012223185, -67.39574715587182, -156.27929782994875, -149.3977445120741, -177.06971066022058, -230.1073421422188, 244.87482508078008, -221.51266694475692, 161.40275643294808, -327.42175338241316, 612.215078090129, -299.5344019952572, 600.8308638125251, 262.7261971178489, 173.4893186057953, 365.5476217353225, 217.58420294700386, 117.0330639014172, 255.5647251684875, 259.55975636532634, 15.776714095369258, 362.2809596656409, 183.94722336789744, -70.55796592315708, -66.31259804172379, -381.4493342601536, -144.62395063442304, -225.29994739934634, -74.57749802839604, -348.33215971837717, -382.3155980481178, -157.1687501955648, -276.22473131108273, -315.253714741694, 625.3191290031455, -228.3079690278908, 622.1401474096742, -192.2709091144965, 597.7016241157664, -312.85311767584716, 74.7197021790956, 216.89181435517082, 331.5165607919426, 280.01424712730295, 38.44326743687995, 281.51614928205055, 54.34149160176425, 208.09220031644693, -331.04913190505584, -115.39178234867273, -141.13049492776747, -323.71244301199914, 24.31437492986884, -118.21394825724599, -234.81819274322217, -402.41012793616125, -249.60780353380133, -338.8458415459849]}, "sampler_perf": {"mean_env_wait_ms": 67.69807461097643, "mean_raw_obs_processing_ms": 2.749046191150658, "mean_inference_ms": 2.894994060285496, "mean_action_processing_ms": 0.16963631978210944}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 84000, "timers": {"sample_time_ms": 79727.59, "sample_throughput": 52.679, "load_time_ms": 13.92, "load_throughput": 301719.547, "learn_time_ms": 13310.121, "learn_throughput": 315.549, "update_time_ms": 7.576}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 15.21003246307373, "policy_loss": -0.04234778881072998, "vf_loss": 15.248868942260742, "vf_explained_var": 0.9883648157119751, "kl": 0.01755138859152794, "entropy": 0.9860954880714417, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 29.318283081054688, "policy_loss": -0.05018983036279678, "vf_loss": 29.364459991455078, "vf_explained_var": 0.9838493466377258, "kl": 0.02008005976676941, "entropy": 1.1340969800949097, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 32.63549041748047, "policy_loss": -0.05065971985459328, "vf_loss": 32.68290328979492, "vf_explained_var": 0.9762381911277771, "kl": 0.016249891370534897, "entropy": 1.1701492071151733, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 18.190187454223633, "policy_loss": -0.05048450827598572, "vf_loss": 18.23334312438965, "vf_explained_var": 0.9876623153686523, "kl": 0.016291910782456398, "entropy": 1.020467758178711, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 84000, "num_steps_trained": 84000}, "done": false, "episodes_total": 657, "training_iteration": 20, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-02-01", "timestamp": 1624201321, "time_this_iter_s": 82.35285496711731, "time_total_s": 2534.3795008659363, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f017c560>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f017c680>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f017cb00>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f017cc20>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f017cb00>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f017cc20>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f017cb00>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f017cc20>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f017cb00>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f017cc20>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f03d9290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2534.3795008659363, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 51.671794871794866, "ram_util_percent": 88.0}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1781.6166668825986, "episode_reward_min": -1378.3853379946343, "episode_reward_mean": 194.0780944348085, "episode_len_mean": 153.33, "episodes_this_iter": 28, "policy_reward_min": {"AGENT-2": -376.5041902766156, "AGENT-3": -376.4768516567872, "AGENT-0": -445.4729325542436, "AGENT-1": -402.41012793616125}, "policy_reward_max": {"AGENT-2": 384.86746806118134, "AGENT-3": 590.944987394549, "AGENT-0": 553.1961018489588, "AGENT-1": 635.8613174754989}, "policy_reward_mean": {"AGENT-2": 20.603675249737876, "AGENT-3": 76.6454097638762, "AGENT-0": 47.42775394330208, "AGENT-1": 49.40125547789226}, "custom_metrics": {"mean_ego_speed_mean": 40.548305, "mean_ego_speed_min": 11.98, "mean_ego_speed_max": 51.30525, "distance_travelled_mean": 104.16429, "distance_travelled_min": 33.33, "distance_travelled_max": 124.90199999999999}, "hist_stats": {"episode_reward": [1358.6250527319403, -596.1934520813752, 199.5748594289696, -633.8856896129893, 1523.5170790207383, -250.88136920367853, 1298.0012235972824, -674.0599091946224, 1184.9337564381522, 1247.4726863636636, 1140.5180064976325, 1206.6312091423117, 1364.482305557191, 1487.6103503350107, 161.32989337605534, 965.8601698721465, -491.60783995143987, -760.2090852481896, -70.59057264063144, -735.3614508944277, 152.7382781343565, -817.9314729357528, -138.20155284203912, -499.59506846136145, 287.1117300258215, -604.4820380949982, -477.2503846439241, -242.71431666414375, 1161.5316798899241, 618.4591006359896, 1781.6166668825986, 866.2134833493417, 1259.6321074033108, 962.1932539440077, 1036.2411741677984, 873.0854157097157, 1391.724909773425, 754.9022704836891, -372.9292754193483, -359.5010500107102, -1313.4266008598122, -573.0281302326341, -788.5389170086655, -310.06069883275, -754.2780028750386, -750.624294035761, -564.8671261124348, -615.2354493524657, -1372.178255975438, 1293.1777045171134, -1208.706794094283, 1241.7778419109345, -674.2346626008086, 1346.318723309752, -1378.3853379946343, 1204.8113079808727, 881.1388249560222, 1563.7680217237064, 1055.9032475070192, 1185.2778486904112, 1016.0587139550637, 1136.7455328003775, 783.9548633430051, -1101.666881261192, -298.09467420462454, -479.0134700623799, -1032.0561144321455, 165.93866293616315, -302.41937141727624, -843.9039999914951, -968.5900458717014, -951.1205193505713, -956.5685301948629, 1318.5885462830875, -530.3728928051034, 1115.515736651734, -818.0875836852138, 1166.9249005721642, -625.8204275219916, 1131.4008013086952, -802.2951816447646, 1423.3352057928014, 693.3760011436397, 1702.4612514344117, 706.0909181263436, 1272.9314642340105, 1053.4284845396794, 783.9173200438406, 1475.2691836859972, 799.3504739186951, -682.028565762292, -739.5550456870277, -120.83203849597254, -528.3104787623973, 353.74456090460853, -1180.347763788574, -86.3054711070549, 287.06819676382554, -870.6072327923064, -1087.5164716008956], "episode_lengths": [228, 82, 180, 145, 219, 41, 247, 66, 222, 196, 159, 219, 174, 136, 179, 191, 128, 148, 134, 124, 143, 106, 105, 130, 180, 143, 128, 104, 157, 132, 165, 113, 180, 135, 131, 144, 154, 138, 67, 67, 161, 159, 132, 114, 146, 149, 127, 146, 147, 244, 135, 231, 100, 211, 165, 171, 147, 164, 132, 217, 139, 213, 145, 153, 106, 136, 148, 130, 122, 135, 202, 141, 147, 305, 104, 259, 127, 225, 100, 259, 96, 240, 129, 169, 133, 171, 166, 132, 186, 152, 127, 137, 108, 134, 155, 154, 139, 180, 138, 153], "policy_AGENT-2_reward": [201.60479147150016, -124.86604619656688, 153.67530188701176, -147.88690752822617, 239.37669718872905, -31.2658118523586, 64.15631253705564, -194.65766384959832, 97.4598213492323, 71.62373490670466, 338.91850895418605, 95.27139603242455, 370.09601492219645, 306.35955773304056, -34.008846614888505, 91.4864100766107, -31.49118240116702, -159.35190636244528, -19.174071160724147, -184.0193409397032, 33.546851026217205, -229.87536217563644, -62.800800970645135, -108.57830432747362, -7.78795318959345, -80.88997351523807, -15.791986811914636, -45.58218768678771, 220.37902037813163, 154.43240058573375, 365.1169195359187, 195.0904486306537, 116.60461456046934, 245.70377231126628, 271.81832420353567, 278.7255076228796, 314.2458237751582, 217.2128050001598, -116.02892941208195, -113.3408263008798, -249.6321540499632, -134.19272714779348, -180.17405648768798, -102.80503430980875, -9.7492772984832, -8.593188677019581, -131.4308422100656, -13.398103304826929, -376.5041902766156, 60.79391953701522, -228.73039415816476, 33.72279576507968, -144.9532460817672, 199.1591347463962, -313.3227636730629, 74.28746235483021, 228.01701942197568, 355.7098980640858, 276.02741438203645, 37.71393917308801, 286.96289234484897, 53.92290690799578, 224.78774185776453, -199.00392506958653, -33.674923554970555, -97.12753159808867, -355.1768929779138, 32.3756353444824, -8.781200597277373, -166.81055100725902, -60.34201016459104, -202.72371259306496, -156.24364531933395, 84.65154899825231, -157.3068779518662, -3.474386071505712, -204.34845883039586, 302.4335531411839, -182.58898870576596, -4.253770738963578, -168.44503949950737, 184.04563504255566, 133.59807825061648, 330.34854742945345, 181.01095255889317, 290.60003091669404, 54.82321044444775, 215.76598470744167, 384.86746806118134, 246.59483384425366, -150.14212104677765, -170.19621003844017, -27.811217362544834, -12.481623607157239, -7.966494333762882, -284.5043397975646, -9.166533286828152, -11.453841421563775, -189.19523116661028, -190.65450729707146], "policy_AGENT-3_reward": [367.48777779040114, -125.13965225134596, -64.97230891989086, -169.6805097335451, 443.5232216772747, -31.141053902970313, 64.11111000458749, -194.7122911273832, 338.6080506501445, 550.4956336483635, 274.4441656077723, 547.3114922577117, 256.0243456242402, 500.5220775584305, -33.86769023287688, 538.2862758393675, -31.496092620608145, -123.91082923063993, -19.13335897114052, -188.56233165371353, 38.491302550452694, -229.96185070478344, -16.88973883995415, -110.65542781269873, -7.707186663278613, -81.11456985216755, -15.969943072563646, -71.06806900969477, 425.85246736627033, 174.4999993692827, 546.5639907682897, 235.84955672915487, 538.0673760957745, 204.6025020094392, 284.23500992216606, 337.60094827460887, 435.35187936293613, 214.7903608524408, -116.09219060858126, -113.39627029417733, -266.06101408080576, -135.05230467553181, -180.11488904724118, -58.18675557940196, -9.823576620121926, -8.56890375184329, -142.01539953323226, -13.380734905372142, -376.4768516567872, 60.81501887805723, -357.54672474179586, 33.71378228689194, -144.92382006088744, 315.5847937421352, -369.5893465815849, 518.3284029516566, 207.2943503047974, 510.4753790211509, 267.27711160020704, 590.944987394549, 211.5720697401713, 551.4501537049246, 187.1933216889477, -199.09763447521792, -33.86736992622547, -98.8101086340107, -289.7500578196254, 39.48256082135017, -8.78637009062614, -166.75437130036357, -60.364975216705375, -205.68992750056066, -156.1872840720154, 84.63424692921174, -158.06092770707343, -3.668334971940321, -212.15666280859625, 334.0688800422874, -182.68372641148005, -4.263111172764343, -216.05617821921166, 540.0342165799949, 232.03625811193228, 511.4418202143355, 199.46439493337556, 317.03415401846587, 492.9199512243056, 199.87414991595472, 538.8047346248816, 208.5096253783655, -157.3980054991981, -146.431365125928, -27.809295604739933, -12.492780767194164, -7.900747907527475, -236.77865899131194, -9.425285270155156, -11.439744433698424, -201.37778891843752, -190.6705320982139], "policy_AGENT-0_reward": [167.864439005473, -173.09606477280497, -43.28592563258053, -166.01049059316733, 204.75584267923574, -94.0946660764485, 543.7197534335245, -142.25860694269815, 114.89107211089267, 553.1961018489588, 245.65348116493357, 468.2176308477798, 326.4689265882661, 306.9222817849097, 108.33332888954982, 55.40049998197922, -237.2027924601022, -260.73483223837417, -18.341242853119407, -171.07414622848725, 38.098054649705716, -179.06788895793142, -29.11744397317124, -162.44541500669288, 126.52762958633437, -243.46814796980124, -243.61424743932102, -63.00843064766967, 252.57399502767242, 116.0373820751781, 504.3881348430664, 217.68927504252946, 487.92705284565005, 256.32225445481487, 220.62808367676965, 240.98224571685878, 279.8462469696914, 138.95188126319113, -70.25018947552779, -66.45135537392903, -416.284098468889, -159.15914777488575, -202.95002407439054, -74.49141091514315, -386.3729892380563, -351.1466035587806, -134.25213417357196, -312.23187983118356, -303.94349930034116, 546.2496370988941, -394.1217061664325, 552.2011164492878, -192.08668734365736, 233.8731707054543, -382.6201100641378, 537.47574049529, 228.93564087407944, 366.0661838465263, 232.5844743974734, 518.175654685894, 236.00760258799193, 477.03098058569185, 163.8815994798449, -372.5161898113319, -115.16059837475574, -141.94533490251288, -63.416720622608715, 69.76609184046168, -166.63785247212655, -275.52088494065094, -445.4729325542436, -293.09907572314376, -305.29175925752907, 515.451770973181, -107.55653305470015, 519.9189515384792, -203.48859610863747, 227.4278484089984, -130.28046461884477, 527.7022152381812, -167.8837164155994, 514.7720267317169, 193.49810625130397, 529.6430661042953, 143.99319930627274, 325.40759034126495, 450.1557453900259, 161.52412947356277, 257.0323773794285, 148.8903309590271, -211.1433299792763, -235.19647627512217, -60.19842959736302, -273.74076175788036, 178.18384120098, -323.58294490832554, -38.80912831891982, 147.58915674872233, -260.60594475957606, -371.328597244643], "policy_AGENT-1_reward": [621.6680444645646, -173.09168886065714, 154.15779209442897, -150.30778175805082, 635.8613174754989, -94.37983737190112, 626.0140476221137, -142.43134727494217, 633.9748123278832, 72.15721595963699, 281.5018507707404, 95.83069000439521, 411.8930184224893, 373.8064332586276, 120.87310133427101, 280.6869839741891, -191.41777246956292, -216.21151741673012, -13.94189965564737, -191.7056320725239, 42.602069907980855, -179.02637109740164, -29.393569058268643, -117.91592131449652, 176.07924029235934, -199.00934675779172, -201.87420732012504, -63.055629319991866, 262.7261971178489, 173.4893186057953, 365.5476217353225, 217.58420294700386, 117.0330639014172, 255.5647251684875, 259.55975636532634, 15.776714095369258, 362.2809596656409, 183.94722336789744, -70.55796592315708, -66.31259804172379, -381.4493342601536, -144.62395063442304, -225.29994739934634, -74.57749802839604, -348.33215971837717, -382.3155980481178, -157.1687501955648, -276.22473131108273, -315.253714741694, 625.3191290031455, -228.3079690278908, 622.1401474096742, -192.2709091144965, 597.7016241157664, -312.85311767584716, 74.7197021790956, 216.89181435517082, 331.5165607919426, 280.01424712730295, 38.44326743687995, 281.51614928205055, 54.34149160176425, 208.09220031644693, -331.04913190505584, -115.39178234867273, -141.13049492776747, -323.71244301199914, 24.31437492986884, -118.21394825724599, -234.81819274322217, -402.41012793616125, -249.60780353380133, -338.8458415459849, 633.8509793824428, -107.44855409146334, 602.7395061567028, -198.0938659375842, 302.99461897969536, -130.26724778590082, 612.2154679822422, -249.91024751044645, 184.4833274385342, 134.2435585297873, 331.02781768632696, 181.6223713278016, 339.88968895758455, 55.529577480900386, 206.7530559468815, 294.5646036205035, 195.3556837370489, -163.34510923704013, -187.73099424753715, -5.01309593132469, -229.5953126301656, 191.42796194491862, -335.48182009137105, -28.904524231151694, 162.37262587036562, -219.42826794768217, -334.862834960967]}, "sampler_perf": {"mean_env_wait_ms": 66.3378989737194, "mean_raw_obs_processing_ms": 2.6909509811233545, "mean_inference_ms": 2.8483479588649483, "mean_action_processing_ms": 0.16716670733995906}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 88200, "timers": {"sample_time_ms": 78282.291, "sample_throughput": 53.652, "load_time_ms": 13.828, "load_throughput": 303728.604, "learn_time_ms": 13910.505, "learn_throughput": 301.93, "update_time_ms": 8.443}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 23.303424835205078, "policy_loss": -0.04278440773487091, "vf_loss": 23.342592239379883, "vf_explained_var": 0.9868484735488892, "kl": 0.01809835433959961, "entropy": 0.9832540154457092, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 30.907470703125, "policy_loss": -0.048987843096256256, "vf_loss": 30.951364517211914, "vf_explained_var": 0.9831907749176025, "kl": 0.016981348395347595, "entropy": 1.1275662183761597, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 48.76568603515625, "policy_loss": -0.04812159761786461, "vf_loss": 48.810203552246094, "vf_explained_var": 0.9725157618522644, "kl": 0.018023939803242683, "entropy": 1.160090446472168, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 32.690242767333984, "policy_loss": -0.03671536594629288, "vf_loss": 32.721221923828125, "vf_explained_var": 0.9813213348388672, "kl": 0.012739323079586029, "entropy": 1.018235683441162, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 88200, "num_steps_trained": 88200}, "done": false, "episodes_total": 685, "training_iteration": 21, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-03-38", "timestamp": 1624201418, "time_this_iter_s": 95.72021341323853, "time_total_s": 2630.099714279175, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f03d9200>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f03d9d40>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d93b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a5f0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d93b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a5f0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d93b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a5f0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d93b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a5f0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f017ce60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2630.099714279175, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 52.307299270072996, "ram_util_percent": 87.94452554744524}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1702.4612514344117, "episode_reward_min": -1378.3853379946343, "episode_reward_mean": 281.61614765292217, "episode_len_mean": 157.57, "episodes_this_iter": 25, "policy_reward_min": {"AGENT-2": -355.1768929779138, "AGENT-1": -402.41012793616125, "AGENT-3": -369.5893465815849, "AGENT-0": -445.4729325542436}, "policy_reward_max": {"AGENT-2": 384.86746806118134, "AGENT-1": 645.1905102635516, "AGENT-3": 590.944987394549, "AGENT-0": 627.7413265345999}, "policy_reward_mean": {"AGENT-2": 30.810510168413288, "AGENT-1": 84.75812234158809, "AGENT-3": 94.58844735116222, "AGENT-0": 71.45906779175853}, "custom_metrics": {"mean_ego_speed_mean": 40.97678, "mean_ego_speed_min": 11.98, "mean_ego_speed_max": 51.30525, "distance_travelled_mean": 105.16875250000001, "distance_travelled_min": 33.33, "distance_travelled_max": 124.90199999999999}, "hist_stats": {"episode_reward": [-1126.2552575477014, 1259.047621773214, -805.5569055323323, 1576.1636717398446, 661.8606084032635, 1511.1329273317897, -676.2788320543357, 1376.6355329548373, 746.5805737621745, 1360.4116328002544, 1138.6653347788847, 615.3830902117089, 745.8644270993879, 1277.634484800475, 851.8769818453682, 1444.6121248360996, 64.53558024288945, -273.40745578543675, 220.36820338724274, -52.72413439595505, -485.8141918411646, 137.3559888885521, -273.7726531148977, 935.6732398678116, 106.75907861709005, 1346.318723309752, -1378.3853379946343, 1204.8113079808727, 881.1388249560222, 1563.7680217237064, 1055.9032475070192, 1185.2778486904112, 1016.0587139550637, 1136.7455328003775, 783.9548633430051, -1101.666881261192, -298.09467420462454, -479.0134700623799, -1032.0561144321455, 165.93866293616315, -302.41937141727624, -843.9039999914951, -968.5900458717014, -951.1205193505713, -956.5685301948629, 1318.5885462830875, -530.3728928051034, 1115.515736651734, -818.0875836852138, 1166.9249005721642, -625.8204275219916, 1131.4008013086952, -802.2951816447646, 1423.3352057928014, 693.3760011436397, 1702.4612514344117, 706.0909181263436, 1272.9314642340105, 1053.4284845396794, 783.9173200438406, 1475.2691836859972, 799.3504739186951, -682.028565762292, -739.5550456870277, -120.83203849597254, -528.3104787623973, 353.74456090460853, -1180.347763788574, -86.3054711070549, 287.06819676382554, -870.6072327923064, -1087.5164716008956, 1358.6250527319403, -596.1934520813752, 199.5748594289696, -633.8856896129893, 1523.5170790207383, -250.88136920367853, 1298.0012235972824, -674.0599091946224, 1184.9337564381522, 1247.4726863636636, 1140.5180064976325, 1206.6312091423117, 1364.482305557191, 1487.6103503350107, 161.32989337605534, 965.8601698721465, -491.60783995143987, -760.2090852481896, -70.59057264063144, -735.3614508944277, 152.7382781343565, -817.9314729357528, -138.20155284203912, -499.59506846136145, 287.1117300258215, -604.4820380949982, -477.2503846439241, -242.71431666414375], "episode_lengths": [113, 223, 141, 202, 249, 216, 122, 170, 140, 165, 173, 177, 129, 166, 152, 148, 142, 125, 148, 126, 111, 191, 118, 173, 178, 211, 165, 171, 147, 164, 132, 217, 139, 213, 145, 153, 106, 136, 148, 130, 122, 135, 202, 141, 147, 305, 104, 259, 127, 225, 100, 259, 96, 240, 129, 169, 133, 171, 166, 132, 186, 152, 127, 137, 108, 134, 155, 154, 139, 180, 138, 153, 228, 82, 180, 145, 219, 41, 247, 66, 222, 196, 159, 219, 174, 136, 179, 191, 128, 148, 134, 124, 143, 106, 105, 130, 180, 143, 128, 104], "policy_AGENT-2_reward": [-260.21992845017274, 0.874005717809079, -183.20515724590922, 286.8638954825797, -30.423578982144164, 274.4765829410098, -232.8645408480919, 186.7408561256432, 172.20386573212124, 282.1424932139556, 271.1210619457835, 29.218013894485953, 134.05011879436256, 270.6879183921784, 146.56412239293562, 304.4970180225557, -13.7924043350526, -8.234927911681524, 28.850681965423227, -7.322329542633924, -93.6621565522927, -10.137954675447732, -15.205984898519796, 187.73352229520512, -35.958319415717874, 199.1591347463962, -313.3227636730629, 74.28746235483021, 228.01701942197568, 355.7098980640858, 276.02741438203645, 37.71393917308801, 286.96289234484897, 53.92290690799578, 224.78774185776453, -199.00392506958653, -33.674923554970555, -97.12753159808867, -355.1768929779138, 32.3756353444824, -8.781200597277373, -166.81055100725902, -60.34201016459104, -202.72371259306496, -156.24364531933395, 84.65154899825231, -157.3068779518662, -3.474386071505712, -204.34845883039586, 302.4335531411839, -182.58898870576596, -4.253770738963578, -168.44503949950737, 184.04563504255566, 133.59807825061648, 330.34854742945345, 181.01095255889317, 290.60003091669404, 54.82321044444775, 215.76598470744167, 384.86746806118134, 246.59483384425366, -150.14212104677765, -170.19621003844017, -27.811217362544834, -12.481623607157239, -7.966494333762882, -284.5043397975646, -9.166533286828152, -11.453841421563775, -189.19523116661028, -190.65450729707146, 201.60479147150016, -124.86604619656688, 153.67530188701176, -147.88690752822617, 239.37669718872905, -31.2658118523586, 64.15631253705564, -194.65766384959832, 97.4598213492323, 71.62373490670466, 338.91850895418605, 95.27139603242455, 370.09601492219645, 306.35955773304056, -34.008846614888505, 91.4864100766107, -31.49118240116702, -159.35190636244528, -19.174071160724147, -184.0193409397032, 33.546851026217205, -229.87536217563644, -62.800800970645135, -108.57830432747362, -7.78795318959345, -80.88997351523807, -15.791986811914636, -45.58218768678771], "policy_AGENT-1_reward": [-304.8774545327169, 629.5021501153068, -204.15248149954115, 623.726612106761, 344.23280720222664, 645.1905102635516, -111.02555402044166, 187.1731262613467, 200.28420352871726, 339.2753628237037, 297.85435616919176, 78.23045823377647, 254.79348378611576, 290.5753761868635, 287.17093053175654, 344.02483915816936, 45.956815911239055, -105.55186680537162, 85.9837574672301, -17.932680417259636, -147.43209999398908, 89.22414959608018, -121.69585149537436, 306.4067459047357, 97.02292282600853, 597.7016241157664, -312.85311767584716, 74.7197021790956, 216.89181435517082, 331.5165607919426, 280.01424712730295, 38.44326743687995, 281.51614928205055, 54.34149160176425, 208.09220031644693, -331.04913190505584, -115.39178234867273, -141.13049492776747, -323.71244301199914, 24.31437492986884, -118.21394825724599, -234.81819274322217, -402.41012793616125, -249.60780353380133, -338.8458415459849, 633.8509793824428, -107.44855409146334, 602.7395061567028, -198.0938659375842, 302.99461897969536, -130.26724778590082, 612.2154679822422, -249.91024751044645, 184.4833274385342, 134.2435585297873, 331.02781768632696, 181.6223713278016, 339.88968895758455, 55.529577480900386, 206.7530559468815, 294.5646036205035, 195.3556837370489, -163.34510923704013, -187.73099424753715, -5.01309593132469, -229.5953126301656, 191.42796194491862, -335.48182009137105, -28.904524231151694, 162.37262587036562, -219.42826794768217, -334.862834960967, 621.6680444645646, -173.09168886065714, 154.15779209442897, -150.30778175805082, 635.8613174754989, -94.37983737190112, 626.0140476221137, -142.43134727494217, 633.9748123278832, 72.15721595963699, 281.5018507707404, 95.83069000439521, 411.8930184224893, 373.8064332586276, 120.87310133427101, 280.6869839741891, -191.41777246956292, -216.21151741673012, -13.94189965564737, -191.7056320725239, 42.602069907980855, -179.02637109740164, -29.393569058268643, -117.91592131449652, 176.07924029235934, -199.00934675779172, -201.87420732012504, -63.055629319991866], "policy_AGENT-3_reward": [-256.23590286870274, 0.9301394054973993, -182.71042224351902, 346.0133367533301, -30.350038442524195, 353.8796917977564, -221.60531564204467, 525.0064564089543, 152.5803527692878, 493.9362798797089, 299.5248788600432, 452.41913184095716, 222.41541937232267, 479.52873839206455, 271.02052951242723, 462.6319952969297, -2.828124831744704, -8.475499068208176, 31.463794936421557, -7.293715294212453, -97.25686677182009, -16.56764565394739, -15.401951582691076, 148.22867548235655, -36.2467232205098, 315.5847937421352, -369.5893465815849, 518.3284029516566, 207.2943503047974, 510.4753790211509, 267.27711160020704, 590.944987394549, 211.5720697401713, 551.4501537049246, 187.1933216889477, -199.09763447521792, -33.86736992622547, -98.8101086340107, -289.7500578196254, 39.48256082135017, -8.78637009062614, -166.75437130036357, -60.364975216705375, -205.68992750056066, -156.1872840720154, 84.63424692921174, -158.06092770707343, -3.668334971940321, -212.15666280859625, 334.0688800422874, -182.68372641148005, -4.263111172764343, -216.05617821921166, 540.0342165799949, 232.03625811193228, 511.4418202143355, 199.46439493337556, 317.03415401846587, 492.9199512243056, 199.87414991595472, 538.8047346248816, 208.5096253783655, -157.3980054991981, -146.431365125928, -27.809295604739933, -12.492780767194164, -7.900747907527475, -236.77865899131194, -9.425285270155156, -11.439744433698424, -201.37778891843752, -190.6705320982139, 367.48777779040114, -125.13965225134596, -64.97230891989086, -169.6805097335451, 443.5232216772747, -31.141053902970313, 64.11111000458749, -194.7122911273832, 338.6080506501445, 550.4956336483635, 274.4441656077723, 547.3114922577117, 256.0243456242402, 500.5220775584305, -33.86769023287688, 538.2862758393675, -31.496092620608145, -123.91082923063993, -19.13335897114052, -188.56233165371353, 38.491302550452694, -229.96185070478344, -16.88973883995415, -110.65542781269873, -7.707186663278613, -81.11456985216755, -15.969943072563646, -71.06806900969477], "policy_AGENT-0_reward": [-304.921971696108, 627.7413265345999, -235.48884454336286, 319.559827397175, 378.40141862570454, 237.5861423294741, -110.78342154375721, 477.715094158894, 221.51215173204866, 245.05749688288654, 270.1650378038653, 55.515486242487675, 134.60540514658675, 236.84245182936698, 147.12139940824818, 333.4582723584446, 35.199293498447574, -151.14516200017573, 74.06996901816777, -20.17540914184909, -147.46306852306245, 74.83743962186733, -121.46886513831242, 293.30429618551454, 81.94119842730926, 233.8731707054543, -382.6201100641378, 537.47574049529, 228.93564087407944, 366.0661838465263, 232.5844743974734, 518.175654685894, 236.00760258799193, 477.03098058569185, 163.8815994798449, -372.5161898113319, -115.16059837475574, -141.94533490251288, -63.416720622608715, 69.76609184046168, -166.63785247212655, -275.52088494065094, -445.4729325542436, -293.09907572314376, -305.29175925752907, 515.451770973181, -107.55653305470015, 519.9189515384792, -203.48859610863747, 227.4278484089984, -130.28046461884477, 527.7022152381812, -167.8837164155994, 514.7720267317169, 193.49810625130397, 529.6430661042953, 143.99319930627274, 325.40759034126495, 450.1557453900259, 161.52412947356277, 257.0323773794285, 148.8903309590271, -211.1433299792763, -235.19647627512217, -60.19842959736302, -273.74076175788036, 178.18384120098, -323.58294490832554, -38.80912831891982, 147.58915674872233, -260.60594475957606, -371.328597244643, 167.864439005473, -173.09606477280497, -43.28592563258053, -166.01049059316733, 204.75584267923574, -94.0946660764485, 543.7197534335245, -142.25860694269815, 114.89107211089267, 553.1961018489588, 245.65348116493357, 468.2176308477798, 326.4689265882661, 306.9222817849097, 108.33332888954982, 55.40049998197922, -237.2027924601022, -260.73483223837417, -18.341242853119407, -171.07414622848725, 38.098054649705716, -179.06788895793142, -29.11744397317124, -162.44541500669288, 126.52762958633437, -243.46814796980124, -243.61424743932102, -63.00843064766967]}, "sampler_perf": {"mean_env_wait_ms": 65.71123005790766, "mean_raw_obs_processing_ms": 2.6561225280915397, "mean_inference_ms": 2.832927371119935, "mean_action_processing_ms": 0.1663950144829251}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 92400, "timers": {"sample_time_ms": 85200.385, "sample_throughput": 49.296, "load_time_ms": 15.523, "load_throughput": 270564.1, "learn_time_ms": 14688.899, "learn_throughput": 285.93, "update_time_ms": 8.64}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 21.22730827331543, "policy_loss": -0.05448680371046066, "vf_loss": 21.277883529663086, "vf_explained_var": 0.9883324503898621, "kl": 0.019535426050424576, "entropy": 0.9538513422012329, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 25.358816146850586, "policy_loss": -0.04864787682890892, "vf_loss": 25.401662826538086, "vf_explained_var": 0.9861953258514404, "kl": 0.019337931647896767, "entropy": 1.0776342153549194, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 38.79472351074219, "policy_loss": -0.04920780658721924, "vf_loss": 38.83980178833008, "vf_explained_var": 0.9794079661369324, "kl": 0.020667364820837975, "entropy": 1.1107178926467896, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 15.76859188079834, "policy_loss": -0.04669653996825218, "vf_loss": 15.80786418914795, "vf_explained_var": 0.9893999695777893, "kl": 0.016496896743774414, "entropy": 0.9506052136421204, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 92400, "num_steps_trained": 92400}, "done": false, "episodes_total": 710, "training_iteration": 22, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-06-34", "timestamp": 1624201594, "time_this_iter_s": 176.599928855896, "time_total_s": 2806.699643135071, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f041bb90>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f0246f80>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246a70>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246050>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0104050>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246a70>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246050>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0104050>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246a70>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246050>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0104050>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246a70>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0246050>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0104050>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f02c8dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2806.699643135071, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 58.443824701195226, "ram_util_percent": 87.99203187250995}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1702.4612514344117, "episode_reward_min": -1180.347763788574, "episode_reward_mean": 380.6439417725133, "episode_len_mean": 156.39, "episodes_this_iter": 27, "policy_reward_min": {"AGENT-2": -284.5043397975646, "AGENT-3": -256.23590286870274, "AGENT-0": -371.328597244643, "AGENT-1": -335.48182009137105}, "policy_reward_max": {"AGENT-2": 384.86746806118134, "AGENT-3": 568.2434263495863, "AGENT-0": 627.7413265345999, "AGENT-1": 645.2252013605595}, "policy_reward_mean": {"AGENT-2": 51.51232418599473, "AGENT-3": 120.49971614533194, "AGENT-0": 85.73683266915421, "AGENT-1": 122.89506877203226}, "custom_metrics": {"mean_ego_speed_mean": 41.725517499999995, "mean_ego_speed_min": 28.55025, "mean_ego_speed_max": 51.30525, "distance_travelled_mean": 104.22052249999999, "distance_travelled_min": 33.33, "distance_travelled_max": 124.91025}, "hist_stats": {"episode_reward": [1313.4822893909072, -513.9881308495728, 1373.5739939401205, -512.2637480967616, 1284.329153109074, -330.798657054137, 1321.8786854846708, -851.1056127700998, 214.75850750605386, 912.911815526293, 1033.3915997255501, 993.6691484119957, 1523.651918105515, 572.6390381260387, 1207.8127579059035, 675.0178397191909, 1188.3931250332378, 586.8575480744164, 938.8708934185128, 905.6619931257837, 335.4831107837453, 330.9819087521242, 292.5357484698204, -627.3138005709014, -102.59721020718203, 993.5040913444394, -372.3127112207482, -802.2951816447646, 1423.3352057928014, 693.3760011436397, 1702.4612514344117, 706.0909181263436, 1272.9314642340105, 1053.4284845396794, 783.9173200438406, 1475.2691836859972, 799.3504739186951, -682.028565762292, -739.5550456870277, -120.83203849597254, -528.3104787623973, 353.74456090460853, -1180.347763788574, -86.3054711070549, 287.06819676382554, -870.6072327923064, -1087.5164716008956, 1358.6250527319403, -596.1934520813752, 199.5748594289696, -633.8856896129893, 1523.5170790207383, -250.88136920367853, 1298.0012235972824, -674.0599091946224, 1184.9337564381522, 1247.4726863636636, 1140.5180064976325, 1206.6312091423117, 1364.482305557191, 1487.6103503350107, 161.32989337605534, 965.8601698721465, -491.60783995143987, -760.2090852481896, -70.59057264063144, -735.3614508944277, 152.7382781343565, -817.9314729357528, -138.20155284203912, -499.59506846136145, 287.1117300258215, -604.4820380949982, -477.2503846439241, -242.71431666414375, -1126.2552575477014, 1259.047621773214, -805.5569055323323, 1576.1636717398446, 661.8606084032635, 1511.1329273317897, -676.2788320543357, 1376.6355329548373, 746.5805737621745, 1360.4116328002544, 1138.6653347788847, 615.3830902117089, 745.8644270993879, 1277.634484800475, 851.8769818453682, 1444.6121248360996, 64.53558024288945, -273.40745578543675, 220.36820338724274, -52.72413439595505, -485.8141918411646, 137.3559888885521, -273.7726531148977, 935.6732398678116, 106.75907861709005], "episode_lengths": [226, 53, 233, 108, 218, 136, 233, 149, 209, 106, 180, 161, 161, 122, 235, 145, 179, 143, 182, 170, 191, 183, 140, 145, 144, 192, 41, 96, 240, 129, 169, 133, 171, 166, 132, 186, 152, 127, 137, 108, 134, 155, 154, 139, 180, 138, 153, 228, 82, 180, 145, 219, 41, 247, 66, 222, 196, 159, 219, 174, 136, 179, 191, 128, 148, 134, 124, 143, 106, 105, 130, 180, 143, 128, 104, 113, 223, 141, 202, 249, 216, 122, 170, 140, 165, 173, 177, 129, 166, 152, 148, 142, 125, 148, 126, 111, 191, 118, 173, 178], "policy_AGENT-2_reward": [142.5102134084514, -154.6036320745077, 166.89592311112054, -132.02306337641573, 182.60074947176278, -30.934319516571783, 62.39608538668324, -220.3485660581434, 151.56757418149496, 265.67863545815874, 152.99356312205276, 168.87155739443935, 205.55769089299503, 88.44011486411492, 45.9344434468017, 199.48174036386584, 208.03273386544686, 48.813861246975, 174.14143122211337, 231.07107462614638, -24.076535790650492, 56.530868450446874, 84.06448245676451, -95.88307463859383, 34.574977299156316, 188.728485172209, -119.96610434487826, -168.44503949950737, 184.04563504255566, 133.59807825061648, 330.34854742945345, 181.01095255889317, 290.60003091669404, 54.82321044444775, 215.76598470744167, 384.86746806118134, 246.59483384425366, -150.14212104677765, -170.19621003844017, -27.811217362544834, -12.481623607157239, -7.966494333762882, -284.5043397975646, -9.166533286828152, -11.453841421563775, -189.19523116661028, -190.65450729707146, 201.60479147150016, -124.86604619656688, 153.67530188701176, -147.88690752822617, 239.37669718872905, -31.2658118523586, 64.15631253705564, -194.65766384959832, 97.4598213492323, 71.62373490670466, 338.91850895418605, 95.27139603242455, 370.09601492219645, 306.35955773304056, -34.008846614888505, 91.4864100766107, -31.49118240116702, -159.35190636244528, -19.174071160724147, -184.0193409397032, 33.546851026217205, -229.87536217563644, -62.800800970645135, -108.57830432747362, -7.78795318959345, -80.88997351523807, -15.791986811914636, -45.58218768678771, -260.21992845017274, 0.874005717809079, -183.20515724590922, 286.8638954825797, -30.423578982144164, 274.4765829410098, -232.8645408480919, 186.7408561256432, 172.20386573212124, 282.1424932139556, 271.1210619457835, 29.218013894485953, 134.05011879436256, 270.6879183921784, 146.56412239293562, 304.4970180225557, -13.7924043350526, -8.234927911681524, 28.850681965423227, -7.322329542633924, -93.6621565522927, -10.137954675447732, -15.205984898519796, 187.73352229520512, -35.958319415717874], "policy_AGENT-3_reward": [435.25870795262114, -154.76423304662254, 359.58022994959913, -158.92374284373466, 341.9171303417097, -31.034553379406347, 62.36129635045298, -215.00912015436495, -41.84659855670655, 237.89633953198773, 493.9883962233344, 321.2106609587392, 512.4328538985001, 191.2051978840574, 568.2434263495863, 235.69655295469633, 519.5194236198422, 235.97554947710282, 163.9116534966382, 162.06297005823052, -24.091930589896517, 47.605553045825424, 72.8270658449805, -139.93357471566847, 1.2345807976920966, 182.61833622788396, -120.23924300750315, -216.05617821921166, 540.0342165799949, 232.03625811193228, 511.4418202143355, 199.46439493337556, 317.03415401846587, 492.9199512243056, 199.87414991595472, 538.8047346248816, 208.5096253783655, -157.3980054991981, -146.431365125928, -27.809295604739933, -12.492780767194164, -7.900747907527475, -236.77865899131194, -9.425285270155156, -11.439744433698424, -201.37778891843752, -190.6705320982139, 367.48777779040114, -125.13965225134596, -64.97230891989086, -169.6805097335451, 443.5232216772747, -31.141053902970313, 64.11111000458749, -194.7122911273832, 338.6080506501445, 550.4956336483635, 274.4441656077723, 547.3114922577117, 256.0243456242402, 500.5220775584305, -33.86769023287688, 538.2862758393675, -31.496092620608145, -123.91082923063993, -19.13335897114052, -188.56233165371353, 38.491302550452694, -229.96185070478344, -16.88973883995415, -110.65542781269873, -7.707186663278613, -81.11456985216755, -15.969943072563646, -71.06806900969477, -256.23590286870274, 0.9301394054973993, -182.71042224351902, 346.0133367533301, -30.350038442524195, 353.8796917977564, -221.60531564204467, 525.0064564089543, 152.5803527692878, 493.9362798797089, 299.5248788600432, 452.41913184095716, 222.41541937232267, 479.52873839206455, 271.02052951242723, 462.6319952969297, -2.828124831744704, -8.475499068208176, 31.463794936421557, -7.293715294212453, -97.25686677182009, -16.56764565394739, -15.401951582691076, 148.22867548235655, -36.2467232205098], "policy_AGENT-0_reward": [108.54639964078898, -102.35302220009495, 201.8726395188408, -110.5949229608768, 148.72815958913816, -139.4075363612459, 562.3338513453681, -214.62195102491802, -47.00450514706417, 204.74436003081215, 113.91842509909343, 315.5902772620606, 419.9101283719582, 89.01793733763431, 546.9999970681707, 119.89758175391867, 165.7720509760452, 49.24243667837742, 293.60715773028954, 249.3974418889541, 185.60196901755617, 105.43857516288429, 63.65873981102321, -220.34392390075647, -69.12798776339025, 304.29201535526846, -66.04893338794503, -167.8837164155994, 514.7720267317169, 193.49810625130397, 529.6430661042953, 143.99319930627274, 325.40759034126495, 450.1557453900259, 161.52412947356277, 257.0323773794285, 148.8903309590271, -211.1433299792763, -235.19647627512217, -60.19842959736302, -273.74076175788036, 178.18384120098, -323.58294490832554, -38.80912831891982, 147.58915674872233, -260.60594475957606, -371.328597244643, 167.864439005473, -173.09606477280497, -43.28592563258053, -166.01049059316733, 204.75584267923574, -94.0946660764485, 543.7197534335245, -142.25860694269815, 114.89107211089267, 553.1961018489588, 245.65348116493357, 468.2176308477798, 326.4689265882661, 306.9222817849097, 108.33332888954982, 55.40049998197922, -237.2027924601022, -260.73483223837417, -18.341242853119407, -171.07414622848725, 38.098054649705716, -179.06788895793142, -29.11744397317124, -162.44541500669288, 126.52762958633437, -243.46814796980124, -243.61424743932102, -63.00843064766967, -304.921971696108, 627.7413265345999, -235.48884454336286, 319.559827397175, 378.40141862570454, 237.5861423294741, -110.78342154375721, 477.715094158894, 221.51215173204866, 245.05749688288654, 270.1650378038653, 55.515486242487675, 134.60540514658675, 236.84245182936698, 147.12139940824818, 333.4582723584446, 35.199293498447574, -151.14516200017573, 74.06996901816777, -20.17540914184909, -147.46306852306245, 74.83743962186733, -121.46886513831242, 293.30429618551454, 81.94119842730926], "policy_AGENT-1_reward": [627.1669683890448, -102.26724352834782, 645.2252013605595, -110.72201891573425, 611.0831137064646, -129.42224779691284, 634.7874524021651, -201.1259755326736, 152.04203702832996, 204.5924805053347, 272.4912152810695, 187.99665279675582, 385.75124494206295, 203.97578804023257, 46.634891041344076, 119.94196464670983, 295.06891657190334, 252.82570067196121, 307.2106509694723, 263.1305065524534, 198.0496081467361, 121.40691209296756, 71.98546035705235, -171.15322731588245, -69.27878054064008, 317.8652545890777, -66.05843048042185, -249.91024751044645, 184.4833274385342, 134.2435585297873, 331.02781768632696, 181.6223713278016, 339.88968895758455, 55.529577480900386, 206.7530559468815, 294.5646036205035, 195.3556837370489, -163.34510923704013, -187.73099424753715, -5.01309593132469, -229.5953126301656, 191.42796194491862, -335.48182009137105, -28.904524231151694, 162.37262587036562, -219.42826794768217, -334.862834960967, 621.6680444645646, -173.09168886065714, 154.15779209442897, -150.30778175805082, 635.8613174754989, -94.37983737190112, 626.0140476221137, -142.43134727494217, 633.9748123278832, 72.15721595963699, 281.5018507707404, 95.83069000439521, 411.8930184224893, 373.8064332586276, 120.87310133427101, 280.6869839741891, -191.41777246956292, -216.21151741673012, -13.94189965564737, -191.7056320725239, 42.602069907980855, -179.02637109740164, -29.393569058268643, -117.91592131449652, 176.07924029235934, -199.00934675779172, -201.87420732012504, -63.055629319991866, -304.8774545327169, 629.5021501153068, -204.15248149954115, 623.726612106761, 344.23280720222664, 645.1905102635516, -111.02555402044166, 187.1731262613467, 200.28420352871726, 339.2753628237037, 297.85435616919176, 78.23045823377647, 254.79348378611576, 290.5753761868635, 287.17093053175654, 344.02483915816936, 45.956815911239055, -105.55186680537162, 85.9837574672301, -17.932680417259636, -147.43209999398908, 89.22414959608018, -121.69585149537436, 306.4067459047357, 97.02292282600853]}, "sampler_perf": {"mean_env_wait_ms": 65.66190399517046, "mean_raw_obs_processing_ms": 2.6458551955494682, "mean_inference_ms": 2.837355506456862, "mean_action_processing_ms": 0.1667918001833373}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 96600, "timers": {"sample_time_ms": 89666.394, "sample_throughput": 46.84, "load_time_ms": 15.474, "load_throughput": 271430.811, "learn_time_ms": 14534.32, "learn_throughput": 288.971, "update_time_ms": 8.521}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 35.250762939453125, "policy_loss": -0.0409163199365139, "vf_loss": 35.28803253173828, "vf_explained_var": 0.9836345911026001, "kl": 0.018245477229356766, "entropy": 0.9385573863983154, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 39.84173583984375, "policy_loss": -0.04114355891942978, "vf_loss": 39.877586364746094, "vf_explained_var": 0.9807636141777039, "kl": 0.017633145675063133, "entropy": 1.0657107830047607, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 63.55106735229492, "policy_loss": -0.04036647453904152, "vf_loss": 63.5867919921875, "vf_explained_var": 0.968657374382019, "kl": 0.015470542013645172, "entropy": 1.1082457304000854, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 28.180633544921875, "policy_loss": -0.0443267785012722, "vf_loss": 28.21898651123047, "vf_explained_var": 0.9837411642074585, "kl": 0.013269156217575073, "entropy": 0.9345515966415405, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 96600, "num_steps_trained": 96600}, "done": false, "episodes_total": 737, "training_iteration": 23, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-08-55", "timestamp": 1624201735, "time_this_iter_s": 140.6099557876587, "time_total_s": 2947.3095989227295, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f03d9050>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f03d9200>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f017ce60>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f017ce60>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f017ce60>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f017ce60>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f0104320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2947.3095989227295, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 57.12039800995025, "ram_util_percent": 88.04975124378109}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1576.1636717398446, "episode_reward_min": -1126.2552575477014, "episode_reward_mean": 445.4819658697996, "episode_len_mean": 159.82, "episodes_this_iter": 26, "policy_reward_min": {"AGENT-2": -260.21992845017274, "AGENT-1": -304.8774545327169, "AGENT-3": -256.23590286870274, "AGENT-0": -304.921971696108}, "policy_reward_max": {"AGENT-2": 370.09601492219645, "AGENT-1": 645.2252013605595, "AGENT-3": 568.2434263495863, "AGENT-0": 627.7413265345999}, "policy_reward_mean": {"AGENT-2": 57.01437444308843, "AGENT-1": 154.43120856024296, "AGENT-3": 127.72404131763335, "AGENT-0": 106.31234154883487}, "custom_metrics": {"mean_ego_speed_mean": 41.9551525, "mean_ego_speed_min": 29.26225, "mean_ego_speed_max": 51.497749999999996, "distance_travelled_mean": 105.21371, "distance_travelled_min": 40.45875, "distance_travelled_max": 124.91025}, "hist_stats": {"episode_reward": [-523.1404457295152, 1273.8816343020333, -704.6109224635915, 1531.5491182877577, -500.08408145125395, 1318.9954362765902, -780.4826443460784, 1298.203136811755, 947.9274500915222, 750.9824758207301, 1343.2807491777974, 1017.5983711193568, 1298.6428713461382, 926.4251609169006, 917.0235006970959, 748.3584009737789, 687.0540787188801, 200.00329580689578, -453.3085864364965, -185.74738036090682, -387.3832180773407, 369.061625145048, 744.5524840838644, 485.00030576913315, -276.8488464832968, 490.7997309620212, 1298.0012235972824, -674.0599091946224, 1184.9337564381522, 1247.4726863636636, 1140.5180064976325, 1206.6312091423117, 1364.482305557191, 1487.6103503350107, 161.32989337605534, 965.8601698721465, -491.60783995143987, -760.2090852481896, -70.59057264063144, -735.3614508944277, 152.7382781343565, -817.9314729357528, -138.20155284203912, -499.59506846136145, 287.1117300258215, -604.4820380949982, -477.2503846439241, -242.71431666414375, -1126.2552575477014, 1259.047621773214, -805.5569055323323, 1576.1636717398446, 661.8606084032635, 1511.1329273317897, -676.2788320543357, 1376.6355329548373, 746.5805737621745, 1360.4116328002544, 1138.6653347788847, 615.3830902117089, 745.8644270993879, 1277.634484800475, 851.8769818453682, 1444.6121248360996, 64.53558024288945, -273.40745578543675, 220.36820338724274, -52.72413439595505, -485.8141918411646, 137.3559888885521, -273.7726531148977, 935.6732398678116, 106.75907861709005, 1313.4822893909072, -513.9881308495728, 1373.5739939401205, -512.2637480967616, 1284.329153109074, -330.798657054137, 1321.8786854846708, -851.1056127700998, 214.75850750605386, 912.911815526293, 1033.3915997255501, 993.6691484119957, 1523.651918105515, 572.6390381260387, 1207.8127579059035, 675.0178397191909, 1188.3931250332378, 586.8575480744164, 938.8708934185128, 905.6619931257837, 335.4831107837453, 330.9819087521242, 292.5357484698204, -627.3138005709014, -102.59721020718203, 993.5040913444394, -372.3127112207482], "episode_lengths": [106, 236, 138, 207, 114, 241, 120, 243, 186, 130, 183, 132, 117, 124, 164, 149, 208, 170, 164, 103, 126, 174, 184, 173, 110, 235, 247, 66, 222, 196, 159, 219, 174, 136, 179, 191, 128, 148, 134, 124, 143, 106, 105, 130, 180, 143, 128, 104, 113, 223, 141, 202, 249, 216, 122, 170, 140, 165, 173, 177, 129, 166, 152, 148, 142, 125, 148, 126, 111, 191, 118, 173, 178, 226, 53, 233, 108, 218, 136, 233, 149, 209, 106, 180, 161, 161, 122, 235, 145, 179, 143, 182, 170, 191, 183, 140, 145, 144, 192, 41], "policy_AGENT-2_reward": [-136.40854880576694, 40.59850726146018, -156.36588996267628, 303.4409940478952, -126.90565017048431, 75.17792794441912, -149.02923579667208, 84.46706026883533, 136.25752884704653, 148.46045053972603, 295.0115393840578, 278.414977233671, 270.5022447549525, 251.88728730187512, 145.81495918049575, 90.24916003849006, -40.79067180661206, 55.33925182818072, -49.32652796483654, -52.99515759803656, -80.18251246077551, -15.948924050272016, 197.98938919288076, 119.72786679560463, -104.08297499534604, 59.17758206905519, 64.15631253705564, -194.65766384959832, 97.4598213492323, 71.62373490670466, 338.91850895418605, 95.27139603242455, 370.09601492219645, 306.35955773304056, -34.008846614888505, 91.4864100766107, -31.49118240116702, -159.35190636244528, -19.174071160724147, -184.0193409397032, 33.546851026217205, -229.87536217563644, -62.800800970645135, -108.57830432747362, -7.78795318959345, -80.88997351523807, -15.791986811914636, -45.58218768678771, -260.21992845017274, 0.874005717809079, -183.20515724590922, 286.8638954825797, -30.423578982144164, 274.4765829410098, -232.8645408480919, 186.7408561256432, 172.20386573212124, 282.1424932139556, 271.1210619457835, 29.218013894485953, 134.05011879436256, 270.6879183921784, 146.56412239293562, 304.4970180225557, -13.7924043350526, -8.234927911681524, 28.850681965423227, -7.322329542633924, -93.6621565522927, -10.137954675447732, -15.205984898519796, 187.73352229520512, -35.958319415717874, 142.5102134084514, -154.6036320745077, 166.89592311112054, -132.02306337641573, 182.60074947176278, -30.934319516571783, 62.39608538668324, -220.3485660581434, 151.56757418149496, 265.67863545815874, 152.99356312205276, 168.87155739443935, 205.55769089299503, 88.44011486411492, 45.9344434468017, 199.48174036386584, 208.03273386544686, 48.813861246975, 174.14143122211337, 231.07107462614638, -24.076535790650492, 56.530868450446874, 84.06448245676451, -95.88307463859383, 34.574977299156316, 188.728485172209, -119.96610434487826], "policy_AGENT-1_reward": [-112.6826604853044, 635.2363576089116, -203.05095134097263, 644.3003288194799, -106.61464134105182, 624.1414642560692, -228.65316537960092, 604.2514331073043, 252.28379540058978, 234.29015794035735, 295.66204655128837, 264.34550266198283, 273.12545225701786, 212.67463201237095, 215.7182304446431, 292.62461400443, 267.82128523668393, 89.26906082572485, -164.31738330657038, -64.36717759942866, -88.54699311690287, 181.40676919806737, 211.1563718079405, 146.4284462772403, -12.783196098642179, 206.80011087629248, 626.0140476221137, -142.43134727494217, 633.9748123278832, 72.15721595963699, 281.5018507707404, 95.83069000439521, 411.8930184224893, 373.8064332586276, 120.87310133427101, 280.6869839741891, -191.41777246956292, -216.21151741673012, -13.94189965564737, -191.7056320725239, 42.602069907980855, -179.02637109740164, -29.393569058268643, -117.91592131449652, 176.07924029235934, -199.00934675779172, -201.87420732012504, -63.055629319991866, -304.8774545327169, 629.5021501153068, -204.15248149954115, 623.726612106761, 344.23280720222664, 645.1905102635516, -111.02555402044166, 187.1731262613467, 200.28420352871726, 339.2753628237037, 297.85435616919176, 78.23045823377647, 254.79348378611576, 290.5753761868635, 287.17093053175654, 344.02483915816936, 45.956815911239055, -105.55186680537162, 85.9837574672301, -17.932680417259636, -147.43209999398908, 89.22414959608018, -121.69585149537436, 306.4067459047357, 97.02292282600853, 627.1669683890448, -102.26724352834782, 645.2252013605595, -110.72201891573425, 611.0831137064646, -129.42224779691284, 634.7874524021651, -201.1259755326736, 152.04203702832996, 204.5924805053347, 272.4912152810695, 187.99665279675582, 385.75124494206295, 203.97578804023257, 46.634891041344076, 119.94196464670983, 295.06891657190334, 252.82570067196121, 307.2106509694723, 263.1305065524534, 198.0496081467361, 121.40691209296756, 71.98546035705235, -171.15322731588245, -69.27878054064008, 317.8652545890777, -66.05843048042185], "policy_AGENT-3_reward": [-161.43060900052237, 40.651499203961734, -180.9071279459299, 320.3335894134175, -135.66354649177234, 75.1664794432776, -254.3222256763833, 84.52013833179566, 457.11765070890453, 219.22249535678384, 493.5531678651317, 258.4514704141212, 483.95485962554545, 252.66690202164537, 446.55344350217575, 274.68670742474046, 534.4101119422801, -20.818526770330585, -190.8893001210644, -4.03684834615035, -84.04478508746217, -16.049113184431498, 136.66912041014635, 89.27778584056662, -13.347942618039529, 59.12351779365123, 64.11111000458749, -194.7122911273832, 338.6080506501445, 550.4956336483635, 274.4441656077723, 547.3114922577117, 256.0243456242402, 500.5220775584305, -33.86769023287688, 538.2862758393675, -31.496092620608145, -123.91082923063993, -19.13335897114052, -188.56233165371353, 38.491302550452694, -229.96185070478344, -16.88973883995415, -110.65542781269873, -7.707186663278613, -81.11456985216755, -15.969943072563646, -71.06806900969477, -256.23590286870274, 0.9301394054973993, -182.71042224351902, 346.0133367533301, -30.350038442524195, 353.8796917977564, -221.60531564204467, 525.0064564089543, 152.5803527692878, 493.9362798797089, 299.5248788600432, 452.41913184095716, 222.41541937232267, 479.52873839206455, 271.02052951242723, 462.6319952969297, -2.828124831744704, -8.475499068208176, 31.463794936421557, -7.293715294212453, -97.25686677182009, -16.56764565394739, -15.401951582691076, 148.22867548235655, -36.2467232205098, 435.25870795262114, -154.76423304662254, 359.58022994959913, -158.92374284373466, 341.9171303417097, -31.034553379406347, 62.36129635045298, -215.00912015436495, -41.84659855670655, 237.89633953198773, 493.9883962233344, 321.2106609587392, 512.4328538985001, 191.2051978840574, 568.2434263495863, 235.69655295469633, 519.5194236198422, 235.97554947710282, 163.9116534966382, 162.06297005823052, -24.091930589896517, 47.605553045825424, 72.8270658449805, -139.93357471566847, 1.2345807976920966, 182.61833622788396, -120.23924300750315], "policy_AGENT-0_reward": [-112.61862743792173, 557.3952702276996, -164.2869532140125, 263.47420600696677, -130.90024344794512, 544.5095646328219, -148.47801749342182, 524.964505103818, 102.2684751349815, 149.00937198386313, 259.0539953773183, 216.38642080958218, 271.06031470862206, 209.1963395810103, 108.93686756978215, 90.79791950611853, -74.38664665347422, 76.21350992332074, -48.775375044025125, -64.34819681729124, -134.6089274122001, 219.65289318168433, 198.7376026728964, 129.56620685572165, -146.634732771269, 165.69852022302223, 543.7197534335245, -142.25860694269815, 114.89107211089267, 553.1961018489588, 245.65348116493357, 468.2176308477798, 326.4689265882661, 306.9222817849097, 108.33332888954982, 55.40049998197922, -237.2027924601022, -260.73483223837417, -18.341242853119407, -171.07414622848725, 38.098054649705716, -179.06788895793142, -29.11744397317124, -162.44541500669288, 126.52762958633437, -243.46814796980124, -243.61424743932102, -63.00843064766967, -304.921971696108, 627.7413265345999, -235.48884454336286, 319.559827397175, 378.40141862570454, 237.5861423294741, -110.78342154375721, 477.715094158894, 221.51215173204866, 245.05749688288654, 270.1650378038653, 55.515486242487675, 134.60540514658675, 236.84245182936698, 147.12139940824818, 333.4582723584446, 35.199293498447574, -151.14516200017573, 74.06996901816777, -20.17540914184909, -147.46306852306245, 74.83743962186733, -121.46886513831242, 293.30429618551454, 81.94119842730926, 108.54639964078898, -102.35302220009495, 201.8726395188408, -110.5949229608768, 148.72815958913816, -139.4075363612459, 562.3338513453681, -214.62195102491802, -47.00450514706417, 204.74436003081215, 113.91842509909343, 315.5902772620606, 419.9101283719582, 89.01793733763431, 546.9999970681707, 119.89758175391867, 165.7720509760452, 49.24243667837742, 293.60715773028954, 249.3974418889541, 185.60196901755617, 105.43857516288429, 63.65873981102321, -220.34392390075647, -69.12798776339025, 304.29201535526846, -66.04893338794503]}, "sampler_perf": {"mean_env_wait_ms": 65.6337750970427, "mean_raw_obs_processing_ms": 2.6359140118444633, "mean_inference_ms": 2.8425053134009204, "mean_action_processing_ms": 0.16725244235893563}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 100800, "timers": {"sample_time_ms": 88853.808, "sample_throughput": 47.269, "load_time_ms": 15.504, "load_throughput": 270906.536, "learn_time_ms": 14420.508, "learn_throughput": 291.252, "update_time_ms": 8.75}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 9.999999747378752e-05, "total_loss": 36.41082763671875, "policy_loss": -0.04260222613811493, "vf_loss": 36.44886779785156, "vf_explained_var": 0.9849062561988831, "kl": 0.02278737910091877, "entropy": 0.9112459421157837, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 45.15278244018555, "policy_loss": -0.04299081489443779, "vf_loss": 45.19016647338867, "vf_explained_var": 0.9819040894508362, "kl": 0.01871166005730629, "entropy": 1.0218024253845215, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 57.435001373291016, "policy_loss": -0.041382357478141785, "vf_loss": 57.47189712524414, "vf_explained_var": 0.977333664894104, "kl": 0.01497405394911766, "entropy": 1.1346628665924072, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 24.55329132080078, "policy_loss": -0.042256057262420654, "vf_loss": 24.58942985534668, "vf_explained_var": 0.986961841583252, "kl": 0.013590105809271336, "entropy": 0.9341591596603394, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 100800, "num_steps_trained": 100800}, "done": false, "episodes_total": 763, "training_iteration": 24, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-10-22", "timestamp": 1624201822, "time_this_iter_s": 86.71424913406372, "time_total_s": 3034.023848056793, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f01049e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f01047a0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0104560>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0104440>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0104200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f01040e0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0104560>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0104440>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0104200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f01040e0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0104560>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0104440>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0104200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f01040e0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0104560>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0104440>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0104200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f01040e0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f0104cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3034.023848056793, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 54.27419354838709, "ram_util_percent": 88.00645161290322}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1531.5491182877577, "episode_reward_min": -1055.3835726153427, "episode_reward_mean": 504.77170648501954, "episode_len_mean": 157.69, "episodes_this_iter": 27, "policy_reward_min": {"AGENT-2": -249.66600347339974, "AGENT-1": -356.64406077379857, "AGENT-3": -373.32774339574587, "AGENT-0": -291.4098005213659}, "policy_reward_max": {"AGENT-2": 340.4530294666071, "AGENT-1": 645.2252013605595, "AGENT-3": 568.2434263495863, "AGENT-0": 562.3338513453681}, "policy_reward_mean": {"AGENT-2": 75.4598857845061, "AGENT-1": 164.6787098017157, "AGENT-3": 146.1531094083833, "AGENT-0": 118.48000149041441}, "custom_metrics": {"mean_ego_speed_mean": 42.5644925, "mean_ego_speed_min": 29.893, "mean_ego_speed_max": 51.497749999999996, "distance_travelled_mean": 104.4474025, "distance_travelled_min": 40.45875, "distance_travelled_max": 124.91025}, "hist_stats": {"episode_reward": [-655.3062987121133, 1508.7184440654603, -584.680109036902, 1412.6165015641363, -538.6940496750397, 1410.218198760755, -1055.3835726153427, -924.294117382878, 1236.3553808793574, 1308.2952433223234, 647.7422393867017, 1175.8269944323358, 801.0514439494128, 752.9441872903614, 1195.3409756623048, 1072.3731128195202, 1129.020484391036, 1202.646691670803, -89.48078865641824, 214.583969292256, -606.1552202409611, 435.8710609002885, 574.0056184624425, 1273.7773848273223, 53.284140332252356, -402.5380225282749, -69.22017503477218, 1511.1329273317897, -676.2788320543357, 1376.6355329548373, 746.5805737621745, 1360.4116328002544, 1138.6653347788847, 615.3830902117089, 745.8644270993879, 1277.634484800475, 851.8769818453682, 1444.6121248360996, 64.53558024288945, -273.40745578543675, 220.36820338724274, -52.72413439595505, -485.8141918411646, 137.3559888885521, -273.7726531148977, 935.6732398678116, 106.75907861709005, 1313.4822893909072, -513.9881308495728, 1373.5739939401205, -512.2637480967616, 1284.329153109074, -330.798657054137, 1321.8786854846708, -851.1056127700998, 214.75850750605386, 912.911815526293, 1033.3915997255501, 993.6691484119957, 1523.651918105515, 572.6390381260387, 1207.8127579059035, 675.0178397191909, 1188.3931250332378, 586.8575480744164, 938.8708934185128, 905.6619931257837, 335.4831107837453, 330.9819087521242, 292.5357484698204, -627.3138005709014, -102.59721020718203, 993.5040913444394, -372.3127112207482, -523.1404457295152, 1273.8816343020333, -704.6109224635915, 1531.5491182877577, -500.08408145125395, 1318.9954362765902, -780.4826443460784, 1298.203136811755, 947.9274500915222, 750.9824758207301, 1343.2807491777974, 1017.5983711193568, 1298.6428713461382, 926.4251609169006, 917.0235006970959, 748.3584009737789, 687.0540787188801, 200.00329580689578, -453.3085864364965, -185.74738036090682, -387.3832180773407, 369.061625145048, 744.5524840838644, 485.00030576913315, -276.8488464832968, 490.7997309620212], "episode_lengths": [118, 217, 64, 197, 70, 223, 117, 144, 233, 144, 120, 202, 102, 160, 179, 102, 208, 123, 137, 147, 133, 152, 165, 183, 167, 122, 148, 216, 122, 170, 140, 165, 173, 177, 129, 166, 152, 148, 142, 125, 148, 126, 111, 191, 118, 173, 178, 226, 53, 233, 108, 218, 136, 233, 149, 209, 106, 180, 161, 161, 122, 235, 145, 179, 143, 182, 170, 191, 183, 140, 145, 144, 192, 41, 106, 236, 138, 207, 114, 241, 120, 243, 186, 130, 183, 132, 117, 124, 164, 149, 208, 170, 164, 103, 126, 174, 184, 173, 110, 235], "policy_AGENT-2_reward": [-165.00523758182774, 240.7176836471671, -178.40133551907985, 222.16334332350834, -165.9575679162749, 194.51333786522412, -249.66600347339974, -97.38328709597889, 21.640887595728778, 319.8864315587352, 204.97498915297925, 61.786623289232395, 152.72579210094915, 117.36589318976961, 179.258910327933, 252.6877055218871, 49.27502148697286, 250.7129753842462, -17.130865078014615, 58.867086140722606, -60.57050463405446, 114.88899882761201, 87.13298444744682, 340.4530294666071, 97.66420515779522, -88.04719786497016, 8.795498874866162, 274.4765829410098, -232.8645408480919, 186.7408561256432, 172.20386573212124, 282.1424932139556, 271.1210619457835, 29.218013894485953, 134.05011879436256, 270.6879183921784, 146.56412239293562, 304.4970180225557, -13.7924043350526, -8.234927911681524, 28.850681965423227, -7.322329542633924, -93.6621565522927, -10.137954675447732, -15.205984898519796, 187.73352229520512, -35.958319415717874, 142.5102134084514, -154.6036320745077, 166.89592311112054, -132.02306337641573, 182.60074947176278, -30.934319516571783, 62.39608538668324, -220.3485660581434, 151.56757418149496, 265.67863545815874, 152.99356312205276, 168.87155739443935, 205.55769089299503, 88.44011486411492, 45.9344434468017, 199.48174036386584, 208.03273386544686, 48.813861246975, 174.14143122211337, 231.07107462614638, -24.076535790650492, 56.530868450446874, 84.06448245676451, -95.88307463859383, 34.574977299156316, 188.728485172209, -119.96610434487826, -136.40854880576694, 40.59850726146018, -156.36588996267628, 303.4409940478952, -126.90565017048431, 75.17792794441912, -149.02923579667208, 84.46706026883533, 136.25752884704653, 148.46045053972603, 295.0115393840578, 278.414977233671, 270.5022447549525, 251.88728730187512, 145.81495918049575, 90.24916003849006, -40.79067180661206, 55.33925182818072, -49.32652796483654, -52.99515759803656, -80.18251246077551, -15.948924050272016, 197.98938919288076, 119.72786679560463, -104.08297499534604, 59.17758206905519], "policy_AGENT-1_reward": [-159.317952130958, 642.1839171272042, -113.91327820159165, 630.4639213276668, -103.38259841022469, 634.1056091124818, -251.3014868279263, -356.64406077379857, 633.3396793610926, 343.530105700687, 92.88202920180079, 62.33715866922496, 198.7590501156318, 268.3369321755249, 351.2059912021946, 262.47231812878107, 49.96224086011671, 294.6990119763778, -28.581126458254992, 45.85497462277398, -237.33494871051641, 113.96681695900759, 190.71280318626597, 352.8029824346809, -63.11201867424529, -110.23245252004403, -61.1776117974382, 645.1905102635516, -111.02555402044166, 187.1731262613467, 200.28420352871726, 339.2753628237037, 297.85435616919176, 78.23045823377647, 254.79348378611576, 290.5753761868635, 287.17093053175654, 344.02483915816936, 45.956815911239055, -105.55186680537162, 85.9837574672301, -17.932680417259636, -147.43209999398908, 89.22414959608018, -121.69585149537436, 306.4067459047357, 97.02292282600853, 627.1669683890448, -102.26724352834782, 645.2252013605595, -110.72201891573425, 611.0831137064646, -129.42224779691284, 634.7874524021651, -201.1259755326736, 152.04203702832996, 204.5924805053347, 272.4912152810695, 187.99665279675582, 385.75124494206295, 203.97578804023257, 46.634891041344076, 119.94196464670983, 295.06891657190334, 252.82570067196121, 307.2106509694723, 263.1305065524534, 198.0496081467361, 121.40691209296756, 71.98546035705235, -171.15322731588245, -69.27878054064008, 317.8652545890777, -66.05843048042185, -112.6826604853044, 635.2363576089116, -203.05095134097263, 644.3003288194799, -106.61464134105182, 624.1414642560692, -228.65316537960092, 604.2514331073043, 252.28379540058978, 234.29015794035735, 295.66204655128837, 264.34550266198283, 273.12545225701786, 212.67463201237095, 215.7182304446431, 292.62461400443, 267.82128523668393, 89.26906082572485, -164.31738330657038, -64.36717759942866, -88.54699311690287, 181.40676919806737, 211.1563718079405, 146.4284462772403, -12.783196098642179, 206.80011087629248], "policy_AGENT-3_reward": [-169.2943988255517, 418.86315874686284, -178.34238683110055, 337.1586332054157, -165.92276016238412, 420.5157350351201, -263.00628179265175, -373.32774339574587, 21.69506057293277, 324.41753086407255, 256.68747019103085, 559.7277492631414, 250.52727027118735, 249.29385704744044, 520.3181393202094, 294.47454650336397, 551.9858316002974, 362.2656913711695, -6.4557664774284795, 76.2275437608329, -248.23381339690044, 108.9553000728977, 106.66624637415525, 239.37599503897698, 81.75656472414305, -116.76799658883971, 44.237819135996915, 353.8796917977564, -221.60531564204467, 525.0064564089543, 152.5803527692878, 493.9362798797089, 299.5248788600432, 452.41913184095716, 222.41541937232267, 479.52873839206455, 271.02052951242723, 462.6319952969297, -2.828124831744704, -8.475499068208176, 31.463794936421557, -7.293715294212453, -97.25686677182009, -16.56764565394739, -15.401951582691076, 148.22867548235655, -36.2467232205098, 435.25870795262114, -154.76423304662254, 359.58022994959913, -158.92374284373466, 341.9171303417097, -31.034553379406347, 62.36129635045298, -215.00912015436495, -41.84659855670655, 237.89633953198773, 493.9883962233344, 321.2106609587392, 512.4328538985001, 191.2051978840574, 568.2434263495863, 235.69655295469633, 519.5194236198422, 235.97554947710282, 163.9116534966382, 162.06297005823052, -24.091930589896517, 47.605553045825424, 72.8270658449805, -139.93357471566847, 1.2345807976920966, 182.61833622788396, -120.23924300750315, -161.43060900052237, 40.651499203961734, -180.9071279459299, 320.3335894134175, -135.66354649177234, 75.1664794432776, -254.3222256763833, 84.52013833179566, 457.11765070890453, 219.22249535678384, 493.5531678651317, 258.4514704141212, 483.95485962554545, 252.66690202164537, 446.55344350217575, 274.68670742474046, 534.4101119422801, -20.818526770330585, -190.8893001210644, -4.03684834615035, -84.04478508746217, -16.049113184431498, 136.66912041014635, 89.27778584056662, -13.347942618039529, 59.12351779365123], "policy_AGENT-0_reward": [-161.68871017377555, 206.9536845442259, -114.02310848512981, 222.83060370754745, -103.43112318615583, 161.08351674792914, -291.4098005213659, -96.93902611735534, 559.6797533496045, 320.461175198831, 93.1977508408913, 491.97546321073764, 199.03933146164434, 117.94750487762657, 144.5579348119665, 262.73854266548847, 477.79739044364936, 294.96901293900856, -37.3130306427203, 33.63436476792655, -60.01595349949011, 98.05994504077125, 189.49358445457486, 341.1453778870583, -63.02461087544068, -87.49037555442119, -61.07588124819698, 237.5861423294741, -110.78342154375721, 477.715094158894, 221.51215173204866, 245.05749688288654, 270.1650378038653, 55.515486242487675, 134.60540514658675, 236.84245182936698, 147.12139940824818, 333.4582723584446, 35.199293498447574, -151.14516200017573, 74.06996901816777, -20.17540914184909, -147.46306852306245, 74.83743962186733, -121.46886513831242, 293.30429618551454, 81.94119842730926, 108.54639964078898, -102.35302220009495, 201.8726395188408, -110.5949229608768, 148.72815958913816, -139.4075363612459, 562.3338513453681, -214.62195102491802, -47.00450514706417, 204.74436003081215, 113.91842509909343, 315.5902772620606, 419.9101283719582, 89.01793733763431, 546.9999970681707, 119.89758175391867, 165.7720509760452, 49.24243667837742, 293.60715773028954, 249.3974418889541, 185.60196901755617, 105.43857516288429, 63.65873981102321, -220.34392390075647, -69.12798776339025, 304.29201535526846, -66.04893338794503, -112.61862743792173, 557.3952702276996, -164.2869532140125, 263.47420600696677, -130.90024344794512, 544.5095646328219, -148.47801749342182, 524.964505103818, 102.2684751349815, 149.00937198386313, 259.0539953773183, 216.38642080958218, 271.06031470862206, 209.1963395810103, 108.93686756978215, 90.79791950611853, -74.38664665347422, 76.21350992332074, -48.775375044025125, -64.34819681729124, -134.6089274122001, 219.65289318168433, 198.7376026728964, 129.56620685572165, -146.634732771269, 165.69852022302223]}, "sampler_perf": {"mean_env_wait_ms": 65.52515671198867, "mean_raw_obs_processing_ms": 2.6244868070704257, "mean_inference_ms": 2.84380517322213, "mean_action_processing_ms": 0.16749912833824773}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 105000, "timers": {"sample_time_ms": 88458.45, "sample_throughput": 47.48, "load_time_ms": 16.015, "load_throughput": 262247.416, "learn_time_ms": 14321.57, "learn_throughput": 293.264, "update_time_ms": 8.736}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 19.398799896240234, "policy_loss": -0.052243273705244064, "vf_loss": 19.444950103759766, "vf_explained_var": 0.9935272336006165, "kl": 0.020309874787926674, "entropy": 0.90130615234375, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 27.72321891784668, "policy_loss": -0.05066593736410141, "vf_loss": 27.768098831176758, "vf_explained_var": 0.9890469908714294, "kl": 0.019286371767520905, "entropy": 1.0397013425827026, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 54.70953369140625, "policy_loss": -0.045128751546144485, "vf_loss": 54.74945068359375, "vf_explained_var": 0.9800960421562195, "kl": 0.017363475635647774, "entropy": 1.0737721920013428, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 19.186565399169922, "policy_loss": -0.04766124114394188, "vf_loss": 19.226680755615234, "vf_explained_var": 0.9907812476158142, "kl": 0.016771487891674042, "entropy": 0.9332405924797058, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 105000, "num_steps_trained": 105000}, "done": false, "episodes_total": 790, "training_iteration": 25, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-11-50", "timestamp": 1624201910, "time_this_iter_s": 87.31778454780579, "time_total_s": 3121.341632604599, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f024bc20>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f024bf80>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f017cef0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f017cef0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f017cef0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f017cef0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f0104ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3121.341632604599, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 52.807199999999995, "ram_util_percent": 88.10159999999999}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1534.5503357009525, "episode_reward_min": -1367.3651545990224, "episode_reward_mean": 464.6695064677449, "episode_len_mean": 159.03, "episodes_this_iter": 26, "policy_reward_min": {"AGENT-2": -365.0493449162931, "AGENT-1": -356.64406077379857, "AGENT-3": -373.32774339574587, "AGENT-0": -364.466829253985}, "policy_reward_max": {"AGENT-2": 340.4530294666071, "AGENT-1": 644.3003288194799, "AGENT-3": 568.2434263495863, "AGENT-0": 562.3338513453681}, "policy_reward_mean": {"AGENT-2": 69.21187279397286, "AGENT-1": 143.9708221875804, "AGENT-3": 134.65321005792262, "AGENT-0": 116.83360142826903}, "custom_metrics": {"mean_ego_speed_mean": 42.611090000000004, "mean_ego_speed_min": 29.893, "mean_ego_speed_max": 51.497749999999996, "distance_travelled_mean": 102.0754525, "distance_travelled_min": 29.35875, "distance_travelled_max": 124.91025}, "hist_stats": {"episode_reward": [-478.87686323941, 500.9720479206983, -247.9871023217217, 435.32934134099287, -1367.3651545990224, 1534.5503357009525, -767.0314644819872, 1373.8446892405327, -283.32452510716365, 831.7268008086221, 40.101569314735634, 1055.1897663255484, 837.4321330291365, 1100.1333756037566, 1228.6687883865068, 1223.430244014816, 1110.9427649694685, 386.850424607682, 358.7792313389735, 39.403626638641256, 599.2816649123544, -542.3383378047932, -614.2057711074757, 456.6065949981899, 99.88983529307093, 463.60281716183687, 1321.8786854846708, -851.1056127700998, 214.75850750605386, 912.911815526293, 1033.3915997255501, 993.6691484119957, 1523.651918105515, 572.6390381260387, 1207.8127579059035, 675.0178397191909, 1188.3931250332378, 586.8575480744164, 938.8708934185128, 905.6619931257837, 335.4831107837453, 330.9819087521242, 292.5357484698204, -627.3138005709014, -102.59721020718203, 993.5040913444394, -372.3127112207482, -523.1404457295152, 1273.8816343020333, -704.6109224635915, 1531.5491182877577, -500.08408145125395, 1318.9954362765902, -780.4826443460784, 1298.203136811755, 947.9274500915222, 750.9824758207301, 1343.2807491777974, 1017.5983711193568, 1298.6428713461382, 926.4251609169006, 917.0235006970959, 748.3584009737789, 687.0540787188801, 200.00329580689578, -453.3085864364965, -185.74738036090682, -387.3832180773407, 369.061625145048, 744.5524840838644, 485.00030576913315, -276.8488464832968, 490.7997309620212, -655.3062987121133, 1508.7184440654603, -584.680109036902, 1412.6165015641363, -538.6940496750397, 1410.218198760755, -1055.3835726153427, -924.294117382878, 1236.3553808793574, 1308.2952433223234, 647.7422393867017, 1175.8269944323358, 801.0514439494128, 752.9441872903614, 1195.3409756623048, 1072.3731128195202, 1129.020484391036, 1202.646691670803, -89.48078865641824, 214.583969292256, -606.1552202409611, 435.8710609002885, 574.0056184624425, 1273.7773848273223, 53.284140332252356, -402.5380225282749, -69.22017503477218], "episode_lengths": [100, 195, 36, 212, 122, 219, 114, 228, 127, 157, 191, 139, 151, 211, 135, 197, 125, 155, 174, 153, 195, 168, 147, 185, 145, 197, 233, 149, 209, 106, 180, 161, 161, 122, 235, 145, 179, 143, 182, 170, 191, 183, 140, 145, 144, 192, 41, 106, 236, 138, 207, 114, 241, 120, 243, 186, 130, 183, 132, 117, 124, 164, 149, 208, 170, 164, 103, 126, 174, 184, 173, 110, 235, 118, 217, 64, 197, 70, 223, 117, 144, 233, 144, 120, 202, 102, 160, 179, 102, 208, 123, 137, 147, 133, 152, 165, 183, 167, 122, 148], "policy_AGENT-2_reward": [-126.40275745626491, 194.79903907559242, -32.06125226436451, 186.88162808636423, -365.0493449162931, 266.60493097889565, -193.27071853644173, 157.2565419611148, -34.18725712666853, 236.96700366986246, -145.80450331671804, 245.16915019487007, 110.41503482983883, 43.249780642943186, 326.0947332870998, 69.10762939033823, 324.53269278945834, 108.5481425677311, -10.014754244360867, 107.89572358589487, -10.13517018356108, -55.17868353707119, -50.48352825560077, -14.005261733523284, 88.32603728922318, -8.50262727162251, 62.39608538668324, -220.3485660581434, 151.56757418149496, 265.67863545815874, 152.99356312205276, 168.87155739443935, 205.55769089299503, 88.44011486411492, 45.9344434468017, 199.48174036386584, 208.03273386544686, 48.813861246975, 174.14143122211337, 231.07107462614638, -24.076535790650492, 56.530868450446874, 84.06448245676451, -95.88307463859383, 34.574977299156316, 188.728485172209, -119.96610434487826, -136.40854880576694, 40.59850726146018, -156.36588996267628, 303.4409940478952, -126.90565017048431, 75.17792794441912, -149.02923579667208, 84.46706026883533, 136.25752884704653, 148.46045053972603, 295.0115393840578, 278.414977233671, 270.5022447549525, 251.88728730187512, 145.81495918049575, 90.24916003849006, -40.79067180661206, 55.33925182818072, -49.32652796483654, -52.99515759803656, -80.18251246077551, -15.948924050272016, 197.98938919288076, 119.72786679560463, -104.08297499534604, 59.17758206905519, -165.00523758182774, 240.7176836471671, -178.40133551907985, 222.16334332350834, -165.9575679162749, 194.51333786522412, -249.66600347339974, -97.38328709597889, 21.640887595728778, 319.8864315587352, 204.97498915297925, 61.786623289232395, 152.72579210094915, 117.36589318976961, 179.258910327933, 252.6877055218871, 49.27502148697286, 250.7129753842462, -17.130865078014615, 58.867086140722606, -60.57050463405446, 114.88899882761201, 87.13298444744682, 340.4530294666071, 97.66420515779522, -88.04719786497016, 8.795498874866162], "policy_AGENT-1_reward": [-101.26720141799281, 195.38504918215432, -92.01380238546335, 187.44934995920178, -319.4361642297592, 639.910155494136, -167.1981698596416, 637.1916517324061, -95.4915669971702, 15.740803011594357, -105.00649294125036, 245.64577877221816, 316.6539568090602, 43.990063702415135, 314.89603897591206, 69.70777041176859, 232.41868262378594, 107.14765162787754, 171.41592394610677, -72.23325044320922, 313.8517800178875, -205.21469539800555, -247.07679155373998, 247.71568017798216, -65.16154058646734, 246.7833370857851, 634.7874524021651, -201.1259755326736, 152.04203702832996, 204.5924805053347, 272.4912152810695, 187.99665279675582, 385.75124494206295, 203.97578804023257, 46.634891041344076, 119.94196464670983, 295.06891657190334, 252.82570067196121, 307.2106509694723, 263.1305065524534, 198.0496081467361, 121.40691209296756, 71.98546035705235, -171.15322731588245, -69.27878054064008, 317.8652545890777, -66.05843048042185, -112.6826604853044, 635.2363576089116, -203.05095134097263, 644.3003288194799, -106.61464134105182, 624.1414642560692, -228.65316537960092, 604.2514331073043, 252.28379540058978, 234.29015794035735, 295.66204655128837, 264.34550266198283, 273.12545225701786, 212.67463201237095, 215.7182304446431, 292.62461400443, 267.82128523668393, 89.26906082572485, -164.31738330657038, -64.36717759942866, -88.54699311690287, 181.40676919806737, 211.1563718079405, 146.4284462772403, -12.783196098642179, 206.80011087629248, -159.317952130958, 642.1839171272042, -113.91327820159165, 630.4639213276668, -103.38259841022469, 634.1056091124818, -251.3014868279263, -356.64406077379857, 633.3396793610926, 343.530105700687, 92.88202920180079, 62.33715866922496, 198.7590501156318, 268.3369321755249, 351.2059912021946, 262.47231812878107, 49.96224086011671, 294.6990119763778, -28.581126458254992, 45.85497462277398, -237.33494871051641, 113.96681695900759, 190.71280318626597, 352.8029824346809, -63.11201867424529, -110.23245252004403, -61.1776117974382], "policy_AGENT-3_reward": [-149.95125246349767, 82.56177794100918, -32.00986791674601, 64.08682045861437, -318.41281619898706, 394.4540768938055, -191.35556989188663, 456.0609067243897, -34.061361309140196, 311.2203737824265, 476.8386209440177, 283.9999624212169, 299.3999443632328, 543.510934104252, 320.6567115044918, 541.7358334606479, 321.43420355826765, 77.93292949152195, -10.034668984654143, 75.71689264726994, -10.088161773464664, -227.32573089666312, -266.71907175288936, -14.034740885719357, 141.77904446619254, -8.392084275557902, 62.36129635045298, -215.00912015436495, -41.84659855670655, 237.89633953198773, 493.9883962233344, 321.2106609587392, 512.4328538985001, 191.2051978840574, 568.2434263495863, 235.69655295469633, 519.5194236198422, 235.97554947710282, 163.9116534966382, 162.06297005823052, -24.091930589896517, 47.605553045825424, 72.8270658449805, -139.93357471566847, 1.2345807976920966, 182.61833622788396, -120.23924300750315, -161.43060900052237, 40.651499203961734, -180.9071279459299, 320.3335894134175, -135.66354649177234, 75.1664794432776, -254.3222256763833, 84.52013833179566, 457.11765070890453, 219.22249535678384, 493.5531678651317, 258.4514704141212, 483.95485962554545, 252.66690202164537, 446.55344350217575, 274.68670742474046, 534.4101119422801, -20.818526770330585, -190.8893001210644, -4.03684834615035, -84.04478508746217, -16.049113184431498, 136.66912041014635, 89.27778584056662, -13.347942618039529, 59.12351779365123, -169.2943988255517, 418.86315874686284, -178.34238683110055, 337.1586332054157, -165.92276016238412, 420.5157350351201, -263.00628179265175, -373.32774339574587, 21.69506057293277, 324.41753086407255, 256.68747019103085, 559.7277492631414, 250.52727027118735, 249.29385704744044, 520.3181393202094, 294.47454650336397, 551.9858316002974, 362.2656913711695, -6.4557664774284795, 76.2275437608329, -248.23381339690044, 108.9553000728977, 106.66624637415525, 239.37599503897698, 81.75656472414305, -116.76799658883971, 44.237819135996915], "policy_AGENT-0_reward": [-101.25565190165432, 28.22618172194239, -91.90217975514774, -3.0884571631873428, -364.466829253985, 233.5811723341124, -215.2070061940176, 123.33558882262446, -119.58433967418468, 267.79862034473825, -185.92605537131297, 280.37487493724393, 110.96319702700512, 469.38259715414466, 267.0213046190028, 542.8790107520631, 232.55718599795725, 93.22170092055144, 207.4127306218818, -71.97573915131429, 305.65321685149274, -54.61922797305316, -49.926379545245325, 236.93091743945052, -65.05370587587736, 233.71419162323238, 562.3338513453681, -214.62195102491802, -47.00450514706417, 204.74436003081215, 113.91842509909343, 315.5902772620606, 419.9101283719582, 89.01793733763431, 546.9999970681707, 119.89758175391867, 165.7720509760452, 49.24243667837742, 293.60715773028954, 249.3974418889541, 185.60196901755617, 105.43857516288429, 63.65873981102321, -220.34392390075647, -69.12798776339025, 304.29201535526846, -66.04893338794503, -112.61862743792173, 557.3952702276996, -164.2869532140125, 263.47420600696677, -130.90024344794512, 544.5095646328219, -148.47801749342182, 524.964505103818, 102.2684751349815, 149.00937198386313, 259.0539953773183, 216.38642080958218, 271.06031470862206, 209.1963395810103, 108.93686756978215, 90.79791950611853, -74.38664665347422, 76.21350992332074, -48.775375044025125, -64.34819681729124, -134.6089274122001, 219.65289318168433, 198.7376026728964, 129.56620685572165, -146.634732771269, 165.69852022302223, -161.68871017377555, 206.9536845442259, -114.02310848512981, 222.83060370754745, -103.43112318615583, 161.08351674792914, -291.4098005213659, -96.93902611735534, 559.6797533496045, 320.461175198831, 93.1977508408913, 491.97546321073764, 199.03933146164434, 117.94750487762657, 144.5579348119665, 262.73854266548847, 477.79739044364936, 294.96901293900856, -37.3130306427203, 33.63436476792655, -60.01595349949011, 98.05994504077125, 189.49358445457486, 341.1453778870583, -63.02461087544068, -87.49037555442119, -61.07588124819698]}, "sampler_perf": {"mean_env_wait_ms": 64.83127365033971, "mean_raw_obs_processing_ms": 2.5981982420355383, "mean_inference_ms": 2.8195797685091875, "mean_action_processing_ms": 0.16636215483592273}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 109200, "timers": {"sample_time_ms": 87799.581, "sample_throughput": 47.836, "load_time_ms": 15.884, "load_throughput": 264423.869, "learn_time_ms": 14136.199, "learn_throughput": 297.11, "update_time_ms": 8.731}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 54.135169982910156, "policy_loss": -0.03196612745523453, "vf_loss": 54.1618537902832, "vf_explained_var": 0.9815579056739807, "kl": 0.011724921874701977, "entropy": 0.8587815165519714, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 54.57954025268555, "policy_loss": -0.042160697281360626, "vf_loss": 54.616790771484375, "vf_explained_var": 0.9803608655929565, "kl": 0.016395213082432747, "entropy": 0.9953987002372742, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 98.45147705078125, "policy_loss": -0.041771452873945236, "vf_loss": 98.48921966552734, "vf_explained_var": 0.9690343141555786, "kl": 0.013413024134933949, "entropy": 1.0459095239639282, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 47.72188949584961, "policy_loss": -0.0372362844645977, "vf_loss": 47.75385284423828, "vf_explained_var": 0.9838155508041382, "kl": 0.011723638512194157, "entropy": 0.8460273742675781, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 109200, "num_steps_trained": 109200}, "done": false, "episodes_total": 816, "training_iteration": 26, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-13-10", "timestamp": 1624201990, "time_this_iter_s": 80.1563663482666, "time_total_s": 3201.4979989528656, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f02115f0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f02114d0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211170>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211cb0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211dd0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211170>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211cb0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211dd0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211170>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211cb0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211dd0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211170>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211cb0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211dd0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f0211a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3201.4979989528656, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 52.950434782608696, "ram_util_percent": 88.1}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1557.2122985323576, "episode_reward_min": -1367.3651545990224, "episode_reward_mean": 445.487534355162, "episode_len_mean": 158.81, "episodes_this_iter": 25, "policy_reward_min": {"AGENT-2": -365.0493449162931, "AGENT-3": -373.32774339574587, "AGENT-0": -364.466829253985, "AGENT-1": -356.64406077379857}, "policy_reward_max": {"AGENT-2": 366.8006635037028, "AGENT-3": 559.7277492631414, "AGENT-0": 598.8337738709066, "AGENT-1": 642.1839171272042}, "policy_reward_mean": {"AGENT-2": 69.87768690149149, "AGENT-3": 138.265035332999, "AGENT-0": 106.90764263340122, "AGENT-1": 130.4371694872702}, "custom_metrics": {"mean_ego_speed_mean": 42.200047500000004, "mean_ego_speed_min": 29.893, "mean_ego_speed_max": 51.497749999999996, "distance_travelled_mean": 98.62125750000001, "distance_travelled_min": 27.4835, "distance_travelled_max": 124.91424999999998}, "hist_stats": {"episode_reward": [1147.8358792792003, -266.9270427862786, 363.1966423746438, -241.52306254889345, 1532.4161151332742, -463.16569587229407, 1228.7478488847678, -404.6029913843831, 1170.0154247454802, 1375.5132743275963, 329.6094908290349, 973.1730560903011, 1557.2122985323576, 773.6128762019368, 1199.4131590407924, 1031.990643198061, -169.11612388327845, -652.5815457421043, 59.46930875323638, -245.19371294976764, -50.311756007043186, -390.92297371754296, 1046.6364692290647, 986.2157419088098, -156.540755754228, -500.08408145125395, 1318.9954362765902, -780.4826443460784, 1298.203136811755, 947.9274500915222, 750.9824758207301, 1343.2807491777974, 1017.5983711193568, 1298.6428713461382, 926.4251609169006, 917.0235006970959, 748.3584009737789, 687.0540787188801, 200.00329580689578, -453.3085864364965, -185.74738036090682, -387.3832180773407, 369.061625145048, 744.5524840838644, 485.00030576913315, -276.8488464832968, 490.7997309620212, -655.3062987121133, 1508.7184440654603, -584.680109036902, 1412.6165015641363, -538.6940496750397, 1410.218198760755, -1055.3835726153427, -924.294117382878, 1236.3553808793574, 1308.2952433223234, 647.7422393867017, 1175.8269944323358, 801.0514439494128, 752.9441872903614, 1195.3409756623048, 1072.3731128195202, 1129.020484391036, 1202.646691670803, -89.48078865641824, 214.583969292256, -606.1552202409611, 435.8710609002885, 574.0056184624425, 1273.7773848273223, 53.284140332252356, -402.5380225282749, -69.22017503477218, -478.87686323941, 500.9720479206983, -247.9871023217217, 435.32934134099287, -1367.3651545990224, 1534.5503357009525, -767.0314644819872, 1373.8446892405327, -283.32452510716365, 831.7268008086221, 40.101569314735634, 1055.1897663255484, 837.4321330291365, 1100.1333756037566, 1228.6687883865068, 1223.430244014816, 1110.9427649694685, 386.850424607682, 358.7792313389735, 39.403626638641256, 599.2816649123544, -542.3383378047932, -614.2057711074757, 456.6065949981899, 99.88983529307093, 463.60281716183687], "episode_lengths": [213, 60, 203, 127, 224, 104, 253, 110, 231, 194, 198, 164, 207, 168, 198, 138, 40, 147, 148, 123, 179, 213, 186, 216, 32, 114, 241, 120, 243, 186, 130, 183, 132, 117, 124, 164, 149, 208, 170, 164, 103, 126, 174, 184, 173, 110, 235, 118, 217, 64, 197, 70, 223, 117, 144, 233, 144, 120, 202, 102, 160, 179, 102, 208, 123, 137, 147, 133, 152, 165, 183, 167, 122, 148, 100, 195, 36, 212, 122, 219, 114, 228, 127, 157, 191, 139, 151, 211, 135, 197, 125, 155, 174, 153, 195, 168, 147, 185, 145, 197], "policy_AGENT-2_reward": [147.06231861265073, -33.56069998805665, 181.5500630057007, -30.293964750284495, 241.78267452203917, -118.64618377106369, 0.6583859814024782, -92.95934314939616, 80.39667721133355, 340.6817216125342, -103.55595286162918, 186.88160708490966, 366.8006635037028, 64.53524106569229, 53.679061813252595, 260.25747649705875, -11.639993493660512, -58.26131581381809, 113.4315027044693, -30.60442861995977, -9.249400325403542, -27.969289466575248, 276.1053560768852, 236.45454715882647, -9.085212700236708, -126.90565017048431, 75.17792794441912, -149.02923579667208, 84.46706026883533, 136.25752884704653, 148.46045053972603, 295.0115393840578, 278.414977233671, 270.5022447549525, 251.88728730187512, 145.81495918049575, 90.24916003849006, -40.79067180661206, 55.33925182818072, -49.32652796483654, -52.99515759803656, -80.18251246077551, -15.948924050272016, 197.98938919288076, 119.72786679560463, -104.08297499534604, 59.17758206905519, -165.00523758182774, 240.7176836471671, -178.40133551907985, 222.16334332350834, -165.9575679162749, 194.51333786522412, -249.66600347339974, -97.38328709597889, 21.640887595728778, 319.8864315587352, 204.97498915297925, 61.786623289232395, 152.72579210094915, 117.36589318976961, 179.258910327933, 252.6877055218871, 49.27502148697286, 250.7129753842462, -17.130865078014615, 58.867086140722606, -60.57050463405446, 114.88899882761201, 87.13298444744682, 340.4530294666071, 97.66420515779522, -88.04719786497016, 8.795498874866162, -126.40275745626491, 194.79903907559242, -32.06125226436451, 186.88162808636423, -365.0493449162931, 266.60493097889565, -193.27071853644173, 157.2565419611148, -34.18725712666853, 236.96700366986246, -145.80450331671804, 245.16915019487007, 110.41503482983883, 43.249780642943186, 326.0947332870998, 69.10762939033823, 324.53269278945834, 108.5481425677311, -10.014754244360867, 107.89572358589487, -10.13517018356108, -55.17868353707119, -50.48352825560077, -14.005261733523284, 88.32603728922318, -8.50262727162251], "policy_AGENT-3_reward": [342.08478073261705, -33.43023548161878, 28.097525783159888, -30.52138703370212, 444.77396438090113, -142.08480901355867, 0.6670094148815271, -116.90340451097, 548.6245603397577, 330.2887499308414, 472.3993473143437, 377.56269857090547, 437.77642598219086, 313.1557723982552, 546.6312263931752, 314.471045739449, -11.500965384947884, -286.5079689042228, 81.57092497840169, -30.559438993632554, -9.130908774808734, -189.8158679173184, 206.01037548755662, 262.8535515165396, -9.013704074223819, -135.66354649177234, 75.1664794432776, -254.3222256763833, 84.52013833179566, 457.11765070890453, 219.22249535678384, 493.5531678651317, 258.4514704141212, 483.95485962554545, 252.66690202164537, 446.55344350217575, 274.68670742474046, 534.4101119422801, -20.818526770330585, -190.8893001210644, -4.03684834615035, -84.04478508746217, -16.049113184431498, 136.66912041014635, 89.27778584056662, -13.347942618039529, 59.12351779365123, -169.2943988255517, 418.86315874686284, -178.34238683110055, 337.1586332054157, -165.92276016238412, 420.5157350351201, -263.00628179265175, -373.32774339574587, 21.69506057293277, 324.41753086407255, 256.68747019103085, 559.7277492631414, 250.52727027118735, 249.29385704744044, 520.3181393202094, 294.47454650336397, 551.9858316002974, 362.2656913711695, -6.4557664774284795, 76.2275437608329, -248.23381339690044, 108.9553000728977, 106.66624637415525, 239.37599503897698, 81.75656472414305, -116.76799658883971, 44.237819135996915, -149.95125246349767, 82.56177794100918, -32.00986791674601, 64.08682045861437, -318.41281619898706, 394.4540768938055, -191.35556989188663, 456.0609067243897, -34.061361309140196, 311.2203737824265, 476.8386209440177, 283.9999624212169, 299.3999443632328, 543.510934104252, 320.6567115044918, 541.7358334606479, 321.43420355826765, 77.93292949152195, -10.034668984654143, 75.71689264726994, -10.088161773464664, -227.32573089666312, -266.71907175288936, -14.034740885719357, 141.77904446619254, -8.392084275557902], "policy_AGENT-0_reward": [114.11276389624814, -99.81186340314463, -28.433344591353062, -95.40590985576578, 208.05309363443976, -101.1817533312602, 598.8337738709066, -97.39029699364963, 460.1702635985727, 344.6867228036381, -137.46980574408306, 187.53897343915813, 367.3565433314523, 65.09590471701287, 545.0038314831914, 291.0626014817297, -72.88858648415729, -57.675099056058805, -67.679007581894, -93.75817394757608, -23.620084843225396, -27.412236826737704, 276.67953733332223, 237.04152741124005, -69.2657145807124, -130.90024344794512, 544.5095646328219, -148.47801749342182, 524.964505103818, 102.2684751349815, 149.00937198386313, 259.0539953773183, 216.38642080958218, 271.06031470862206, 209.1963395810103, 108.93686756978215, 90.79791950611853, -74.38664665347422, 76.21350992332074, -48.775375044025125, -64.34819681729124, -134.6089274122001, 219.65289318168433, 198.7376026728964, 129.56620685572165, -146.634732771269, 165.69852022302223, -161.68871017377555, 206.9536845442259, -114.02310848512981, 222.83060370754745, -103.43112318615583, 161.08351674792914, -291.4098005213659, -96.93902611735534, 559.6797533496045, 320.461175198831, 93.1977508408913, 491.97546321073764, 199.03933146164434, 117.94750487762657, 144.5579348119665, 262.73854266548847, 477.79739044364936, 294.96901293900856, -37.3130306427203, 33.63436476792655, -60.01595349949011, 98.05994504077125, 189.49358445457486, 341.1453778870583, -63.02461087544068, -87.49037555442119, -61.07588124819698, -101.25565190165432, 28.22618172194239, -91.90217975514774, -3.0884571631873428, -364.466829253985, 233.5811723341124, -215.2070061940176, 123.33558882262446, -119.58433967418468, 267.79862034473825, -185.92605537131297, 280.37487493724393, 110.96319702700512, 469.38259715414466, 267.0213046190028, 542.8790107520631, 232.55718599795725, 93.22170092055144, 207.4127306218818, -71.97573915131429, 305.65321685149274, -54.61922797305316, -49.926379545245325, 236.93091743945052, -65.05370587587736, 233.71419162323238], "policy_AGENT-1_reward": [544.5760160376846, -100.12424391345837, 181.98239817713602, -85.30180090914129, 637.8063825958955, -101.25294975641168, 628.5886796175774, -97.34994673036752, 80.82392359581378, 359.85607998058344, 98.23590212040489, 221.18977699532815, 385.2786657150124, 330.8259580209761, 54.09903935117315, 166.19951947982318, -73.08657852051277, -250.13716196800456, -67.85411134774058, -90.27167138859916, -8.311362063605408, -145.7255795069117, 287.8412003313008, 249.86611582220382, -69.17612439905508, -106.61464134105182, 624.1414642560692, -228.65316537960092, 604.2514331073043, 252.28379540058978, 234.29015794035735, 295.66204655128837, 264.34550266198283, 273.12545225701786, 212.67463201237095, 215.7182304446431, 292.62461400443, 267.82128523668393, 89.26906082572485, -164.31738330657038, -64.36717759942866, -88.54699311690287, 181.40676919806737, 211.1563718079405, 146.4284462772403, -12.783196098642179, 206.80011087629248, -159.317952130958, 642.1839171272042, -113.91327820159165, 630.4639213276668, -103.38259841022469, 634.1056091124818, -251.3014868279263, -356.64406077379857, 633.3396793610926, 343.530105700687, 92.88202920180079, 62.33715866922496, 198.7590501156318, 268.3369321755249, 351.2059912021946, 262.47231812878107, 49.96224086011671, 294.6990119763778, -28.581126458254992, 45.85497462277398, -237.33494871051641, 113.96681695900759, 190.71280318626597, 352.8029824346809, -63.11201867424529, -110.23245252004403, -61.1776117974382, -101.26720141799281, 195.38504918215432, -92.01380238546335, 187.44934995920178, -319.4361642297592, 639.910155494136, -167.1981698596416, 637.1916517324061, -95.4915669971702, 15.740803011594357, -105.00649294125036, 245.64577877221816, 316.6539568090602, 43.990063702415135, 314.89603897591206, 69.70777041176859, 232.41868262378594, 107.14765162787754, 171.41592394610677, -72.23325044320922, 313.8517800178875, -205.21469539800555, -247.07679155373998, 247.71568017798216, -65.16154058646734, 246.7833370857851]}, "sampler_perf": {"mean_env_wait_ms": 63.86875124411507, "mean_raw_obs_processing_ms": 2.563070221608248, "mean_inference_ms": 2.785516985323798, "mean_action_processing_ms": 0.16461657643918262}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 113400, "timers": {"sample_time_ms": 86160.354, "sample_throughput": 48.746, "load_time_ms": 15.853, "load_throughput": 264936.876, "learn_time_ms": 13856.748, "learn_throughput": 303.101, "update_time_ms": 8.661}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 75.39763641357422, "policy_loss": -0.034185443073511124, "vf_loss": 75.4266128540039, "vf_explained_var": 0.9788870811462402, "kl": 0.01156341377645731, "entropy": 0.87070631980896, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 82.52096557617188, "policy_loss": -0.03955332934856415, "vf_loss": 82.5558090209961, "vf_explained_var": 0.966888427734375, "kl": 0.01571844518184662, "entropy": 0.981539785861969, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 108.71099853515625, "policy_loss": -0.03736032918095589, "vf_loss": 108.74363708496094, "vf_explained_var": 0.968045175075531, "kl": 0.015723412856459618, "entropy": 1.0377415418624878, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 56.73561096191406, "policy_loss": -0.03282885253429413, "vf_loss": 56.7639274597168, "vf_explained_var": 0.9797277450561523, "kl": 0.010020855814218521, "entropy": 0.8350510001182556, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 113400, "num_steps_trained": 113400}, "done": false, "episodes_total": 841, "training_iteration": 27, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-14-27", "timestamp": 1624202067, "time_this_iter_s": 76.08973908424377, "time_total_s": 3277.5877380371094, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f017cdd0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f023cf80>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f023ccb0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f024bcb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f024bf80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9d40>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f023ccb0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f024bcb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f024bf80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9d40>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f023ccb0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f024bcb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f024bf80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9d40>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f023ccb0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f024bcb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f024bf80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9d40>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f0211ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3277.5877380371094, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 52.617431192660554, "ram_util_percent": 88.11284403669727}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1664.5234777361284, "episode_reward_min": -1367.3651545990224, "episode_reward_mean": 464.17417848601974, "episode_len_mean": 164.01, "episodes_this_iter": 23, "policy_reward_min": {"AGENT-2": -365.0493449162931, "AGENT-3": -406.47769160020016, "AGENT-0": -364.466829253985, "AGENT-1": -389.57788962500484}, "policy_reward_max": {"AGENT-2": 385.77046736054217, "AGENT-3": 559.7277492631414, "AGENT-0": 610.0964222046059, "AGENT-1": 650.3767436554725}, "policy_reward_mean": {"AGENT-2": 73.29682076762322, "AGENT-3": 141.48412732179105, "AGENT-0": 111.65289271868343, "AGENT-1": 137.74033767792213}, "custom_metrics": {"mean_ego_speed_mean": 41.74876749999999, "mean_ego_speed_min": 29.893, "mean_ego_speed_max": 50.06224999999999, "distance_travelled_mean": 96.94770250000002, "distance_travelled_min": 27.4835, "distance_travelled_max": 124.91424999999998}, "hist_stats": {"episode_reward": [257.51135344936574, -505.29545919303985, 1195.0315102001912, -646.7531051792123, 1426.0053940971113, -751.6306419362793, 548.3889557656358, 367.55300409510056, 1308.8432569382512, 345.3746053908171, 975.2864483559512, 1664.5234777361284, 772.9461937687792, 1270.13895978018, 1270.4930095228149, 551.6828109345774, 17.618957962462325, 465.7267710942309, -947.3956809321626, 541.9056056774419, 814.3115264456501, 320.2464892725926, 910.8989876892166, 1508.7184440654603, -584.680109036902, 1412.6165015641363, -538.6940496750397, 1410.218198760755, -1055.3835726153427, -924.294117382878, 1236.3553808793574, 1308.2952433223234, 647.7422393867017, 1175.8269944323358, 801.0514439494128, 752.9441872903614, 1195.3409756623048, 1072.3731128195202, 1129.020484391036, 1202.646691670803, -89.48078865641824, 214.583969292256, -606.1552202409611, 435.8710609002885, 574.0056184624425, 1273.7773848273223, 53.284140332252356, -402.5380225282749, -69.22017503477218, -478.87686323941, 500.9720479206983, -247.9871023217217, 435.32934134099287, -1367.3651545990224, 1534.5503357009525, -767.0314644819872, 1373.8446892405327, -283.32452510716365, 831.7268008086221, 40.101569314735634, 1055.1897663255484, 837.4321330291365, 1100.1333756037566, 1228.6687883865068, 1223.430244014816, 1110.9427649694685, 386.850424607682, 358.7792313389735, 39.403626638641256, 599.2816649123544, -542.3383378047932, -614.2057711074757, 456.6065949981899, 99.88983529307093, 463.60281716183687, 1147.8358792792003, -266.9270427862786, 363.1966423746438, -241.52306254889345, 1532.4161151332742, -463.16569587229407, 1228.7478488847678, -404.6029913843831, 1170.0154247454802, 1375.5132743275963, 329.6094908290349, 973.1730560903011, 1557.2122985323576, 773.6128762019368, 1199.4131590407924, 1031.990643198061, -169.11612388327845, -652.5815457421043, 59.46930875323638, -245.19371294976764, -50.311756007043186, -390.92297371754296, 1046.6364692290647, 986.2157419088098, -156.540755754228], "episode_lengths": [232, 100, 254, 123, 245, 127, 202, 203, 117, 202, 165, 180, 163, 168, 162, 189, 135, 206, 171, 193, 248, 198, 205, 217, 64, 197, 70, 223, 117, 144, 233, 144, 120, 202, 102, 160, 179, 102, 208, 123, 137, 147, 133, 152, 165, 183, 167, 122, 148, 100, 195, 36, 212, 122, 219, 114, 228, 127, 157, 191, 139, 151, 211, 135, 197, 125, 155, 174, 153, 195, 168, 147, 185, 145, 197, 213, 60, 203, 127, 224, 104, 253, 110, 231, 194, 198, 164, 207, 168, 198, 138, 40, 147, 148, 123, 179, 213, 186, 216, 32], "policy_AGENT-2_reward": [196.06681617812373, -170.7800425038572, 65.49197101830372, -157.82983130495, 95.01065365209985, -159.684491061598, 196.31636272858378, -136.18293760224975, 361.7606093874712, -99.34259149238197, 144.9633297618219, 385.77046736054217, 131.21065814588195, 234.258902143443, 299.8346556196814, -8.918424885469513, 56.03474902755915, -10.865555530575248, -75.94436948191856, -10.597829109308435, 203.67920059777904, -8.41078908445449, 234.2822060030728, 240.7176836471671, -178.40133551907985, 222.16334332350834, -165.9575679162749, 194.51333786522412, -249.66600347339974, -97.38328709597889, 21.640887595728778, 319.8864315587352, 204.97498915297925, 61.786623289232395, 152.72579210094915, 117.36589318976961, 179.258910327933, 252.6877055218871, 49.27502148697286, 250.7129753842462, -17.130865078014615, 58.867086140722606, -60.57050463405446, 114.88899882761201, 87.13298444744682, 340.4530294666071, 97.66420515779522, -88.04719786497016, 8.795498874866162, -126.40275745626491, 194.79903907559242, -32.06125226436451, 186.88162808636423, -365.0493449162931, 266.60493097889565, -193.27071853644173, 157.2565419611148, -34.18725712666853, 236.96700366986246, -145.80450331671804, 245.16915019487007, 110.41503482983883, 43.249780642943186, 326.0947332870998, 69.10762939033823, 324.53269278945834, 108.5481425677311, -10.014754244360867, 107.89572358589487, -10.13517018356108, -55.17868353707119, -50.48352825560077, -14.005261733523284, 88.32603728922318, -8.50262727162251, 147.06231861265073, -33.56069998805665, 181.5500630057007, -30.293964750284495, 241.78267452203917, -118.64618377106369, 0.6583859814024782, -92.95934314939616, 80.39667721133355, 340.6817216125342, -103.55595286162918, 186.88160708490966, 366.8006635037028, 64.53524106569229, 53.679061813252595, 260.25747649705875, -11.639993493660512, -58.26131581381809, 113.4315027044693, -30.60442861995977, -9.249400325403542, -27.969289466575248, 276.1053560768852, 236.45454715882647, -9.085212700236708], "policy_AGENT-3_reward": [-29.702650715469417, -130.5162538336547, 447.34856708280665, -157.7804997611884, 95.0660935960833, -196.7602010353555, 75.04667918546424, 474.5247783438253, 328.9166597016376, 469.8507650073476, 354.4626205325866, 427.39245395393107, 240.31550526853542, 490.3660953503334, 351.202587030023, -8.91280937829892, 110.11957051279786, -10.797605408738452, -406.47769160020016, -10.792932140094916, 204.41694918752182, -8.50022380997239, 190.02790536886064, 418.86315874686284, -178.34238683110055, 337.1586332054157, -165.92276016238412, 420.5157350351201, -263.00628179265175, -373.32774339574587, 21.69506057293277, 324.41753086407255, 256.68747019103085, 559.7277492631414, 250.52727027118735, 249.29385704744044, 520.3181393202094, 294.47454650336397, 551.9858316002974, 362.2656913711695, -6.4557664774284795, 76.2275437608329, -248.23381339690044, 108.9553000728977, 106.66624637415525, 239.37599503897698, 81.75656472414305, -116.76799658883971, 44.237819135996915, -149.95125246349767, 82.56177794100918, -32.00986791674601, 64.08682045861437, -318.41281619898706, 394.4540768938055, -191.35556989188663, 456.0609067243897, -34.061361309140196, 311.2203737824265, 476.8386209440177, 283.9999624212169, 299.3999443632328, 543.510934104252, 320.6567115044918, 541.7358334606479, 321.43420355826765, 77.93292949152195, -10.034668984654143, 75.71689264726994, -10.088161773464664, -227.32573089666312, -266.71907175288936, -14.034740885719357, 141.77904446619254, -8.392084275557902, 342.08478073261705, -33.43023548161878, 28.097525783159888, -30.52138703370212, 444.77396438090113, -142.08480901355867, 0.6670094148815271, -116.90340451097, 548.6245603397577, 330.2887499308414, 472.3993473143437, 377.56269857090547, 437.77642598219086, 313.1557723982552, 546.6312263931752, 314.471045739449, -11.500965384947884, -286.5079689042228, 81.57092497840169, -30.559438993632554, -9.130908774808734, -189.8158679173184, 206.01037548755662, 262.8535515165396, -9.013704074223819], "policy_AGENT-0_reward": [-105.60431306600626, -102.01412600715136, 31.814228443611213, -179.57755082340094, 610.0964222046059, -198.98781452442972, 80.24338291885846, -101.92173223036816, 309.0611057292965, -132.75874834039246, 302.9773567194801, 386.3510953599828, 131.77263029748016, 259.9586890306392, 300.43312321546165, 277.94414931325815, -74.2453483529904, 236.8247135770203, -75.39573022503893, 271.3804771365438, 204.2715448060916, 163.2834196180304, 234.84969117879842, 206.9536845442259, -114.02310848512981, 222.83060370754745, -103.43112318615583, 161.08351674792914, -291.4098005213659, -96.93902611735534, 559.6797533496045, 320.461175198831, 93.1977508408913, 491.97546321073764, 199.03933146164434, 117.94750487762657, 144.5579348119665, 262.73854266548847, 477.79739044364936, 294.96901293900856, -37.3130306427203, 33.63436476792655, -60.01595349949011, 98.05994504077125, 189.49358445457486, 341.1453778870583, -63.02461087544068, -87.49037555442119, -61.07588124819698, -101.25565190165432, 28.22618172194239, -91.90217975514774, -3.0884571631873428, -364.466829253985, 233.5811723341124, -215.2070061940176, 123.33558882262446, -119.58433967418468, 267.79862034473825, -185.92605537131297, 280.37487493724393, 110.96319702700512, 469.38259715414466, 267.0213046190028, 542.8790107520631, 232.55718599795725, 93.22170092055144, 207.4127306218818, -71.97573915131429, 305.65321685149274, -54.61922797305316, -49.926379545245325, 236.93091743945052, -65.05370587587736, 233.71419162323238, 114.11276389624814, -99.81186340314463, -28.433344591353062, -95.40590985576578, 208.05309363443976, -101.1817533312602, 598.8337738709066, -97.39029699364963, 460.1702635985727, 344.6867228036381, -137.46980574408306, 187.53897343915813, 367.3565433314523, 65.09590471701287, 545.0038314831914, 291.0626014817297, -72.88858648415729, -57.675099056058805, -67.679007581894, -93.75817394757608, -23.620084843225396, -27.412236826737704, 276.67953733332223, 237.04152741124005, -69.2657145807124], "policy_AGENT-1_reward": [196.75150105271769, -101.9850368483765, 650.3767436554725, -151.56522328967256, 625.8322246443221, -196.19813531489595, 196.78253093272878, 131.13289558389403, 309.10488211984557, 107.62518021624568, 172.88314134206138, 465.00946106167146, 269.647400056881, 285.5552732557638, 319.0226436576484, 291.5698958850887, -74.29001322490424, 250.56521845652466, -389.57788962500484, 291.9158897903015, 201.94383185425815, 173.87408254898895, 251.73918513848398, 642.1839171272042, -113.91327820159165, 630.4639213276668, -103.38259841022469, 634.1056091124818, -251.3014868279263, -356.64406077379857, 633.3396793610926, 343.530105700687, 92.88202920180079, 62.33715866922496, 198.7590501156318, 268.3369321755249, 351.2059912021946, 262.47231812878107, 49.96224086011671, 294.6990119763778, -28.581126458254992, 45.85497462277398, -237.33494871051641, 113.96681695900759, 190.71280318626597, 352.8029824346809, -63.11201867424529, -110.23245252004403, -61.1776117974382, -101.26720141799281, 195.38504918215432, -92.01380238546335, 187.44934995920178, -319.4361642297592, 639.910155494136, -167.1981698596416, 637.1916517324061, -95.4915669971702, 15.740803011594357, -105.00649294125036, 245.64577877221816, 316.6539568090602, 43.990063702415135, 314.89603897591206, 69.70777041176859, 232.41868262378594, 107.14765162787754, 171.41592394610677, -72.23325044320922, 313.8517800178875, -205.21469539800555, -247.07679155373998, 247.71568017798216, -65.16154058646734, 246.7833370857851, 544.5760160376846, -100.12424391345837, 181.98239817713602, -85.30180090914129, 637.8063825958955, -101.25294975641168, 628.5886796175774, -97.34994673036752, 80.82392359581378, 359.85607998058344, 98.23590212040489, 221.18977699532815, 385.2786657150124, 330.8259580209761, 54.09903935117315, 166.19951947982318, -73.08657852051277, -250.13716196800456, -67.85411134774058, -90.27167138859916, -8.311362063605408, -145.7255795069117, 287.8412003313008, 249.86611582220382, -69.17612439905508]}, "sampler_perf": {"mean_env_wait_ms": 62.92752224071846, "mean_raw_obs_processing_ms": 2.5276053383243373, "mean_inference_ms": 2.7541824806142166, "mean_action_processing_ms": 0.1630122142688117}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 117600, "timers": {"sample_time_ms": 85438.038, "sample_throughput": 49.158, "load_time_ms": 15.905, "load_throughput": 264070.694, "learn_time_ms": 13688.105, "learn_throughput": 306.836, "update_time_ms": 8.791}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 60.61231994628906, "policy_loss": -0.039252039045095444, "vf_loss": 60.645450592041016, "vf_explained_var": 0.981363832950592, "kl": 0.013605443760752678, "entropy": 0.8492413759231567, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 63.48215866088867, "policy_loss": -0.037643130868673325, "vf_loss": 63.514583587646484, "vf_explained_var": 0.9792559146881104, "kl": 0.01738121174275875, "entropy": 0.9723532199859619, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 93.4188003540039, "policy_loss": -0.040750958025455475, "vf_loss": 93.45470428466797, "vf_explained_var": 0.9789724349975586, "kl": 0.016157029196619987, "entropy": 1.0329478979110718, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 46.152610778808594, "policy_loss": -0.04559760168194771, "vf_loss": 46.192466735839844, "vf_explained_var": 0.9848402738571167, "kl": 0.012750502675771713, "entropy": 0.7885918021202087, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 117600, "num_steps_trained": 117600}, "done": false, "episodes_total": 864, "training_iteration": 28, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-15-48", "timestamp": 1624202148, "time_this_iter_s": 81.08257365226746, "time_total_s": 3358.670311689377, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f00cf0e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f00cf3b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf710>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf710>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf710>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf710>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f031a5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3358.670311689377, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 51.099130434782616, "ram_util_percent": 87.67304347826091}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1686.4510744713, "episode_reward_min": -1367.3651545990224, "episode_reward_mean": 509.2989073631288, "episode_len_mean": 174.91, "episodes_this_iter": 21, "policy_reward_min": {"AGENT-2": -365.0493449162931, "AGENT-1": -389.57788962500484, "AGENT-3": -406.47769160020016, "AGENT-0": -364.466829253985}, "policy_reward_max": {"AGENT-2": 406.05494332147686, "AGENT-1": 751.2885950795103, "AGENT-3": 548.6245603397577, "AGENT-0": 714.847774260463}, "policy_reward_mean": {"AGENT-2": 77.86570657745753, "AGENT-1": 162.72195915522823, "AGENT-3": 141.37974176482243, "AGENT-0": 127.33149986562071}, "custom_metrics": {"mean_ego_speed_mean": 41.032067500000004, "mean_ego_speed_min": 15.95625, "mean_ego_speed_max": 50.78, "distance_travelled_mean": 97.08086999999999, "distance_travelled_min": 27.4835, "distance_travelled_max": 124.91424999999998}, "hist_stats": {"episode_reward": [1402.778078142815, 359.91287534323396, -857.573375145325, 1325.262556462156, -186.47875996836217, 1540.362706769048, -292.7566446420976, 1400.299427937708, 885.4450099789763, 1333.4469691869815, 815.6823768074889, 1686.4510744713, 890.4580747689271, 1590.6036931869344, 719.6105528537644, 518.9605307539144, 817.3670152432553, 371.1907720710019, 714.2797773667473, 402.3896426737425, 779.6976042282096, 574.0056184624425, 1273.7773848273223, 53.284140332252356, -402.5380225282749, -69.22017503477218, -478.87686323941, 500.9720479206983, -247.9871023217217, 435.32934134099287, -1367.3651545990224, 1534.5503357009525, -767.0314644819872, 1373.8446892405327, -283.32452510716365, 831.7268008086221, 40.101569314735634, 1055.1897663255484, 837.4321330291365, 1100.1333756037566, 1228.6687883865068, 1223.430244014816, 1110.9427649694685, 386.850424607682, 358.7792313389735, 39.403626638641256, 599.2816649123544, -542.3383378047932, -614.2057711074757, 456.6065949981899, 99.88983529307093, 463.60281716183687, 1147.8358792792003, -266.9270427862786, 363.1966423746438, -241.52306254889345, 1532.4161151332742, -463.16569587229407, 1228.7478488847678, -404.6029913843831, 1170.0154247454802, 1375.5132743275963, 329.6094908290349, 973.1730560903011, 1557.2122985323576, 773.6128762019368, 1199.4131590407924, 1031.990643198061, -169.11612388327845, -652.5815457421043, 59.46930875323638, -245.19371294976764, -50.311756007043186, -390.92297371754296, 1046.6364692290647, 986.2157419088098, -156.540755754228, 257.51135344936574, -505.29545919303985, 1195.0315102001912, -646.7531051792123, 1426.0053940971113, -751.6306419362793, 548.3889557656358, 367.55300409510056, 1308.8432569382512, 345.3746053908171, 975.2864483559512, 1664.5234777361284, 772.9461937687792, 1270.13895978018, 1270.4930095228149, 551.6828109345774, 17.618957962462325, 465.7267710942309, -947.3956809321626, 541.9056056774419, 814.3115264456501, 320.2464892725926, 910.8989876892166], "episode_lengths": [371, 197, 133, 246, 80, 227, 319, 193, 175, 166, 197, 199, 176, 249, 191, 190, 208, 192, 165, 181, 209, 165, 183, 167, 122, 148, 100, 195, 36, 212, 122, 219, 114, 228, 127, 157, 191, 139, 151, 211, 135, 197, 125, 155, 174, 153, 195, 168, 147, 185, 145, 197, 213, 60, 203, 127, 224, 104, 253, 110, 231, 194, 198, 164, 207, 168, 198, 138, 40, 147, 148, 123, 179, 213, 186, 216, 32, 232, 100, 254, 123, 245, 127, 202, 203, 117, 202, 165, 180, 163, 168, 162, 189, 135, 206, 171, 193, 248, 198, 205], "policy_AGENT-2_reward": [-31.708173248271436, 203.03517024032442, -179.48611137404623, 69.43572068819414, -31.30175703456138, 243.89796001744241, -225.9456225616713, 262.93332928289357, 73.63843603004996, 313.0517876410719, 42.02541817882264, 406.05494332147686, 130.71882213417834, 366.3461735998256, -8.05446471201339, -7.6637840755708835, 204.91214830506175, -10.171656482907268, -9.423581463662366, 129.03358877715667, 187.91634941550348, 87.13298444744682, 340.4530294666071, 97.66420515779522, -88.04719786497016, 8.795498874866162, -126.40275745626491, 194.79903907559242, -32.06125226436451, 186.88162808636423, -365.0493449162931, 266.60493097889565, -193.27071853644173, 157.2565419611148, -34.18725712666853, 236.96700366986246, -145.80450331671804, 245.16915019487007, 110.41503482983883, 43.249780642943186, 326.0947332870998, 69.10762939033823, 324.53269278945834, 108.5481425677311, -10.014754244360867, 107.89572358589487, -10.13517018356108, -55.17868353707119, -50.48352825560077, -14.005261733523284, 88.32603728922318, -8.50262727162251, 147.06231861265073, -33.56069998805665, 181.5500630057007, -30.293964750284495, 241.78267452203917, -118.64618377106369, 0.6583859814024782, -92.95934314939616, 80.39667721133355, 340.6817216125342, -103.55595286162918, 186.88160708490966, 366.8006635037028, 64.53524106569229, 53.679061813252595, 260.25747649705875, -11.639993493660512, -58.26131581381809, 113.4315027044693, -30.60442861995977, -9.249400325403542, -27.969289466575248, 276.1053560768852, 236.45454715882647, -9.085212700236708, 196.06681617812373, -170.7800425038572, 65.49197101830372, -157.82983130495, 95.01065365209985, -159.684491061598, 196.31636272858378, -136.18293760224975, 361.7606093874712, -99.34259149238197, 144.9633297618219, 385.77046736054217, 131.21065814588195, 234.258902143443, 299.8346556196814, -8.918424885469513, 56.03474902755915, -10.865555530575248, -75.94436948191856, -10.597829109308435, 203.67920059777904, -8.41078908445449, 234.2822060030728], "policy_AGENT-1_reward": [751.2885950795103, 203.63908006832332, -240.85932729475888, 634.3140770231856, -61.944060709897066, 645.6044992805465, 62.681167289060056, 440.9077855033926, 240.11196117148458, 361.253122446246, 219.4224044598686, 418.47461534073307, 322.246821094878, 306.85868596105024, 380.7428209788919, 274.2797429969674, 201.38163654228742, 201.71608642330187, 379.5335211508533, 86.97058877424774, 202.48058130868904, 190.71280318626597, 352.8029824346809, -63.11201867424529, -110.23245252004403, -61.1776117974382, -101.26720141799281, 195.38504918215432, -92.01380238546335, 187.44934995920178, -319.4361642297592, 639.910155494136, -167.1981698596416, 637.1916517324061, -95.4915669971702, 15.740803011594357, -105.00649294125036, 245.64577877221816, 316.6539568090602, 43.990063702415135, 314.89603897591206, 69.70777041176859, 232.41868262378594, 107.14765162787754, 171.41592394610677, -72.23325044320922, 313.8517800178875, -205.21469539800555, -247.07679155373998, 247.71568017798216, -65.16154058646734, 246.7833370857851, 544.5760160376846, -100.12424391345837, 181.98239817713602, -85.30180090914129, 637.8063825958955, -101.25294975641168, 628.5886796175774, -97.34994673036752, 80.82392359581378, 359.85607998058344, 98.23590212040489, 221.18977699532815, 385.2786657150124, 330.8259580209761, 54.09903935117315, 166.19951947982318, -73.08657852051277, -250.13716196800456, -67.85411134774058, -90.27167138859916, -8.311362063605408, -145.7255795069117, 287.8412003313008, 249.86611582220382, -69.17612439905508, 196.75150105271769, -101.9850368483765, 650.3767436554725, -151.56522328967256, 625.8322246443221, -196.19813531489595, 196.78253093272878, 131.13289558389403, 309.10488211984557, 107.62518021624568, 172.88314134206138, 465.00946106167146, 269.647400056881, 285.5552732557638, 319.0226436576484, 291.5698958850887, -74.29001322490424, 250.56521845652466, -389.57788962500484, 291.9158897903015, 201.94383185425815, 173.87408254898895, 251.73918513848398], "policy_AGENT-3_reward": [-31.650117948883413, 2.692861348206801, -258.2987541546529, 69.48553120501762, -31.238091790808532, 441.15257553615453, -226.08206875742871, 432.9690133542933, 497.4773721356985, 345.52897342235616, 547.2722363836995, 455.3045020291655, 306.208637164458, 528.6048517155185, -8.05500963603705, -7.661198205620798, 205.5995554416552, -10.104106714266088, -9.40289261690996, 56.79707087145571, 200.78526928983564, 106.66624637415525, 239.37599503897698, 81.75656472414305, -116.76799658883971, 44.237819135996915, -149.95125246349767, 82.56177794100918, -32.00986791674601, 64.08682045861437, -318.41281619898706, 394.4540768938055, -191.35556989188663, 456.0609067243897, -34.061361309140196, 311.2203737824265, 476.8386209440177, 283.9999624212169, 299.3999443632328, 543.510934104252, 320.6567115044918, 541.7358334606479, 321.43420355826765, 77.93292949152195, -10.034668984654143, 75.71689264726994, -10.088161773464664, -227.32573089666312, -266.71907175288936, -14.034740885719357, 141.77904446619254, -8.392084275557902, 342.08478073261705, -33.43023548161878, 28.097525783159888, -30.52138703370212, 444.77396438090113, -142.08480901355867, 0.6670094148815271, -116.90340451097, 548.6245603397577, 330.2887499308414, 472.3993473143437, 377.56269857090547, 437.77642598219086, 313.1557723982552, 546.6312263931752, 314.471045739449, -11.500965384947884, -286.5079689042228, 81.57092497840169, -30.559438993632554, -9.130908774808734, -189.8158679173184, 206.01037548755662, 262.8535515165396, -9.013704074223819, -29.702650715469417, -130.5162538336547, 447.34856708280665, -157.7804997611884, 95.0660935960833, -196.7602010353555, 75.04667918546424, 474.5247783438253, 328.9166597016376, 469.8507650073476, 354.4626205325866, 427.39245395393107, 240.31550526853542, 490.3660953503334, 351.202587030023, -8.91280937829892, 110.11957051279786, -10.797605408738452, -406.47769160020016, -10.792932140094916, 204.41694918752182, -8.50022380997239, 190.02790536886064], "policy_AGENT-0_reward": [714.847774260463, -49.454236313620626, -178.9291823218682, 552.0272275457593, -61.99485043309518, 209.70767193490707, 96.5898793879426, 263.4892997971309, 74.2172406417416, 313.61308567730833, 6.962317785098257, 406.6170137799232, 131.2837943754127, 388.7939819105415, 354.9772062229225, 260.0057700381383, 205.47367495425112, 189.75044884487326, 353.5727302964662, 129.5883942508822, 188.5154042141807, 189.49358445457486, 341.1453778870583, -63.02461087544068, -87.49037555442119, -61.07588124819698, -101.25565190165432, 28.22618172194239, -91.90217975514774, -3.0884571631873428, -364.466829253985, 233.5811723341124, -215.2070061940176, 123.33558882262446, -119.58433967418468, 267.79862034473825, -185.92605537131297, 280.37487493724393, 110.96319702700512, 469.38259715414466, 267.0213046190028, 542.8790107520631, 232.55718599795725, 93.22170092055144, 207.4127306218818, -71.97573915131429, 305.65321685149274, -54.61922797305316, -49.926379545245325, 236.93091743945052, -65.05370587587736, 233.71419162323238, 114.11276389624814, -99.81186340314463, -28.433344591353062, -95.40590985576578, 208.05309363443976, -101.1817533312602, 598.8337738709066, -97.39029699364963, 460.1702635985727, 344.6867228036381, -137.46980574408306, 187.53897343915813, 367.3565433314523, 65.09590471701287, 545.0038314831914, 291.0626014817297, -72.88858648415729, -57.675099056058805, -67.679007581894, -93.75817394757608, -23.620084843225396, -27.412236826737704, 276.67953733332223, 237.04152741124005, -69.2657145807124, -105.60431306600626, -102.01412600715136, 31.814228443611213, -179.57755082340094, 610.0964222046059, -198.98781452442972, 80.24338291885846, -101.92173223036816, 309.0611057292965, -132.75874834039246, 302.9773567194801, 386.3510953599828, 131.77263029748016, 259.9586890306392, 300.43312321546165, 277.94414931325815, -74.2453483529904, 236.8247135770203, -75.39573022503893, 271.3804771365438, 204.2715448060916, 163.2834196180304, 234.84969117879842]}, "sampler_perf": {"mean_env_wait_ms": 62.21826913606353, "mean_raw_obs_processing_ms": 2.5022522379756627, "mean_inference_ms": 2.7254102867709595, "mean_action_processing_ms": 0.16159896088082326}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 121800, "timers": {"sample_time_ms": 84769.766, "sample_throughput": 49.546, "load_time_ms": 15.604, "load_throughput": 269158.133, "learn_time_ms": 13550.951, "learn_throughput": 309.941, "update_time_ms": 8.794}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 85.5331802368164, "policy_loss": -0.03436620160937309, "vf_loss": 85.56197357177734, "vf_explained_var": 0.978081226348877, "kl": 0.012380999512970448, "entropy": 0.8386766314506531, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 75.58866882324219, "policy_loss": -0.03556103631854057, "vf_loss": 75.61993408203125, "vf_explained_var": 0.9766402840614319, "kl": 0.014284481294453144, "entropy": 0.9407006502151489, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 127.54834747314453, "policy_loss": -0.036307111382484436, "vf_loss": 127.57987976074219, "vf_explained_var": 0.9693093299865723, "kl": 0.01593921147286892, "entropy": 1.0396920442581177, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 81.0790023803711, "policy_loss": -0.03945358842611313, "vf_loss": 81.1136245727539, "vf_explained_var": 0.9752655625343323, "kl": 0.010727758519351482, "entropy": 0.7430530190467834, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 121800, "num_steps_trained": 121800}, "done": false, "episodes_total": 885, "training_iteration": 29, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-17-05", "timestamp": 1624202225, "time_this_iter_s": 77.06040477752686, "time_total_s": 3435.7307164669037, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f02117a0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f0211b00>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f017cef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f023cf80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f017cef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f023cf80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f017cef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f023cf80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f017cef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f023cf80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f00cfb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3435.7307164669037, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 53.3108108108108, "ram_util_percent": 87.9279279279279}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 1873.5139957470408, "episode_reward_min": -947.3956809321626, "episode_reward_mean": 578.8173995173738, "episode_len_mean": 181.05, "episodes_this_iter": 22, "policy_reward_min": {"AGENT-2": -225.9456225616713, "AGENT-3": -406.47769160020016, "AGENT-0": -224.3776314942096, "AGENT-1": -389.57788962500484}, "policy_reward_max": {"AGENT-2": 465.78682532886177, "AGENT-3": 549.5647283332066, "AGENT-0": 714.847774260463, "AGENT-1": 751.2885950795103}, "policy_reward_mean": {"AGENT-2": 91.13212328106817, "AGENT-3": 147.30496695359315, "AGENT-0": 150.65670763519245, "AGENT-1": 189.72360164752007}, "custom_metrics": {"mean_ego_speed_mean": 40.825747500000006, "mean_ego_speed_min": 15.95625, "mean_ego_speed_max": 51.74675, "distance_travelled_mean": 98.03920750000002, "distance_travelled_min": 27.4835, "distance_travelled_max": 124.91424999999998}, "hist_stats": {"episode_reward": [305.79584471458105, -710.0620238359655, 1168.6682437375005, 507.08188906705135, 1342.1941133161547, -236.69234800749385, 148.8928520931194, 1547.6339392559148, 1873.5139957470408, 1344.5036743373696, 542.2776362765505, 1067.2085774857462, 1119.7531332646474, 1170.96201748536, 939.4240205398263, 702.772676162407, 567.9703312325663, 312.92297655558764, 1730.0447809929387, 1080.05544837824, -479.6023281326172, 463.5754577234029, 386.850424607682, 358.7792313389735, 39.403626638641256, 599.2816649123544, -542.3383378047932, -614.2057711074757, 456.6065949981899, 99.88983529307093, 463.60281716183687, 1147.8358792792003, -266.9270427862786, 363.1966423746438, -241.52306254889345, 1532.4161151332742, -463.16569587229407, 1228.7478488847678, -404.6029913843831, 1170.0154247454802, 1375.5132743275963, 329.6094908290349, 973.1730560903011, 1557.2122985323576, 773.6128762019368, 1199.4131590407924, 1031.990643198061, -169.11612388327845, -652.5815457421043, 59.46930875323638, -245.19371294976764, -50.311756007043186, -390.92297371754296, 1046.6364692290647, 986.2157419088098, -156.540755754228, 257.51135344936574, -505.29545919303985, 1195.0315102001912, -646.7531051792123, 1426.0053940971113, -751.6306419362793, 548.3889557656358, 367.55300409510056, 1308.8432569382512, 345.3746053908171, 975.2864483559512, 1664.5234777361284, 772.9461937687792, 1270.13895978018, 1270.4930095228149, 551.6828109345774, 17.618957962462325, 465.7267710942309, -947.3956809321626, 541.9056056774419, 814.3115264456501, 320.2464892725926, 910.8989876892166, 1402.778078142815, 359.91287534323396, -857.573375145325, 1325.262556462156, -186.47875996836217, 1540.362706769048, -292.7566446420976, 1400.299427937708, 885.4450099789763, 1333.4469691869815, 815.6823768074889, 1686.4510744713, 890.4580747689271, 1590.6036931869344, 719.6105528537644, 518.9605307539144, 817.3670152432553, 371.1907720710019, 714.2797773667473, 402.3896426737425, 779.6976042282096], "episode_lengths": [188, 113, 244, 172, 228, 40, 220, 176, 194, 139, 189, 210, 230, 199, 196, 207, 180, 187, 189, 225, 137, 195, 155, 174, 153, 195, 168, 147, 185, 145, 197, 213, 60, 203, 127, 224, 104, 253, 110, 231, 194, 198, 164, 207, 168, 198, 138, 40, 147, 148, 123, 179, 213, 186, 216, 32, 232, 100, 254, 123, 245, 127, 202, 203, 117, 202, 165, 180, 163, 168, 162, 189, 135, 206, 171, 193, 248, 198, 205, 371, 197, 133, 246, 80, 227, 319, 193, 175, 166, 197, 199, 176, 249, 191, 190, 208, 192, 165, 181, 209], "policy_AGENT-2_reward": [158.31470153882861, -154.19394702983857, 2.170836889142021, -28.662505576955933, 148.80331045292968, -30.709542065860024, 139.90820336150244, 374.05726710203703, 453.05742875468525, 303.473326642692, -4.111403204772416, 204.08879417941876, 52.610487092416676, 248.6428637359049, 121.02724909029234, 170.7520250333715, 127.63539091283354, 39.99179117226725, 465.78682532886177, 293.65778411963953, -37.11029822121246, -12.248067575745553, 108.5481425677311, -10.014754244360867, 107.89572358589487, -10.13517018356108, -55.17868353707119, -50.48352825560077, -14.005261733523284, 88.32603728922318, -8.50262727162251, 147.06231861265073, -33.56069998805665, 181.5500630057007, -30.293964750284495, 241.78267452203917, -118.64618377106369, 0.6583859814024782, -92.95934314939616, 80.39667721133355, 340.6817216125342, -103.55595286162918, 186.88160708490966, 366.8006635037028, 64.53524106569229, 53.679061813252595, 260.25747649705875, -11.639993493660512, -58.26131581381809, 113.4315027044693, -30.60442861995977, -9.249400325403542, -27.969289466575248, 276.1053560768852, 236.45454715882647, -9.085212700236708, 196.06681617812373, -170.7800425038572, 65.49197101830372, -157.82983130495, 95.01065365209985, -159.684491061598, 196.31636272858378, -136.18293760224975, 361.7606093874712, -99.34259149238197, 144.9633297618219, 385.77046736054217, 131.21065814588195, 234.258902143443, 299.8346556196814, -8.918424885469513, 56.03474902755915, -10.865555530575248, -75.94436948191856, -10.597829109308435, 203.67920059777904, -8.41078908445449, 234.2822060030728, -31.708173248271436, 203.03517024032442, -179.48611137404623, 69.43572068819414, -31.30175703456138, 243.89796001744241, -225.9456225616713, 262.93332928289357, 73.63843603004996, 313.0517876410719, 42.02541817882264, 406.05494332147686, 130.71882213417834, 366.3461735998256, -8.05446471201339, -7.6637840755708835, 204.91214830506175, -10.171656482907268, -9.423581463662366, 129.03358877715667, 187.91634941550348], "policy_AGENT-3_reward": [-13.69534506368922, -178.05689908274556, 2.2121056332515194, -28.680011605286797, 447.49924359856783, -30.671471519819754, -63.83606441185013, 401.91582873699633, 501.4479962640774, 352.2624131459533, 460.3472269351314, 383.9462007722515, 549.5647283332066, 332.94734897030946, 541.9012468409857, 170.78457839488462, 171.51329589224457, 65.23304388204217, 298.35454886329484, 184.6894057373808, -219.2752374622095, -12.443736917360795, 77.93292949152195, -10.034668984654143, 75.71689264726994, -10.088161773464664, -227.32573089666312, -266.71907175288936, -14.034740885719357, 141.77904446619254, -8.392084275557902, 342.08478073261705, -33.43023548161878, 28.097525783159888, -30.52138703370212, 444.77396438090113, -142.08480901355867, 0.6670094148815271, -116.90340451097, 548.6245603397577, 330.2887499308414, 472.3993473143437, 377.56269857090547, 437.77642598219086, 313.1557723982552, 546.6312263931752, 314.471045739449, -11.500965384947884, -286.5079689042228, 81.57092497840169, -30.559438993632554, -9.130908774808734, -189.8158679173184, 206.01037548755662, 262.8535515165396, -9.013704074223819, -29.702650715469417, -130.5162538336547, 447.34856708280665, -157.7804997611884, 95.0660935960833, -196.7602010353555, 75.04667918546424, 474.5247783438253, 328.9166597016376, 469.8507650073476, 354.4626205325866, 427.39245395393107, 240.31550526853542, 490.3660953503334, 351.202587030023, -8.91280937829892, 110.11957051279786, -10.797605408738452, -406.47769160020016, -10.792932140094916, 204.41694918752182, -8.50022380997239, 190.02790536886064, -31.650117948883413, 2.692861348206801, -258.2987541546529, 69.48553120501762, -31.238091790808532, 441.15257553615453, -226.08206875742871, 432.9690133542933, 497.4773721356985, 345.52897342235616, 547.2722363836995, 455.3045020291655, 306.208637164458, 528.6048517155185, -8.05500963603705, -7.661198205620798, 205.5995554416552, -10.104106714266088, -9.40289261690996, 56.79707087145571, 200.78526928983564], "policy_AGENT-0_reward": [2.429822058010725, -224.3776314942096, 540.8989338989551, 262.52693417806034, 115.40723726565244, -87.6499337577776, -67.52273402382843, 374.61905544570715, 453.6077965339071, 304.03263550433047, 5.5454559213411585, 226.27003985435024, 464.3145884807531, 285.33218432763664, 77.82939287183011, 171.35492350452884, 128.20280978028865, 120.27143247544099, 475.43501725161525, 294.4314823526723, -36.54210668164438, 239.84075027047226, 93.22170092055144, 207.4127306218818, -71.97573915131429, 305.65321685149274, -54.61922797305316, -49.926379545245325, 236.93091743945052, -65.05370587587736, 233.71419162323238, 114.11276389624814, -99.81186340314463, -28.433344591353062, -95.40590985576578, 208.05309363443976, -101.1817533312602, 598.8337738709066, -97.39029699364963, 460.1702635985727, 344.6867228036381, -137.46980574408306, 187.53897343915813, 367.3565433314523, 65.09590471701287, 545.0038314831914, 291.0626014817297, -72.88858648415729, -57.675099056058805, -67.679007581894, -93.75817394757608, -23.620084843225396, -27.412236826737704, 276.67953733332223, 237.04152741124005, -69.2657145807124, -105.60431306600626, -102.01412600715136, 31.814228443611213, -179.57755082340094, 610.0964222046059, -198.98781452442972, 80.24338291885846, -101.92173223036816, 309.0611057292965, -132.75874834039246, 302.9773567194801, 386.3510953599828, 131.77263029748016, 259.9586890306392, 300.43312321546165, 277.94414931325815, -74.2453483529904, 236.8247135770203, -75.39573022503893, 271.3804771365438, 204.2715448060916, 163.2834196180304, 234.84969117879842, 714.847774260463, -49.454236313620626, -178.9291823218682, 552.0272275457593, -61.99485043309518, 209.70767193490707, 96.5898793879426, 263.4892997971309, 74.2172406417416, 313.61308567730833, 6.962317785098257, 406.6170137799232, 131.2837943754127, 388.7939819105415, 354.9772062229225, 260.0057700381383, 205.47367495425112, 189.75044884487326, 353.5727302964662, 129.5883942508822, 188.5154042141807], "policy_AGENT-1_reward": [158.7466661814309, -153.43354622917138, 623.3863673161504, 301.8974720712338, 630.4843219990034, -87.66140066403656, 140.3434471672952, 397.0417879711734, 465.4007741943717, 384.7352990443939, 80.49635662484997, 252.9035426797257, 53.263329358270276, 304.0396204515081, 198.66613173672127, 189.88114922962163, 140.61883464719995, 87.42670902583706, 490.4683895491652, 307.2767761685473, -186.67468576755056, 248.4265119460368, 107.14765162787754, 171.41592394610677, -72.23325044320922, 313.8517800178875, -205.21469539800555, -247.07679155373998, 247.71568017798216, -65.16154058646734, 246.7833370857851, 544.5760160376846, -100.12424391345837, 181.98239817713602, -85.30180090914129, 637.8063825958955, -101.25294975641168, 628.5886796175774, -97.34994673036752, 80.82392359581378, 359.85607998058344, 98.23590212040489, 221.18977699532815, 385.2786657150124, 330.8259580209761, 54.09903935117315, 166.19951947982318, -73.08657852051277, -250.13716196800456, -67.85411134774058, -90.27167138859916, -8.311362063605408, -145.7255795069117, 287.8412003313008, 249.86611582220382, -69.17612439905508, 196.75150105271769, -101.9850368483765, 650.3767436554725, -151.56522328967256, 625.8322246443221, -196.19813531489595, 196.78253093272878, 131.13289558389403, 309.10488211984557, 107.62518021624568, 172.88314134206138, 465.00946106167146, 269.647400056881, 285.5552732557638, 319.0226436576484, 291.5698958850887, -74.29001322490424, 250.56521845652466, -389.57788962500484, 291.9158897903015, 201.94383185425815, 173.87408254898895, 251.73918513848398, 751.2885950795103, 203.63908006832332, -240.85932729475888, 634.3140770231856, -61.944060709897066, 645.6044992805465, 62.681167289060056, 440.9077855033926, 240.11196117148458, 361.253122446246, 219.4224044598686, 418.47461534073307, 322.246821094878, 306.85868596105024, 380.7428209788919, 274.2797429969674, 201.38163654228742, 201.71608642330187, 379.5335211508533, 86.97058877424774, 202.48058130868904]}, "sampler_perf": {"mean_env_wait_ms": 61.49614105634997, "mean_raw_obs_processing_ms": 2.474794265363322, "mean_inference_ms": 2.696902208364276, "mean_action_processing_ms": 0.16014714854198753}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 126000, "timers": {"sample_time_ms": 84397.416, "sample_throughput": 49.765, "load_time_ms": 15.387, "load_throughput": 272964.271, "learn_time_ms": 13488.801, "learn_throughput": 311.369, "update_time_ms": 8.778}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 81.88848114013672, "policy_loss": -0.03477209806442261, "vf_loss": 81.91787719726562, "vf_explained_var": 0.9791936278343201, "kl": 0.01194257102906704, "entropy": 0.8148974776268005, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 75.50377655029297, "policy_loss": -0.03688766434788704, "vf_loss": 75.53593444824219, "vf_explained_var": 0.9777194857597351, "kl": 0.015738941729068756, "entropy": 0.9057526588439941, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 117.14606475830078, "policy_loss": -0.03809021785855293, "vf_loss": 117.17942810058594, "vf_explained_var": 0.9690390825271606, "kl": 0.01574290171265602, "entropy": 1.012203574180603, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 48.47525405883789, "policy_loss": -0.03900051489472389, "vf_loss": 48.50851058959961, "vf_explained_var": 0.9867316484451294, "kl": 0.012763408944010735, "entropy": 0.7859043478965759, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 126000, "num_steps_trained": 126000}, "done": false, "episodes_total": 907, "training_iteration": 30, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-18-23", "timestamp": 1624202303, "time_this_iter_s": 78.00528764724731, "time_total_s": 3513.736004114151, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f00384d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f00383b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f00385f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3513.736004114151, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 51.86486486486485, "ram_util_percent": 87.89999999999998}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2090.923326216376, "episode_reward_min": -947.3956809321626, "episode_reward_mean": 649.1551916235481, "episode_len_mean": 184.15, "episodes_this_iter": 23, "policy_reward_min": {"AGENT-2": -244.11050801659016, "AGENT-1": -389.57788962500484, "AGENT-3": -406.47769160020016, "AGENT-0": -289.3208278854451}, "policy_reward_max": {"AGENT-2": 517.3036506904834, "AGENT-1": 942.4828237221931, "AGENT-3": 549.5647283332066, "AGENT-0": 904.6051914876375}, "policy_reward_mean": {"AGENT-2": 111.04260897265993, "AGENT-1": 207.4055995183283, "AGENT-3": 159.90044766090082, "AGENT-0": 170.80653547165926}, "custom_metrics": {"mean_ego_speed_mean": 40.95048, "mean_ego_speed_min": 15.95625, "mean_ego_speed_max": 51.74675, "distance_travelled_mean": 99.28860750000001, "distance_travelled_min": 27.4835, "distance_travelled_max": 124.9535}, "hist_stats": {"episode_reward": [1439.726219466311, -10.440145051853932, -937.5707189540486, 1122.2099282476233, 306.9504123184398, 233.27743340670222, -484.35421645687563, 1598.2588509647023, 2090.923326216376, 1244.0260788000821, 1489.8522371075996, 1229.0281620858134, 1787.1293784975512, 1591.9275595272907, 1099.565141934122, 294.03579515544055, 883.0753209410743, -538.5286497102865, -558.2151574936715, 113.48272353908484, 1455.3088684581492, 845.6420067833884, 1061.452854679653, 1199.4131590407924, 1031.990643198061, -169.11612388327845, -652.5815457421043, 59.46930875323638, -245.19371294976764, -50.311756007043186, -390.92297371754296, 1046.6364692290647, 986.2157419088098, -156.540755754228, 257.51135344936574, -505.29545919303985, 1195.0315102001912, -646.7531051792123, 1426.0053940971113, -751.6306419362793, 548.3889557656358, 367.55300409510056, 1308.8432569382512, 345.3746053908171, 975.2864483559512, 1664.5234777361284, 772.9461937687792, 1270.13895978018, 1270.4930095228149, 551.6828109345774, 17.618957962462325, 465.7267710942309, -947.3956809321626, 541.9056056774419, 814.3115264456501, 320.2464892725926, 910.8989876892166, 1402.778078142815, 359.91287534323396, -857.573375145325, 1325.262556462156, -186.47875996836217, 1540.362706769048, -292.7566446420976, 1400.299427937708, 885.4450099789763, 1333.4469691869815, 815.6823768074889, 1686.4510744713, 890.4580747689271, 1590.6036931869344, 719.6105528537644, 518.9605307539144, 817.3670152432553, 371.1907720710019, 714.2797773667473, 402.3896426737425, 779.6976042282096, 305.79584471458105, -710.0620238359655, 1168.6682437375005, 507.08188906705135, 1342.1941133161547, -236.69234800749385, 148.8928520931194, 1547.6339392559148, 1873.5139957470408, 1344.5036743373696, 542.2776362765505, 1067.2085774857462, 1119.7531332646474, 1170.96201748536, 939.4240205398263, 702.772676162407, 567.9703312325663, 312.92297655558764, 1730.0447809929387, 1080.05544837824, -479.6023281326172, 463.5754577234029], "episode_lengths": [521, 184, 113, 243, 159, 219, 102, 201, 123, 197, 140, 194, 126, 121, 227, 179, 200, 173, 154, 157, 157, 203, 192, 198, 138, 40, 147, 148, 123, 179, 213, 186, 216, 32, 232, 100, 254, 123, 245, 127, 202, 203, 117, 202, 165, 180, 163, 168, 162, 189, 135, 206, 171, 193, 248, 198, 205, 371, 197, 133, 246, 80, 227, 319, 193, 175, 166, 197, 199, 176, 249, 191, 190, 208, 192, 165, 181, 209, 188, 113, 244, 172, 228, 40, 220, 176, 194, 139, 189, 210, 230, 199, 196, 207, 180, 187, 189, 225, 137, 195], "policy_AGENT-2_reward": [-203.70858813881026, 132.18559989192008, -244.11050801659016, 91.3423428208531, -33.22070536192752, 151.3869217438944, -118.96814832363941, 356.05863292773887, 517.3036506904834, 231.4195764147517, 334.5228526846512, 246.67573556247444, 421.05403941119334, 347.9502400620271, 49.751756059946594, 223.70226740150727, -8.090847456277515, -39.48906154669007, -57.67195112438032, 140.31735953309018, 365.0225647706276, 198.02470543333783, 277.37322001563524, 53.679061813252595, 260.25747649705875, -11.639993493660512, -58.26131581381809, 113.4315027044693, -30.60442861995977, -9.249400325403542, -27.969289466575248, 276.1053560768852, 236.45454715882647, -9.085212700236708, 196.06681617812373, -170.7800425038572, 65.49197101830372, -157.82983130495, 95.01065365209985, -159.684491061598, 196.31636272858378, -136.18293760224975, 361.7606093874712, -99.34259149238197, 144.9633297618219, 385.77046736054217, 131.21065814588195, 234.258902143443, 299.8346556196814, -8.918424885469513, 56.03474902755915, -10.865555530575248, -75.94436948191856, -10.597829109308435, 203.67920059777904, -8.41078908445449, 234.2822060030728, -31.708173248271436, 203.03517024032442, -179.48611137404623, 69.43572068819414, -31.30175703456138, 243.89796001744241, -225.9456225616713, 262.93332928289357, 73.63843603004996, 313.0517876410719, 42.02541817882264, 406.05494332147686, 130.71882213417834, 366.3461735998256, -8.05446471201339, -7.6637840755708835, 204.91214830506175, -10.171656482907268, -9.423581463662366, 129.03358877715667, 187.91634941550348, 158.31470153882861, -154.19394702983857, 2.170836889142021, -28.662505576955933, 148.80331045292968, -30.709542065860024, 139.90820336150244, 374.05726710203703, 453.05742875468525, 303.473326642692, -4.111403204772416, 204.08879417941876, 52.610487092416676, 248.6428637359049, 121.02724909029234, 170.7520250333715, 127.63539091283354, 39.99179117226725, 465.78682532886177, 293.65778411963953, -37.11029822121246, -12.248067575745553], "policy_AGENT-1_reward": [942.4828237221931, 132.61682848507425, -201.78882349208828, 631.3658479196799, 172.75348827727214, 151.81742730889826, -111.20023830304784, 446.74187816477195, 534.557979870091, 283.4397736227731, 418.8414610604013, 257.45984158742533, 444.9314113872403, 380.69897810839404, 50.41534014489817, -64.40166032120166, 457.5216913372246, -218.601526302379, -210.65039834077544, -69.57982990792652, 406.2614624063918, 216.7455172725081, 298.13344949425704, 54.09903935117315, 166.19951947982318, -73.08657852051277, -250.13716196800456, -67.85411134774058, -90.27167138859916, -8.311362063605408, -145.7255795069117, 287.8412003313008, 249.86611582220382, -69.17612439905508, 196.75150105271769, -101.9850368483765, 650.3767436554725, -151.56522328967256, 625.8322246443221, -196.19813531489595, 196.78253093272878, 131.13289558389403, 309.10488211984557, 107.62518021624568, 172.88314134206138, 465.00946106167146, 269.647400056881, 285.5552732557638, 319.0226436576484, 291.5698958850887, -74.29001322490424, 250.56521845652466, -389.57788962500484, 291.9158897903015, 201.94383185425815, 173.87408254898895, 251.73918513848398, 751.2885950795103, 203.63908006832332, -240.85932729475888, 634.3140770231856, -61.944060709897066, 645.6044992805465, 62.681167289060056, 440.9077855033926, 240.11196117148458, 361.253122446246, 219.4224044598686, 418.47461534073307, 322.246821094878, 306.85868596105024, 380.7428209788919, 274.2797429969674, 201.38163654228742, 201.71608642330187, 379.5335211508533, 86.97058877424774, 202.48058130868904, 158.7466661814309, -153.43354622917138, 623.3863673161504, 301.8974720712338, 630.4843219990034, -87.66140066403656, 140.3434471672952, 397.0417879711734, 465.4007741943717, 384.7352990443939, 80.49635662484997, 252.9035426797257, 53.263329358270276, 304.0396204515081, 198.66613173672127, 189.88114922962163, 140.61883464719995, 87.42670902583706, 490.4683895491652, 307.2767761685473, -186.67468576755056, 248.4265119460368], "policy_AGENT-3_reward": [-203.65320760470766, -114.18634610544315, -202.3505595599249, 343.90426893673185, -33.16518730011909, -32.431237983381436, -142.97584277250553, 438.8466391472643, 521.1737632091576, 462.23808820843504, 401.4187068918622, 484.79700338179293, 499.5404386086058, 450.11728809162395, 541.5809249295185, 199.07851278975153, -8.012273063082855, -241.50892180264165, -232.77640598220975, 112.35116057846862, 306.7221367338651, 232.2762325519385, 207.88829568980563, 546.6312263931752, 314.471045739449, -11.500965384947884, -286.5079689042228, 81.57092497840169, -30.559438993632554, -9.130908774808734, -189.8158679173184, 206.01037548755662, 262.8535515165396, -9.013704074223819, -29.702650715469417, -130.5162538336547, 447.34856708280665, -157.7804997611884, 95.0660935960833, -196.7602010353555, 75.04667918546424, 474.5247783438253, 328.9166597016376, 469.8507650073476, 354.4626205325866, 427.39245395393107, 240.31550526853542, 490.3660953503334, 351.202587030023, -8.91280937829892, 110.11957051279786, -10.797605408738452, -406.47769160020016, -10.792932140094916, 204.41694918752182, -8.50022380997239, 190.02790536886064, -31.650117948883413, 2.692861348206801, -258.2987541546529, 69.48553120501762, -31.238091790808532, 441.15257553615453, -226.08206875742871, 432.9690133542933, 497.4773721356985, 345.52897342235616, 547.2722363836995, 455.3045020291655, 306.208637164458, 528.6048517155185, -8.05500963603705, -7.661198205620798, 205.5995554416552, -10.104106714266088, -9.40289261690996, 56.79707087145571, 200.78526928983564, -13.69534506368922, -178.05689908274556, 2.2121056332515194, -28.680011605286797, 447.49924359856783, -30.671471519819754, -63.83606441185013, 401.91582873699633, 501.4479962640774, 352.2624131459533, 460.3472269351314, 383.9462007722515, 549.5647283332066, 332.94734897030946, 541.9012468409857, 170.78457839488462, 171.51329589224457, 65.23304388204217, 298.35454886329484, 184.6894057373808, -219.2752374622095, -12.443736917360795], "policy_AGENT-0_reward": [904.6051914876375, -161.05622732340515, -289.3208278854451, 55.59746857035804, 200.58281670321455, -37.49567766270867, -111.20998705768255, 356.61170072492735, 517.887932446643, 266.9286405541216, 335.0692164706849, 240.0955815541208, 421.6034890905125, 413.1610532652463, 457.8171207997603, -64.34332471461664, 441.65675012321, -38.92914005857597, -57.11640204630605, -69.60596666454728, 377.30270454726445, 198.59555152560324, 278.0578894799552, 545.0038314831914, 291.0626014817297, -72.88858648415729, -57.675099056058805, -67.679007581894, -93.75817394757608, -23.620084843225396, -27.412236826737704, 276.67953733332223, 237.04152741124005, -69.2657145807124, -105.60431306600626, -102.01412600715136, 31.814228443611213, -179.57755082340094, 610.0964222046059, -198.98781452442972, 80.24338291885846, -101.92173223036816, 309.0611057292965, -132.75874834039246, 302.9773567194801, 386.3510953599828, 131.77263029748016, 259.9586890306392, 300.43312321546165, 277.94414931325815, -74.2453483529904, 236.8247135770203, -75.39573022503893, 271.3804771365438, 204.2715448060916, 163.2834196180304, 234.84969117879842, 714.847774260463, -49.454236313620626, -178.9291823218682, 552.0272275457593, -61.99485043309518, 209.70767193490707, 96.5898793879426, 263.4892997971309, 74.2172406417416, 313.61308567730833, 6.962317785098257, 406.6170137799232, 131.2837943754127, 388.7939819105415, 354.9772062229225, 260.0057700381383, 205.47367495425112, 189.75044884487326, 353.5727302964662, 129.5883942508822, 188.5154042141807, 2.429822058010725, -224.3776314942096, 540.8989338989551, 262.52693417806034, 115.40723726565244, -87.6499337577776, -67.52273402382843, 374.61905544570715, 453.6077965339071, 304.03263550433047, 5.5454559213411585, 226.27003985435024, 464.3145884807531, 285.33218432763664, 77.82939287183011, 171.35492350452884, 128.20280978028865, 120.27143247544099, 475.43501725161525, 294.4314823526723, -36.54210668164438, 239.84075027047226]}, "sampler_perf": {"mean_env_wait_ms": 60.737202415121644, "mean_raw_obs_processing_ms": 2.441092959882175, "mean_inference_ms": 2.6705985175518423, "mean_action_processing_ms": 0.15873625097380425}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 130200, "timers": {"sample_time_ms": 83858.661, "sample_throughput": 50.084, "load_time_ms": 15.404, "load_throughput": 272663.875, "learn_time_ms": 12470.077, "learn_throughput": 336.806, "update_time_ms": 8.044}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 119.54061126708984, "policy_loss": -0.03307276591658592, "vf_loss": 119.56864929199219, "vf_explained_var": 0.9741625785827637, "kl": 0.011179079301655293, "entropy": 0.8082869052886963, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 103.32054138183594, "policy_loss": -0.03078828565776348, "vf_loss": 103.34602355957031, "vf_explained_var": 0.968902051448822, "kl": 0.01772216148674488, "entropy": 0.8878859877586365, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 126.47052764892578, "policy_loss": -0.038050368428230286, "vf_loss": 126.5042953491211, "vf_explained_var": 0.9725117087364197, "kl": 0.01429231371730566, "entropy": 0.9571115374565125, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 93.21511840820312, "policy_loss": -0.03617175295948982, "vf_loss": 93.24638366699219, "vf_explained_var": 0.9777277708053589, "kl": 0.010844860225915909, "entropy": 0.7484146952629089, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 130200, "num_steps_trained": 130200}, "done": false, "episodes_total": 930, "training_iteration": 31, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-19-44", "timestamp": 1624202384, "time_this_iter_s": 80.11670422554016, "time_total_s": 3593.852708339691, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f0211ef0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f0104d40>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d95f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9dd0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d95f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9dd0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d95f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9dd0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d95f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9dd0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f0038b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3593.852708339691, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 51.86347826086957, "ram_util_percent": 87.9295652173913}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2090.923326216376, "episode_reward_min": -947.3956809321626, "episode_reward_mean": 762.1116012940241, "episode_len_mean": 188.14, "episodes_this_iter": 24, "policy_reward_min": {"AGENT-2": -244.11050801659016, "AGENT-3": -406.47769160020016, "AGENT-0": -289.3208278854451, "AGENT-1": -389.57788962500484}, "policy_reward_max": {"AGENT-2": 530.6357898097712, "AGENT-3": 549.5647283332066, "AGENT-0": 904.6051914876375, "AGENT-1": 942.4828237221931}, "policy_reward_mean": {"AGENT-2": 131.187851067501, "AGENT-3": 184.41898168237583, "AGENT-0": 202.67747259673612, "AGENT-1": 243.82729594741136}, "custom_metrics": {"mean_ego_speed_mean": 41.2332125, "mean_ego_speed_min": 15.95625, "mean_ego_speed_max": 51.74675, "distance_travelled_mean": 100.70823250000001, "distance_travelled_min": 33.05075, "distance_travelled_max": 124.9535}, "hist_stats": {"episode_reward": [1571.2984163163774, -87.63157133955735, 322.6709808100969, 75.51525977281916, 1380.143045108333, -142.36465484816006, 1507.4779558487967, 93.56843768583742, 1380.726334891013, 1232.6555201837211, 1118.8972150963373, 1289.1452911626984, 1123.8362988830925, 941.5012505484814, 1324.698145983179, 1316.9453485542194, 286.9110170953888, 2020.49690886574, 635.5464735279046, 736.8139635436844, 795.1022997165109, 505.39333844607523, 697.9966932408239, 785.140445518989, 1270.13895978018, 1270.4930095228149, 551.6828109345774, 17.618957962462325, 465.7267710942309, -947.3956809321626, 541.9056056774419, 814.3115264456501, 320.2464892725926, 910.8989876892166, 1402.778078142815, 359.91287534323396, -857.573375145325, 1325.262556462156, -186.47875996836217, 1540.362706769048, -292.7566446420976, 1400.299427937708, 885.4450099789763, 1333.4469691869815, 815.6823768074889, 1686.4510744713, 890.4580747689271, 1590.6036931869344, 719.6105528537644, 518.9605307539144, 817.3670152432553, 371.1907720710019, 714.2797773667473, 402.3896426737425, 779.6976042282096, 305.79584471458105, -710.0620238359655, 1168.6682437375005, 507.08188906705135, 1342.1941133161547, -236.69234800749385, 148.8928520931194, 1547.6339392559148, 1873.5139957470408, 1344.5036743373696, 542.2776362765505, 1067.2085774857462, 1119.7531332646474, 1170.96201748536, 939.4240205398263, 702.772676162407, 567.9703312325663, 312.92297655558764, 1730.0447809929387, 1080.05544837824, -479.6023281326172, 463.5754577234029, 1439.726219466311, -10.440145051853932, -937.5707189540486, 1122.2099282476233, 306.9504123184398, 233.27743340670222, -484.35421645687563, 1598.2588509647023, 2090.923326216376, 1244.0260788000821, 1489.8522371075996, 1229.0281620858134, 1787.1293784975512, 1591.9275595272907, 1099.565141934122, 294.03579515544055, 883.0753209410743, -538.5286497102865, -558.2151574936715, 113.48272353908484, 1455.3088684581492, 845.6420067833884, 1061.452854679653], "episode_lengths": [223, 82, 193, 161, 258, 121, 228, 156, 197, 122, 180, 169, 203, 189, 201, 120, 171, 235, 203, 106, 206, 182, 245, 181, 168, 162, 189, 135, 206, 171, 193, 248, 198, 205, 371, 197, 133, 246, 80, 227, 319, 193, 175, 166, 197, 199, 176, 249, 191, 190, 208, 192, 165, 181, 209, 188, 113, 244, 172, 228, 40, 220, 176, 194, 139, 189, 210, 230, 199, 196, 207, 180, 187, 189, 225, 137, 195, 521, 184, 113, 243, 159, 219, 102, 201, 123, 197, 140, 194, 126, 121, 227, 179, 200, 173, 154, 157, 157, 203, 192], "policy_AGENT-2_reward": [243.17331040769184, -1.0304084556116067, 170.39124510259506, -29.44898688577462, 103.19017765783325, 21.724001936609856, 206.87302925950164, -29.099786111782386, 295.10083273877177, 246.65471150691639, 221.5964759325078, 214.90340370295962, 220.34876309511318, 62.11510895951982, 266.64207500335453, 261.40226338890403, 221.12667969260661, 530.6357898097712, 157.393970589381, -7.531562320916361, 190.0110550896015, -10.238901271458484, -9.16379718034486, 113.64403593498503, 234.258902143443, 299.8346556196814, -8.918424885469513, 56.03474902755915, -10.865555530575248, -75.94436948191856, -10.597829109308435, 203.67920059777904, -8.41078908445449, 234.2822060030728, -31.708173248271436, 203.03517024032442, -179.48611137404623, 69.43572068819414, -31.30175703456138, 243.89796001744241, -225.9456225616713, 262.93332928289357, 73.63843603004996, 313.0517876410719, 42.02541817882264, 406.05494332147686, 130.71882213417834, 366.3461735998256, -8.05446471201339, -7.6637840755708835, 204.91214830506175, -10.171656482907268, -9.423581463662366, 129.03358877715667, 187.91634941550348, 158.31470153882861, -154.19394702983857, 2.170836889142021, -28.662505576955933, 148.80331045292968, -30.709542065860024, 139.90820336150244, 374.05726710203703, 453.05742875468525, 303.473326642692, -4.111403204772416, 204.08879417941876, 52.610487092416676, 248.6428637359049, 121.02724909029234, 170.7520250333715, 127.63539091283354, 39.99179117226725, 465.78682532886177, 293.65778411963953, -37.11029822121246, -12.248067575745553, -203.70858813881026, 132.18559989192008, -244.11050801659016, 91.3423428208531, -33.22070536192752, 151.3869217438944, -118.96814832363941, 356.05863292773887, 517.3036506904834, 231.4195764147517, 334.5228526846512, 246.67573556247444, 421.05403941119334, 347.9502400620271, 49.751756059946594, 223.70226740150727, -8.090847456277515, -39.48906154669007, -57.67195112438032, 140.31735953309018, 365.0225647706276, 198.02470543333783, 277.37322001563524], "policy_AGENT-3_reward": [426.07082609136313, -43.3508255098728, 17.265237978800982, -29.406627008341005, 103.2202691246939, 29.837433604089124, 429.23672912467083, -29.038253955617396, 452.85175991811985, 483.02153468905425, 441.8773178269718, 513.3220242691674, 432.81191372035175, 541.4488887450146, 439.9709595895135, 478.360329518923, 193.58789301459612, 312.8277494429639, 150.08386023090318, -7.512729875554045, 215.0884165277385, -10.267364549058628, -9.098404363369614, 192.81725138489756, 490.3660953503334, 351.202587030023, -8.91280937829892, 110.11957051279786, -10.797605408738452, -406.47769160020016, -10.792932140094916, 204.41694918752182, -8.50022380997239, 190.02790536886064, -31.650117948883413, 2.692861348206801, -258.2987541546529, 69.48553120501762, -31.238091790808532, 441.15257553615453, -226.08206875742871, 432.9690133542933, 497.4773721356985, 345.52897342235616, 547.2722363836995, 455.3045020291655, 306.208637164458, 528.6048517155185, -8.05500963603705, -7.661198205620798, 205.5995554416552, -10.104106714266088, -9.40289261690996, 56.79707087145571, 200.78526928983564, -13.69534506368922, -178.05689908274556, 2.2121056332515194, -28.680011605286797, 447.49924359856783, -30.671471519819754, -63.83606441185013, 401.91582873699633, 501.4479962640774, 352.2624131459533, 460.3472269351314, 383.9462007722515, 549.5647283332066, 332.94734897030946, 541.9012468409857, 170.78457839488462, 171.51329589224457, 65.23304388204217, 298.35454886329484, 184.6894057373808, -219.2752374622095, -12.443736917360795, -203.65320760470766, -114.18634610544315, -202.3505595599249, 343.90426893673185, -33.16518730011909, -32.431237983381436, -142.97584277250553, 438.8466391472643, 521.1737632091576, 462.23808820843504, 401.4187068918622, 484.79700338179293, 499.5404386086058, 450.11728809162395, 541.5809249295185, 199.07851278975153, -8.012273063082855, -241.50892180264165, -232.77640598220975, 112.35116057846862, 306.7221367338651, 232.2762325519385, 207.88829568980563], "policy_AGENT-0_reward": [261.5520535324655, -0.4682979119089268, -35.814718939255016, 83.09392113459323, 543.0562087095977, -96.9681675048568, 237.1246753985573, 55.85878245139854, 307.4391736310747, 247.23327528720966, 220.76297496738994, 239.55251411291752, 224.82130283097501, 92.21160929605185, 298.13202730732746, 261.95779535381723, -63.90287201362127, 587.8913419276525, 157.97470659867358, 378.1799495548054, 190.57138276313594, 254.58207803284944, 346.5909183556952, 364.6016087018294, 259.9586890306392, 300.43312321546165, 277.94414931325815, -74.2453483529904, 236.8247135770203, -75.39573022503893, 271.3804771365438, 204.2715448060916, 163.2834196180304, 234.84969117879842, 714.847774260463, -49.454236313620626, -178.9291823218682, 552.0272275457593, -61.99485043309518, 209.70767193490707, 96.5898793879426, 263.4892997971309, 74.2172406417416, 313.61308567730833, 6.962317785098257, 406.6170137799232, 131.2837943754127, 388.7939819105415, 354.9772062229225, 260.0057700381383, 205.47367495425112, 189.75044884487326, 353.5727302964662, 129.5883942508822, 188.5154042141807, 2.429822058010725, -224.3776314942096, 540.8989338989551, 262.52693417806034, 115.40723726565244, -87.6499337577776, -67.52273402382843, 374.61905544570715, 453.6077965339071, 304.03263550433047, 5.5454559213411585, 226.27003985435024, 464.3145884807531, 285.33218432763664, 77.82939287183011, 171.35492350452884, 128.20280978028865, 120.27143247544099, 475.43501725161525, 294.4314823526723, -36.54210668164438, 239.84075027047226, 904.6051914876375, -161.05622732340515, -289.3208278854451, 55.59746857035804, 200.58281670321455, -37.49567766270867, -111.20998705768255, 356.61170072492735, 517.887932446643, 266.9286405541216, 335.0692164706849, 240.0955815541208, 421.6034890905125, 413.1610532652463, 457.8171207997603, -64.34332471461664, 441.65675012321, -38.92914005857597, -57.11640204630605, -69.60596666454728, 377.30270454726445, 198.59555152560324, 278.0578894799552], "policy_AGENT-1_reward": [640.5022262848587, -42.782039462164, 170.82921666795605, 51.27695253234148, 630.6763896162088, -96.95792288400244, 634.2435220660667, 95.84769530183873, 325.3345686030458, 255.74599870054251, 234.66044636946705, 321.3673490776553, 245.85431923665345, 245.72564354789205, 319.95308408298285, 315.22496029257564, -63.900683598192806, 589.1420276853507, 170.09393610894693, 373.67830618534947, 199.43144533603544, 271.3175262337424, 369.66797642884364, 114.07754949727672, 285.5552732557638, 319.0226436576484, 291.5698958850887, -74.29001322490424, 250.56521845652466, -389.57788962500484, 291.9158897903015, 201.94383185425815, 173.87408254898895, 251.73918513848398, 751.2885950795103, 203.63908006832332, -240.85932729475888, 634.3140770231856, -61.944060709897066, 645.6044992805465, 62.681167289060056, 440.9077855033926, 240.11196117148458, 361.253122446246, 219.4224044598686, 418.47461534073307, 322.246821094878, 306.85868596105024, 380.7428209788919, 274.2797429969674, 201.38163654228742, 201.71608642330187, 379.5335211508533, 86.97058877424774, 202.48058130868904, 158.7466661814309, -153.43354622917138, 623.3863673161504, 301.8974720712338, 630.4843219990034, -87.66140066403656, 140.3434471672952, 397.0417879711734, 465.4007741943717, 384.7352990443939, 80.49635662484997, 252.9035426797257, 53.263329358270276, 304.0396204515081, 198.66613173672127, 189.88114922962163, 140.61883464719995, 87.42670902583706, 490.4683895491652, 307.2767761685473, -186.67468576755056, 248.4265119460368, 942.4828237221931, 132.61682848507425, -201.78882349208828, 631.3658479196799, 172.75348827727214, 151.81742730889826, -111.20023830304784, 446.74187816477195, 534.557979870091, 283.4397736227731, 418.8414610604013, 257.45984158742533, 444.9314113872403, 380.69897810839404, 50.41534014489817, -64.40166032120166, 457.5216913372246, -218.601526302379, -210.65039834077544, -69.57982990792652, 406.2614624063918, 216.7455172725081, 298.13344949425704]}, "sampler_perf": {"mean_env_wait_ms": 59.898904323528186, "mean_raw_obs_processing_ms": 2.404645745025229, "mean_inference_ms": 2.6432931282991516, "mean_action_processing_ms": 0.15727841957901847}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 134400, "timers": {"sample_time_ms": 75337.292, "sample_throughput": 55.749, "load_time_ms": 13.703, "load_throughput": 306499.814, "learn_time_ms": 11395.7, "learn_throughput": 368.56, "update_time_ms": 7.682}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 97.06764221191406, "policy_loss": -0.03580278158187866, "vf_loss": 97.09781646728516, "vf_explained_var": 0.9806350469589233, "kl": 0.012529244646430016, "entropy": 0.8199829459190369, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 85.09954071044922, "policy_loss": -0.037695519626140594, "vf_loss": 85.13270568847656, "vf_explained_var": 0.9794797897338867, "kl": 0.015088801272213459, "entropy": 0.8903136253356934, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 156.5211944580078, "policy_loss": -0.03818712383508682, "vf_loss": 156.55397033691406, "vf_explained_var": 0.9676334261894226, "kl": 0.017950531095266342, "entropy": 0.9780289530754089, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 70.48365783691406, "policy_loss": -0.029986433684825897, "vf_loss": 70.50971221923828, "vf_explained_var": 0.9766737222671509, "kl": 0.00874205119907856, "entropy": 0.6711984276771545, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 134400, "num_steps_trained": 134400}, "done": false, "episodes_total": 954, "training_iteration": 32, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-21-04", "timestamp": 1624202464, "time_this_iter_s": 80.60040402412415, "time_total_s": 3674.4531123638153, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5d876a4d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5d876a3b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5d876a5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3674.4531123638153, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 51.321739130434786, "ram_util_percent": 87.9}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2250.5460655546103, "episode_reward_min": -937.5707189540486, "episode_reward_mean": 878.8561813167753, "episode_len_mean": 190.34, "episodes_this_iter": 19, "policy_reward_min": {"AGENT-2": -244.11050801659016, "AGENT-3": -241.50892180264165, "AGENT-0": -289.3208278854451, "AGENT-1": -218.601526302379}, "policy_reward_max": {"AGENT-2": 530.6357898097712, "AGENT-3": 549.5647283332066, "AGENT-0": 1165.6375212546811, "AGENT-1": 1134.0039008810365}, "policy_reward_mean": {"AGENT-2": 147.37178894930298, "AGENT-3": 211.89110833905488, "AGENT-0": 237.45175327602297, "AGENT-1": 282.1415307523945}, "custom_metrics": {"mean_ego_speed_mean": 41.641724999999994, "mean_ego_speed_min": 26.423499999999997, "mean_ego_speed_max": 51.74675, "distance_travelled_mean": 102.10871250000002, "distance_travelled_min": 33.05075, "distance_travelled_max": 124.9535}, "hist_stats": {"episode_reward": [1227.4054838850882, 616.3166729562694, 1340.567643836793, 2250.5460655546103, 1373.0357851562846, 381.24271812244893, 1362.4932444032181, 1354.6151998321466, 1484.740410694457, 1520.9974966772277, 1332.0601577297255, 956.044702655239, 1662.9116991569608, 1264.6134596533846, 895.4617767068478, 630.7135625230596, 1590.7451657336317, 582.6683230228437, 640.1577463000386, 1333.4469691869815, 815.6823768074889, 1686.4510744713, 890.4580747689271, 1590.6036931869344, 719.6105528537644, 518.9605307539144, 817.3670152432553, 371.1907720710019, 714.2797773667473, 402.3896426737425, 779.6976042282096, 305.79584471458105, -710.0620238359655, 1168.6682437375005, 507.08188906705135, 1342.1941133161547, -236.69234800749385, 148.8928520931194, 1547.6339392559148, 1873.5139957470408, 1344.5036743373696, 542.2776362765505, 1067.2085774857462, 1119.7531332646474, 1170.96201748536, 939.4240205398263, 702.772676162407, 567.9703312325663, 312.92297655558764, 1730.0447809929387, 1080.05544837824, -479.6023281326172, 463.5754577234029, 1439.726219466311, -10.440145051853932, -937.5707189540486, 1122.2099282476233, 306.9504123184398, 233.27743340670222, -484.35421645687563, 1598.2588509647023, 2090.923326216376, 1244.0260788000821, 1489.8522371075996, 1229.0281620858134, 1787.1293784975512, 1591.9275595272907, 1099.565141934122, 294.03579515544055, 883.0753209410743, -538.5286497102865, -558.2151574936715, 113.48272353908484, 1455.3088684581492, 845.6420067833884, 1061.452854679653, 1571.2984163163774, -87.63157133955735, 322.6709808100969, 75.51525977281916, 1380.143045108333, -142.36465484816006, 1507.4779558487967, 93.56843768583742, 1380.726334891013, 1232.6555201837211, 1118.8972150963373, 1289.1452911626984, 1123.8362988830925, 941.5012505484814, 1324.698145983179, 1316.9453485542194, 286.9110170953888, 2020.49690886574, 635.5464735279046, 736.8139635436844, 795.1022997165109, 505.39333844607523, 697.9966932408239, 785.140445518989], "episode_lengths": [213, 170, 257, 450, 218, 182, 175, 153, 193, 127, 222, 208, 207, 186, 179, 224, 229, 197, 246, 166, 197, 199, 176, 249, 191, 190, 208, 192, 165, 181, 209, 188, 113, 244, 172, 228, 40, 220, 176, 194, 139, 189, 210, 230, 199, 196, 207, 180, 187, 189, 225, 137, 195, 521, 184, 113, 243, 159, 219, 102, 201, 123, 197, 140, 194, 126, 121, 227, 179, 200, 173, 154, 157, 157, 203, 192, 223, 82, 193, 161, 258, 121, 228, 156, 197, 122, 180, 169, 203, 189, 201, 120, 171, 235, 203, 106, 206, 182, 245, 181], "policy_AGENT-2_reward": [0.6949328570594004, -44.29510366692027, 62.36205626944877, -24.53123459157811, 173.08124718806525, -28.365753316207712, 286.7960115207434, 295.65946320278897, 277.15337301916173, 345.42857201903456, 232.16989931534414, 81.76562668584388, 296.8753564042425, 201.59778064950177, 218.57725532684304, -12.544249632120962, 436.25597622184296, 130.08066452090776, -12.516388473633729, 313.0517876410719, 42.02541817882264, 406.05494332147686, 130.71882213417834, 366.3461735998256, -8.05446471201339, -7.6637840755708835, 204.91214830506175, -10.171656482907268, -9.423581463662366, 129.03358877715667, 187.91634941550348, 158.31470153882861, -154.19394702983857, 2.170836889142021, -28.662505576955933, 148.80331045292968, -30.709542065860024, 139.90820336150244, 374.05726710203703, 453.05742875468525, 303.473326642692, -4.111403204772416, 204.08879417941876, 52.610487092416676, 248.6428637359049, 121.02724909029234, 170.7520250333715, 127.63539091283354, 39.99179117226725, 465.78682532886177, 293.65778411963953, -37.11029822121246, -12.248067575745553, -203.70858813881026, 132.18559989192008, -244.11050801659016, 91.3423428208531, -33.22070536192752, 151.3869217438944, -118.96814832363941, 356.05863292773887, 517.3036506904834, 231.4195764147517, 334.5228526846512, 246.67573556247444, 421.05403941119334, 347.9502400620271, 49.751756059946594, 223.70226740150727, -8.090847456277515, -39.48906154669007, -57.67195112438032, 140.31735953309018, 365.0225647706276, 198.02470543333783, 277.37322001563524, 243.17331040769184, -1.0304084556116067, 170.39124510259506, -29.44898688577462, 103.19017765783325, 21.724001936609856, 206.87302925950164, -29.099786111782386, 295.10083273877177, 246.65471150691639, 221.5964759325078, 214.90340370295962, 220.34876309511318, 62.11510895951982, 266.64207500335453, 261.40226338890403, 221.12667969260661, 530.6357898097712, 157.393970589381, -7.531562320916361, 190.0110550896015, -10.238901271458484, -9.16379718034486, 113.64403593498503], "policy_AGENT-3_reward": [0.7205568832186802, -44.47013212600996, 62.31447739476376, -24.564121989528932, 428.8431499358146, -28.403229482991396, 386.5022926744612, 482.28116005811637, 421.2583693802387, 407.0348874861472, 407.8813392834104, 499.84424195052384, 419.4006232237338, 532.5806574105849, 218.57234376316123, -12.546813280065962, 269.54950542212885, 130.03680992927684, -12.463286209251226, 345.52897342235616, 547.2722363836995, 455.3045020291655, 306.208637164458, 528.6048517155185, -8.05500963603705, -7.661198205620798, 205.5995554416552, -10.104106714266088, -9.40289261690996, 56.79707087145571, 200.78526928983564, -13.69534506368922, -178.05689908274556, 2.2121056332515194, -28.680011605286797, 447.49924359856783, -30.671471519819754, -63.83606441185013, 401.91582873699633, 501.4479962640774, 352.2624131459533, 460.3472269351314, 383.9462007722515, 549.5647283332066, 332.94734897030946, 541.9012468409857, 170.78457839488462, 171.51329589224457, 65.23304388204217, 298.35454886329484, 184.6894057373808, -219.2752374622095, -12.443736917360795, -203.65320760470766, -114.18634610544315, -202.3505595599249, 343.90426893673185, -33.16518730011909, -32.431237983381436, -142.97584277250553, 438.8466391472643, 521.1737632091576, 462.23808820843504, 401.4187068918622, 484.79700338179293, 499.5404386086058, 450.11728809162395, 541.5809249295185, 199.07851278975153, -8.012273063082855, -241.50892180264165, -232.77640598220975, 112.35116057846862, 306.7221367338651, 232.2762325519385, 207.88829568980563, 426.07082609136313, -43.3508255098728, 17.265237978800982, -29.406627008341005, 103.2202691246939, 29.837433604089124, 429.23672912467083, -29.038253955617396, 452.85175991811985, 483.02153468905425, 441.8773178269718, 513.3220242691674, 432.81191372035175, 541.4488887450146, 439.9709595895135, 478.360329518923, 193.58789301459612, 312.8277494429639, 150.08386023090318, -7.512729875554045, 215.0884165277385, -10.267364549058628, -9.098404363369614, 192.81725138489756], "policy_AGENT-0_reward": [615.3289526614678, 359.19382871567564, 591.1466998430814, 1165.6375212546811, 127.89513678697028, 235.09577767633445, 287.34457713778585, 251.74597760204796, 385.2260779311341, 345.9687142112951, 330.3979071323773, 114.74233582948573, 466.75224894513786, 159.65595528816434, 219.15061464782514, 325.96417752243684, 437.01247390633444, 153.7056103050041, 325.2690343286208, 313.61308567730833, 6.962317785098257, 406.6170137799232, 131.2837943754127, 388.7939819105415, 354.9772062229225, 260.0057700381383, 205.47367495425112, 189.75044884487326, 353.5727302964662, 129.5883942508822, 188.5154042141807, 2.429822058010725, -224.3776314942096, 540.8989338989551, 262.52693417806034, 115.40723726565244, -87.6499337577776, -67.52273402382843, 374.61905544570715, 453.6077965339071, 304.03263550433047, 5.5454559213411585, 226.27003985435024, 464.3145884807531, 285.33218432763664, 77.82939287183011, 171.35492350452884, 128.20280978028865, 120.27143247544099, 475.43501725161525, 294.4314823526723, -36.54210668164438, 239.84075027047226, 904.6051914876375, -161.05622732340515, -289.3208278854451, 55.59746857035804, 200.58281670321455, -37.49567766270867, -111.20998705768255, 356.61170072492735, 517.887932446643, 266.9286405541216, 335.0692164706849, 240.0955815541208, 421.6034890905125, 413.1610532652463, 457.8171207997603, -64.34332471461664, 441.65675012321, -38.92914005857597, -57.11640204630605, -69.60596666454728, 377.30270454726445, 198.59555152560324, 278.0578894799552, 261.5520535324655, -0.4682979119089268, -35.814718939255016, 83.09392113459323, 543.0562087095977, -96.9681675048568, 237.1246753985573, 55.85878245139854, 307.4391736310747, 247.23327528720966, 220.76297496738994, 239.55251411291752, 224.82130283097501, 92.21160929605185, 298.13202730732746, 261.95779535381723, -63.90287201362127, 587.8913419276525, 157.97470659867358, 378.1799495548054, 190.57138276313594, 254.58207803284944, 346.5909183556952, 364.6016087018294], "policy_AGENT-1_reward": [610.6610414833432, 345.8880800335234, 624.7444103295, 1134.0039008810365, 643.2162512454347, 202.91592324531334, 401.8503630702277, 324.9285989691923, 401.1025903639227, 422.56532296075085, 361.6110119985924, 259.69249818938573, 479.8834705838484, 370.7790663051307, 239.16156296901835, 329.8404479128101, 447.9272101833249, 168.84523826765513, 339.8683866543031, 361.253122446246, 219.4224044598686, 418.47461534073307, 322.246821094878, 306.85868596105024, 380.7428209788919, 274.2797429969674, 201.38163654228742, 201.71608642330187, 379.5335211508533, 86.97058877424774, 202.48058130868904, 158.7466661814309, -153.43354622917138, 623.3863673161504, 301.8974720712338, 630.4843219990034, -87.66140066403656, 140.3434471672952, 397.0417879711734, 465.4007741943717, 384.7352990443939, 80.49635662484997, 252.9035426797257, 53.263329358270276, 304.0396204515081, 198.66613173672127, 189.88114922962163, 140.61883464719995, 87.42670902583706, 490.4683895491652, 307.2767761685473, -186.67468576755056, 248.4265119460368, 942.4828237221931, 132.61682848507425, -201.78882349208828, 631.3658479196799, 172.75348827727214, 151.81742730889826, -111.20023830304784, 446.74187816477195, 534.557979870091, 283.4397736227731, 418.8414610604013, 257.45984158742533, 444.9314113872403, 380.69897810839404, 50.41534014489817, -64.40166032120166, 457.5216913372246, -218.601526302379, -210.65039834077544, -69.57982990792652, 406.2614624063918, 216.7455172725081, 298.13344949425704, 640.5022262848587, -42.782039462164, 170.82921666795605, 51.27695253234148, 630.6763896162088, -96.95792288400244, 634.2435220660667, 95.84769530183873, 325.3345686030458, 255.74599870054251, 234.66044636946705, 321.3673490776553, 245.85431923665345, 245.72564354789205, 319.95308408298285, 315.22496029257564, -63.900683598192806, 589.1420276853507, 170.09393610894693, 373.67830618534947, 199.43144533603544, 271.3175262337424, 369.66797642884364, 114.07754949727672]}, "sampler_perf": {"mean_env_wait_ms": 59.373446494700985, "mean_raw_obs_processing_ms": 2.377647378591673, "mean_inference_ms": 2.626931966591386, "mean_action_processing_ms": 0.1563336146675131}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 138600, "timers": {"sample_time_ms": 69167.779, "sample_throughput": 60.722, "load_time_ms": 13.788, "load_throughput": 304616.202, "learn_time_ms": 11317.078, "learn_throughput": 371.121, "update_time_ms": 7.612}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 56.21636199951172, "policy_loss": -0.037695467472076416, "vf_loss": 56.247982025146484, "vf_explained_var": 0.989024817943573, "kl": 0.013501022011041641, "entropy": 0.7924819588661194, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 43.80012893676758, "policy_loss": -0.03700878843665123, "vf_loss": 43.832393646240234, "vf_explained_var": 0.987402081489563, "kl": 0.01580883003771305, "entropy": 0.85252445936203, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 90.22038269042969, "policy_loss": -0.046086981892585754, "vf_loss": 90.26139831542969, "vf_explained_var": 0.9855350852012634, "kl": 0.01688314788043499, "entropy": 0.9864092469215393, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 41.68982696533203, "policy_loss": -0.03766385838389397, "vf_loss": 41.72220230102539, "vf_explained_var": 0.9872457385063171, "kl": 0.011759186163544655, "entropy": 0.6195560693740845, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 138600, "num_steps_trained": 138600}, "done": false, "episodes_total": 973, "training_iteration": 33, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-22-23", "timestamp": 1624202543, "time_this_iter_s": 78.13857674598694, "time_total_s": 3752.5916891098022, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f02119e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f00cfef0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cfc20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f023cf80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9200>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cfc20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f023cf80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9200>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cfc20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f023cf80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9200>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cfc20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f023cf80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9200>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5d876ab90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3752.5916891098022, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 51.34553571428571, "ram_util_percent": 88.12053571428571}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2250.5460655546103, "episode_reward_min": -1344.2278394611706, "episode_reward_mean": 859.0854322424924, "episode_len_mean": 192.39, "episodes_this_iter": 22, "policy_reward_min": {"AGENT-2": -351.2979369555082, "AGENT-3": -409.94399555423814, "AGENT-0": -302.05468527316583, "AGENT-1": -390.8748336083541}, "policy_reward_max": {"AGENT-2": 530.6357898097712, "AGENT-3": 549.5647283332066, "AGENT-0": 1165.6375212546811, "AGENT-1": 1134.0039008810365}, "policy_reward_mean": {"AGENT-2": 138.34100574784364, "AGENT-3": 211.7948313803024, "AGENT-0": 235.08576372941658, "AGENT-1": 273.86383138492954}, "custom_metrics": {"mean_ego_speed_mean": 41.6116575, "mean_ego_speed_min": 26.423499999999997, "mean_ego_speed_max": 50.945750000000004, "distance_travelled_mean": 105.40185249999999, "distance_travelled_min": 48.156499999999994, "distance_travelled_max": 124.9535}, "hist_stats": {"episode_reward": [1358.5982873955593, -591.8356323607885, 879.3746374305607, -1344.2278394611706, 349.8394002353321, -582.7655852203833, 1493.358002576377, -516.9982548683231, 1437.3513905600505, 48.172107009042975, 1260.9776613687575, 1240.0713117719738, 1855.3073115043037, 1110.2935284656082, 2157.889023161966, 1972.585554518288, 1664.6740067151832, 839.1518804406751, 104.23719210776092, 1059.2670732647168, -882.8045229778851, 1042.076822971619, 542.2776362765505, 1067.2085774857462, 1119.7531332646474, 1170.96201748536, 939.4240205398263, 702.772676162407, 567.9703312325663, 312.92297655558764, 1730.0447809929387, 1080.05544837824, -479.6023281326172, 463.5754577234029, 1439.726219466311, -10.440145051853932, -937.5707189540486, 1122.2099282476233, 306.9504123184398, 233.27743340670222, -484.35421645687563, 1598.2588509647023, 2090.923326216376, 1244.0260788000821, 1489.8522371075996, 1229.0281620858134, 1787.1293784975512, 1591.9275595272907, 1099.565141934122, 294.03579515544055, 883.0753209410743, -538.5286497102865, -558.2151574936715, 113.48272353908484, 1455.3088684581492, 845.6420067833884, 1061.452854679653, 1571.2984163163774, -87.63157133955735, 322.6709808100969, 75.51525977281916, 1380.143045108333, -142.36465484816006, 1507.4779558487967, 93.56843768583742, 1380.726334891013, 1232.6555201837211, 1118.8972150963373, 1289.1452911626984, 1123.8362988830925, 941.5012505484814, 1324.698145983179, 1316.9453485542194, 286.9110170953888, 2020.49690886574, 635.5464735279046, 736.8139635436844, 795.1022997165109, 505.39333844607523, 697.9966932408239, 785.140445518989, 1227.4054838850882, 616.3166729562694, 1340.567643836793, 2250.5460655546103, 1373.0357851562846, 381.24271812244893, 1362.4932444032181, 1354.6151998321466, 1484.740410694457, 1520.9974966772277, 1332.0601577297255, 956.044702655239, 1662.9116991569608, 1264.6134596533846, 895.4617767068478, 630.7135625230596, 1590.7451657336317, 582.6683230228437, 640.1577463000386], "episode_lengths": [231, 139, 194, 131, 208, 92, 231, 107, 195, 191, 136, 177, 203, 191, 219, 413, 222, 188, 196, 200, 162, 216, 189, 210, 230, 199, 196, 207, 180, 187, 189, 225, 137, 195, 521, 184, 113, 243, 159, 219, 102, 201, 123, 197, 140, 194, 126, 121, 227, 179, 200, 173, 154, 157, 157, 203, 192, 223, 82, 193, 161, 258, 121, 228, 156, 197, 122, 180, 169, 203, 189, 201, 120, 171, 235, 203, 106, 206, 182, 245, 181, 213, 170, 257, 450, 218, 182, 175, 153, 193, 127, 222, 208, 207, 186, 179, 224, 229, 197, 246], "policy_AGENT-2_reward": [116.37122429004424, -146.73252819153026, 245.9618009145406, -351.2979369555082, 171.03082333859172, -162.57283348735803, 185.4683862278538, -112.01901035474206, 272.98159990654335, -152.0426963202086, 308.3409265082923, 229.1396318913368, 351.7080864861587, 143.46037548316858, 91.64628860192286, -7.213895338342303, 437.1227120776161, -6.030425758333451, 124.11334737664376, 258.5993372981793, -41.26957010913251, 251.12086067643054, -4.111403204772416, 204.08879417941876, 52.610487092416676, 248.6428637359049, 121.02724909029234, 170.7520250333715, 127.63539091283354, 39.99179117226725, 465.78682532886177, 293.65778411963953, -37.11029822121246, -12.248067575745553, -203.70858813881026, 132.18559989192008, -244.11050801659016, 91.3423428208531, -33.22070536192752, 151.3869217438944, -118.96814832363941, 356.05863292773887, 517.3036506904834, 231.4195764147517, 334.5228526846512, 246.67573556247444, 421.05403941119334, 347.9502400620271, 49.751756059946594, 223.70226740150727, -8.090847456277515, -39.48906154669007, -57.67195112438032, 140.31735953309018, 365.0225647706276, 198.02470543333783, 277.37322001563524, 243.17331040769184, -1.0304084556116067, 170.39124510259506, -29.44898688577462, 103.19017765783325, 21.724001936609856, 206.87302925950164, -29.099786111782386, 295.10083273877177, 246.65471150691639, 221.5964759325078, 214.90340370295962, 220.34876309511318, 62.11510895951982, 266.64207500335453, 261.40226338890403, 221.12667969260661, 530.6357898097712, 157.393970589381, -7.531562320916361, 190.0110550896015, -10.238901271458484, -9.16379718034486, 113.64403593498503, 0.6949328570594004, -44.29510366692027, 62.36205626944877, -24.53123459157811, 173.08124718806525, -28.365753316207712, 286.7960115207434, 295.65946320278897, 277.15337301916173, 345.42857201903456, 232.16989931534414, 81.76562668584388, 296.8753564042425, 201.59778064950177, 218.57725532684304, -12.544249632120962, 436.25597622184296, 130.08066452090776, -12.516388473633729], "policy_AGENT-3_reward": [448.9690864435735, -146.8020032257173, 188.7137987669727, -359.683912916666, 7.227582088876352, -129.3726020288508, 460.1077537788124, -122.65367973516973, 469.7781467969428, 477.7049029299904, 367.5465426589245, 490.624900179294, 470.2103751420922, 495.31758977431315, 502.38778009042636, -7.211842238295251, 314.4417090525442, -6.078305779250424, -81.10923671304472, 269.31758485951184, -409.94399555423814, 292.1558145944859, 460.3472269351314, 383.9462007722515, 549.5647283332066, 332.94734897030946, 541.9012468409857, 170.78457839488462, 171.51329589224457, 65.23304388204217, 298.35454886329484, 184.6894057373808, -219.2752374622095, -12.443736917360795, -203.65320760470766, -114.18634610544315, -202.3505595599249, 343.90426893673185, -33.16518730011909, -32.431237983381436, -142.97584277250553, 438.8466391472643, 521.1737632091576, 462.23808820843504, 401.4187068918622, 484.79700338179293, 499.5404386086058, 450.11728809162395, 541.5809249295185, 199.07851278975153, -8.012273063082855, -241.50892180264165, -232.77640598220975, 112.35116057846862, 306.7221367338651, 232.2762325519385, 207.88829568980563, 426.07082609136313, -43.3508255098728, 17.265237978800982, -29.406627008341005, 103.2202691246939, 29.837433604089124, 429.23672912467083, -29.038253955617396, 452.85175991811985, 483.02153468905425, 441.8773178269718, 513.3220242691674, 432.81191372035175, 541.4488887450146, 439.9709595895135, 478.360329518923, 193.58789301459612, 312.8277494429639, 150.08386023090318, -7.512729875554045, 215.0884165277385, -10.267364549058628, -9.098404363369614, 192.81725138489756, 0.7205568832186802, -44.47013212600996, 62.31447739476376, -24.564121989528932, 428.8431499358146, -28.403229482991396, 386.5022926744612, 482.28116005811637, 421.2583693802387, 407.0348874861472, 407.8813392834104, 499.84424195052384, 419.4006232237338, 532.5806574105849, 218.57234376316123, -12.546813280065962, 269.54950542212885, 130.03680992927684, -12.463286209251226], "policy_AGENT-0_reward": [150.51488403165285, -166.36364411399686, 198.1531116839126, -302.05468527316583, 0.11025545199839576, -162.01096952994712, 215.11062538999278, -170.72456378320095, 341.44362936836797, -194.37789652119903, 278.62875439929036, 264.02425619383723, 507.8445432979067, 177.94496766194018, 775.7309263439699, 987.0953710158468, 451.16989536506424, 419.45890665916437, 124.67112232252168, 259.1800655097304, -40.71612370616031, 251.69355153063708, 5.5454559213411585, 226.27003985435024, 464.3145884807531, 285.33218432763664, 77.82939287183011, 171.35492350452884, 128.20280978028865, 120.27143247544099, 475.43501725161525, 294.4314823526723, -36.54210668164438, 239.84075027047226, 904.6051914876375, -161.05622732340515, -289.3208278854451, 55.59746857035804, 200.58281670321455, -37.49567766270867, -111.20998705768255, 356.61170072492735, 517.887932446643, 266.9286405541216, 335.0692164706849, 240.0955815541208, 421.6034890905125, 413.1610532652463, 457.8171207997603, -64.34332471461664, 441.65675012321, -38.92914005857597, -57.11640204630605, -69.60596666454728, 377.30270454726445, 198.59555152560324, 278.0578894799552, 261.5520535324655, -0.4682979119089268, -35.814718939255016, 83.09392113459323, 543.0562087095977, -96.9681675048568, 237.1246753985573, 55.85878245139854, 307.4391736310747, 247.23327528720966, 220.76297496738994, 239.55251411291752, 224.82130283097501, 92.21160929605185, 298.13202730732746, 261.95779535381723, -63.90287201362127, 587.8913419276525, 157.97470659867358, 378.1799495548054, 190.57138276313594, 254.58207803284944, 346.5909183556952, 364.6016087018294, 615.3289526614678, 359.19382871567564, 591.1466998430814, 1165.6375212546811, 127.89513678697028, 235.09577767633445, 287.34457713778585, 251.74597760204796, 385.2260779311341, 345.9687142112951, 330.3979071323773, 114.74233582948573, 466.75224894513786, 159.65595528816434, 219.15061464782514, 325.96417752243684, 437.01247390633444, 153.7056103050041, 325.2690343286208], "policy_AGENT-1_reward": [642.7430926302869, -131.93745682954454, 246.54592606513566, -331.19130431582954, 171.47073935586502, -128.80918017422727, 632.6712371797133, -111.6010009952104, 353.14801448819685, -83.11220307953825, 306.46143780225026, 256.2825235075066, 525.5443065781451, 293.5705955461842, 788.1240281256481, 999.9159210790783, 461.9396902199583, 431.8017053190938, -63.4380408783597, 272.17008559729516, -390.8748336083541, 247.10659617006618, 80.49635662484997, 252.9035426797257, 53.263329358270276, 304.0396204515081, 198.66613173672127, 189.88114922962163, 140.61883464719995, 87.42670902583706, 490.4683895491652, 307.2767761685473, -186.67468576755056, 248.4265119460368, 942.4828237221931, 132.61682848507425, -201.78882349208828, 631.3658479196799, 172.75348827727214, 151.81742730889826, -111.20023830304784, 446.74187816477195, 534.557979870091, 283.4397736227731, 418.8414610604013, 257.45984158742533, 444.9314113872403, 380.69897810839404, 50.41534014489817, -64.40166032120166, 457.5216913372246, -218.601526302379, -210.65039834077544, -69.57982990792652, 406.2614624063918, 216.7455172725081, 298.13344949425704, 640.5022262848587, -42.782039462164, 170.82921666795605, 51.27695253234148, 630.6763896162088, -96.95792288400244, 634.2435220660667, 95.84769530183873, 325.3345686030458, 255.74599870054251, 234.66044636946705, 321.3673490776553, 245.85431923665345, 245.72564354789205, 319.95308408298285, 315.22496029257564, -63.900683598192806, 589.1420276853507, 170.09393610894693, 373.67830618534947, 199.43144533603544, 271.3175262337424, 369.66797642884364, 114.07754949727672, 610.6610414833432, 345.8880800335234, 624.7444103295, 1134.0039008810365, 643.2162512454347, 202.91592324531334, 401.8503630702277, 324.9285989691923, 401.1025903639227, 422.56532296075085, 361.6110119985924, 259.69249818938573, 479.8834705838484, 370.7790663051307, 239.16156296901835, 329.8404479128101, 447.9272101833249, 168.84523826765513, 339.8683866543031]}, "sampler_perf": {"mean_env_wait_ms": 58.703224623580006, "mean_raw_obs_processing_ms": 2.347888266112273, "mean_inference_ms": 2.603918445739467, "mean_action_processing_ms": 0.15514208891773046}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 142800, "timers": {"sample_time_ms": 68874.653, "sample_throughput": 60.98, "load_time_ms": 13.833, "load_throughput": 303616.056, "learn_time_ms": 11248.386, "learn_throughput": 373.387, "update_time_ms": 7.395}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 168.38211059570312, "policy_loss": -0.027149220928549767, "vf_loss": 168.40451049804688, "vf_explained_var": 0.976142942905426, "kl": 0.010588177479803562, "entropy": 0.8240267038345337, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 113.07750701904297, "policy_loss": -0.03703978657722473, "vf_loss": 113.10995483398438, "vf_explained_var": 0.9769188761711121, "kl": 0.01531603466719389, "entropy": 0.9080172181129456, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 185.53567504882812, "policy_loss": -0.03692196309566498, "vf_loss": 185.5671844482422, "vf_explained_var": 0.974448025226593, "kl": 0.018015140667557716, "entropy": 1.0155991315841675, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 109.44977569580078, "policy_loss": -0.03374809771776199, "vf_loss": 109.47856903076172, "vf_explained_var": 0.9796978235244751, "kl": 0.011001843959093094, "entropy": 0.7519739866256714, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 142800, "num_steps_trained": 142800}, "done": false, "episodes_total": 995, "training_iteration": 34, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-23-46", "timestamp": 1624202626, "time_this_iter_s": 83.0931785106659, "time_total_s": 3835.684867620468, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5d86e04d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5d86e03b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5d86e05f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3835.684867620468, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 53.453389830508485, "ram_util_percent": 87.55847457627114}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2250.5460655546103, "episode_reward_min": -1344.2278394611706, "episode_reward_mean": 863.1568448571902, "episode_len_mean": 192.45, "episodes_this_iter": 22, "policy_reward_min": {"AGENT-2": -351.2979369555082, "AGENT-3": -460.4199811929214, "AGENT-0": -302.05468527316583, "AGENT-1": -435.58596551368504}, "policy_reward_max": {"AGENT-2": 530.6357898097712, "AGENT-3": 551.4614346751973, "AGENT-0": 1165.6375212546811, "AGENT-1": 1134.0039008810365}, "policy_reward_mean": {"AGENT-2": 141.848552557185, "AGENT-3": 210.65534245640822, "AGENT-0": 237.8292048331926, "AGENT-1": 272.82374501040437}, "custom_metrics": {"mean_ego_speed_mean": 41.477977499999994, "mean_ego_speed_min": 22.82725, "mean_ego_speed_max": 50.945750000000004, "distance_travelled_mean": 105.81408499999998, "distance_travelled_min": 48.156499999999994, "distance_travelled_max": 124.9665}, "hist_stats": {"episode_reward": [1156.6325623154432, 82.99512846731142, 156.50182688314968, -438.7398695563979, 1645.8772293697195, -806.0505008883183, 1584.522375119293, -484.9204637824743, 1335.9268925792362, 1707.9352398447795, 1192.4447481190014, 1786.061080586346, 1367.8146733890137, 1041.0181803646421, 1315.1089103770792, -499.97169171910815, 1575.012110615677, 1729.4665149933974, 591.3711876774896, -996.4947730299778, 545.5848196887514, 639.4169769778458, 1489.8522371075996, 1229.0281620858134, 1787.1293784975512, 1591.9275595272907, 1099.565141934122, 294.03579515544055, 883.0753209410743, -538.5286497102865, -558.2151574936715, 113.48272353908484, 1455.3088684581492, 845.6420067833884, 1061.452854679653, 1571.2984163163774, -87.63157133955735, 322.6709808100969, 75.51525977281916, 1380.143045108333, -142.36465484816006, 1507.4779558487967, 93.56843768583742, 1380.726334891013, 1232.6555201837211, 1118.8972150963373, 1289.1452911626984, 1123.8362988830925, 941.5012505484814, 1324.698145983179, 1316.9453485542194, 286.9110170953888, 2020.49690886574, 635.5464735279046, 736.8139635436844, 795.1022997165109, 505.39333844607523, 697.9966932408239, 785.140445518989, 1227.4054838850882, 616.3166729562694, 1340.567643836793, 2250.5460655546103, 1373.0357851562846, 381.24271812244893, 1362.4932444032181, 1354.6151998321466, 1484.740410694457, 1520.9974966772277, 1332.0601577297255, 956.044702655239, 1662.9116991569608, 1264.6134596533846, 895.4617767068478, 630.7135625230596, 1590.7451657336317, 582.6683230228437, 640.1577463000386, 1358.5982873955593, -591.8356323607885, 879.3746374305607, -1344.2278394611706, 349.8394002353321, -582.7655852203833, 1493.358002576377, -516.9982548683231, 1437.3513905600505, 48.172107009042975, 1260.9776613687575, 1240.0713117719738, 1855.3073115043037, 1110.2935284656082, 2157.889023161966, 1972.585554518288, 1664.6740067151832, 839.1518804406751, 104.23719210776092, 1059.2670732647168, -882.8045229778851, 1042.076822971619], "episode_lengths": [222, 263, 196, 110, 212, 116, 239, 111, 159, 333, 203, 282, 160, 209, 183, 175, 207, 309, 242, 177, 127, 177, 140, 194, 126, 121, 227, 179, 200, 173, 154, 157, 157, 203, 192, 223, 82, 193, 161, 258, 121, 228, 156, 197, 122, 180, 169, 203, 189, 201, 120, 171, 235, 203, 106, 206, 182, 245, 181, 213, 170, 257, 450, 218, 182, 175, 153, 193, 127, 222, 208, 207, 186, 179, 224, 229, 197, 246, 231, 139, 194, 131, 208, 92, 231, 107, 195, 191, 136, 177, 203, 191, 219, 413, 222, 188, 196, 200, 162, 216], "policy_AGENT-2_reward": [75.53995530751344, -156.7741704799878, 178.2255618622088, -91.81261206763826, 306.50468521257545, -175.31500310471435, 276.6668399773702, -106.40593275043759, 280.4242298668029, 328.2296796330924, 46.2148676044838, 359.4510060122096, 284.83716138628404, 178.1161176973899, 247.25065990323264, -32.70230106756523, 416.58200990100113, 393.4003952655102, -6.47017495641955, -50.52524768004843, -9.011465059647156, 158.74063478286868, 334.5228526846512, 246.67573556247444, 421.05403941119334, 347.9502400620271, 49.751756059946594, 223.70226740150727, -8.090847456277515, -39.48906154669007, -57.67195112438032, 140.31735953309018, 365.0225647706276, 198.02470543333783, 277.37322001563524, 243.17331040769184, -1.0304084556116067, 170.39124510259506, -29.44898688577462, 103.19017765783325, 21.724001936609856, 206.87302925950164, -29.099786111782386, 295.10083273877177, 246.65471150691639, 221.5964759325078, 214.90340370295962, 220.34876309511318, 62.11510895951982, 266.64207500335453, 261.40226338890403, 221.12667969260661, 530.6357898097712, 157.393970589381, -7.531562320916361, 190.0110550896015, -10.238901271458484, -9.16379718034486, 113.64403593498503, 0.6949328570594004, -44.29510366692027, 62.36205626944877, -24.53123459157811, 173.08124718806525, -28.365753316207712, 286.7960115207434, 295.65946320278897, 277.15337301916173, 345.42857201903456, 232.16989931534414, 81.76562668584388, 296.8753564042425, 201.59778064950177, 218.57725532684304, -12.544249632120962, 436.25597622184296, 130.08066452090776, -12.516388473633729, 116.37122429004424, -146.73252819153026, 245.9618009145406, -351.2979369555082, 171.03082333859172, -162.57283348735803, 185.4683862278538, -112.01901035474206, 272.98159990654335, -152.0426963202086, 308.3409265082923, 229.1396318913368, 351.7080864861587, 143.46037548316858, 91.64628860192286, -7.213895338342303, 437.1227120776161, -6.030425758333451, 124.11334737664376, 258.5993372981793, -41.26957010913251, 251.12086067643054], "policy_AGENT-3_reward": [338.895560986884, -156.72163261915728, -103.12003266740962, -139.8190048833893, 362.8516017399, -203.56430015350594, 430.6523512745679, -148.35105594320308, 491.4728619011331, 461.80606086792454, 551.4614346751973, 480.50636573612695, 503.03588905549196, 475.55440565657796, 496.78129533061946, -228.9713661255771, 316.3198652082239, 232.06096320207504, -6.4827802240567, -460.4199811929214, -8.909683447698802, 165.9753176504356, 401.4187068918622, 484.79700338179293, 499.5404386086058, 450.11728809162395, 541.5809249295185, 199.07851278975153, -8.012273063082855, -241.50892180264165, -232.77640598220975, 112.35116057846862, 306.7221367338651, 232.2762325519385, 207.88829568980563, 426.07082609136313, -43.3508255098728, 17.265237978800982, -29.406627008341005, 103.2202691246939, 29.837433604089124, 429.23672912467083, -29.038253955617396, 452.85175991811985, 483.02153468905425, 441.8773178269718, 513.3220242691674, 432.81191372035175, 541.4488887450146, 439.9709595895135, 478.360329518923, 193.58789301459612, 312.8277494429639, 150.08386023090318, -7.512729875554045, 215.0884165277385, -10.267364549058628, -9.098404363369614, 192.81725138489756, 0.7205568832186802, -44.47013212600996, 62.31447739476376, -24.564121989528932, 428.8431499358146, -28.403229482991396, 386.5022926744612, 482.28116005811637, 421.2583693802387, 407.0348874861472, 407.8813392834104, 499.84424195052384, 419.4006232237338, 532.5806574105849, 218.57234376316123, -12.546813280065962, 269.54950542212885, 130.03680992927684, -12.463286209251226, 448.9690864435735, -146.8020032257173, 188.7137987669727, -359.683912916666, 7.227582088876352, -129.3726020288508, 460.1077537788124, -122.65367973516973, 469.7781467969428, 477.7049029299904, 367.5465426589245, 490.624900179294, 470.2103751420922, 495.31758977431315, 502.38778009042636, -7.211842238295251, 314.4417090525442, -6.078305779250424, -81.10923671304472, 269.31758485951184, -409.94399555423814, 292.1558145944859], "policy_AGENT-0_reward": [109.76417521136928, 180.73928357646324, -97.26311653407684, -67.85543484805136, 339.16693350072296, -252.3886099057416, 230.81441919089457, -82.37669616287026, 241.674725899939, 425.9026867675576, 547.8782152837177, 484.2184052867819, 243.56631700899442, 186.0850338643994, 281.2653841535355, -32.12269989039974, 417.1323591984762, 540.5366016118251, 291.72450047383074, -49.96357864332269, 317.6426136113569, 173.61959268914737, 335.0692164706849, 240.0955815541208, 421.6034890905125, 413.1610532652463, 457.8171207997603, -64.34332471461664, 441.65675012321, -38.92914005857597, -57.11640204630605, -69.60596666454728, 377.30270454726445, 198.59555152560324, 278.0578894799552, 261.5520535324655, -0.4682979119089268, -35.814718939255016, 83.09392113459323, 543.0562087095977, -96.9681675048568, 237.1246753985573, 55.85878245139854, 307.4391736310747, 247.23327528720966, 220.76297496738994, 239.55251411291752, 224.82130283097501, 92.21160929605185, 298.13202730732746, 261.95779535381723, -63.90287201362127, 587.8913419276525, 157.97470659867358, 378.1799495548054, 190.57138276313594, 254.58207803284944, 346.5909183556952, 364.6016087018294, 615.3289526614678, 359.19382871567564, 591.1466998430814, 1165.6375212546811, 127.89513678697028, 235.09577767633445, 287.34457713778585, 251.74597760204796, 385.2260779311341, 345.9687142112951, 330.3979071323773, 114.74233582948573, 466.75224894513786, 159.65595528816434, 219.15061464782514, 325.96417752243684, 437.01247390633444, 153.7056103050041, 325.2690343286208, 150.51488403165285, -166.36364411399686, 198.1531116839126, -302.05468527316583, 0.11025545199839576, -162.01096952994712, 215.11062538999278, -170.72456378320095, 341.44362936836797, -194.37789652119903, 278.62875439929036, 264.02425619383723, 507.8445432979067, 177.94496766194018, 775.7309263439699, 987.0953710158468, 451.16989536506424, 419.45890665916437, 124.67112232252168, 259.1800655097304, -40.71612370616031, 251.69355153063708], "policy_AGENT-1_reward": [632.4328708096781, 215.7516479899938, 178.65941422242747, -139.25281775731904, 637.354008916521, -174.78258772435697, 646.3887646764608, -147.7867789259627, 322.3550749113606, 491.9968125762047, 46.89023055560408, 461.8853035512264, 336.37530593824295, 201.26262314627488, 289.81157098969334, -206.17532463556645, 424.9778763079775, 563.4685549139876, 312.5996423841341, -435.58596551368504, 245.8633545847412, 141.081431855394, 418.8414610604013, 257.45984158742533, 444.9314113872403, 380.69897810839404, 50.41534014489817, -64.40166032120166, 457.5216913372246, -218.601526302379, -210.65039834077544, -69.57982990792652, 406.2614624063918, 216.7455172725081, 298.13344949425704, 640.5022262848587, -42.782039462164, 170.82921666795605, 51.27695253234148, 630.6763896162088, -96.95792288400244, 634.2435220660667, 95.84769530183873, 325.3345686030458, 255.74599870054251, 234.66044636946705, 321.3673490776553, 245.85431923665345, 245.72564354789205, 319.95308408298285, 315.22496029257564, -63.900683598192806, 589.1420276853507, 170.09393610894693, 373.67830618534947, 199.43144533603544, 271.3175262337424, 369.66797642884364, 114.07754949727672, 610.6610414833432, 345.8880800335234, 624.7444103295, 1134.0039008810365, 643.2162512454347, 202.91592324531334, 401.8503630702277, 324.9285989691923, 401.1025903639227, 422.56532296075085, 361.6110119985924, 259.69249818938573, 479.8834705838484, 370.7790663051307, 239.16156296901835, 329.8404479128101, 447.9272101833249, 168.84523826765513, 339.8683866543031, 642.7430926302869, -131.93745682954454, 246.54592606513566, -331.19130431582954, 171.47073935586502, -128.80918017422727, 632.6712371797133, -111.6010009952104, 353.14801448819685, -83.11220307953825, 306.46143780225026, 256.2825235075066, 525.5443065781451, 293.5705955461842, 788.1240281256481, 999.9159210790783, 461.9396902199583, 431.8017053190938, -63.4380408783597, 272.17008559729516, -390.8748336083541, 247.10659617006618]}, "sampler_perf": {"mean_env_wait_ms": 58.0756019035817, "mean_raw_obs_processing_ms": 2.319625697218585, "mean_inference_ms": 2.582240980582013, "mean_action_processing_ms": 0.15403240293451673}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 147000, "timers": {"sample_time_ms": 68243.938, "sample_throughput": 61.544, "load_time_ms": 13.333, "load_throughput": 315018.326, "learn_time_ms": 11143.159, "learn_throughput": 376.913, "update_time_ms": 7.443}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 96.66192626953125, "policy_loss": -0.03341703489422798, "vf_loss": 96.6901626586914, "vf_explained_var": 0.9836490750312805, "kl": 0.011498001404106617, "entropy": 0.7810371518135071, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 67.99786376953125, "policy_loss": -0.03746728599071503, "vf_loss": 68.03047943115234, "vf_explained_var": 0.9847711324691772, "kl": 0.016205351799726486, "entropy": 0.8730618357658386, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 133.6073760986328, "policy_loss": -0.03780807927250862, "vf_loss": 133.64022827148438, "vf_explained_var": 0.9795244336128235, "kl": 0.016575997695326805, "entropy": 0.9709575772285461, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 73.91856384277344, "policy_loss": -0.0359322763979435, "vf_loss": 73.94982147216797, "vf_explained_var": 0.9856438040733337, "kl": 0.010411100462079048, "entropy": 0.7717940211296082, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 147000, "num_steps_trained": 147000}, "done": false, "episodes_total": 1017, "training_iteration": 35, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-25-06", "timestamp": 1624202706, "time_this_iter_s": 79.95789575576782, "time_total_s": 3915.642763376236, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f0038d40>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f0038ef0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a290>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a290>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a290>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f017c440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a290>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d97a0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5d86e0b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3915.642763376236, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 52.47652173913043, "ram_util_percent": 88.0113043478261}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2250.5460655546103, "episode_reward_min": -1344.2278394611706, "episode_reward_mean": 882.4608811404197, "episode_len_mean": 198.73, "episodes_this_iter": 20, "policy_reward_min": {"AGENT-2": -351.2979369555082, "AGENT-3": -460.4199811929214, "AGENT-0": -302.05468527316583, "AGENT-1": -435.58596551368504}, "policy_reward_max": {"AGENT-2": 530.6357898097712, "AGENT-3": 551.4614346751973, "AGENT-0": 1165.6375212546811, "AGENT-1": 1134.0039008810365}, "policy_reward_mean": {"AGENT-2": 130.44893865160248, "AGENT-3": 222.2492905978227, "AGENT-0": 239.30864549735242, "AGENT-1": 290.454006393642}, "custom_metrics": {"mean_ego_speed_mean": 41.268060000000006, "mean_ego_speed_min": 22.82725, "mean_ego_speed_max": 50.945750000000004, "distance_travelled_mean": 108.86103500000002, "distance_travelled_min": 42.2575, "distance_travelled_max": 124.9665}, "hist_stats": {"episode_reward": [1488.7315695749842, -568.6146498193862, 1383.1121564414257, 1348.8605647160991, 1495.6976994371537, -624.9345336912236, 1326.8453275109518, 1502.5800935960594, 85.84493418787476, 1782.3469105757847, 670.7444409672789, 992.3279632453795, 681.1615799431531, 808.2768176089047, 1359.1663069769033, -149.19144825426244, 601.3502387825822, 825.447268749705, 1065.4902882445137, 1236.0257727029696, 93.56843768583742, 1380.726334891013, 1232.6555201837211, 1118.8972150963373, 1289.1452911626984, 1123.8362988830925, 941.5012505484814, 1324.698145983179, 1316.9453485542194, 286.9110170953888, 2020.49690886574, 635.5464735279046, 736.8139635436844, 795.1022997165109, 505.39333844607523, 697.9966932408239, 785.140445518989, 1227.4054838850882, 616.3166729562694, 1340.567643836793, 2250.5460655546103, 1373.0357851562846, 381.24271812244893, 1362.4932444032181, 1354.6151998321466, 1484.740410694457, 1520.9974966772277, 1332.0601577297255, 956.044702655239, 1662.9116991569608, 1264.6134596533846, 895.4617767068478, 630.7135625230596, 1590.7451657336317, 582.6683230228437, 640.1577463000386, 1358.5982873955593, -591.8356323607885, 879.3746374305607, -1344.2278394611706, 349.8394002353321, -582.7655852203833, 1493.358002576377, -516.9982548683231, 1437.3513905600505, 48.172107009042975, 1260.9776613687575, 1240.0713117719738, 1855.3073115043037, 1110.2935284656082, 2157.889023161966, 1972.585554518288, 1664.6740067151832, 839.1518804406751, 104.23719210776092, 1059.2670732647168, -882.8045229778851, 1042.076822971619, 1156.6325623154432, 82.99512846731142, 156.50182688314968, -438.7398695563979, 1645.8772293697195, -806.0505008883183, 1584.522375119293, -484.9204637824743, 1335.9268925792362, 1707.9352398447795, 1192.4447481190014, 1786.061080586346, 1367.8146733890137, 1041.0181803646421, 1315.1089103770792, -499.97169171910815, 1575.012110615677, 1729.4665149933974, 591.3711876774896, -996.4947730299778, 545.5848196887514, 639.4169769778458], "episode_lengths": [227, 42, 235, 346, 229, 129, 232, 195, 210, 226, 216, 206, 211, 200, 222, 147, 172, 285, 184, 203, 156, 197, 122, 180, 169, 203, 189, 201, 120, 171, 235, 203, 106, 206, 182, 245, 181, 213, 170, 257, 450, 218, 182, 175, 153, 193, 127, 222, 208, 207, 186, 179, 224, 229, 197, 246, 231, 139, 194, 131, 208, 92, 231, 107, 195, 191, 136, 177, 203, 191, 219, 413, 222, 188, 196, 200, 162, 216, 222, 263, 196, 110, 212, 116, 239, 111, 159, 333, 203, 282, 160, 209, 183, 175, 207, 309, 242, 177, 127, 177], "policy_AGENT-2_reward": [234.10442067976993, -167.97208089381138, 94.2353695825972, -37.31775244947711, 203.79105880481487, -156.7699965317306, 112.93948235887613, 303.79647546087097, -244.68342687578178, 363.2572741235675, 35.77389173437398, 134.9071422160705, -59.75034605521513, 223.3822786015784, 350.0747048959797, 31.590274169366438, 145.41101789509457, -8.65486643970507, 210.64860166252268, 305.29033633197497, -29.099786111782386, 295.10083273877177, 246.65471150691639, 221.5964759325078, 214.90340370295962, 220.34876309511318, 62.11510895951982, 266.64207500335453, 261.40226338890403, 221.12667969260661, 530.6357898097712, 157.393970589381, -7.531562320916361, 190.0110550896015, -10.238901271458484, -9.16379718034486, 113.64403593498503, 0.6949328570594004, -44.29510366692027, 62.36205626944877, -24.53123459157811, 173.08124718806525, -28.365753316207712, 286.7960115207434, 295.65946320278897, 277.15337301916173, 345.42857201903456, 232.16989931534414, 81.76562668584388, 296.8753564042425, 201.59778064950177, 218.57725532684304, -12.544249632120962, 436.25597622184296, 130.08066452090776, -12.516388473633729, 116.37122429004424, -146.73252819153026, 245.9618009145406, -351.2979369555082, 171.03082333859172, -162.57283348735803, 185.4683862278538, -112.01901035474206, 272.98159990654335, -152.0426963202086, 308.3409265082923, 229.1396318913368, 351.7080864861587, 143.46037548316858, 91.64628860192286, -7.213895338342303, 437.1227120776161, -6.030425758333451, 124.11334737664376, 258.5993372981793, -41.26957010913251, 251.12086067643054, 75.53995530751344, -156.7741704799878, 178.2255618622088, -91.81261206763826, 306.50468521257545, -175.31500310471435, 276.6668399773702, -106.40593275043759, 280.4242298668029, 328.2296796330924, 46.2148676044838, 359.4510060122096, 284.83716138628404, 178.1161176973899, 247.25065990323264, -32.70230106756523, 416.58200990100113, 393.4003952655102, -6.47017495641955, -50.52524768004843, -9.011465059647156, 158.74063478286868], "policy_AGENT-3_reward": [346.2942666523488, -168.1189167140204, 94.27071070655637, -37.366833236312345, 427.67923726558683, -157.42359389552047, 426.0265863392303, 466.86546996791475, 486.00154815908087, 476.86668779242814, 476.06188020061853, 499.2681033076163, 526.9389916102801, 170.88732712423558, 305.17219225646204, -1.9456023300645855, 137.95045015441195, -8.766780541908926, 269.49109200901563, 309.58814011819584, -29.038253955617396, 452.85175991811985, 483.02153468905425, 441.8773178269718, 513.3220242691674, 432.81191372035175, 541.4488887450146, 439.9709595895135, 478.360329518923, 193.58789301459612, 312.8277494429639, 150.08386023090318, -7.512729875554045, 215.0884165277385, -10.267364549058628, -9.098404363369614, 192.81725138489756, 0.7205568832186802, -44.47013212600996, 62.31447739476376, -24.564121989528932, 428.8431499358146, -28.403229482991396, 386.5022926744612, 482.28116005811637, 421.2583693802387, 407.0348874861472, 407.8813392834104, 499.84424195052384, 419.4006232237338, 532.5806574105849, 218.57234376316123, -12.546813280065962, 269.54950542212885, 130.03680992927684, -12.463286209251226, 448.9690864435735, -146.8020032257173, 188.7137987669727, -359.683912916666, 7.227582088876352, -129.3726020288508, 460.1077537788124, -122.65367973516973, 469.7781467969428, 477.7049029299904, 367.5465426589245, 490.624900179294, 470.2103751420922, 495.31758977431315, 502.38778009042636, -7.211842238295251, 314.4417090525442, -6.078305779250424, -81.10923671304472, 269.31758485951184, -409.94399555423814, 292.1558145944859, 338.895560986884, -156.72163261915728, -103.12003266740962, -139.8190048833893, 362.8516017399, -203.56430015350594, 430.6523512745679, -148.35105594320308, 491.4728619011331, 461.80606086792454, 551.4614346751973, 480.50636573612695, 503.03588905549196, 475.55440565657796, 496.78129533061946, -228.9713661255771, 316.3198652082239, 232.06096320207504, -6.4827802240567, -460.4199811929214, -8.909683447698802, 165.9753176504356], "policy_AGENT-0_reward": [265.3263805395157, -116.27189707797046, 560.1917017578406, 693.420029316242, 221.30840641037702, -156.21345817838784, 146.02224534465498, 359.38531560364703, -209.57130629567416, 457.6490964585699, 55.01586203409724, 205.79596915659144, -25.72794567678142, 223.9554345617099, 350.64030182255635, -89.43696107121127, 145.97370101807513, 397.6168562197918, 281.94064021453926, 305.86389204929395, 55.85878245139854, 307.4391736310747, 247.23327528720966, 220.76297496738994, 239.55251411291752, 224.82130283097501, 92.21160929605185, 298.13202730732746, 261.95779535381723, -63.90287201362127, 587.8913419276525, 157.97470659867358, 378.1799495548054, 190.57138276313594, 254.58207803284944, 346.5909183556952, 364.6016087018294, 615.3289526614678, 359.19382871567564, 591.1466998430814, 1165.6375212546811, 127.89513678697028, 235.09577767633445, 287.34457713778585, 251.74597760204796, 385.2260779311341, 345.9687142112951, 330.3979071323773, 114.74233582948573, 466.75224894513786, 159.65595528816434, 219.15061464782514, 325.96417752243684, 437.01247390633444, 153.7056103050041, 325.2690343286208, 150.51488403165285, -166.36364411399686, 198.1531116839126, -302.05468527316583, 0.11025545199839576, -162.01096952994712, 215.11062538999278, -170.72456378320095, 341.44362936836797, -194.37789652119903, 278.62875439929036, 264.02425619383723, 507.8445432979067, 177.94496766194018, 775.7309263439699, 987.0953710158468, 451.16989536506424, 419.45890665916437, 124.67112232252168, 259.1800655097304, -40.71612370616031, 251.69355153063708, 109.76417521136928, 180.73928357646324, -97.26311653407684, -67.85543484805136, 339.16693350072296, -252.3886099057416, 230.81441919089457, -82.37669616287026, 241.674725899939, 425.9026867675576, 547.8782152837177, 484.2184052867819, 243.56631700899442, 186.0850338643994, 281.2653841535355, -32.12269989039974, 417.1323591984762, 540.5366016118251, 291.72450047383074, -49.96357864332269, 317.6426136113569, 173.61959268914737], "policy_AGENT-1_reward": [643.006501703348, -116.25175513358403, 634.4143743944311, 730.1251210856469, 642.9189969563746, -154.52748508558486, 641.8570134681902, 372.53283256362533, 54.09811920025227, 484.5738522012211, 103.89280699818923, 152.35674856510073, 239.70088006487, 190.05177732138048, 353.2791080019055, -89.39915902235307, 172.01506971500044, 445.252059511527, 303.40995435843774, 315.28340420350565, 95.84769530183873, 325.3345686030458, 255.74599870054251, 234.66044636946705, 321.3673490776553, 245.85431923665345, 245.72564354789205, 319.95308408298285, 315.22496029257564, -63.900683598192806, 589.1420276853507, 170.09393610894693, 373.67830618534947, 199.43144533603544, 271.3175262337424, 369.66797642884364, 114.07754949727672, 610.6610414833432, 345.8880800335234, 624.7444103295, 1134.0039008810365, 643.2162512454347, 202.91592324531334, 401.8503630702277, 324.9285989691923, 401.1025903639227, 422.56532296075085, 361.6110119985924, 259.69249818938573, 479.8834705838484, 370.7790663051307, 239.16156296901835, 329.8404479128101, 447.9272101833249, 168.84523826765513, 339.8683866543031, 642.7430926302869, -131.93745682954454, 246.54592606513566, -331.19130431582954, 171.47073935586502, -128.80918017422727, 632.6712371797133, -111.6010009952104, 353.14801448819685, -83.11220307953825, 306.46143780225026, 256.2825235075066, 525.5443065781451, 293.5705955461842, 788.1240281256481, 999.9159210790783, 461.9396902199583, 431.8017053190938, -63.4380408783597, 272.17008559729516, -390.8748336083541, 247.10659617006618, 632.4328708096781, 215.7516479899938, 178.65941422242747, -139.25281775731904, 637.354008916521, -174.78258772435697, 646.3887646764608, -147.7867789259627, 322.3550749113606, 491.9968125762047, 46.89023055560408, 461.8853035512264, 336.37530593824295, 201.26262314627488, 289.81157098969334, -206.17532463556645, 424.9778763079775, 563.4685549139876, 312.5996423841341, -435.58596551368504, 245.8633545847412, 141.081431855394]}, "sampler_perf": {"mean_env_wait_ms": 57.58127114079389, "mean_raw_obs_processing_ms": 2.2942816423279466, "mean_inference_ms": 2.5655482408093415, "mean_action_processing_ms": 0.15314121206977746}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 151200, "timers": {"sample_time_ms": 67974.152, "sample_throughput": 61.788, "load_time_ms": 13.337, "load_throughput": 314910.767, "learn_time_ms": 11167.567, "learn_throughput": 376.089, "update_time_ms": 7.37}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 132.38510131835938, "policy_loss": -0.03188643977046013, "vf_loss": 132.4119110107422, "vf_explained_var": 0.9826327562332153, "kl": 0.011294526979327202, "entropy": 0.776300847530365, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 87.86256408691406, "policy_loss": -0.03204759582877159, "vf_loss": 87.89010620117188, "vf_explained_var": 0.9814440608024597, "kl": 0.015043535269796848, "entropy": 0.8340345025062561, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 213.7000274658203, "policy_loss": -0.03747206926345825, "vf_loss": 213.7323455810547, "vf_explained_var": 0.9759078025817871, "kl": 0.01714739389717579, "entropy": 0.9696469902992249, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 68.5112075805664, "policy_loss": -0.03294014185667038, "vf_loss": 68.53909301757812, "vf_explained_var": 0.9834266304969788, "kl": 0.011209438554942608, "entropy": 0.7103840708732605, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 151200, "num_steps_trained": 151200}, "done": false, "episodes_total": 1037, "training_iteration": 36, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-26-24", "timestamp": 1624202784, "time_this_iter_s": 77.70229005813599, "time_total_s": 3993.345053434372, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5d87954d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5d87953b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5d87955f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3993.345053434372, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 54.88468468468469, "ram_util_percent": 88.0}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2250.5460655546103, "episode_reward_min": -1344.2278394611706, "episode_reward_mean": 870.7055937324466, "episode_len_mean": 205.76, "episodes_this_iter": 19, "policy_reward_min": {"AGENT-2": -351.2979369555082, "AGENT-1": -435.58596551368504, "AGENT-3": -460.4199811929214, "AGENT-0": -302.05468527316583}, "policy_reward_max": {"AGENT-2": 437.1227120776161, "AGENT-1": 1134.0039008810365, "AGENT-3": 562.9727376007519, "AGENT-0": 1165.6375212546811}, "policy_reward_mean": {"AGENT-2": 129.9734635951001, "AGENT-1": 292.93007282472877, "AGENT-3": 224.7887657080451, "AGENT-0": 223.0132916045727}, "custom_metrics": {"mean_ego_speed_mean": 40.673135, "mean_ego_speed_min": 22.82725, "mean_ego_speed_max": 50.945750000000004, "distance_travelled_mean": 111.8176375, "distance_travelled_min": 42.2575, "distance_travelled_max": 124.9665}, "hist_stats": {"episode_reward": [-111.70776053891785, 310.1810060255496, 78.52424532953776, 874.6107814711892, -490.96157714018057, 1367.7879456893713, -832.5496271602086, 1599.894114683631, 1262.3659272347675, 2142.9260131341534, 383.26332873790614, 1490.2066650515824, 777.3479264031606, 1711.7864182162414, 1203.3960316719335, 2093.449761493867, 1203.1529095100302, 723.2086926343183, 1166.685596539828, 1340.567643836793, 2250.5460655546103, 1373.0357851562846, 381.24271812244893, 1362.4932444032181, 1354.6151998321466, 1484.740410694457, 1520.9974966772277, 1332.0601577297255, 956.044702655239, 1662.9116991569608, 1264.6134596533846, 895.4617767068478, 630.7135625230596, 1590.7451657336317, 582.6683230228437, 640.1577463000386, 1358.5982873955593, -591.8356323607885, 879.3746374305607, -1344.2278394611706, 349.8394002353321, -582.7655852203833, 1493.358002576377, -516.9982548683231, 1437.3513905600505, 48.172107009042975, 1260.9776613687575, 1240.0713117719738, 1855.3073115043037, 1110.2935284656082, 2157.889023161966, 1972.585554518288, 1664.6740067151832, 839.1518804406751, 104.23719210776092, 1059.2670732647168, -882.8045229778851, 1042.076822971619, 1156.6325623154432, 82.99512846731142, 156.50182688314968, -438.7398695563979, 1645.8772293697195, -806.0505008883183, 1584.522375119293, -484.9204637824743, 1335.9268925792362, 1707.9352398447795, 1192.4447481190014, 1786.061080586346, 1367.8146733890137, 1041.0181803646421, 1315.1089103770792, -499.97169171910815, 1575.012110615677, 1729.4665149933974, 591.3711876774896, -996.4947730299778, 545.5848196887514, 639.4169769778458, 1488.7315695749842, -568.6146498193862, 1383.1121564414257, 1348.8605647160991, 1495.6976994371537, -624.9345336912236, 1326.8453275109518, 1502.5800935960594, 85.84493418787476, 1782.3469105757847, 670.7444409672789, 992.3279632453795, 681.1615799431531, 808.2768176089047, 1359.1663069769033, -149.19144825426244, 601.3502387825822, 825.447268749705, 1065.4902882445137, 1236.0257727029696], "episode_lengths": [252, 194, 253, 252, 80, 225, 110, 194, 169, 203, 221, 173, 203, 201, 163, 288, 211, 466, 294, 257, 450, 218, 182, 175, 153, 193, 127, 222, 208, 207, 186, 179, 224, 229, 197, 246, 231, 139, 194, 131, 208, 92, 231, 107, 195, 191, 136, 177, 203, 191, 219, 413, 222, 188, 196, 200, 162, 216, 222, 263, 196, 110, 212, 116, 239, 111, 159, 333, 203, 282, 160, 209, 183, 175, 207, 309, 242, 177, 127, 177, 227, 42, 235, 346, 229, 129, 232, 195, 210, 226, 216, 206, 211, 200, 222, 147, 172, 285, 184, 203], "policy_AGENT-2_reward": [74.84691288854916, 196.33056423874018, -138.74422811237466, -51.846543800523364, -139.60025669552843, 132.7832240507243, -185.71009551386658, 347.4351078154964, 212.79211857600947, 391.93942213783004, -113.2800010810883, 325.65606181120154, 11.160629645173314, 358.9941333638958, 206.2473778540357, 435.82945824203904, 305.10896764215266, 192.28052092624654, 292.1700681110821, 62.36205626944877, -24.53123459157811, 173.08124718806525, -28.365753316207712, 286.7960115207434, 295.65946320278897, 277.15337301916173, 345.42857201903456, 232.16989931534414, 81.76562668584388, 296.8753564042425, 201.59778064950177, 218.57725532684304, -12.544249632120962, 436.25597622184296, 130.08066452090776, -12.516388473633729, 116.37122429004424, -146.73252819153026, 245.9618009145406, -351.2979369555082, 171.03082333859172, -162.57283348735803, 185.4683862278538, -112.01901035474206, 272.98159990654335, -152.0426963202086, 308.3409265082923, 229.1396318913368, 351.7080864861587, 143.46037548316858, 91.64628860192286, -7.213895338342303, 437.1227120776161, -6.030425758333451, 124.11334737664376, 258.5993372981793, -41.26957010913251, 251.12086067643054, 75.53995530751344, -156.7741704799878, 178.2255618622088, -91.81261206763826, 306.50468521257545, -175.31500310471435, 276.6668399773702, -106.40593275043759, 280.4242298668029, 328.2296796330924, 46.2148676044838, 359.4510060122096, 284.83716138628404, 178.1161176973899, 247.25065990323264, -32.70230106756523, 416.58200990100113, 393.4003952655102, -6.47017495641955, -50.52524768004843, -9.011465059647156, 158.74063478286868, 234.10442067976993, -167.97208089381138, 94.2353695825972, -37.31775244947711, 203.79105880481487, -156.7699965317306, 112.93948235887613, 303.79647546087097, -244.68342687578178, 363.2572741235675, 35.77389173437398, 134.9071422160705, -59.75034605521513, 223.3822786015784, 350.0747048959797, 31.590274169366438, 145.41101789509457, -8.65486643970507, 210.64860166252268, 305.29033633197497], "policy_AGENT-1_reward": [-110.7057958808081, 196.77112483826056, 196.26446840361737, 629.6692666999982, -105.87750669503065, 636.0647385739353, -230.6192248354145, 416.71584836597424, 308.87117284462494, 637.1147619349592, 109.30809345833585, 383.29040564813454, 227.85643435609884, 426.86865308273843, 286.3037099067532, 718.1188772406492, 301.9464598664181, 229.62703687821198, 329.7893890280929, 624.7444103295, 1134.0039008810365, 643.2162512454347, 202.91592324531334, 401.8503630702277, 324.9285989691923, 401.1025903639227, 422.56532296075085, 361.6110119985924, 259.69249818938573, 479.8834705838484, 370.7790663051307, 239.16156296901835, 329.8404479128101, 447.9272101833249, 168.84523826765513, 339.8683866543031, 642.7430926302869, -131.93745682954454, 246.54592606513566, -331.19130431582954, 171.47073935586502, -128.80918017422727, 632.6712371797133, -111.6010009952104, 353.14801448819685, -83.11220307953825, 306.46143780225026, 256.2825235075066, 525.5443065781451, 293.5705955461842, 788.1240281256481, 999.9159210790783, 461.9396902199583, 431.8017053190938, -63.4380408783597, 272.17008559729516, -390.8748336083541, 247.10659617006618, 632.4328708096781, 215.7516479899938, 178.65941422242747, -139.25281775731904, 637.354008916521, -174.78258772435697, 646.3887646764608, -147.7867789259627, 322.3550749113606, 491.9968125762047, 46.89023055560408, 461.8853035512264, 336.37530593824295, 201.26262314627488, 289.81157098969334, -206.17532463556645, 424.9778763079775, 563.4685549139876, 312.5996423841341, -435.58596551368504, 245.8633545847412, 141.081431855394, 643.006501703348, -116.25175513358403, 634.4143743944311, 730.1251210856469, 642.9189969563746, -154.52748508558486, 641.8570134681902, 372.53283256362533, 54.09811920025227, 484.5738522012211, 103.89280699818923, 152.35674856510073, 239.70088006487, 190.05177732138048, 353.2791080019055, -89.39915902235307, 172.01506971500044, 445.252059511527, 303.40995435843774, 315.28340420350565], "policy_AGENT-3_reward": [-111.26521530248341, -17.01179742625346, -138.6873494881108, 382.86299935289935, -106.44376947558332, 430.52965448564555, -185.73180431961745, 440.99316127997326, 496.7209841080461, 490.5265786697624, 476.1233135518031, 411.9722894261837, 562.9727376007519, 513.3612253763905, 476.1501575653458, 228.44871915725813, 290.4170016576203, 108.43333585762649, 251.97885983680987, 62.31447739476376, -24.564121989528932, 428.8431499358146, -28.403229482991396, 386.5022926744612, 482.28116005811637, 421.2583693802387, 407.0348874861472, 407.8813392834104, 499.84424195052384, 419.4006232237338, 532.5806574105849, 218.57234376316123, -12.546813280065962, 269.54950542212885, 130.03680992927684, -12.463286209251226, 448.9690864435735, -146.8020032257173, 188.7137987669727, -359.683912916666, 7.227582088876352, -129.3726020288508, 460.1077537788124, -122.65367973516973, 469.7781467969428, 477.7049029299904, 367.5465426589245, 490.624900179294, 470.2103751420922, 495.31758977431315, 502.38778009042636, -7.211842238295251, 314.4417090525442, -6.078305779250424, -81.10923671304472, 269.31758485951184, -409.94399555423814, 292.1558145944859, 338.895560986884, -156.72163261915728, -103.12003266740962, -139.8190048833893, 362.8516017399, -203.56430015350594, 430.6523512745679, -148.35105594320308, 491.4728619011331, 461.80606086792454, 551.4614346751973, 480.50636573612695, 503.03588905549196, 475.55440565657796, 496.78129533061946, -228.9713661255771, 316.3198652082239, 232.06096320207504, -6.4827802240567, -460.4199811929214, -8.909683447698802, 165.9753176504356, 346.2942666523488, -168.1189167140204, 94.27071070655637, -37.366833236312345, 427.67923726558683, -157.42359389552047, 426.0265863392303, 466.86546996791475, 486.00154815908087, 476.86668779242814, 476.06188020061853, 499.2681033076163, 526.9389916102801, 170.88732712423558, 305.17219225646204, -1.9456023300645855, 137.95045015441195, -8.766780541908926, 269.49109200901563, 309.58814011819584], "policy_AGENT-0_reward": [35.41633775582442, -65.90888562519771, 159.69135452640526, -86.07494078118302, -139.0400442740381, 168.4103285790701, -230.48850249130965, 394.7499972221867, 243.98165170608848, 623.3452503916029, -88.88807719114429, 369.2879081660625, -24.641875198861776, 412.5624063932163, 234.6947863458008, 711.0527068539209, 305.6804803438401, 192.8677989722325, 292.7472795638439, 591.1466998430814, 1165.6375212546811, 127.89513678697028, 235.09577767633445, 287.34457713778585, 251.74597760204796, 385.2260779311341, 345.9687142112951, 330.3979071323773, 114.74233582948573, 466.75224894513786, 159.65595528816434, 219.15061464782514, 325.96417752243684, 437.01247390633444, 153.7056103050041, 325.2690343286208, 150.51488403165285, -166.36364411399686, 198.1531116839126, -302.05468527316583, 0.11025545199839576, -162.01096952994712, 215.11062538999278, -170.72456378320095, 341.44362936836797, -194.37789652119903, 278.62875439929036, 264.02425619383723, 507.8445432979067, 177.94496766194018, 775.7309263439699, 987.0953710158468, 451.16989536506424, 419.45890665916437, 124.67112232252168, 259.1800655097304, -40.71612370616031, 251.69355153063708, 109.76417521136928, 180.73928357646324, -97.26311653407684, -67.85543484805136, 339.16693350072296, -252.3886099057416, 230.81441919089457, -82.37669616287026, 241.674725899939, 425.9026867675576, 547.8782152837177, 484.2184052867819, 243.56631700899442, 186.0850338643994, 281.2653841535355, -32.12269989039974, 417.1323591984762, 540.5366016118251, 291.72450047383074, -49.96357864332269, 317.6426136113569, 173.61959268914737, 265.3263805395157, -116.27189707797046, 560.1917017578406, 693.420029316242, 221.30840641037702, -156.21345817838784, 146.02224534465498, 359.38531560364703, -209.57130629567416, 457.6490964585699, 55.01586203409724, 205.79596915659144, -25.72794567678142, 223.9554345617099, 350.64030182255635, -89.43696107121127, 145.97370101807513, 397.6168562197918, 281.94064021453926, 305.86389204929395]}, "sampler_perf": {"mean_env_wait_ms": 56.983165174839876, "mean_raw_obs_processing_ms": 2.2637399780270817, "mean_inference_ms": 2.5499776060975834, "mean_action_processing_ms": 0.15230622229729276}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 155400, "timers": {"sample_time_ms": 68039.266, "sample_throughput": 61.729, "load_time_ms": 13.289, "load_throughput": 316042.964, "learn_time_ms": 11184.803, "learn_throughput": 375.51, "update_time_ms": 7.39}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 119.65495300292969, "policy_loss": -0.035231512039899826, "vf_loss": 119.6850357055664, "vf_explained_var": 0.9838699102401733, "kl": 0.011443437077105045, "entropy": 0.7589410543441772, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 77.04106140136719, "policy_loss": -0.03242627531290054, "vf_loss": 77.06912231445312, "vf_explained_var": 0.9838262796401978, "kl": 0.014558193273842335, "entropy": 0.8096522688865662, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 173.9555206298828, "policy_loss": -0.03849732130765915, "vf_loss": 173.98934936523438, "vf_explained_var": 0.9791463017463684, "kl": 0.015565718524158001, "entropy": 0.9452252388000488, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 66.64684295654297, "policy_loss": -0.0351773276925087, "vf_loss": 66.67792510986328, "vf_explained_var": 0.9872039556503296, "kl": 0.00910152867436409, "entropy": 0.6344621777534485, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 155400, "num_steps_trained": 155400}, "done": false, "episodes_total": 1056, "training_iteration": 37, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-27-41", "timestamp": 1624202861, "time_this_iter_s": 76.91485834121704, "time_total_s": 4070.259911775589, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f0211ef0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f02119e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d876ad40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f023cf80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d876ad40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f023cf80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d876ad40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f023cf80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d876a9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d876ad40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f023cf80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5d8795b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4070.259911775589, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 51.870909090909095, "ram_util_percent": 88.06454545454548}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2494.2346690751633, "episode_reward_min": -1344.2278394611706, "episode_reward_mean": 812.153078051183, "episode_len_mean": 208.61, "episodes_this_iter": 18, "policy_reward_min": {"AGENT-2": -351.2979369555082, "AGENT-3": -460.4199811929214, "AGENT-0": -302.05468527316583, "AGENT-1": -435.58596551368504}, "policy_reward_max": {"AGENT-2": 490.93172247261185, "AGENT-3": 562.9727376007519, "AGENT-0": 987.0953710158468, "AGENT-1": 999.9159210790783}, "policy_reward_mean": {"AGENT-2": 123.03479506172798, "AGENT-3": 210.94188075141545, "AGENT-0": 206.7040623596886, "AGENT-1": 271.47233987835114}, "custom_metrics": {"mean_ego_speed_mean": 40.2683375, "mean_ego_speed_min": 22.82725, "mean_ego_speed_max": 50.135, "distance_travelled_mean": 110.925745, "distance_travelled_min": 33.6135, "distance_travelled_max": 124.9665}, "hist_stats": {"episode_reward": [1177.6754148478108, -631.7382487884213, 1426.5939170344434, 89.00901332132345, 1287.5886608347137, -291.3245520286551, 2061.606536075906, 389.50083100782047, 2494.2346690751633, 641.6390465604351, 1678.186920354093, 1064.6570921625216, 1583.982115652838, 677.2767338212208, 747.7630948604437, -345.15248291454475, 1183.9136472144805, 891.5494679365321, -591.8356323607885, 879.3746374305607, -1344.2278394611706, 349.8394002353321, -582.7655852203833, 1493.358002576377, -516.9982548683231, 1437.3513905600505, 48.172107009042975, 1260.9776613687575, 1240.0713117719738, 1855.3073115043037, 1110.2935284656082, 2157.889023161966, 1972.585554518288, 1664.6740067151832, 839.1518804406751, 104.23719210776092, 1059.2670732647168, -882.8045229778851, 1042.076822971619, 1156.6325623154432, 82.99512846731142, 156.50182688314968, -438.7398695563979, 1645.8772293697195, -806.0505008883183, 1584.522375119293, -484.9204637824743, 1335.9268925792362, 1707.9352398447795, 1192.4447481190014, 1786.061080586346, 1367.8146733890137, 1041.0181803646421, 1315.1089103770792, -499.97169171910815, 1575.012110615677, 1729.4665149933974, 591.3711876774896, -996.4947730299778, 545.5848196887514, 639.4169769778458, 1488.7315695749842, -568.6146498193862, 1383.1121564414257, 1348.8605647160991, 1495.6976994371537, -624.9345336912236, 1326.8453275109518, 1502.5800935960594, 85.84493418787476, 1782.3469105757847, 670.7444409672789, 992.3279632453795, 681.1615799431531, 808.2768176089047, 1359.1663069769033, -149.19144825426244, 601.3502387825822, 825.447268749705, 1065.4902882445137, 1236.0257727029696, -111.70776053891785, 310.1810060255496, 78.52424532953776, 874.6107814711892, -490.96157714018057, 1367.7879456893713, -832.5496271602086, 1599.894114683631, 1262.3659272347675, 2142.9260131341534, 383.26332873790614, 1490.2066650515824, 777.3479264031606, 1711.7864182162414, 1203.3960316719335, 2093.449761493867, 1203.1529095100302, 723.2086926343183, 1166.685596539828], "episode_lengths": [251, 109, 223, 346, 239, 86, 184, 198, 417, 218, 270, 434, 243, 201, 227, 29, 382, 112, 139, 194, 131, 208, 92, 231, 107, 195, 191, 136, 177, 203, 191, 219, 413, 222, 188, 196, 200, 162, 216, 222, 263, 196, 110, 212, 116, 239, 111, 159, 333, 203, 282, 160, 209, 183, 175, 207, 309, 242, 177, 127, 177, 227, 42, 235, 346, 229, 129, 232, 195, 210, 226, 216, 206, 211, 200, 222, 147, 172, 285, 184, 203, 252, 194, 253, 252, 80, 225, 110, 194, 169, 203, 221, 173, 203, 201, 163, 288, 211, 466, 294], "policy_AGENT-2_reward": [0.9127143804819284, -131.07518912629408, 147.81753018749902, 152.01372088432342, 171.2359985932924, -77.86218855784969, 397.7312880197204, -63.37090312006321, 490.93172247261185, 52.42033205149004, 326.10011197711304, 243.0775219815615, 322.35692285951757, 194.36713059125591, -9.983966924213602, -111.39895873824494, 281.46337528209824, -4.38713553123991, -146.73252819153026, 245.9618009145406, -351.2979369555082, 171.03082333859172, -162.57283348735803, 185.4683862278538, -112.01901035474206, 272.98159990654335, -152.0426963202086, 308.3409265082923, 229.1396318913368, 351.7080864861587, 143.46037548316858, 91.64628860192286, -7.213895338342303, 437.1227120776161, -6.030425758333451, 124.11334737664376, 258.5993372981793, -41.26957010913251, 251.12086067643054, 75.53995530751344, -156.7741704799878, 178.2255618622088, -91.81261206763826, 306.50468521257545, -175.31500310471435, 276.6668399773702, -106.40593275043759, 280.4242298668029, 328.2296796330924, 46.2148676044838, 359.4510060122096, 284.83716138628404, 178.1161176973899, 247.25065990323264, -32.70230106756523, 416.58200990100113, 393.4003952655102, -6.47017495641955, -50.52524768004843, -9.011465059647156, 158.74063478286868, 234.10442067976993, -167.97208089381138, 94.2353695825972, -37.31775244947711, 203.79105880481487, -156.7699965317306, 112.93948235887613, 303.79647546087097, -244.68342687578178, 363.2572741235675, 35.77389173437398, 134.9071422160705, -59.75034605521513, 223.3822786015784, 350.0747048959797, 31.590274169366438, 145.41101789509457, -8.65486643970507, 210.64860166252268, 305.29033633197497, 74.84691288854916, 196.33056423874018, -138.74422811237466, -51.846543800523364, -139.60025669552843, 132.7832240507243, -185.71009551386658, 347.4351078154964, 212.79211857600947, 391.93942213783004, -113.2800010810883, 325.65606181120154, 11.160629645173314, 358.9941333638958, 206.2473778540357, 435.82945824203904, 305.10896764215266, 192.28052092624654, 292.1700681110821], "policy_AGENT-3_reward": [0.9712765938628594, -161.66732492421858, 455.86081202790103, -121.9773609068873, 349.28514393961814, -68.36581983891938, 481.74838740346297, 468.1582716184662, 500.2888100595531, 469.1409732809422, 463.18200654678907, 244.26780294967577, 295.55263863981054, 133.29596468077312, -10.155929615933992, -111.43466821697876, 268.5402105052898, -4.288197012078665, -146.8020032257173, 188.7137987669727, -359.683912916666, 7.227582088876352, -129.3726020288508, 460.1077537788124, -122.65367973516973, 469.7781467969428, 477.7049029299904, 367.5465426589245, 490.624900179294, 470.2103751420922, 495.31758977431315, 502.38778009042636, -7.211842238295251, 314.4417090525442, -6.078305779250424, -81.10923671304472, 269.31758485951184, -409.94399555423814, 292.1558145944859, 338.895560986884, -156.72163261915728, -103.12003266740962, -139.8190048833893, 362.8516017399, -203.56430015350594, 430.6523512745679, -148.35105594320308, 491.4728619011331, 461.80606086792454, 551.4614346751973, 480.50636573612695, 503.03588905549196, 475.55440565657796, 496.78129533061946, -228.9713661255771, 316.3198652082239, 232.06096320207504, -6.4827802240567, -460.4199811929214, -8.909683447698802, 165.9753176504356, 346.2942666523488, -168.1189167140204, 94.27071070655637, -37.366833236312345, 427.67923726558683, -157.42359389552047, 426.0265863392303, 466.86546996791475, 486.00154815908087, 476.86668779242814, 476.06188020061853, 499.2681033076163, 526.9389916102801, 170.88732712423558, 305.17219225646204, -1.9456023300645855, 137.95045015441195, -8.766780541908926, 269.49109200901563, 309.58814011819584, -111.26521530248341, -17.01179742625346, -138.6873494881108, 382.86299935289935, -106.44376947558332, 430.52965448564555, -185.73180431961745, 440.99316127997326, 496.7209841080461, 490.5265786697624, 476.1233135518031, 411.9722894261837, 562.9727376007519, 513.3612253763905, 476.1501575653458, 228.44871915725813, 290.4170016576203, 108.43333585762649, 251.97885983680987], "policy_AGENT-0_reward": [544.7403883558361, -208.39873471436965, 183.33787597370312, 180.3841393421105, 132.24443137593488, -77.29331192271931, 576.0704658632139, -98.20296758258709, 707.3994264447967, 66.98094170054021, 422.38242915651875, 243.66004582069655, 487.31602041518795, 194.93546244631182, 384.056671810118, -61.090868502862634, 282.0382463682835, 481.74213754125685, -166.36364411399686, 198.1531116839126, -302.05468527316583, 0.11025545199839576, -162.01096952994712, 215.11062538999278, -170.72456378320095, 341.44362936836797, -194.37789652119903, 278.62875439929036, 264.02425619383723, 507.8445432979067, 177.94496766194018, 775.7309263439699, 987.0953710158468, 451.16989536506424, 419.45890665916437, 124.67112232252168, 259.1800655097304, -40.71612370616031, 251.69355153063708, 109.76417521136928, 180.73928357646324, -97.26311653407684, -67.85543484805136, 339.16693350072296, -252.3886099057416, 230.81441919089457, -82.37669616287026, 241.674725899939, 425.9026867675576, 547.8782152837177, 484.2184052867819, 243.56631700899442, 186.0850338643994, 281.2653841535355, -32.12269989039974, 417.1323591984762, 540.5366016118251, 291.72450047383074, -49.96357864332269, 317.6426136113569, 173.61959268914737, 265.3263805395157, -116.27189707797046, 560.1917017578406, 693.420029316242, 221.30840641037702, -156.21345817838784, 146.02224534465498, 359.38531560364703, -209.57130629567416, 457.6490964585699, 55.01586203409724, 205.79596915659144, -25.72794567678142, 223.9554345617099, 350.64030182255635, -89.43696107121127, 145.97370101807513, 397.6168562197918, 281.94064021453926, 305.86389204929395, 35.41633775582442, -65.90888562519771, 159.69135452640526, -86.07494078118302, -139.0400442740381, 168.4103285790701, -230.48850249130965, 394.7499972221867, 243.98165170608848, 623.3452503916029, -88.88807719114429, 369.2879081660625, -24.641875198861776, 412.5624063932163, 234.6947863458008, 711.0527068539209, 305.6804803438401, 192.8677989722325, 292.7472795638439], "policy_AGENT-1_reward": [631.051035517629, -130.59700002353918, 639.5776988453405, -121.41148599822318, 634.8230869258723, -67.80323170916665, 606.0563947895087, 82.91643009200496, 795.6147100981988, 53.09679952746287, 466.52237267367326, 333.6517214105876, 478.7565337383253, 154.67817610288049, 383.8463195904736, -61.227987456458365, 351.8718150588087, 418.4826629385938, -131.93745682954454, 246.54592606513566, -331.19130431582954, 171.47073935586502, -128.80918017422727, 632.6712371797133, -111.6010009952104, 353.14801448819685, -83.11220307953825, 306.46143780225026, 256.2825235075066, 525.5443065781451, 293.5705955461842, 788.1240281256481, 999.9159210790783, 461.9396902199583, 431.8017053190938, -63.4380408783597, 272.17008559729516, -390.8748336083541, 247.10659617006618, 632.4328708096781, 215.7516479899938, 178.65941422242747, -139.25281775731904, 637.354008916521, -174.78258772435697, 646.3887646764608, -147.7867789259627, 322.3550749113606, 491.9968125762047, 46.89023055560408, 461.8853035512264, 336.37530593824295, 201.26262314627488, 289.81157098969334, -206.17532463556645, 424.9778763079775, 563.4685549139876, 312.5996423841341, -435.58596551368504, 245.8633545847412, 141.081431855394, 643.006501703348, -116.25175513358403, 634.4143743944311, 730.1251210856469, 642.9189969563746, -154.52748508558486, 641.8570134681902, 372.53283256362533, 54.09811920025227, 484.5738522012211, 103.89280699818923, 152.35674856510073, 239.70088006487, 190.05177732138048, 353.2791080019055, -89.39915902235307, 172.01506971500044, 445.252059511527, 303.40995435843774, 315.28340420350565, -110.7057958808081, 196.77112483826056, 196.26446840361737, 629.6692666999982, -105.87750669503065, 636.0647385739353, -230.6192248354145, 416.71584836597424, 308.87117284462494, 637.1147619349592, 109.30809345833585, 383.29040564813454, 227.85643435609884, 426.86865308273843, 286.3037099067532, 718.1188772406492, 301.9464598664181, 229.62703687821198, 329.7893890280929]}, "sampler_perf": {"mean_env_wait_ms": 56.4691183936322, "mean_raw_obs_processing_ms": 2.2421929475026077, "mean_inference_ms": 2.5315432365309163, "mean_action_processing_ms": 0.1514009206806886}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 159600, "timers": {"sample_time_ms": 68337.443, "sample_throughput": 61.46, "load_time_ms": 13.732, "load_throughput": 305857.5, "learn_time_ms": 11198.029, "learn_throughput": 375.066, "update_time_ms": 7.663}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 112.073486328125, "policy_loss": -0.031273920089006424, "vf_loss": 112.098876953125, "vf_explained_var": 0.9850125312805176, "kl": 0.013067537918686867, "entropy": 0.7733163833618164, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 73.65597534179688, "policy_loss": -0.032711729407310486, "vf_loss": 73.68433380126953, "vf_explained_var": 0.9869948625564575, "kl": 0.01453483011573553, "entropy": 0.734666109085083, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 173.38726806640625, "policy_loss": -0.039929404854774475, "vf_loss": 173.42263793945312, "vf_explained_var": 0.9831129312515259, "kl": 0.01528981700539589, "entropy": 0.9050732254981995, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 35.51244354248047, "policy_loss": -0.04310457035899162, "vf_loss": 35.549476623535156, "vf_explained_var": 0.9918026924133301, "kl": 0.013495607301592827, "entropy": 0.6678014397621155, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 159600, "num_steps_trained": 159600}, "done": false, "episodes_total": 1074, "training_iteration": 38, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-29-06", "timestamp": 1624202946, "time_this_iter_s": 84.2155601978302, "time_total_s": 4154.475471973419, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5d87014d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5d87013b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5d87015f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4154.475471973419, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 51.79833333333333, "ram_util_percent": 88.09416666666665}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2494.2346690751633, "episode_reward_min": -996.4947730299778, "episode_reward_mean": 895.05746991549, "episode_len_mean": 220.58, "episodes_this_iter": 15, "policy_reward_min": {"AGENT-2": -244.68342687578178, "AGENT-3": -460.4199811929214, "AGENT-0": -252.3886099057416, "AGENT-1": -435.58596551368504}, "policy_reward_max": {"AGENT-2": 559.4493152624741, "AGENT-3": 562.9727376007519, "AGENT-0": 732.8728789282811, "AGENT-1": 795.6147100981988}, "policy_reward_mean": {"AGENT-2": 144.0694323858276, "AGENT-3": 225.8897200455367, "AGENT-0": 225.91709270327843, "AGENT-1": 299.1812247808476}, "custom_metrics": {"mean_ego_speed_mean": 39.62479750000001, "mean_ego_speed_min": 22.82725, "mean_ego_speed_max": 49.0965, "distance_travelled_mean": 109.94212750000001, "distance_travelled_min": 33.6135, "distance_travelled_max": 124.9665}, "hist_stats": {"episode_reward": [1569.0903225305271, 1440.544920738279, 974.0035832303669, 319.21057259590157, 2180.665858808847, 1316.8597875342427, 1632.9527881200336, 811.4900950937185, 1617.5401216737032, 1447.4465051914601, 1561.8546660842785, 559.402434236241, 1562.1350065417664, 922.684254884785, 1143.9508858581455, 1664.6740067151832, 839.1518804406751, 104.23719210776092, 1059.2670732647168, -882.8045229778851, 1042.076822971619, 1156.6325623154432, 82.99512846731142, 156.50182688314968, -438.7398695563979, 1645.8772293697195, -806.0505008883183, 1584.522375119293, -484.9204637824743, 1335.9268925792362, 1707.9352398447795, 1192.4447481190014, 1786.061080586346, 1367.8146733890137, 1041.0181803646421, 1315.1089103770792, -499.97169171910815, 1575.012110615677, 1729.4665149933974, 591.3711876774896, -996.4947730299778, 545.5848196887514, 639.4169769778458, 1488.7315695749842, -568.6146498193862, 1383.1121564414257, 1348.8605647160991, 1495.6976994371537, -624.9345336912236, 1326.8453275109518, 1502.5800935960594, 85.84493418787476, 1782.3469105757847, 670.7444409672789, 992.3279632453795, 681.1615799431531, 808.2768176089047, 1359.1663069769033, -149.19144825426244, 601.3502387825822, 825.447268749705, 1065.4902882445137, 1236.0257727029696, -111.70776053891785, 310.1810060255496, 78.52424532953776, 874.6107814711892, -490.96157714018057, 1367.7879456893713, -832.5496271602086, 1599.894114683631, 1262.3659272347675, 2142.9260131341534, 383.26332873790614, 1490.2066650515824, 777.3479264031606, 1711.7864182162414, 1203.3960316719335, 2093.449761493867, 1203.1529095100302, 723.2086926343183, 1166.685596539828, 1177.6754148478108, -631.7382487884213, 1426.5939170344434, 89.00901332132345, 1287.5886608347137, -291.3245520286551, 2061.606536075906, 389.50083100782047, 2494.2346690751633, 641.6390465604351, 1678.186920354093, 1064.6570921625216, 1583.982115652838, 677.2767338212208, 747.7630948604437, -345.15248291454475, 1183.9136472144805, 891.5494679365321], "episode_lengths": [232, 338, 244, 122, 367, 142, 398, 237, 191, 162, 342, 443, 165, 207, 434, 222, 188, 196, 200, 162, 216, 222, 263, 196, 110, 212, 116, 239, 111, 159, 333, 203, 282, 160, 209, 183, 175, 207, 309, 242, 177, 127, 177, 227, 42, 235, 346, 229, 129, 232, 195, 210, 226, 216, 206, 211, 200, 222, 147, 172, 285, 184, 203, 252, 194, 253, 252, 80, 225, 110, 194, 169, 203, 221, 173, 203, 201, 163, 288, 211, 466, 294, 251, 109, 223, 346, 239, 86, 184, 198, 417, 218, 270, 434, 243, 201, 227, 29, 382, 112], "policy_AGENT-2_reward": [251.12804672331563, -31.26548187667252, 25.268884894588233, 278.20786933111776, 559.4493152624741, 249.41908965829506, 308.5413071157518, 10.709389106137667, 318.7242311369195, 331.07010877935045, 321.91368155496855, 182.59541173121946, 382.3860547934712, -6.623842255449915, -10.20131483480409, 437.1227120776161, -6.030425758333451, 124.11334737664376, 258.5993372981793, -41.26957010913251, 251.12086067643054, 75.53995530751344, -156.7741704799878, 178.2255618622088, -91.81261206763826, 306.50468521257545, -175.31500310471435, 276.6668399773702, -106.40593275043759, 280.4242298668029, 328.2296796330924, 46.2148676044838, 359.4510060122096, 284.83716138628404, 178.1161176973899, 247.25065990323264, -32.70230106756523, 416.58200990100113, 393.4003952655102, -6.47017495641955, -50.52524768004843, -9.011465059647156, 158.74063478286868, 234.10442067976993, -167.97208089381138, 94.2353695825972, -37.31775244947711, 203.79105880481487, -156.7699965317306, 112.93948235887613, 303.79647546087097, -244.68342687578178, 363.2572741235675, 35.77389173437398, 134.9071422160705, -59.75034605521513, 223.3822786015784, 350.0747048959797, 31.590274169366438, 145.41101789509457, -8.65486643970507, 210.64860166252268, 305.29033633197497, 74.84691288854916, 196.33056423874018, -138.74422811237466, -51.846543800523364, -139.60025669552843, 132.7832240507243, -185.71009551386658, 347.4351078154964, 212.79211857600947, 391.93942213783004, -113.2800010810883, 325.65606181120154, 11.160629645173314, 358.9941333638958, 206.2473778540357, 435.82945824203904, 305.10896764215266, 192.28052092624654, 292.1700681110821, 0.9127143804819284, -131.07518912629408, 147.81753018749902, 152.01372088432342, 171.2359985932924, -77.86218855784969, 397.7312880197204, -63.37090312006321, 490.93172247261185, 52.42033205149004, 326.10011197711304, 243.0775219815615, 322.35692285951757, 194.36713059125591, -9.983966924213602, -111.39895873824494, 281.46337528209824, -4.38713553123991], "policy_AGENT-3_reward": [401.51908410740657, -31.32742191326361, 320.9490214271709, -84.43621078044794, 443.62060945117406, 494.30497783841605, 473.25534682565103, 537.1976694604042, 500.6808622789061, 494.05781769729464, 510.2061415456869, 36.54787503929298, 252.34502594402122, -6.653966696278565, 316.41242924864065, 314.4417090525442, -6.078305779250424, -81.10923671304472, 269.31758485951184, -409.94399555423814, 292.1558145944859, 338.895560986884, -156.72163261915728, -103.12003266740962, -139.8190048833893, 362.8516017399, -203.56430015350594, 430.6523512745679, -148.35105594320308, 491.4728619011331, 461.80606086792454, 551.4614346751973, 480.50636573612695, 503.03588905549196, 475.55440565657796, 496.78129533061946, -228.9713661255771, 316.3198652082239, 232.06096320207504, -6.4827802240567, -460.4199811929214, -8.909683447698802, 165.9753176504356, 346.2942666523488, -168.1189167140204, 94.27071070655637, -37.366833236312345, 427.67923726558683, -157.42359389552047, 426.0265863392303, 466.86546996791475, 486.00154815908087, 476.86668779242814, 476.06188020061853, 499.2681033076163, 526.9389916102801, 170.88732712423558, 305.17219225646204, -1.9456023300645855, 137.95045015441195, -8.766780541908926, 269.49109200901563, 309.58814011819584, -111.26521530248341, -17.01179742625346, -138.6873494881108, 382.86299935289935, -106.44376947558332, 430.52965448564555, -185.73180431961745, 440.99316127997326, 496.7209841080461, 490.5265786697624, 476.1233135518031, 411.9722894261837, 562.9727376007519, 513.3612253763905, 476.1501575653458, 228.44871915725813, 290.4170016576203, 108.43333585762649, 251.97885983680987, 0.9712765938628594, -161.66732492421858, 455.86081202790103, -121.9773609068873, 349.28514393961814, -68.36581983891938, 481.74838740346297, 468.1582716184662, 500.2888100595531, 469.1409732809422, 463.18200654678907, 244.26780294967577, 295.55263863981054, 133.29596468077312, -10.155929615933992, -111.43466821697876, 268.5402105052898, -4.288197012078665], "policy_AGENT-0_reward": [278.1768756185994, 732.8728789282811, -8.70569265405608, -83.72659607988948, 560.2056910149412, 249.97139037395448, 382.999632150755, 29.08164519008018, 388.29245904648906, 328.4514383433522, 322.4740707351018, 183.15010640619735, 481.7903867810008, 461.9203437006771, 364.9030863890442, 451.16989536506424, 419.45890665916437, 124.67112232252168, 259.1800655097304, -40.71612370616031, 251.69355153063708, 109.76417521136928, 180.73928357646324, -97.26311653407684, -67.85543484805136, 339.16693350072296, -252.3886099057416, 230.81441919089457, -82.37669616287026, 241.674725899939, 425.9026867675576, 547.8782152837177, 484.2184052867819, 243.56631700899442, 186.0850338643994, 281.2653841535355, -32.12269989039974, 417.1323591984762, 540.5366016118251, 291.72450047383074, -49.96357864332269, 317.6426136113569, 173.61959268914737, 265.3263805395157, -116.27189707797046, 560.1917017578406, 693.420029316242, 221.30840641037702, -156.21345817838784, 146.02224534465498, 359.38531560364703, -209.57130629567416, 457.6490964585699, 55.01586203409724, 205.79596915659144, -25.72794567678142, 223.9554345617099, 350.64030182255635, -89.43696107121127, 145.97370101807513, 397.6168562197918, 281.94064021453926, 305.86389204929395, 35.41633775582442, -65.90888562519771, 159.69135452640526, -86.07494078118302, -139.0400442740381, 168.4103285790701, -230.48850249130965, 394.7499972221867, 243.98165170608848, 623.3452503916029, -88.88807719114429, 369.2879081660625, -24.641875198861776, 412.5624063932163, 234.6947863458008, 711.0527068539209, 305.6804803438401, 192.8677989722325, 292.7472795638439, 544.7403883558361, -208.39873471436965, 183.33787597370312, 180.3841393421105, 132.24443137593488, -77.29331192271931, 576.0704658632139, -98.20296758258709, 707.3994264447967, 66.98094170054021, 422.38242915651875, 243.66004582069655, 487.31602041518795, 194.93546244631182, 384.056671810118, -61.090868502862634, 282.0382463682835, 481.74213754125685], "policy_AGENT-1_reward": [638.2663160812062, 770.2649455999352, 636.4913695626626, 209.16551012512105, 617.3902430802568, 323.1643296635771, 468.15650202787754, 234.50139133709726, 409.8425692113892, 293.86714037146356, 407.26077224852236, 157.10904105953077, 445.6135390232733, 474.04172013583667, 472.83668505526515, 461.9396902199583, 431.8017053190938, -63.4380408783597, 272.17008559729516, -390.8748336083541, 247.10659617006618, 632.4328708096781, 215.7516479899938, 178.65941422242747, -139.25281775731904, 637.354008916521, -174.78258772435697, 646.3887646764608, -147.7867789259627, 322.3550749113606, 491.9968125762047, 46.89023055560408, 461.8853035512264, 336.37530593824295, 201.26262314627488, 289.81157098969334, -206.17532463556645, 424.9778763079775, 563.4685549139876, 312.5996423841341, -435.58596551368504, 245.8633545847412, 141.081431855394, 643.006501703348, -116.25175513358403, 634.4143743944311, 730.1251210856469, 642.9189969563746, -154.52748508558486, 641.8570134681902, 372.53283256362533, 54.09811920025227, 484.5738522012211, 103.89280699818923, 152.35674856510073, 239.70088006487, 190.05177732138048, 353.2791080019055, -89.39915902235307, 172.01506971500044, 445.252059511527, 303.40995435843774, 315.28340420350565, -110.7057958808081, 196.77112483826056, 196.26446840361737, 629.6692666999982, -105.87750669503065, 636.0647385739353, -230.6192248354145, 416.71584836597424, 308.87117284462494, 637.1147619349592, 109.30809345833585, 383.29040564813454, 227.85643435609884, 426.86865308273843, 286.3037099067532, 718.1188772406492, 301.9464598664181, 229.62703687821198, 329.7893890280929, 631.051035517629, -130.59700002353918, 639.5776988453405, -121.41148599822318, 634.8230869258723, -67.80323170916665, 606.0563947895087, 82.91643009200496, 795.6147100981988, 53.09679952746287, 466.52237267367326, 333.6517214105876, 478.7565337383253, 154.67817610288049, 383.8463195904736, -61.227987456458365, 351.8718150588087, 418.4826629385938]}, "sampler_perf": {"mean_env_wait_ms": 56.16759248100158, "mean_raw_obs_processing_ms": 2.2282765980897805, "mean_inference_ms": 2.5185049087954634, "mean_action_processing_ms": 0.15076278541996538}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 163800, "timers": {"sample_time_ms": 69341.336, "sample_throughput": 60.57, "load_time_ms": 13.815, "load_throughput": 304013.226, "learn_time_ms": 11421.82, "learn_throughput": 367.717, "update_time_ms": 8.859}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 98.18000030517578, "policy_loss": -0.037170637398958206, "vf_loss": 98.21131134033203, "vf_explained_var": 0.9825292229652405, "kl": 0.0130071509629488, "entropy": 0.7469357848167419, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 59.9156608581543, "policy_loss": -0.03164677321910858, "vf_loss": 59.94280242919922, "vf_explained_var": 0.9854892492294312, "kl": 0.015029467642307281, "entropy": 0.7263960242271423, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 123.62866973876953, "policy_loss": -0.03911709785461426, "vf_loss": 123.66289520263672, "vf_explained_var": 0.9860066771507263, "kl": 0.01638319343328476, "entropy": 0.8681821823120117, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 67.4135513305664, "policy_loss": -0.041078560054302216, "vf_loss": 67.45083618164062, "vf_explained_var": 0.985760509967804, "kl": 0.008444218896329403, "entropy": 0.5595582127571106, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 163800, "num_steps_trained": 163800}, "done": false, "episodes_total": 1089, "training_iteration": 39, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-30-35", "timestamp": 1624203035, "time_this_iter_s": 89.37088108062744, "time_total_s": 4243.846353054047, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f0038ef0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f0038d40>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0b90>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f031ab90>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9560>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0b90>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f031ab90>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9560>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0b90>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f031ab90>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9560>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0b90>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f031ab90>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f03d9560>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5d8701b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4243.846353054047, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 50.318604651162794, "ram_util_percent": 88.07364341085271}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2494.2346690751633, "episode_reward_min": -996.4947730299778, "episode_reward_mean": 953.5730248681259, "episode_len_mean": 235.55, "episodes_this_iter": 14, "policy_reward_min": {"AGENT-2": -244.68342687578178, "AGENT-1": -435.58596551368504, "AGENT-3": -460.4199811929214, "AGENT-0": -265.3359570856054}, "policy_reward_max": {"AGENT-2": 559.4493152624741, "AGENT-1": 944.2545051911186, "AGENT-3": 562.9727376007519, "AGENT-0": 906.8655687599723}, "policy_reward_mean": {"AGENT-2": 152.12450399138706, "AGENT-1": 315.9401578940518, "AGENT-3": 246.83542617161984, "AGENT-0": 238.67293681106753}, "custom_metrics": {"mean_ego_speed_mean": 39.14237, "mean_ego_speed_min": 22.82725, "mean_ego_speed_max": 49.0965, "distance_travelled_mean": 110.63729000000001, "distance_travelled_min": 33.6135, "distance_travelled_max": 125.04475}, "hist_stats": {"episode_reward": [396.17384187192977, 1416.8763535989488, -909.2054859334858, 1764.5280515335535, 1660.34772648424, 246.1589383520181, -651.1990901258645, 1315.4784634353332, 1089.0549548768042, 1911.3768406991155, 808.6774515984084, 903.6376807869202, 1910.3354196702214, 712.7350888652556, 1335.9268925792362, 1707.9352398447795, 1192.4447481190014, 1786.061080586346, 1367.8146733890137, 1041.0181803646421, 1315.1089103770792, -499.97169171910815, 1575.012110615677, 1729.4665149933974, 591.3711876774896, -996.4947730299778, 545.5848196887514, 639.4169769778458, 1488.7315695749842, -568.6146498193862, 1383.1121564414257, 1348.8605647160991, 1495.6976994371537, -624.9345336912236, 1326.8453275109518, 1502.5800935960594, 85.84493418787476, 1782.3469105757847, 670.7444409672789, 992.3279632453795, 681.1615799431531, 808.2768176089047, 1359.1663069769033, -149.19144825426244, 601.3502387825822, 825.447268749705, 1065.4902882445137, 1236.0257727029696, -111.70776053891785, 310.1810060255496, 78.52424532953776, 874.6107814711892, -490.96157714018057, 1367.7879456893713, -832.5496271602086, 1599.894114683631, 1262.3659272347675, 2142.9260131341534, 383.26332873790614, 1490.2066650515824, 777.3479264031606, 1711.7864182162414, 1203.3960316719335, 2093.449761493867, 1203.1529095100302, 723.2086926343183, 1166.685596539828, 1177.6754148478108, -631.7382487884213, 1426.5939170344434, 89.00901332132345, 1287.5886608347137, -291.3245520286551, 2061.606536075906, 389.50083100782047, 2494.2346690751633, 641.6390465604351, 1678.186920354093, 1064.6570921625216, 1583.982115652838, 677.2767338212208, 747.7630948604437, -345.15248291454475, 1183.9136472144805, 891.5494679365321, 1569.0903225305271, 1440.544920738279, 974.0035832303669, 319.21057259590157, 2180.665858808847, 1316.8597875342427, 1632.9527881200336, 811.4900950937185, 1617.5401216737032, 1447.4465051914601, 1561.8546660842785, 559.402434236241, 1562.1350065417664, 922.684254884785, 1143.9508858581455], "episode_lengths": [344, 265, 139, 228, 404, 193, 89, 483, 188, 436, 204, 244, 485, 448, 159, 333, 203, 282, 160, 209, 183, 175, 207, 309, 242, 177, 127, 177, 227, 42, 235, 346, 229, 129, 232, 195, 210, 226, 216, 206, 211, 200, 222, 147, 172, 285, 184, 203, 252, 194, 253, 252, 80, 225, 110, 194, 169, 203, 221, 173, 203, 201, 163, 288, 211, 466, 294, 251, 109, 223, 346, 239, 86, 184, 198, 417, 218, 270, 434, 243, 201, 227, 29, 382, 112, 232, 338, 244, 122, 367, 142, 398, 237, 191, 162, 342, 443, 165, 207, 434], "policy_AGENT-2_reward": [275.0217018006737, 221.12125570871575, -228.24979539704216, 368.1528468446571, -95.4150368587922, 161.23020311756625, -132.69692403044226, 201.59910999715254, 120.29092338731421, 383.8660666922927, -4.733123919683792, 222.82241058069155, 454.9875056211348, 187.79560252999846, 280.4242298668029, 328.2296796330924, 46.2148676044838, 359.4510060122096, 284.83716138628404, 178.1161176973899, 247.25065990323264, -32.70230106756523, 416.58200990100113, 393.4003952655102, -6.47017495641955, -50.52524768004843, -9.011465059647156, 158.74063478286868, 234.10442067976993, -167.97208089381138, 94.2353695825972, -37.31775244947711, 203.79105880481487, -156.7699965317306, 112.93948235887613, 303.79647546087097, -244.68342687578178, 363.2572741235675, 35.77389173437398, 134.9071422160705, -59.75034605521513, 223.3822786015784, 350.0747048959797, 31.590274169366438, 145.41101789509457, -8.65486643970507, 210.64860166252268, 305.29033633197497, 74.84691288854916, 196.33056423874018, -138.74422811237466, -51.846543800523364, -139.60025669552843, 132.7832240507243, -185.71009551386658, 347.4351078154964, 212.79211857600947, 391.93942213783004, -113.2800010810883, 325.65606181120154, 11.160629645173314, 358.9941333638958, 206.2473778540357, 435.82945824203904, 305.10896764215266, 192.28052092624654, 292.1700681110821, 0.9127143804819284, -131.07518912629408, 147.81753018749902, 152.01372088432342, 171.2359985932924, -77.86218855784969, 397.7312880197204, -63.37090312006321, 490.93172247261185, 52.42033205149004, 326.10011197711304, 243.0775219815615, 322.35692285951757, 194.36713059125591, -9.983966924213602, -111.39895873824494, 281.46337528209824, -4.38713553123991, 251.12804672331563, -31.26548187667252, 25.268884894588233, 278.20786933111776, 559.4493152624741, 249.41908965829506, 308.5413071157518, 10.709389106137667, 318.7242311369195, 331.07010877935045, 321.91368155496855, 182.59541173121946, 382.3860547934712, -6.623842255449915, -10.20131483480409], "policy_AGENT-1_reward": [-92.13797508615968, 644.7645706183526, -207.5279881780818, 637.0947668549559, 944.2545051911186, 161.67116514569634, -132.2622776637779, 370.9042425549343, 284.38278418549385, 579.829887978007, 236.48371673362865, 243.26947460024093, 581.0318453850253, 231.60431802813488, 322.3550749113606, 491.9968125762047, 46.89023055560408, 461.8853035512264, 336.37530593824295, 201.26262314627488, 289.81157098969334, -206.17532463556645, 424.9778763079775, 563.4685549139876, 312.5996423841341, -435.58596551368504, 245.8633545847412, 141.081431855394, 643.006501703348, -116.25175513358403, 634.4143743944311, 730.1251210856469, 642.9189969563746, -154.52748508558486, 641.8570134681902, 372.53283256362533, 54.09811920025227, 484.5738522012211, 103.89280699818923, 152.35674856510073, 239.70088006487, 190.05177732138048, 353.2791080019055, -89.39915902235307, 172.01506971500044, 445.252059511527, 303.40995435843774, 315.28340420350565, -110.7057958808081, 196.77112483826056, 196.26446840361737, 629.6692666999982, -105.87750669503065, 636.0647385739353, -230.6192248354145, 416.71584836597424, 308.87117284462494, 637.1147619349592, 109.30809345833585, 383.29040564813454, 227.85643435609884, 426.86865308273843, 286.3037099067532, 718.1188772406492, 301.9464598664181, 229.62703687821198, 329.7893890280929, 631.051035517629, -130.59700002353918, 639.5776988453405, -121.41148599822318, 634.8230869258723, -67.80323170916665, 606.0563947895087, 82.91643009200496, 795.6147100981988, 53.09679952746287, 466.52237267367326, 333.6517214105876, 478.7565337383253, 154.67817610288049, 383.8463195904736, -61.227987456458365, 351.8718150588087, 418.4826629385938, 638.2663160812062, 770.2649455999352, 636.4913695626626, 209.16551012512105, 617.3902430802568, 323.1643296635771, 468.15650202787754, 234.50139133709726, 409.8425692113892, 293.86714037146356, 407.26077224852236, 157.10904105953077, 445.6135390232733, 474.04172013583667, 472.83668505526515], "policy_AGENT-3_reward": [-92.70339752176916, 318.497794239489, -208.09174527275601, 431.6279830653084, -95.35731060806204, -12.99427489612573, -193.46627128146514, 510.58339146599883, 532.4850218934048, 490.40643165380806, 545.9633885079206, 214.1383394253749, 308.118322202016, 104.96999792986176, 491.4728619011331, 461.80606086792454, 551.4614346751973, 480.50636573612695, 503.03588905549196, 475.55440565657796, 496.78129533061946, -228.9713661255771, 316.3198652082239, 232.06096320207504, -6.4827802240567, -460.4199811929214, -8.909683447698802, 165.9753176504356, 346.2942666523488, -168.1189167140204, 94.27071070655637, -37.366833236312345, 427.67923726558683, -157.42359389552047, 426.0265863392303, 466.86546996791475, 486.00154815908087, 476.86668779242814, 476.06188020061853, 499.2681033076163, 526.9389916102801, 170.88732712423558, 305.17219225646204, -1.9456023300645855, 137.95045015441195, -8.766780541908926, 269.49109200901563, 309.58814011819584, -111.26521530248341, -17.01179742625346, -138.6873494881108, 382.86299935289935, -106.44376947558332, 430.52965448564555, -185.73180431961745, 440.99316127997326, 496.7209841080461, 490.5265786697624, 476.1233135518031, 411.9722894261837, 562.9727376007519, 513.3612253763905, 476.1501575653458, 228.44871915725813, 290.4170016576203, 108.43333585762649, 251.97885983680987, 0.9712765938628594, -161.66732492421858, 455.86081202790103, -121.9773609068873, 349.28514393961814, -68.36581983891938, 481.74838740346297, 468.1582716184662, 500.2888100595531, 469.1409732809422, 463.18200654678907, 244.26780294967577, 295.55263863981054, 133.29596468077312, -10.155929615933992, -111.43466821697876, 268.5402105052898, -4.288197012078665, 401.51908410740657, -31.32742191326361, 320.9490214271709, -84.43621078044794, 443.62060945117406, 494.30497783841605, 473.25534682565103, 537.1976694604042, 500.6808622789061, 494.05781769729464, 510.2061415456869, 36.54787503929298, 252.34502594402122, -6.653966696278565, 316.41242924864065], "policy_AGENT-0_reward": [305.99351267918485, 232.49273303239372, -265.3359570856054, 327.652454768631, 906.8655687599723, -63.74815501511855, -192.77361715017935, 232.39171941724666, 151.8962254105889, 457.2744543750077, 30.963470276542235, 223.40745618061348, 566.1977464620426, 188.36517037726037, 241.674725899939, 425.9026867675576, 547.8782152837177, 484.2184052867819, 243.56631700899442, 186.0850338643994, 281.2653841535355, -32.12269989039974, 417.1323591984762, 540.5366016118251, 291.72450047383074, -49.96357864332269, 317.6426136113569, 173.61959268914737, 265.3263805395157, -116.27189707797046, 560.1917017578406, 693.420029316242, 221.30840641037702, -156.21345817838784, 146.02224534465498, 359.38531560364703, -209.57130629567416, 457.6490964585699, 55.01586203409724, 205.79596915659144, -25.72794567678142, 223.9554345617099, 350.64030182255635, -89.43696107121127, 145.97370101807513, 397.6168562197918, 281.94064021453926, 305.86389204929395, 35.41633775582442, -65.90888562519771, 159.69135452640526, -86.07494078118302, -139.0400442740381, 168.4103285790701, -230.48850249130965, 394.7499972221867, 243.98165170608848, 623.3452503916029, -88.88807719114429, 369.2879081660625, -24.641875198861776, 412.5624063932163, 234.6947863458008, 711.0527068539209, 305.6804803438401, 192.8677989722325, 292.7472795638439, 544.7403883558361, -208.39873471436965, 183.33787597370312, 180.3841393421105, 132.24443137593488, -77.29331192271931, 576.0704658632139, -98.20296758258709, 707.3994264447967, 66.98094170054021, 422.38242915651875, 243.66004582069655, 487.31602041518795, 194.93546244631182, 384.056671810118, -61.090868502862634, 282.0382463682835, 481.74213754125685, 278.1768756185994, 732.8728789282811, -8.70569265405608, -83.72659607988948, 560.2056910149412, 249.97139037395448, 382.999632150755, 29.08164519008018, 388.29245904648906, 328.4514383433522, 322.4740707351018, 183.15010640619735, 481.7903867810008, 461.9203437006771, 364.9030863890442]}, "sampler_perf": {"mean_env_wait_ms": 55.96190872933737, "mean_raw_obs_processing_ms": 2.211945808312484, "mean_inference_ms": 2.5137325199249085, "mean_action_processing_ms": 0.1504841755749171}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 168000, "timers": {"sample_time_ms": 71026.631, "sample_throughput": 59.133, "load_time_ms": 14.179, "load_throughput": 296202.431, "learn_time_ms": 11460.267, "learn_throughput": 366.484, "update_time_ms": 9.166}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 189.67124938964844, "policy_loss": -0.02981622703373432, "vf_loss": 189.69668579101562, "vf_explained_var": 0.9786791801452637, "kl": 0.00973278284072876, "entropy": 0.7428051829338074, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 70.3151626586914, "policy_loss": -0.02874612621963024, "vf_loss": 70.33971405029297, "vf_explained_var": 0.9834760427474976, "kl": 0.01398965623229742, "entropy": 0.6786699891090393, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 278.2945251464844, "policy_loss": -0.03302444517612457, "vf_loss": 278.3233947753906, "vf_explained_var": 0.9746772646903992, "kl": 0.013672213070094585, "entropy": 0.8825181126594543, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 100.52385711669922, "policy_loss": -0.031786445528268814, "vf_loss": 100.5517349243164, "vf_explained_var": 0.9860307574272156, "kl": 0.008694377727806568, "entropy": 0.6570817828178406, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 168000, "num_steps_trained": 168000}, "done": false, "episodes_total": 1103, "training_iteration": 40, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-32-11", "timestamp": 1624203131, "time_this_iter_s": 95.26971554756165, "time_total_s": 4339.116068601608, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5d87964d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5d87963b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5d8796710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4339.116068601608, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 50.67279411764706, "ram_util_percent": 88.00441176470588}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2494.2346690751633, "episode_reward_min": -1241.0811037916892, "episode_reward_mean": 903.6866821777368, "episode_len_mean": 245.32, "episodes_this_iter": 15, "policy_reward_min": {"AGENT-2": -282.5578181621812, "AGENT-3": -293.5256426086221, "AGENT-0": -332.5202999252551, "AGENT-1": -332.47734309563054}, "policy_reward_max": {"AGENT-2": 559.4493152624741, "AGENT-3": 562.9727376007519, "AGENT-0": 906.8655687599723, "AGENT-1": 944.2545051911186}, "policy_reward_mean": {"AGENT-2": 141.60692198227053, "AGENT-3": 236.01632786057456, "AGENT-0": 212.58999522963822, "AGENT-1": 313.4734371052534}, "custom_metrics": {"mean_ego_speed_mean": 38.8761225, "mean_ego_speed_min": 23.276, "mean_ego_speed_max": 49.0965, "distance_travelled_mean": 111.22785250000003, "distance_travelled_min": 33.6135, "distance_travelled_max": 125.04475}, "hist_stats": {"episode_reward": [1395.9967294805308, -342.0929049804869, 1591.501252373613, -625.9940480109863, 116.40572008972859, -1241.0811037916892, -546.2052722928714, 1457.006368618685, 1643.0503301428923, 889.6261923598789, 1806.7656759428596, 1206.6863331595182, 689.356990512582, 627.4739563373769, 1162.295951058577, -568.6146498193862, 1383.1121564414257, 1348.8605647160991, 1495.6976994371537, -624.9345336912236, 1326.8453275109518, 1502.5800935960594, 85.84493418787476, 1782.3469105757847, 670.7444409672789, 992.3279632453795, 681.1615799431531, 808.2768176089047, 1359.1663069769033, -149.19144825426244, 601.3502387825822, 825.447268749705, 1065.4902882445137, 1236.0257727029696, -111.70776053891785, 310.1810060255496, 78.52424532953776, 874.6107814711892, -490.96157714018057, 1367.7879456893713, -832.5496271602086, 1599.894114683631, 1262.3659272347675, 2142.9260131341534, 383.26332873790614, 1490.2066650515824, 777.3479264031606, 1711.7864182162414, 1203.3960316719335, 2093.449761493867, 1203.1529095100302, 723.2086926343183, 1166.685596539828, 1177.6754148478108, -631.7382487884213, 1426.5939170344434, 89.00901332132345, 1287.5886608347137, -291.3245520286551, 2061.606536075906, 389.50083100782047, 2494.2346690751633, 641.6390465604351, 1678.186920354093, 1064.6570921625216, 1583.982115652838, 677.2767338212208, 747.7630948604437, -345.15248291454475, 1183.9136472144805, 891.5494679365321, 1569.0903225305271, 1440.544920738279, 974.0035832303669, 319.21057259590157, 2180.665858808847, 1316.8597875342427, 1632.9527881200336, 811.4900950937185, 1617.5401216737032, 1447.4465051914601, 1561.8546660842785, 559.402434236241, 1562.1350065417664, 922.684254884785, 1143.9508858581455, 396.17384187192977, 1416.8763535989488, -909.2054859334858, 1764.5280515335535, 1660.34772648424, 246.1589383520181, -651.1990901258645, 1315.4784634353332, 1089.0549548768042, 1911.3768406991155, 808.6774515984084, 903.6376807869202, 1910.3354196702214, 712.7350888652556], "episode_lengths": [220, 104, 239, 109, 187, 202, 106, 219, 436, 214, 453, 183, 493, 502, 480, 42, 235, 346, 229, 129, 232, 195, 210, 226, 216, 206, 211, 200, 222, 147, 172, 285, 184, 203, 252, 194, 253, 252, 80, 225, 110, 194, 169, 203, 221, 173, 203, 201, 163, 288, 211, 466, 294, 251, 109, 223, 346, 239, 86, 184, 198, 417, 218, 270, 434, 243, 201, 227, 29, 382, 112, 232, 338, 244, 122, 367, 142, 398, 237, 191, 162, 342, 443, 165, 207, 434, 344, 265, 139, 228, 404, 193, 89, 483, 188, 436, 204, 244, 485, 448], "policy_AGENT-2_reward": [151.3605377826858, -55.93269824156747, 257.0858309649723, -117.98716057949629, 131.47266396433594, -282.5578181621812, -165.38160811751314, 218.37355015647907, 257.3618716682284, 213.90419495296533, 314.7127342919033, 220.68269921656776, 185.7519792144172, 200.3268536989779, 247.7101622465369, -167.97208089381138, 94.2353695825972, -37.31775244947711, 203.79105880481487, -156.7699965317306, 112.93948235887613, 303.79647546087097, -244.68342687578178, 363.2572741235675, 35.77389173437398, 134.9071422160705, -59.75034605521513, 223.3822786015784, 350.0747048959797, 31.590274169366438, 145.41101789509457, -8.65486643970507, 210.64860166252268, 305.29033633197497, 74.84691288854916, 196.33056423874018, -138.74422811237466, -51.846543800523364, -139.60025669552843, 132.7832240507243, -185.71009551386658, 347.4351078154964, 212.79211857600947, 391.93942213783004, -113.2800010810883, 325.65606181120154, 11.160629645173314, 358.9941333638958, 206.2473778540357, 435.82945824203904, 305.10896764215266, 192.28052092624654, 292.1700681110821, 0.9127143804819284, -131.07518912629408, 147.81753018749902, 152.01372088432342, 171.2359985932924, -77.86218855784969, 397.7312880197204, -63.37090312006321, 490.93172247261185, 52.42033205149004, 326.10011197711304, 243.0775219815615, 322.35692285951757, 194.36713059125591, -9.983966924213602, -111.39895873824494, 281.46337528209824, -4.38713553123991, 251.12804672331563, -31.26548187667252, 25.268884894588233, 278.20786933111776, 559.4493152624741, 249.41908965829506, 308.5413071157518, 10.709389106137667, 318.7242311369195, 331.07010877935045, 321.91368155496855, 182.59541173121946, 382.3860547934712, -6.623842255449915, -10.20131483480409, 275.0217018006737, 221.12125570871575, -228.24979539704216, 368.1528468446571, -95.4150368587922, 161.23020311756625, -132.69692403044226, 201.59910999715254, 120.29092338731421, 383.8660666922927, -4.733123919683792, 222.82241058069155, 454.9875056211348, 187.79560252999846], "policy_AGENT-3_reward": [421.38644001093036, -91.82797831428665, 413.1962586691062, -172.83868711936648, -81.3578651799909, -293.5256426086221, -165.4596623316158, 334.5196730626464, 489.3718395021239, 474.5799303934652, 498.10595329984204, 488.3551646758046, 90.22430652436486, 39.41112568854696, 290.4342275684257, -168.1189167140204, 94.27071070655637, -37.366833236312345, 427.67923726558683, -157.42359389552047, 426.0265863392303, 466.86546996791475, 486.00154815908087, 476.86668779242814, 476.06188020061853, 499.2681033076163, 526.9389916102801, 170.88732712423558, 305.17219225646204, -1.9456023300645855, 137.95045015441195, -8.766780541908926, 269.49109200901563, 309.58814011819584, -111.26521530248341, -17.01179742625346, -138.6873494881108, 382.86299935289935, -106.44376947558332, 430.52965448564555, -185.73180431961745, 440.99316127997326, 496.7209841080461, 490.5265786697624, 476.1233135518031, 411.9722894261837, 562.9727376007519, 513.3612253763905, 476.1501575653458, 228.44871915725813, 290.4170016576203, 108.43333585762649, 251.97885983680987, 0.9712765938628594, -161.66732492421858, 455.86081202790103, -121.9773609068873, 349.28514393961814, -68.36581983891938, 481.74838740346297, 468.1582716184662, 500.2888100595531, 469.1409732809422, 463.18200654678907, 244.26780294967577, 295.55263863981054, 133.29596468077312, -10.155929615933992, -111.43466821697876, 268.5402105052898, -4.288197012078665, 401.51908410740657, -31.32742191326361, 320.9490214271709, -84.43621078044794, 443.62060945117406, 494.30497783841605, 473.25534682565103, 537.1976694604042, 500.6808622789061, 494.05781769729464, 510.2061415456869, 36.54787503929298, 252.34502594402122, -6.653966696278565, 316.41242924864065, -92.70339752176916, 318.497794239489, -208.09174527275601, 431.6279830653084, -95.35731060806204, -12.99427489612573, -193.46627128146514, 510.58339146599883, 532.4850218934048, 490.40643165380806, 545.9633885079206, 214.1383394253749, 308.118322202016, 104.96999792986176], "policy_AGENT-0_reward": [186.47422739260864, -103.07132143388372, 271.07632591966245, -217.6843610149697, -65.6081423329, -332.5202999252551, -107.76457889183496, 253.92664388876372, 408.1288997463997, 109.11016719276003, 434.7320805807701, 253.8974014069256, 186.3380423872073, 200.8867145080607, 248.27058028810853, -116.27189707797046, 560.1917017578406, 693.420029316242, 221.30840641037702, -156.21345817838784, 146.02224534465498, 359.38531560364703, -209.57130629567416, 457.6490964585699, 55.01586203409724, 205.79596915659144, -25.72794567678142, 223.9554345617099, 350.64030182255635, -89.43696107121127, 145.97370101807513, 397.6168562197918, 281.94064021453926, 305.86389204929395, 35.41633775582442, -65.90888562519771, 159.69135452640526, -86.07494078118302, -139.0400442740381, 168.4103285790701, -230.48850249130965, 394.7499972221867, 243.98165170608848, 623.3452503916029, -88.88807719114429, 369.2879081660625, -24.641875198861776, 412.5624063932163, 234.6947863458008, 711.0527068539209, 305.6804803438401, 192.8677989722325, 292.7472795638439, 544.7403883558361, -208.39873471436965, 183.33787597370312, 180.3841393421105, 132.24443137593488, -77.29331192271931, 576.0704658632139, -98.20296758258709, 707.3994264447967, 66.98094170054021, 422.38242915651875, 243.66004582069655, 487.31602041518795, 194.93546244631182, 384.056671810118, -61.090868502862634, 282.0382463682835, 481.74213754125685, 278.1768756185994, 732.8728789282811, -8.70569265405608, -83.72659607988948, 560.2056910149412, 249.97139037395448, 382.999632150755, 29.08164519008018, 388.29245904648906, 328.4514383433522, 322.4740707351018, 183.15010640619735, 481.7903867810008, 461.9203437006771, 364.9030863890442, 305.99351267918485, 232.49273303239372, -265.3359570856054, 327.652454768631, 906.8655687599723, -63.74815501511855, -192.77361715017935, 232.39171941724666, 151.8962254105889, 457.2744543750077, 30.963470276542235, 223.40745618061348, 566.1977464620426, 188.36517037726037], "policy_AGENT-1_reward": [636.7755242943061, -91.26090699074905, 650.1428368198731, -117.48383929715447, 131.8990636382836, -332.47734309563054, -107.59942295190717, 650.1865015107946, 488.18771922613917, 92.03189982068913, 559.2149077703444, 243.75106786022087, 227.04266238659284, 186.84926244179036, 375.8809809555055, -116.25175513358403, 634.4143743944311, 730.1251210856469, 642.9189969563746, -154.52748508558486, 641.8570134681902, 372.53283256362533, 54.09811920025227, 484.5738522012211, 103.89280699818923, 152.35674856510073, 239.70088006487, 190.05177732138048, 353.2791080019055, -89.39915902235307, 172.01506971500044, 445.252059511527, 303.40995435843774, 315.28340420350565, -110.7057958808081, 196.77112483826056, 196.26446840361737, 629.6692666999982, -105.87750669503065, 636.0647385739353, -230.6192248354145, 416.71584836597424, 308.87117284462494, 637.1147619349592, 109.30809345833585, 383.29040564813454, 227.85643435609884, 426.86865308273843, 286.3037099067532, 718.1188772406492, 301.9464598664181, 229.62703687821198, 329.7893890280929, 631.051035517629, -130.59700002353918, 639.5776988453405, -121.41148599822318, 634.8230869258723, -67.80323170916665, 606.0563947895087, 82.91643009200496, 795.6147100981988, 53.09679952746287, 466.52237267367326, 333.6517214105876, 478.7565337383253, 154.67817610288049, 383.8463195904736, -61.227987456458365, 351.8718150588087, 418.4826629385938, 638.2663160812062, 770.2649455999352, 636.4913695626626, 209.16551012512105, 617.3902430802568, 323.1643296635771, 468.15650202787754, 234.50139133709726, 409.8425692113892, 293.86714037146356, 407.26077224852236, 157.10904105953077, 445.6135390232733, 474.04172013583667, 472.83668505526515, -92.13797508615968, 644.7645706183526, -207.5279881780818, 637.0947668549559, 944.2545051911186, 161.67116514569634, -132.2622776637779, 370.9042425549343, 284.38278418549385, 579.829887978007, 236.48371673362865, 243.26947460024093, 581.0318453850253, 231.60431802813488]}, "sampler_perf": {"mean_env_wait_ms": 55.40649706800713, "mean_raw_obs_processing_ms": 2.1841524989175056, "mean_inference_ms": 2.50256014283495, "mean_action_processing_ms": 0.14998890114965238}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 172200, "timers": {"sample_time_ms": 71197.583, "sample_throughput": 58.991, "load_time_ms": 13.857, "load_throughput": 303087.411, "learn_time_ms": 11322.897, "learn_throughput": 370.93, "update_time_ms": 9.243}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 210.6544189453125, "policy_loss": -0.029727526009082794, "vf_loss": 210.6800994873047, "vf_explained_var": 0.9809591770172119, "kl": 0.008964650332927704, "entropy": 0.7857106328010559, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 66.41338348388672, "policy_loss": -0.02794721908867359, "vf_loss": 66.43772888183594, "vf_explained_var": 0.9868533611297607, "kl": 0.012037137523293495, "entropy": 0.703155517578125, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 229.56642150878906, "policy_loss": -0.03477033972740173, "vf_loss": 229.59689331054688, "vf_explained_var": 0.9796377420425415, "kl": 0.014441579580307007, "entropy": 0.9021777510643005, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 100.84807586669922, "policy_loss": -0.03657946735620499, "vf_loss": 100.87954711914062, "vf_explained_var": 0.9853397607803345, "kl": 0.011403118260204792, "entropy": 0.7583772540092468, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 172200, "num_steps_trained": 172200}, "done": false, "episodes_total": 1118, "training_iteration": 41, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-33-32", "timestamp": 1624203212, "time_this_iter_s": 80.45388770103455, "time_total_s": 4419.569956302643, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5d8795ef0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5d8795e60>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795c20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02118c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211ef0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f023cf80>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795c20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02118c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211ef0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f023cf80>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795c20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02118c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211ef0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f023cf80>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8795c20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f02118c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0211ef0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f023cf80>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5d8796b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4419.569956302643, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 47.915652173913045, "ram_util_percent": 87.9}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2494.2346690751633, "episode_reward_min": -1241.0811037916892, "episode_reward_mean": 930.3113576034192, "episode_len_mean": 260.06, "episodes_this_iter": 13, "policy_reward_min": {"AGENT-2": -282.5578181621812, "AGENT-1": -332.47734309563054, "AGENT-3": -293.5256426086221, "AGENT-0": -332.5202999252551}, "policy_reward_max": {"AGENT-2": 559.4493152624741, "AGENT-1": 944.2545051911186, "AGENT-3": 562.9727376007519, "AGENT-0": 906.8655687599723}, "policy_reward_mean": {"AGENT-2": 152.07540221632388, "AGENT-1": 325.83637272701117, "AGENT-3": 230.5040346125145, "AGENT-0": 221.89554804756995}, "custom_metrics": {"mean_ego_speed_mean": 38.23320999999999, "mean_ego_speed_min": 23.276, "mean_ego_speed_max": 49.0965, "distance_travelled_mean": 111.7781275, "distance_travelled_min": 33.6135, "distance_travelled_max": 125.04475}, "hist_stats": {"episode_reward": [966.3368985045577, 1457.7388225987072, 579.1652242087279, 1463.6122502167327, -95.5459611486254, 1287.3835076653147, 1858.8149191336672, 186.8389269828957, 1935.5660190481185, 1044.8507185202955, 632.2887385514347, 474.69453874075464, 1754.9722442651448, 1359.1663069769033, -149.19144825426244, 601.3502387825822, 825.447268749705, 1065.4902882445137, 1236.0257727029696, -111.70776053891785, 310.1810060255496, 78.52424532953776, 874.6107814711892, -490.96157714018057, 1367.7879456893713, -832.5496271602086, 1599.894114683631, 1262.3659272347675, 2142.9260131341534, 383.26332873790614, 1490.2066650515824, 777.3479264031606, 1711.7864182162414, 1203.3960316719335, 2093.449761493867, 1203.1529095100302, 723.2086926343183, 1166.685596539828, 1177.6754148478108, -631.7382487884213, 1426.5939170344434, 89.00901332132345, 1287.5886608347137, -291.3245520286551, 2061.606536075906, 389.50083100782047, 2494.2346690751633, 641.6390465604351, 1678.186920354093, 1064.6570921625216, 1583.982115652838, 677.2767338212208, 747.7630948604437, -345.15248291454475, 1183.9136472144805, 891.5494679365321, 1569.0903225305271, 1440.544920738279, 974.0035832303669, 319.21057259590157, 2180.665858808847, 1316.8597875342427, 1632.9527881200336, 811.4900950937185, 1617.5401216737032, 1447.4465051914601, 1561.8546660842785, 559.402434236241, 1562.1350065417664, 922.684254884785, 1143.9508858581455, 396.17384187192977, 1416.8763535989488, -909.2054859334858, 1764.5280515335535, 1660.34772648424, 246.1589383520181, -651.1990901258645, 1315.4784634353332, 1089.0549548768042, 1911.3768406991155, 808.6774515984084, 903.6376807869202, 1910.3354196702214, 712.7350888652556, 1395.9967294805308, -342.0929049804869, 1591.501252373613, -625.9940480109863, 116.40572008972859, -1241.0811037916892, -546.2052722928714, 1457.006368618685, 1643.0503301428923, 889.6261923598789, 1806.7656759428596, 1206.6863331595182, 689.356990512582, 627.4739563373769, 1162.295951058577], "episode_lengths": [350, 244, 162, 208, 216, 265, 463, 227, 444, 191, 473, 453, 455, 222, 147, 172, 285, 184, 203, 252, 194, 253, 252, 80, 225, 110, 194, 169, 203, 221, 173, 203, 201, 163, 288, 211, 466, 294, 251, 109, 223, 346, 239, 86, 184, 198, 417, 218, 270, 434, 243, 201, 227, 29, 382, 112, 232, 338, 244, 122, 367, 142, 398, 237, 191, 162, 342, 443, 165, 207, 434, 344, 265, 139, 228, 404, 193, 89, 483, 188, 436, 204, 244, 485, 448, 220, 104, 239, 109, 187, 202, 106, 219, 436, 214, 453, 183, 493, 502, 480], "policy_AGENT-2_reward": [-131.44512526050121, 181.37842135058602, -51.04826055209071, 244.61819864184338, 84.19019172415571, 109.09981585169812, 278.65046552660243, -195.09995070921562, 396.01572819354664, 141.48591932769574, 188.51884018500635, 166.76145695672247, 439.3116922460197, 350.0747048959797, 31.590274169366438, 145.41101789509457, -8.65486643970507, 210.64860166252268, 305.29033633197497, 74.84691288854916, 196.33056423874018, -138.74422811237466, -51.846543800523364, -139.60025669552843, 132.7832240507243, -185.71009551386658, 347.4351078154964, 212.79211857600947, 391.93942213783004, -113.2800010810883, 325.65606181120154, 11.160629645173314, 358.9941333638958, 206.2473778540357, 435.82945824203904, 305.10896764215266, 192.28052092624654, 292.1700681110821, 0.9127143804819284, -131.07518912629408, 147.81753018749902, 152.01372088432342, 171.2359985932924, -77.86218855784969, 397.7312880197204, -63.37090312006321, 490.93172247261185, 52.42033205149004, 326.10011197711304, 243.0775219815615, 322.35692285951757, 194.36713059125591, -9.983966924213602, -111.39895873824494, 281.46337528209824, -4.38713553123991, 251.12804672331563, -31.26548187667252, 25.268884894588233, 278.20786933111776, 559.4493152624741, 249.41908965829506, 308.5413071157518, 10.709389106137667, 318.7242311369195, 331.07010877935045, 321.91368155496855, 182.59541173121946, 382.3860547934712, -6.623842255449915, -10.20131483480409, 275.0217018006737, 221.12125570871575, -228.24979539704216, 368.1528468446571, -95.4150368587922, 161.23020311756625, -132.69692403044226, 201.59910999715254, 120.29092338731421, 383.8660666922927, -4.733123919683792, 222.82241058069155, 454.9875056211348, 187.79560252999846, 151.3605377826858, -55.93269824156747, 257.0858309649723, -117.98716057949629, 131.47266396433594, -282.5578181621812, -165.38160811751314, 218.37355015647907, 257.3618716682284, 213.90419495296533, 314.7127342919033, 220.68269921656776, 185.7519792144172, 200.3268536989779, 247.7101622465369], "policy_AGENT-1_reward": [633.2160691565884, 647.5365508078798, 325.76649865274294, 635.2840844996458, -113.25540924639922, 644.523651106879, 594.7901210824094, 81.83169704643176, 592.2054448581364, 246.87708603802068, 192.7128126588458, 141.51449543180595, 589.0337426829041, 353.2791080019055, -89.39915902235307, 172.01506971500044, 445.252059511527, 303.40995435843774, 315.28340420350565, -110.7057958808081, 196.77112483826056, 196.26446840361737, 629.6692666999982, -105.87750669503065, 636.0647385739353, -230.6192248354145, 416.71584836597424, 308.87117284462494, 637.1147619349592, 109.30809345833585, 383.29040564813454, 227.85643435609884, 426.86865308273843, 286.3037099067532, 718.1188772406492, 301.9464598664181, 229.62703687821198, 329.7893890280929, 631.051035517629, -130.59700002353918, 639.5776988453405, -121.41148599822318, 634.8230869258723, -67.80323170916665, 606.0563947895087, 82.91643009200496, 795.6147100981988, 53.09679952746287, 466.52237267367326, 333.6517214105876, 478.7565337383253, 154.67817610288049, 383.8463195904736, -61.227987456458365, 351.8718150588087, 418.4826629385938, 638.2663160812062, 770.2649455999352, 636.4913695626626, 209.16551012512105, 617.3902430802568, 323.1643296635771, 468.15650202787754, 234.50139133709726, 409.8425692113892, 293.86714037146356, 407.26077224852236, 157.10904105953077, 445.6135390232733, 474.04172013583667, 472.83668505526515, -92.13797508615968, 644.7645706183526, -207.5279881780818, 637.0947668549559, 944.2545051911186, 161.67116514569634, -132.2622776637779, 370.9042425549343, 284.38278418549385, 579.829887978007, 236.48371673362865, 243.26947460024093, 581.0318453850253, 231.60431802813488, 636.7755242943061, -91.26090699074905, 650.1428368198731, -117.48383929715447, 131.8990636382836, -332.47734309563054, -107.59942295190717, 650.1865015107946, 488.18771922613917, 92.03189982068913, 559.2149077703444, 243.75106786022087, 227.04266238659284, 186.84926244179036, 375.8809809555055], "policy_AGENT-3_reward": [-131.59566375644016, 421.2142188726082, -51.034671630895716, 303.98129274838504, -113.82392452922356, 472.8275131606058, 493.07440420566127, 472.2749737132833, 479.0324418685987, 496.84760741364187, 61.97521385970926, -0.9165339503750403, 232.87100184612493, 305.17219225646204, -1.9456023300645855, 137.95045015441195, -8.766780541908926, 269.49109200901563, 309.58814011819584, -111.26521530248341, -17.01179742625346, -138.6873494881108, 382.86299935289935, -106.44376947558332, 430.52965448564555, -185.73180431961745, 440.99316127997326, 496.7209841080461, 490.5265786697624, 476.1233135518031, 411.9722894261837, 562.9727376007519, 513.3612253763905, 476.1501575653458, 228.44871915725813, 290.4170016576203, 108.43333585762649, 251.97885983680987, 0.9712765938628594, -161.66732492421858, 455.86081202790103, -121.9773609068873, 349.28514393961814, -68.36581983891938, 481.74838740346297, 468.1582716184662, 500.2888100595531, 469.1409732809422, 463.18200654678907, 244.26780294967577, 295.55263863981054, 133.29596468077312, -10.155929615933992, -111.43466821697876, 268.5402105052898, -4.288197012078665, 401.51908410740657, -31.32742191326361, 320.9490214271709, -84.43621078044794, 443.62060945117406, 494.30497783841605, 473.25534682565103, 537.1976694604042, 500.6808622789061, 494.05781769729464, 510.2061415456869, 36.54787503929298, 252.34502594402122, -6.653966696278565, 316.41242924864065, -92.70339752176916, 318.497794239489, -208.09174527275601, 431.6279830653084, -95.35731060806204, -12.99427489612573, -193.46627128146514, 510.58339146599883, 532.4850218934048, 490.40643165380806, 545.9633885079206, 214.1383394253749, 308.118322202016, 104.96999792986176, 421.38644001093036, -91.82797831428665, 413.1962586691062, -172.83868711936648, -81.3578651799909, -293.5256426086221, -165.4596623316158, 334.5196730626464, 489.3718395021239, 474.5799303934652, 498.10595329984204, 488.3551646758046, 90.22430652436486, 39.41112568854696, 290.4342275684257], "policy_AGENT-0_reward": [596.1616183649102, 207.6096315676323, 355.4816577389709, 279.72867432685905, 47.343180902841446, 60.93252754613239, 492.29992831899455, -172.1677930676026, 468.31240412783706, 159.64010574093757, 189.0818718478727, 167.3351203026018, 493.755807490098, 350.64030182255635, -89.43696107121127, 145.97370101807513, 397.6168562197918, 281.94064021453926, 305.86389204929395, 35.41633775582442, -65.90888562519771, 159.69135452640526, -86.07494078118302, -139.0400442740381, 168.4103285790701, -230.48850249130965, 394.7499972221867, 243.98165170608848, 623.3452503916029, -88.88807719114429, 369.2879081660625, -24.641875198861776, 412.5624063932163, 234.6947863458008, 711.0527068539209, 305.6804803438401, 192.8677989722325, 292.7472795638439, 544.7403883558361, -208.39873471436965, 183.33787597370312, 180.3841393421105, 132.24443137593488, -77.29331192271931, 576.0704658632139, -98.20296758258709, 707.3994264447967, 66.98094170054021, 422.38242915651875, 243.66004582069655, 487.31602041518795, 194.93546244631182, 384.056671810118, -61.090868502862634, 282.0382463682835, 481.74213754125685, 278.1768756185994, 732.8728789282811, -8.70569265405608, -83.72659607988948, 560.2056910149412, 249.97139037395448, 382.999632150755, 29.08164519008018, 388.29245904648906, 328.4514383433522, 322.4740707351018, 183.15010640619735, 481.7903867810008, 461.9203437006771, 364.9030863890442, 305.99351267918485, 232.49273303239372, -265.3359570856054, 327.652454768631, 906.8655687599723, -63.74815501511855, -192.77361715017935, 232.39171941724666, 151.8962254105889, 457.2744543750077, 30.963470276542235, 223.40745618061348, 566.1977464620426, 188.36517037726037, 186.47422739260864, -103.07132143388372, 271.07632591966245, -217.6843610149697, -65.6081423329, -332.5202999252551, -107.76457889183496, 253.92664388876372, 408.1288997463997, 109.11016719276003, 434.7320805807701, 253.8974014069256, 186.3380423872073, 200.8867145080607, 248.27058028810853]}, "sampler_perf": {"mean_env_wait_ms": 55.08101526876748, "mean_raw_obs_processing_ms": 2.168377479348626, "mean_inference_ms": 2.4911481023897535, "mean_action_processing_ms": 0.14950129531718603}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 176400, "timers": {"sample_time_ms": 71006.641, "sample_throughput": 59.149, "load_time_ms": 13.863, "load_throughput": 302958.663, "learn_time_ms": 11109.307, "learn_throughput": 378.061, "update_time_ms": 9.307}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 126.91127014160156, "policy_loss": -0.030562978237867355, "vf_loss": 126.93688201904297, "vf_explained_var": 0.9881049990653992, "kl": 0.011005789041519165, "entropy": 0.6885804533958435, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 55.24051284790039, "policy_loss": -0.028155939653515816, "vf_loss": 55.26448440551758, "vf_explained_var": 0.9885743260383606, "kl": 0.013903186656534672, "entropy": 0.6751253604888916, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 255.78526306152344, "policy_loss": -0.03495589271187782, "vf_loss": 255.81541442871094, "vf_explained_var": 0.9824467897415161, "kl": 0.01584596186876297, "entropy": 0.8249202370643616, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 65.49223327636719, "policy_loss": -0.03477904573082924, "vf_loss": 65.52224731445312, "vf_explained_var": 0.9903684854507446, "kl": 0.01056418102234602, "entropy": 0.6250644326210022, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 176400, "num_steps_trained": 176400}, "done": false, "episodes_total": 1131, "training_iteration": 42, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-34-48", "timestamp": 1624203288, "time_this_iter_s": 76.5544924736023, "time_total_s": 4496.124448776245, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5d85f54d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5d85f53b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5d85f55f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4496.124448776245, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 50.40275229357797, "ram_util_percent": 87.81009174311922}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2494.2346690751633, "episode_reward_min": -1241.0811037916892, "episode_reward_mean": 959.3234888874497, "episode_len_mean": 277.54, "episodes_this_iter": 15, "policy_reward_min": {"AGENT-2": -282.5578181621812, "AGENT-1": -375.92076574592335, "AGENT-3": -511.03597463176493, "AGENT-0": -332.5202999252551}, "policy_reward_max": {"AGENT-2": 559.4493152624741, "AGENT-1": 944.2545051911186, "AGENT-3": 562.9727376007519, "AGENT-0": 906.8655687599723}, "policy_reward_mean": {"AGENT-2": 154.5817667848006, "AGENT-1": 334.8827834599899, "AGENT-3": 236.2510317494226, "AGENT-0": 233.60790689323673}, "custom_metrics": {"mean_ego_speed_mean": 37.916885, "mean_ego_speed_min": 23.276, "mean_ego_speed_max": 49.0965, "distance_travelled_mean": 111.32571499999999, "distance_travelled_min": 33.6135, "distance_travelled_max": 125.04475}, "hist_stats": {"episode_reward": [-297.821235074052, 1712.017287861605, -476.39490062059866, 1765.4919723351509, -498.92928583427164, 1401.6452287126276, 1998.1947581572722, 581.9402733754204, 1771.6556955952703, 1034.0300253089247, 1415.1004249638663, -893.4038856774589, 686.8760016640413, 543.2453507996541, 1153.998899632742, 2142.9260131341534, 383.26332873790614, 1490.2066650515824, 777.3479264031606, 1711.7864182162414, 1203.3960316719335, 2093.449761493867, 1203.1529095100302, 723.2086926343183, 1166.685596539828, 1177.6754148478108, -631.7382487884213, 1426.5939170344434, 89.00901332132345, 1287.5886608347137, -291.3245520286551, 2061.606536075906, 389.50083100782047, 2494.2346690751633, 641.6390465604351, 1678.186920354093, 1064.6570921625216, 1583.982115652838, 677.2767338212208, 747.7630948604437, -345.15248291454475, 1183.9136472144805, 891.5494679365321, 1569.0903225305271, 1440.544920738279, 974.0035832303669, 319.21057259590157, 2180.665858808847, 1316.8597875342427, 1632.9527881200336, 811.4900950937185, 1617.5401216737032, 1447.4465051914601, 1561.8546660842785, 559.402434236241, 1562.1350065417664, 922.684254884785, 1143.9508858581455, 396.17384187192977, 1416.8763535989488, -909.2054859334858, 1764.5280515335535, 1660.34772648424, 246.1589383520181, -651.1990901258645, 1315.4784634353332, 1089.0549548768042, 1911.3768406991155, 808.6774515984084, 903.6376807869202, 1910.3354196702214, 712.7350888652556, 1395.9967294805308, -342.0929049804869, 1591.501252373613, -625.9940480109863, 116.40572008972859, -1241.0811037916892, -546.2052722928714, 1457.006368618685, 1643.0503301428923, 889.6261923598789, 1806.7656759428596, 1206.6863331595182, 689.356990512582, 627.4739563373769, 1162.295951058577, 966.3368985045577, 1457.7388225987072, 579.1652242087279, 1463.6122502167327, -95.5459611486254, 1287.3835076653147, 1858.8149191336672, 186.8389269828957, 1935.5660190481185, 1044.8507185202955, 632.2887385514347, 474.69453874075464, 1754.9722442651448], "episode_lengths": [548, 220, 110, 217, 88, 224, 422, 189, 443, 199, 416, 441, 475, 245, 453, 203, 221, 173, 203, 201, 163, 288, 211, 466, 294, 251, 109, 223, 346, 239, 86, 184, 198, 417, 218, 270, 434, 243, 201, 227, 29, 382, 112, 232, 338, 244, 122, 367, 142, 398, 237, 191, 162, 342, 443, 165, 207, 434, 344, 265, 139, 228, 404, 193, 89, 483, 188, 436, 204, 244, 485, 448, 220, 104, 239, 109, 187, 202, 106, 219, 436, 214, 453, 183, 493, 502, 480, 350, 244, 162, 208, 216, 265, 463, 227, 444, 191, 473, 453, 455], "policy_AGENT-2_reward": [-116.45823607613951, 50.115663272071814, -61.78235531272009, 336.8152203012829, -144.32953131922346, 233.4585264883546, 409.4492563863156, -16.421073835755102, 330.5086241002889, 76.98573465868974, 257.1684079223151, -3.501658497910121, 202.6711678654945, 185.62616950297001, -7.022586645902384, 391.93942213783004, -113.2800010810883, 325.65606181120154, 11.160629645173314, 358.9941333638958, 206.2473778540357, 435.82945824203904, 305.10896764215266, 192.28052092624654, 292.1700681110821, 0.9127143804819284, -131.07518912629408, 147.81753018749902, 152.01372088432342, 171.2359985932924, -77.86218855784969, 397.7312880197204, -63.37090312006321, 490.93172247261185, 52.42033205149004, 326.10011197711304, 243.0775219815615, 322.35692285951757, 194.36713059125591, -9.983966924213602, -111.39895873824494, 281.46337528209824, -4.38713553123991, 251.12804672331563, -31.26548187667252, 25.268884894588233, 278.20786933111776, 559.4493152624741, 249.41908965829506, 308.5413071157518, 10.709389106137667, 318.7242311369195, 331.07010877935045, 321.91368155496855, 182.59541173121946, 382.3860547934712, -6.623842255449915, -10.20131483480409, 275.0217018006737, 221.12125570871575, -228.24979539704216, 368.1528468446571, -95.4150368587922, 161.23020311756625, -132.69692403044226, 201.59910999715254, 120.29092338731421, 383.8660666922927, -4.733123919683792, 222.82241058069155, 454.9875056211348, 187.79560252999846, 151.3605377826858, -55.93269824156747, 257.0858309649723, -117.98716057949629, 131.47266396433594, -282.5578181621812, -165.38160811751314, 218.37355015647907, 257.3618716682284, 213.90419495296533, 314.7127342919033, 220.68269921656776, 185.7519792144172, 200.3268536989779, 247.7101622465369, -131.44512526050121, 181.37842135058602, -51.04826055209071, 244.61819864184338, 84.19019172415571, 109.09981585169812, 278.65046552660243, -195.09995070921562, 396.01572819354664, 141.48591932769574, 188.51884018500635, 166.76145695672247, 439.3116922460197], "policy_AGENT-1_reward": [68.29897862350512, 638.9152673238589, -61.24952213363136, 642.4209547306206, -105.10930826714943, 642.6435465856995, 610.5336410823863, 116.89666574144626, 517.999339828932, 333.93167960080376, 366.9809701007856, -375.92076574592335, 208.17477510468464, 104.7412825787132, 632.3780972263191, 637.1147619349592, 109.30809345833585, 383.29040564813454, 227.85643435609884, 426.86865308273843, 286.3037099067532, 718.1188772406492, 301.9464598664181, 229.62703687821198, 329.7893890280929, 631.051035517629, -130.59700002353918, 639.5776988453405, -121.41148599822318, 634.8230869258723, -67.80323170916665, 606.0563947895087, 82.91643009200496, 795.6147100981988, 53.09679952746287, 466.52237267367326, 333.6517214105876, 478.7565337383253, 154.67817610288049, 383.8463195904736, -61.227987456458365, 351.8718150588087, 418.4826629385938, 638.2663160812062, 770.2649455999352, 636.4913695626626, 209.16551012512105, 617.3902430802568, 323.1643296635771, 468.15650202787754, 234.50139133709726, 409.8425692113892, 293.86714037146356, 407.26077224852236, 157.10904105953077, 445.6135390232733, 474.04172013583667, 472.83668505526515, -92.13797508615968, 644.7645706183526, -207.5279881780818, 637.0947668549559, 944.2545051911186, 161.67116514569634, -132.2622776637779, 370.9042425549343, 284.38278418549385, 579.829887978007, 236.48371673362865, 243.26947460024093, 581.0318453850253, 231.60431802813488, 636.7755242943061, -91.26090699074905, 650.1428368198731, -117.48383929715447, 131.8990636382836, -332.47734309563054, -107.59942295190717, 650.1865015107946, 488.18771922613917, 92.03189982068913, 559.2149077703444, 243.75106786022087, 227.04266238659284, 186.84926244179036, 375.8809809555055, 633.2160691565884, 647.5365508078798, 325.76649865274294, 635.2840844996458, -113.25540924639922, 644.523651106879, 594.7901210824094, 81.83169704643176, 592.2054448581364, 246.87708603802068, 192.7128126588458, 141.51449543180595, 589.0337426829041], "policy_AGENT-3_reward": [-133.764851873866, 384.2264890576421, -177.1211951359569, 415.60183465511517, -144.53326658207988, 326.17147762024484, 469.894867643523, 463.65702373839446, 523.4334553193146, 515.6119155466989, 513.4156901882859, -511.03597463176493, 72.79326668904001, 66.68999146660676, -6.8846551297572, 490.5265786697624, 476.1233135518031, 411.9722894261837, 562.9727376007519, 513.3612253763905, 476.1501575653458, 228.44871915725813, 290.4170016576203, 108.43333585762649, 251.97885983680987, 0.9712765938628594, -161.66732492421858, 455.86081202790103, -121.9773609068873, 349.28514393961814, -68.36581983891938, 481.74838740346297, 468.1582716184662, 500.2888100595531, 469.1409732809422, 463.18200654678907, 244.26780294967577, 295.55263863981054, 133.29596468077312, -10.155929615933992, -111.43466821697876, 268.5402105052898, -4.288197012078665, 401.51908410740657, -31.32742191326361, 320.9490214271709, -84.43621078044794, 443.62060945117406, 494.30497783841605, 473.25534682565103, 537.1976694604042, 500.6808622789061, 494.05781769729464, 510.2061415456869, 36.54787503929298, 252.34502594402122, -6.653966696278565, 316.41242924864065, -92.70339752176916, 318.497794239489, -208.09174527275601, 431.6279830653084, -95.35731060806204, -12.99427489612573, -193.46627128146514, 510.58339146599883, 532.4850218934048, 490.40643165380806, 545.9633885079206, 214.1383394253749, 308.118322202016, 104.96999792986176, 421.38644001093036, -91.82797831428665, 413.1962586691062, -172.83868711936648, -81.3578651799909, -293.5256426086221, -165.4596623316158, 334.5196730626464, 489.3718395021239, 474.5799303934652, 498.10595329984204, 488.3551646758046, 90.22430652436486, 39.41112568854696, 290.4342275684257, -131.59566375644016, 421.2142188726082, -51.034671630895716, 303.98129274838504, -113.82392452922356, 472.8275131606058, 493.07440420566127, 472.2749737132833, 479.0324418685987, 496.84760741364187, 61.97521385970926, -0.9165339503750403, 232.87100184612493], "policy_AGENT-0_reward": [-115.89712574755166, 638.7598682080326, -176.24182803829012, 370.6539626481323, -104.95717966581901, 199.37167801832686, 508.3169930450472, 17.807657731333475, 399.71427634673665, 107.5006955027292, 277.53535675248213, -2.9454868018602554, 203.23679200482144, 186.18790725136398, 535.5280441820826, 623.3452503916029, -88.88807719114429, 369.2879081660625, -24.641875198861776, 412.5624063932163, 234.6947863458008, 711.0527068539209, 305.6804803438401, 192.8677989722325, 292.7472795638439, 544.7403883558361, -208.39873471436965, 183.33787597370312, 180.3841393421105, 132.24443137593488, -77.29331192271931, 576.0704658632139, -98.20296758258709, 707.3994264447967, 66.98094170054021, 422.38242915651875, 243.66004582069655, 487.31602041518795, 194.93546244631182, 384.056671810118, -61.090868502862634, 282.0382463682835, 481.74213754125685, 278.1768756185994, 732.8728789282811, -8.70569265405608, -83.72659607988948, 560.2056910149412, 249.97139037395448, 382.999632150755, 29.08164519008018, 388.29245904648906, 328.4514383433522, 322.4740707351018, 183.15010640619735, 481.7903867810008, 461.9203437006771, 364.9030863890442, 305.99351267918485, 232.49273303239372, -265.3359570856054, 327.652454768631, 906.8655687599723, -63.74815501511855, -192.77361715017935, 232.39171941724666, 151.8962254105889, 457.2744543750077, 30.963470276542235, 223.40745618061348, 566.1977464620426, 188.36517037726037, 186.47422739260864, -103.07132143388372, 271.07632591966245, -217.6843610149697, -65.6081423329, -332.5202999252551, -107.76457889183496, 253.92664388876372, 408.1288997463997, 109.11016719276003, 434.7320805807701, 253.8974014069256, 186.3380423872073, 200.8867145080607, 248.27058028810853, 596.1616183649102, 207.6096315676323, 355.4816577389709, 279.72867432685905, 47.343180902841446, 60.93252754613239, 492.29992831899455, -172.1677930676026, 468.31240412783706, 159.64010574093757, 189.0818718478727, 167.3351203026018, 493.755807490098]}, "sampler_perf": {"mean_env_wait_ms": 54.760730519919555, "mean_raw_obs_processing_ms": 2.147528918356677, "mean_inference_ms": 2.4827183739412875, "mean_action_processing_ms": 0.1490993138347979}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 180600, "timers": {"sample_time_ms": 70390.757, "sample_throughput": 59.667, "load_time_ms": 13.741, "load_throughput": 305654.246, "learn_time_ms": 10902.342, "learn_throughput": 385.238, "update_time_ms": 9.333}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 159.7860870361328, "policy_loss": -0.033599209040403366, "vf_loss": 159.81492614746094, "vf_explained_var": 0.9861074686050415, "kl": 0.010541689582169056, "entropy": 0.7384646534919739, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 56.12412643432617, "policy_loss": -0.025279546156525612, "vf_loss": 56.1459846496582, "vf_explained_var": 0.988760232925415, "kl": 0.011407298967242241, "entropy": 0.6882550120353699, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 243.0251007080078, "policy_loss": -0.0336313433945179, "vf_loss": 243.0549774169922, "vf_explained_var": 0.9813212752342224, "kl": 0.012616530992090702, "entropy": 0.8123142123222351, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 45.56714630126953, "policy_loss": -0.04208475723862648, "vf_loss": 45.6046028137207, "vf_explained_var": 0.9934737682342529, "kl": 0.01027934905141592, "entropy": 0.6301156878471375, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 180600, "num_steps_trained": 180600}, "done": false, "episodes_total": 1146, "training_iteration": 43, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-35-59", "timestamp": 1624203359, "time_this_iter_s": 69.90107154846191, "time_total_s": 4566.025520324707, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5f0038d40>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5f0038ef0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701c20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701e60>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a290>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701c20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701e60>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a290>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701c20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701e60>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a290>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701c20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8701e60>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5f031a290>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5d85f5b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4566.025520324707, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 49.53267326732674, "ram_util_percent": 87.89504950495045}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2831.4097591265104, "episode_reward_min": -1440.4968580281804, "episode_reward_mean": 888.3745386250732, "episode_len_mean": 283.04, "episodes_this_iter": 16, "policy_reward_min": {"AGENT-2": -282.5578181621812, "AGENT-1": -607.3052282070385, "AGENT-3": -728.1616158804651, "AGENT-0": -332.5202999252551}, "policy_reward_max": {"AGENT-2": 559.4493152624741, "AGENT-1": 976.3470084904952, "AGENT-3": 545.9633885079206, "AGENT-0": 906.8655687599723}, "policy_reward_mean": {"AGENT-2": 145.30445924289606, "AGENT-1": 312.2809503866931, "AGENT-3": 210.02512391642944, "AGENT-0": 220.7640050790547}, "custom_metrics": {"mean_ego_speed_mean": 37.4503725, "mean_ego_speed_min": 23.276, "mean_ego_speed_max": 50.88325, "distance_travelled_mean": 109.23737000000001, "distance_travelled_min": 33.6135, "distance_travelled_max": 125.04475}, "hist_stats": {"episode_reward": [-236.0670663568614, 138.52674487737679, -668.2129075937145, 1309.037062984242, 233.83875460535154, 1114.5452768834084, -513.6001988198939, 1345.0335930084482, 1965.3012360186617, 436.26612791330365, 2831.4097591265104, 1148.651334612195, 839.3917465885607, -1440.4968580281804, -229.5813725802634, 584.2892891374457, 2061.606536075906, 389.50083100782047, 2494.2346690751633, 641.6390465604351, 1678.186920354093, 1064.6570921625216, 1583.982115652838, 677.2767338212208, 747.7630948604437, -345.15248291454475, 1183.9136472144805, 891.5494679365321, 1569.0903225305271, 1440.544920738279, 974.0035832303669, 319.21057259590157, 2180.665858808847, 1316.8597875342427, 1632.9527881200336, 811.4900950937185, 1617.5401216737032, 1447.4465051914601, 1561.8546660842785, 559.402434236241, 1562.1350065417664, 922.684254884785, 1143.9508858581455, 396.17384187192977, 1416.8763535989488, -909.2054859334858, 1764.5280515335535, 1660.34772648424, 246.1589383520181, -651.1990901258645, 1315.4784634353332, 1089.0549548768042, 1911.3768406991155, 808.6774515984084, 903.6376807869202, 1910.3354196702214, 712.7350888652556, 1395.9967294805308, -342.0929049804869, 1591.501252373613, -625.9940480109863, 116.40572008972859, -1241.0811037916892, -546.2052722928714, 1457.006368618685, 1643.0503301428923, 889.6261923598789, 1806.7656759428596, 1206.6863331595182, 689.356990512582, 627.4739563373769, 1162.295951058577, 966.3368985045577, 1457.7388225987072, 579.1652242087279, 1463.6122502167327, -95.5459611486254, 1287.3835076653147, 1858.8149191336672, 186.8389269828957, 1935.5660190481185, 1044.8507185202955, 632.2887385514347, 474.69453874075464, 1754.9722442651448, -297.821235074052, 1712.017287861605, -476.39490062059866, 1765.4919723351509, -498.92928583427164, 1401.6452287126276, 1998.1947581572722, 581.9402733754204, 1771.6556955952703, 1034.0300253089247, 1415.1004249638663, -893.4038856774589, 686.8760016640413, 543.2453507996541, 1153.998899632742], "episode_lengths": [76, 193, 129, 228, 346, 238, 79, 154, 446, 206, 468, 175, 156, 456, 436, 441, 184, 198, 417, 218, 270, 434, 243, 201, 227, 29, 382, 112, 232, 338, 244, 122, 367, 142, 398, 237, 191, 162, 342, 443, 165, 207, 434, 344, 265, 139, 228, 404, 193, 89, 483, 188, 436, 204, 244, 485, 448, 220, 104, 239, 109, 187, 202, 106, 219, 436, 214, 453, 183, 493, 502, 480, 350, 244, 162, 208, 216, 265, 463, 227, 444, 191, 473, 453, 455, 548, 220, 110, 217, 88, 224, 422, 189, 443, 199, 416, 441, 475, 245, 453], "policy_AGENT-2_reward": [-44.05129184246848, 162.36292929755618, -150.30002348668847, 111.80935287202203, 185.75726103908184, 57.15666648026575, -160.49887864136545, 292.4160534654418, 395.2200778292452, -36.488148639888294, 459.40041193079014, 218.02571926096164, -8.269715568827063, -52.79086307047885, 120.21020088294037, 191.45871901497614, 397.7312880197204, -63.37090312006321, 490.93172247261185, 52.42033205149004, 326.10011197711304, 243.0775219815615, 322.35692285951757, 194.36713059125591, -9.983966924213602, -111.39895873824494, 281.46337528209824, -4.38713553123991, 251.12804672331563, -31.26548187667252, 25.268884894588233, 278.20786933111776, 559.4493152624741, 249.41908965829506, 308.5413071157518, 10.709389106137667, 318.7242311369195, 331.07010877935045, 321.91368155496855, 182.59541173121946, 382.3860547934712, -6.623842255449915, -10.20131483480409, 275.0217018006737, 221.12125570871575, -228.24979539704216, 368.1528468446571, -95.4150368587922, 161.23020311756625, -132.69692403044226, 201.59910999715254, 120.29092338731421, 383.8660666922927, -4.733123919683792, 222.82241058069155, 454.9875056211348, 187.79560252999846, 151.3605377826858, -55.93269824156747, 257.0858309649723, -117.98716057949629, 131.47266396433594, -282.5578181621812, -165.38160811751314, 218.37355015647907, 257.3618716682284, 213.90419495296533, 314.7127342919033, 220.68269921656776, 185.7519792144172, 200.3268536989779, 247.7101622465369, -131.44512526050121, 181.37842135058602, -51.04826055209071, 244.61819864184338, 84.19019172415571, 109.09981585169812, 278.65046552660243, -195.09995070921562, 396.01572819354664, 141.48591932769574, 188.51884018500635, 166.76145695672247, 439.3116922460197, -116.45823607613951, 50.115663272071814, -61.78235531272009, 336.8152203012829, -144.32953131922346, 233.4585264883546, 409.4492563863156, -16.421073835755102, 330.5086241002889, 76.98573465868974, 257.1684079223151, -3.501658497910121, 202.6711678654945, 185.62616950297001, -7.022586645902384], "policy_AGENT-1_reward": [-73.98366704581842, 162.79894428657113, -149.76576421274652, 643.856406450474, -83.33062063333152, 640.9968995579002, -96.27118536235787, 313.63128744538295, 573.7599151370055, 35.51389538497834, 976.3470084904952, 260.18589456041826, 391.70834625559536, -607.3052282070385, -173.74372138314487, 161.28220690424416, 606.0563947895087, 82.91643009200496, 795.6147100981988, 53.09679952746287, 466.52237267367326, 333.6517214105876, 478.7565337383253, 154.67817610288049, 383.8463195904736, -61.227987456458365, 351.8718150588087, 418.4826629385938, 638.2663160812062, 770.2649455999352, 636.4913695626626, 209.16551012512105, 617.3902430802568, 323.1643296635771, 468.15650202787754, 234.50139133709726, 409.8425692113892, 293.86714037146356, 407.26077224852236, 157.10904105953077, 445.6135390232733, 474.04172013583667, 472.83668505526515, -92.13797508615968, 644.7645706183526, -207.5279881780818, 637.0947668549559, 944.2545051911186, 161.67116514569634, -132.2622776637779, 370.9042425549343, 284.38278418549385, 579.829887978007, 236.48371673362865, 243.26947460024093, 581.0318453850253, 231.60431802813488, 636.7755242943061, -91.26090699074905, 650.1428368198731, -117.48383929715447, 131.8990636382836, -332.47734309563054, -107.59942295190717, 650.1865015107946, 488.18771922613917, 92.03189982068913, 559.2149077703444, 243.75106786022087, 227.04266238659284, 186.84926244179036, 375.8809809555055, 633.2160691565884, 647.5365508078798, 325.76649865274294, 635.2840844996458, -113.25540924639922, 644.523651106879, 594.7901210824094, 81.83169704643176, 592.2054448581364, 246.87708603802068, 192.7128126588458, 141.51449543180595, 589.0337426829041, 68.29897862350512, 638.9152673238589, -61.24952213363136, 642.4209547306206, -105.10930826714943, 642.6435465856995, 610.5336410823863, 116.89666574144626, 517.999339828932, 333.93167960080376, 366.9809701007856, -375.92076574592335, 208.17477510468464, 104.7412825787132, 632.3780972263191], "policy_AGENT-3_reward": [-43.99814863498802, -101.45366066561829, -181.1493314050311, 406.6504645049971, -83.89382312953391, 325.2344214741541, -160.5370894108358, 484.0809949810311, 532.9124612071748, 447.50843144522366, 524.2456562545666, 485.87608706096034, -8.130469764435833, -728.1616158804651, -296.8095903178614, 39.52537457225529, 481.74838740346297, 468.1582716184662, 500.2888100595531, 469.1409732809422, 463.18200654678907, 244.26780294967577, 295.55263863981054, 133.29596468077312, -10.155929615933992, -111.43466821697876, 268.5402105052898, -4.288197012078665, 401.51908410740657, -31.32742191326361, 320.9490214271709, -84.43621078044794, 443.62060945117406, 494.30497783841605, 473.25534682565103, 537.1976694604042, 500.6808622789061, 494.05781769729464, 510.2061415456869, 36.54787503929298, 252.34502594402122, -6.653966696278565, 316.41242924864065, -92.70339752176916, 318.497794239489, -208.09174527275601, 431.6279830653084, -95.35731060806204, -12.99427489612573, -193.46627128146514, 510.58339146599883, 532.4850218934048, 490.40643165380806, 545.9633885079206, 214.1383394253749, 308.118322202016, 104.96999792986176, 421.38644001093036, -91.82797831428665, 413.1962586691062, -172.83868711936648, -81.3578651799909, -293.5256426086221, -165.4596623316158, 334.5196730626464, 489.3718395021239, 474.5799303934652, 498.10595329984204, 488.3551646758046, 90.22430652436486, 39.41112568854696, 290.4342275684257, -131.59566375644016, 421.2142188726082, -51.034671630895716, 303.98129274838504, -113.82392452922356, 472.8275131606058, 493.07440420566127, 472.2749737132833, 479.0324418685987, 496.84760741364187, 61.97521385970926, -0.9165339503750403, 232.87100184612493, -133.764851873866, 384.2264890576421, -177.1211951359569, 415.60183465511517, -144.53326658207988, 326.17147762024484, 469.894867643523, 463.65702373839446, 523.4334553193146, 515.6119155466989, 513.4156901882859, -511.03597463176493, 72.79326668904001, 66.68999146660676, -6.8846551297572], "policy_AGENT-0_reward": [-74.03395883358662, -85.18146804113248, -186.99778848924825, 146.72083915675086, 215.30593732913462, 91.157289371089, -96.29304540533465, 254.90525711659237, 463.4087818452347, -10.268050277009795, 871.4166824506639, 184.5636337298543, 464.0835856662282, -52.239150870199325, 120.7617382378025, 192.02298864597003, 576.0704658632139, -98.20296758258709, 707.3994264447967, 66.98094170054021, 422.38242915651875, 243.66004582069655, 487.31602041518795, 194.93546244631182, 384.056671810118, -61.090868502862634, 282.0382463682835, 481.74213754125685, 278.1768756185994, 732.8728789282811, -8.70569265405608, -83.72659607988948, 560.2056910149412, 249.97139037395448, 382.999632150755, 29.08164519008018, 388.29245904648906, 328.4514383433522, 322.4740707351018, 183.15010640619735, 481.7903867810008, 461.9203437006771, 364.9030863890442, 305.99351267918485, 232.49273303239372, -265.3359570856054, 327.652454768631, 906.8655687599723, -63.74815501511855, -192.77361715017935, 232.39171941724666, 151.8962254105889, 457.2744543750077, 30.963470276542235, 223.40745618061348, 566.1977464620426, 188.36517037726037, 186.47422739260864, -103.07132143388372, 271.07632591966245, -217.6843610149697, -65.6081423329, -332.5202999252551, -107.76457889183496, 253.92664388876372, 408.1288997463997, 109.11016719276003, 434.7320805807701, 253.8974014069256, 186.3380423872073, 200.8867145080607, 248.27058028810853, 596.1616183649102, 207.6096315676323, 355.4816577389709, 279.72867432685905, 47.343180902841446, 60.93252754613239, 492.29992831899455, -172.1677930676026, 468.31240412783706, 159.64010574093757, 189.0818718478727, 167.3351203026018, 493.755807490098, -115.89712574755166, 638.7598682080326, -176.24182803829012, 370.6539626481323, -104.95717966581901, 199.37167801832686, 508.3169930450472, 17.807657731333475, 399.71427634673665, 107.5006955027292, 277.53535675248213, -2.9454868018602554, 203.23679200482144, 186.18790725136398, 535.5280441820826]}, "sampler_perf": {"mean_env_wait_ms": 54.307678422479306, "mean_raw_obs_processing_ms": 2.1246305033724457, "mean_inference_ms": 2.4705707317844308, "mean_action_processing_ms": 0.1485368647302585}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 184800, "timers": {"sample_time_ms": 70231.153, "sample_throughput": 59.803, "load_time_ms": 13.319, "load_throughput": 315335.8, "learn_time_ms": 10749.76, "learn_throughput": 390.706, "update_time_ms": 10.094}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 151.61302185058594, "policy_loss": -0.03475893288850784, "vf_loss": 151.64212036132812, "vf_explained_var": 0.9869381785392761, "kl": 0.012538374401628971, "entropy": 0.6994214653968811, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 79.46577453613281, "policy_loss": -0.027414580807089806, "vf_loss": 79.48925018310547, "vf_explained_var": 0.9880385398864746, "kl": 0.013139596208930016, "entropy": 0.6949805617332458, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 162.95169067382812, "policy_loss": -0.034316543489694595, "vf_loss": 162.9813232421875, "vf_explained_var": 0.9872156977653503, "kl": 0.015729794278740883, "entropy": 0.8285077214241028, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 112.3546142578125, "policy_loss": -0.04011762514710426, "vf_loss": 112.38993835449219, "vf_explained_var": 0.9871823787689209, "kl": 0.01060586329549551, "entropy": 0.7152351140975952, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 184800, "num_steps_trained": 184800}, "done": false, "episodes_total": 1162, "training_iteration": 44, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-37-19", "timestamp": 1624203439, "time_this_iter_s": 79.97833323478699, "time_total_s": 4646.003853559494, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5d85804d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5d85803b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8580170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8580050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8580830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8580950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8580170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8580050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8580830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8580950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8580170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8580050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8580830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8580950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8580170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8580050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8580830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8580950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5d85805f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4646.003853559494, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 48.176315789473676, "ram_util_percent": 87.8368421052631}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 2831.4097591265104, "episode_reward_min": -1440.4968580281804, "episode_reward_mean": 853.1118830284452, "episode_len_mean": 287.18, "episodes_this_iter": 14, "policy_reward_min": {"AGENT-2": -282.5578181621812, "AGENT-3": -728.1616158804651, "AGENT-0": -332.5202999252551, "AGENT-1": -607.3052282070385}, "policy_reward_max": {"AGENT-2": 559.4493152624741, "AGENT-3": 545.9633885079206, "AGENT-0": 906.8655687599723, "AGENT-1": 976.3470084904952}, "policy_reward_mean": {"AGENT-2": 141.13430351501472, "AGENT-3": 207.74550286270318, "AGENT-0": 200.4765361999165, "AGENT-1": 303.7555404508108}, "custom_metrics": {"mean_ego_speed_mean": 37.0740775, "mean_ego_speed_min": 21.89425, "mean_ego_speed_max": 50.88325, "distance_travelled_mean": 110.35448250000002, "distance_travelled_min": 55.094750000000005, "distance_travelled_max": 125.04475}, "hist_stats": {"episode_reward": [1394.2124290017255, -781.4046022348704, 1441.5461415918592, 1264.8363173165353, 1581.2348445313921, -446.4614443980574, 1558.8232131159875, 591.9797730276629, 2219.8442749592955, 894.228363380825, 391.3784922153982, 1305.8180754196012, 51.09936246022511, 1085.3921150253368, 974.0035832303669, 319.21057259590157, 2180.665858808847, 1316.8597875342427, 1632.9527881200336, 811.4900950937185, 1617.5401216737032, 1447.4465051914601, 1561.8546660842785, 559.402434236241, 1562.1350065417664, 922.684254884785, 1143.9508858581455, 396.17384187192977, 1416.8763535989488, -909.2054859334858, 1764.5280515335535, 1660.34772648424, 246.1589383520181, -651.1990901258645, 1315.4784634353332, 1089.0549548768042, 1911.3768406991155, 808.6774515984084, 903.6376807869202, 1910.3354196702214, 712.7350888652556, 1395.9967294805308, -342.0929049804869, 1591.501252373613, -625.9940480109863, 116.40572008972859, -1241.0811037916892, -546.2052722928714, 1457.006368618685, 1643.0503301428923, 889.6261923598789, 1806.7656759428596, 1206.6863331595182, 689.356990512582, 627.4739563373769, 1162.295951058577, 966.3368985045577, 1457.7388225987072, 579.1652242087279, 1463.6122502167327, -95.5459611486254, 1287.3835076653147, 1858.8149191336672, 186.8389269828957, 1935.5660190481185, 1044.8507185202955, 632.2887385514347, 474.69453874075464, 1754.9722442651448, -297.821235074052, 1712.017287861605, -476.39490062059866, 1765.4919723351509, -498.92928583427164, 1401.6452287126276, 1998.1947581572722, 581.9402733754204, 1771.6556955952703, 1034.0300253089247, 1415.1004249638663, -893.4038856774589, 686.8760016640413, 543.2453507996541, 1153.998899632742, -236.0670663568614, 138.52674487737679, -668.2129075937145, 1309.037062984242, 233.83875460535154, 1114.5452768834084, -513.6001988198939, 1345.0335930084482, 1965.3012360186617, 436.26612791330365, 2831.4097591265104, 1148.651334612195, 839.3917465885607, -1440.4968580281804, -229.5813725802634, 584.2892891374457], "episode_lengths": [226, 101, 243, 404, 251, 105, 400, 138, 411, 196, 396, 462, 114, 452, 244, 122, 367, 142, 398, 237, 191, 162, 342, 443, 165, 207, 434, 344, 265, 139, 228, 404, 193, 89, 483, 188, 436, 204, 244, 485, 448, 220, 104, 239, 109, 187, 202, 106, 219, 436, 214, 453, 183, 493, 502, 480, 350, 244, 162, 208, 216, 265, 463, 227, 444, 191, 473, 453, 455, 548, 220, 110, 217, 88, 224, 422, 189, 443, 199, 416, 441, 475, 245, 453, 76, 193, 129, 228, 346, 238, 79, 154, 446, 206, 468, 175, 156, 456, 436, 441], "policy_AGENT-2_reward": [170.50201602145273, -184.04791837339567, 200.831199094378, -104.41277417323381, 283.6252974412007, -54.23475137591596, 236.62811294802822, 17.41604955154809, 415.5092810178543, 64.0491053201666, 159.76189532959415, 285.24733898685463, 166.3864508489368, 264.893130342649, 25.268884894588233, 278.20786933111776, 559.4493152624741, 249.41908965829506, 308.5413071157518, 10.709389106137667, 318.7242311369195, 331.07010877935045, 321.91368155496855, 182.59541173121946, 382.3860547934712, -6.623842255449915, -10.20131483480409, 275.0217018006737, 221.12125570871575, -228.24979539704216, 368.1528468446571, -95.4150368587922, 161.23020311756625, -132.69692403044226, 201.59910999715254, 120.29092338731421, 383.8660666922927, -4.733123919683792, 222.82241058069155, 454.9875056211348, 187.79560252999846, 151.3605377826858, -55.93269824156747, 257.0858309649723, -117.98716057949629, 131.47266396433594, -282.5578181621812, -165.38160811751314, 218.37355015647907, 257.3618716682284, 213.90419495296533, 314.7127342919033, 220.68269921656776, 185.7519792144172, 200.3268536989779, 247.7101622465369, -131.44512526050121, 181.37842135058602, -51.04826055209071, 244.61819864184338, 84.19019172415571, 109.09981585169812, 278.65046552660243, -195.09995070921562, 396.01572819354664, 141.48591932769574, 188.51884018500635, 166.76145695672247, 439.3116922460197, -116.45823607613951, 50.115663272071814, -61.78235531272009, 336.8152203012829, -144.32953131922346, 233.4585264883546, 409.4492563863156, -16.421073835755102, 330.5086241002889, 76.98573465868974, 257.1684079223151, -3.501658497910121, 202.6711678654945, 185.62616950297001, -7.022586645902384, -44.05129184246848, 162.36292929755618, -150.30002348668847, 111.80935287202203, 185.75726103908184, 57.15666648026575, -160.49887864136545, 292.4160534654418, 395.2200778292452, -36.488148639888294, 459.40041193079014, 218.02571926096164, -8.269715568827063, -52.79086307047885, 120.21020088294037, 191.45871901497614], "policy_AGENT-3_reward": [440.5986994595966, -163.25882435795796, 437.51145780962315, -104.62874435453799, 418.72982567428744, -145.50152155078197, 527.1793107771982, 479.32643945521755, 503.5848123740499, 527.6830689728608, -19.16547210901051, 327.5227689508424, -111.79502808524171, 222.7390346451454, 320.9490214271709, -84.43621078044794, 443.62060945117406, 494.30497783841605, 473.25534682565103, 537.1976694604042, 500.6808622789061, 494.05781769729464, 510.2061415456869, 36.54787503929298, 252.34502594402122, -6.653966696278565, 316.41242924864065, -92.70339752176916, 318.497794239489, -208.09174527275601, 431.6279830653084, -95.35731060806204, -12.99427489612573, -193.46627128146514, 510.58339146599883, 532.4850218934048, 490.40643165380806, 545.9633885079206, 214.1383394253749, 308.118322202016, 104.96999792986176, 421.38644001093036, -91.82797831428665, 413.1962586691062, -172.83868711936648, -81.3578651799909, -293.5256426086221, -165.4596623316158, 334.5196730626464, 489.3718395021239, 474.5799303934652, 498.10595329984204, 488.3551646758046, 90.22430652436486, 39.41112568854696, 290.4342275684257, -131.59566375644016, 421.2142188726082, -51.034671630895716, 303.98129274838504, -113.82392452922356, 472.8275131606058, 493.07440420566127, 472.2749737132833, 479.0324418685987, 496.84760741364187, 61.97521385970926, -0.9165339503750403, 232.87100184612493, -133.764851873866, 384.2264890576421, -177.1211951359569, 415.60183465511517, -144.53326658207988, 326.17147762024484, 469.894867643523, 463.65702373839446, 523.4334553193146, 515.6119155466989, 513.4156901882859, -511.03597463176493, 72.79326668904001, 66.68999146660676, -6.8846551297572, -43.99814863498802, -101.45366066561829, -181.1493314050311, 406.6504645049971, -83.89382312953391, 325.2344214741541, -160.5370894108358, 484.0809949810311, 532.9124612071748, 447.50843144522366, 524.2456562545666, 485.87608706096034, -8.130469764435833, -728.1616158804651, -296.8095903178614, 39.52537457225529], "policy_AGENT-0_reward": [136.9047677016718, -217.07423667770775, 160.70111713936652, 718.4312190715472, 233.13960492757815, -192.95797932866654, 356.1026416970484, -39.9243342832732, 605.373654944191, 30.315821356380923, 160.32069162826093, 285.83581279304207, 166.9700394311578, 265.45205771393694, -8.70569265405608, -83.72659607988948, 560.2056910149412, 249.97139037395448, 382.999632150755, 29.08164519008018, 388.29245904648906, 328.4514383433522, 322.4740707351018, 183.15010640619735, 481.7903867810008, 461.9203437006771, 364.9030863890442, 305.99351267918485, 232.49273303239372, -265.3359570856054, 327.652454768631, 906.8655687599723, -63.74815501511855, -192.77361715017935, 232.39171941724666, 151.8962254105889, 457.2744543750077, 30.963470276542235, 223.40745618061348, 566.1977464620426, 188.36517037726037, 186.47422739260864, -103.07132143388372, 271.07632591966245, -217.6843610149697, -65.6081423329, -332.5202999252551, -107.76457889183496, 253.92664388876372, 408.1288997463997, 109.11016719276003, 434.7320805807701, 253.8974014069256, 186.3380423872073, 200.8867145080607, 248.27058028810853, 596.1616183649102, 207.6096315676323, 355.4816577389709, 279.72867432685905, 47.343180902841446, 60.93252754613239, 492.29992831899455, -172.1677930676026, 468.31240412783706, 159.64010574093757, 189.0818718478727, 167.3351203026018, 493.755807490098, -115.89712574755166, 638.7598682080326, -176.24182803829012, 370.6539626481323, -104.95717966581901, 199.37167801832686, 508.3169930450472, 17.807657731333475, 399.71427634673665, 107.5006955027292, 277.53535675248213, -2.9454868018602554, 203.23679200482144, 186.18790725136398, 535.5280441820826, -74.03395883358662, -85.18146804113248, -186.99778848924825, 146.72083915675086, 215.30593732913462, 91.157289371089, -96.29304540533465, 254.90525711659237, 463.4087818452347, -10.268050277009795, 871.4166824506639, 184.5636337298543, 464.0835856662282, -52.239150870199325, 120.7617382378025, 192.02298864597003], "policy_AGENT-1_reward": [646.2069458190017, -217.0236228258087, 642.5023675484921, 755.4466167727595, 645.7401164883263, -53.76719214269292, 438.9131476937113, 135.16161830416897, 695.3765266231997, 272.18036773141586, 90.4613773665541, 407.21215468886123, -170.46209973462823, 332.3078923236045, 636.4913695626626, 209.16551012512105, 617.3902430802568, 323.1643296635771, 468.15650202787754, 234.50139133709726, 409.8425692113892, 293.86714037146356, 407.26077224852236, 157.10904105953077, 445.6135390232733, 474.04172013583667, 472.83668505526515, -92.13797508615968, 644.7645706183526, -207.5279881780818, 637.0947668549559, 944.2545051911186, 161.67116514569634, -132.2622776637779, 370.9042425549343, 284.38278418549385, 579.829887978007, 236.48371673362865, 243.26947460024093, 581.0318453850253, 231.60431802813488, 636.7755242943061, -91.26090699074905, 650.1428368198731, -117.48383929715447, 131.8990636382836, -332.47734309563054, -107.59942295190717, 650.1865015107946, 488.18771922613917, 92.03189982068913, 559.2149077703444, 243.75106786022087, 227.04266238659284, 186.84926244179036, 375.8809809555055, 633.2160691565884, 647.5365508078798, 325.76649865274294, 635.2840844996458, -113.25540924639922, 644.523651106879, 594.7901210824094, 81.83169704643176, 592.2054448581364, 246.87708603802068, 192.7128126588458, 141.51449543180595, 589.0337426829041, 68.29897862350512, 638.9152673238589, -61.24952213363136, 642.4209547306206, -105.10930826714943, 642.6435465856995, 610.5336410823863, 116.89666574144626, 517.999339828932, 333.93167960080376, 366.9809701007856, -375.92076574592335, 208.17477510468464, 104.7412825787132, 632.3780972263191, -73.98366704581842, 162.79894428657113, -149.76576421274652, 643.856406450474, -83.33062063333152, 640.9968995579002, -96.27118536235787, 313.63128744538295, 573.7599151370055, 35.51389538497834, 976.3470084904952, 260.18589456041826, 391.70834625559536, -607.3052282070385, -173.74372138314487, 161.28220690424416]}, "sampler_perf": {"mean_env_wait_ms": 53.88608347554649, "mean_raw_obs_processing_ms": 2.100030977593402, "mean_inference_ms": 2.46240973137112, "mean_action_processing_ms": 0.14819654315951783}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 189000, "timers": {"sample_time_ms": 72792.101, "sample_throughput": 57.699, "load_time_ms": 13.389, "load_throughput": 313685.518, "learn_time_ms": 10711.811, "learn_throughput": 392.091, "update_time_ms": 10.225}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 129.6967010498047, "policy_loss": -0.017608139663934708, "vf_loss": 129.7101593017578, "vf_explained_var": 0.9897403120994568, "kl": 0.009210199117660522, "entropy": 0.7203887701034546, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 63.836673736572266, "policy_loss": -0.027634499594569206, "vf_loss": 63.860294342041016, "vf_explained_var": 0.9901454448699951, "kl": 0.013355042785406113, "entropy": 0.7149794697761536, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 239.1995849609375, "policy_loss": -0.033453699201345444, "vf_loss": 239.22763061523438, "vf_explained_var": 0.9857074022293091, "kl": 0.01803767867386341, "entropy": 0.7804906964302063, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 45.91840362548828, "policy_loss": -0.041319847106933594, "vf_loss": 45.95532989501953, "vf_explained_var": 0.9941454529762268, "kl": 0.009759467095136642, "entropy": 0.6213606595993042, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 189000, "num_steps_trained": 189000}, "done": false, "episodes_total": 1176, "training_iteration": 45, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-39-04", "timestamp": 1624203544, "time_this_iter_s": 105.18657541275024, "time_total_s": 4751.190428972244, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5d876ab90>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5d8795d40>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d87969e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796ef0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d87969e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796ef0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d87969e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796ef0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5f00cf9e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d87969e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8796ef0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5d8580b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4751.190428972244, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 49.54834437086093, "ram_util_percent": 87.91721854304633}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 3419.951363170714, "episode_reward_min": -1440.4968580281804, "episode_reward_mean": 867.9281943585, "episode_len_mean": 297.28, "episodes_this_iter": 13, "policy_reward_min": {"AGENT-2": -282.5578181621812, "AGENT-3": -728.1616158804651, "AGENT-0": -332.5202999252551, "AGENT-1": -607.3052282070385}, "policy_reward_max": {"AGENT-2": 465.7186383113194, "AGENT-3": 545.9633885079206, "AGENT-0": 1717.8618411622813, "AGENT-1": 1755.144715608718}, "policy_reward_mean": {"AGENT-2": 137.13843467896936, "AGENT-3": 196.3910756545399, "AGENT-0": 217.53726624582595, "AGENT-1": 316.86141777916487}, "custom_metrics": {"mean_ego_speed_mean": 37.041244999999996, "mean_ego_speed_min": 21.89425, "mean_ego_speed_max": 50.88325, "distance_travelled_mean": 110.76603750000002, "distance_travelled_min": 58.454, "distance_travelled_max": 125.04475}, "hist_stats": {"episode_reward": [1122.1890160214948, 313.72154617148345, 1571.5455378309628, 3419.951363170714, 1332.542926181024, 2590.788240122498, 534.7127214538988, 2641.1919813805075, 1734.2894871814829, 1570.3988303069982, 311.34284887170196, -77.23057595097156, 466.3837701171749, 396.17384187192977, 1416.8763535989488, -909.2054859334858, 1764.5280515335535, 1660.34772648424, 246.1589383520181, -651.1990901258645, 1315.4784634353332, 1089.0549548768042, 1911.3768406991155, 808.6774515984084, 903.6376807869202, 1910.3354196702214, 712.7350888652556, 1395.9967294805308, -342.0929049804869, 1591.501252373613, -625.9940480109863, 116.40572008972859, -1241.0811037916892, -546.2052722928714, 1457.006368618685, 1643.0503301428923, 889.6261923598789, 1806.7656759428596, 1206.6863331595182, 689.356990512582, 627.4739563373769, 1162.295951058577, 966.3368985045577, 1457.7388225987072, 579.1652242087279, 1463.6122502167327, -95.5459611486254, 1287.3835076653147, 1858.8149191336672, 186.8389269828957, 1935.5660190481185, 1044.8507185202955, 632.2887385514347, 474.69453874075464, 1754.9722442651448, -297.821235074052, 1712.017287861605, -476.39490062059866, 1765.4919723351509, -498.92928583427164, 1401.6452287126276, 1998.1947581572722, 581.9402733754204, 1771.6556955952703, 1034.0300253089247, 1415.1004249638663, -893.4038856774589, 686.8760016640413, 543.2453507996541, 1153.998899632742, -236.0670663568614, 138.52674487737679, -668.2129075937145, 1309.037062984242, 233.83875460535154, 1114.5452768834084, -513.6001988198939, 1345.0335930084482, 1965.3012360186617, 436.26612791330365, 2831.4097591265104, 1148.651334612195, 839.3917465885607, -1440.4968580281804, -229.5813725802634, 584.2892891374457, 1394.2124290017255, -781.4046022348704, 1441.5461415918592, 1264.8363173165353, 1581.2348445313921, -446.4614443980574, 1558.8232131159875, 591.9797730276629, 2219.8442749592955, 894.228363380825, 391.3784922153982, 1305.8180754196012, 51.09936246022511, 1085.3921150253368], "episode_lengths": [233, 376, 214, 491, 218, 427, 195, 451, 160, 418, 448, 421, 412, 344, 265, 139, 228, 404, 193, 89, 483, 188, 436, 204, 244, 485, 448, 220, 104, 239, 109, 187, 202, 106, 219, 436, 214, 453, 183, 493, 502, 480, 350, 244, 162, 208, 216, 265, 463, 227, 444, 191, 473, 453, 455, 548, 220, 110, 217, 88, 224, 422, 189, 443, 199, 416, 441, 475, 245, 453, 76, 193, 129, 228, 346, 238, 79, 154, 446, 206, 468, 175, 156, 456, 436, 441, 226, 101, 243, 404, 251, 105, 400, 138, 411, 196, 396, 462, 114, 452], "policy_AGENT-2_reward": [47.28877662538061, 288.86803476595907, 251.4604844296303, -26.51572078802839, 198.28439871975905, 465.7186383113194, -6.107038317139384, 182.86267867011406, 385.6997937919191, 329.293221802973, 161.86598255916707, 98.74030969646208, 174.4137424019902, 275.0217018006737, 221.12125570871575, -228.24979539704216, 368.1528468446571, -95.4150368587922, 161.23020311756625, -132.69692403044226, 201.59910999715254, 120.29092338731421, 383.8660666922927, -4.733123919683792, 222.82241058069155, 454.9875056211348, 187.79560252999846, 151.3605377826858, -55.93269824156747, 257.0858309649723, -117.98716057949629, 131.47266396433594, -282.5578181621812, -165.38160811751314, 218.37355015647907, 257.3618716682284, 213.90419495296533, 314.7127342919033, 220.68269921656776, 185.7519792144172, 200.3268536989779, 247.7101622465369, -131.44512526050121, 181.37842135058602, -51.04826055209071, 244.61819864184338, 84.19019172415571, 109.09981585169812, 278.65046552660243, -195.09995070921562, 396.01572819354664, 141.48591932769574, 188.51884018500635, 166.76145695672247, 439.3116922460197, -116.45823607613951, 50.115663272071814, -61.78235531272009, 336.8152203012829, -144.32953131922346, 233.4585264883546, 409.4492563863156, -16.421073835755102, 330.5086241002889, 76.98573465868974, 257.1684079223151, -3.501658497910121, 202.6711678654945, 185.62616950297001, -7.022586645902384, -44.05129184246848, 162.36292929755618, -150.30002348668847, 111.80935287202203, 185.75726103908184, 57.15666648026575, -160.49887864136545, 292.4160534654418, 395.2200778292452, -36.488148639888294, 459.40041193079014, 218.02571926096164, -8.269715568827063, -52.79086307047885, 120.21020088294037, 191.45871901497614, 170.50201602145273, -184.04791837339567, 200.831199094378, -104.41277417323381, 283.6252974412007, -54.23475137591596, 236.62811294802822, 17.41604955154809, 415.5092810178543, 64.0491053201666, 159.76189532959415, 285.24733898685463, 166.3864508489368, 264.893130342649], "policy_AGENT-3_reward": [347.3035204786123, -148.94451808030934, 393.24089041173096, -26.539472812246952, 332.46214867876, 511.9163770406873, 477.69040211551845, 504.0677888217088, 505.0101768482845, 518.5490600649363, -69.82321775434565, -193.4216897306622, 1.5334123809243643, -92.70339752176916, 318.497794239489, -208.09174527275601, 431.6279830653084, -95.35731060806204, -12.99427489612573, -193.46627128146514, 510.58339146599883, 532.4850218934048, 490.40643165380806, 545.9633885079206, 214.1383394253749, 308.118322202016, 104.96999792986176, 421.38644001093036, -91.82797831428665, 413.1962586691062, -172.83868711936648, -81.3578651799909, -293.5256426086221, -165.4596623316158, 334.5196730626464, 489.3718395021239, 474.5799303934652, 498.10595329984204, 488.3551646758046, 90.22430652436486, 39.41112568854696, 290.4342275684257, -131.59566375644016, 421.2142188726082, -51.034671630895716, 303.98129274838504, -113.82392452922356, 472.8275131606058, 493.07440420566127, 472.2749737132833, 479.0324418685987, 496.84760741364187, 61.97521385970926, -0.9165339503750403, 232.87100184612493, -133.764851873866, 384.2264890576421, -177.1211951359569, 415.60183465511517, -144.53326658207988, 326.17147762024484, 469.894867643523, 463.65702373839446, 523.4334553193146, 515.6119155466989, 513.4156901882859, -511.03597463176493, 72.79326668904001, 66.68999146660676, -6.8846551297572, -43.99814863498802, -101.45366066561829, -181.1493314050311, 406.6504645049971, -83.89382312953391, 325.2344214741541, -160.5370894108358, 484.0809949810311, 532.9124612071748, 447.50843144522366, 524.2456562545666, 485.87608706096034, -8.130469764435833, -728.1616158804651, -296.8095903178614, 39.52537457225529, 440.5986994595966, -163.25882435795796, 437.51145780962315, -104.62874435453799, 418.72982567428744, -145.50152155078197, 527.1793107771982, 479.32643945521755, 503.5848123740499, 527.6830689728608, -19.16547210901051, 327.5227689508424, -111.79502808524171, 222.7390346451454], "policy_AGENT-0_reward": [82.27264069748506, 322.17691802841665, 286.353233209141, 1717.8618411622813, 164.4391907356041, 759.9418036115851, -41.53412927766767, 923.243411246178, 412.501141285777, 302.9276548471783, 162.4292516481588, 99.29274553272572, 174.9752632617297, 305.99351267918485, 232.49273303239372, -265.3359570856054, 327.652454768631, 906.8655687599723, -63.74815501511855, -192.77361715017935, 232.39171941724666, 151.8962254105889, 457.2744543750077, 30.963470276542235, 223.40745618061348, 566.1977464620426, 188.36517037726037, 186.47422739260864, -103.07132143388372, 271.07632591966245, -217.6843610149697, -65.6081423329, -332.5202999252551, -107.76457889183496, 253.92664388876372, 408.1288997463997, 109.11016719276003, 434.7320805807701, 253.8974014069256, 186.3380423872073, 200.8867145080607, 248.27058028810853, 596.1616183649102, 207.6096315676323, 355.4816577389709, 279.72867432685905, 47.343180902841446, 60.93252754613239, 492.29992831899455, -172.1677930676026, 468.31240412783706, 159.64010574093757, 189.0818718478727, 167.3351203026018, 493.755807490098, -115.89712574755166, 638.7598682080326, -176.24182803829012, 370.6539626481323, -104.95717966581901, 199.37167801832686, 508.3169930450472, 17.807657731333475, 399.71427634673665, 107.5006955027292, 277.53535675248213, -2.9454868018602554, 203.23679200482144, 186.18790725136398, 535.5280441820826, -74.03395883358662, -85.18146804113248, -186.99778848924825, 146.72083915675086, 215.30593732913462, 91.157289371089, -96.29304540533465, 254.90525711659237, 463.4087818452347, -10.268050277009795, 871.4166824506639, 184.5636337298543, 464.0835856662282, -52.239150870199325, 120.7617382378025, 192.02298864597003, 136.9047677016718, -217.07423667770775, 160.70111713936652, 718.4312190715472, 233.13960492757815, -192.95797932866654, 356.1026416970484, -39.9243342832732, 605.373654944191, 30.315821356380923, 160.32069162826093, 285.83581279304207, 166.9700394311578, 265.45205771393694], "policy_AGENT-1_reward": [645.3240782200139, -148.3788885425824, 640.4909297804604, 1755.144715608718, 637.3571880468986, 853.2114211589055, 104.66348693318756, 1031.0181026425078, 431.0783752555048, 419.62889359191007, 56.87083241872225, -81.84194144949736, 115.4613520725313, -92.13797508615968, 644.7645706183526, -207.5279881780818, 637.0947668549559, 944.2545051911186, 161.67116514569634, -132.2622776637779, 370.9042425549343, 284.38278418549385, 579.829887978007, 236.48371673362865, 243.26947460024093, 581.0318453850253, 231.60431802813488, 636.7755242943061, -91.26090699074905, 650.1428368198731, -117.48383929715447, 131.8990636382836, -332.47734309563054, -107.59942295190717, 650.1865015107946, 488.18771922613917, 92.03189982068913, 559.2149077703444, 243.75106786022087, 227.04266238659284, 186.84926244179036, 375.8809809555055, 633.2160691565884, 647.5365508078798, 325.76649865274294, 635.2840844996458, -113.25540924639922, 644.523651106879, 594.7901210824094, 81.83169704643176, 592.2054448581364, 246.87708603802068, 192.7128126588458, 141.51449543180595, 589.0337426829041, 68.29897862350512, 638.9152673238589, -61.24952213363136, 642.4209547306206, -105.10930826714943, 642.6435465856995, 610.5336410823863, 116.89666574144626, 517.999339828932, 333.93167960080376, 366.9809701007856, -375.92076574592335, 208.17477510468464, 104.7412825787132, 632.3780972263191, -73.98366704581842, 162.79894428657113, -149.76576421274652, 643.856406450474, -83.33062063333152, 640.9968995579002, -96.27118536235787, 313.63128744538295, 573.7599151370055, 35.51389538497834, 976.3470084904952, 260.18589456041826, 391.70834625559536, -607.3052282070385, -173.74372138314487, 161.28220690424416, 646.2069458190017, -217.0236228258087, 642.5023675484921, 755.4466167727595, 645.7401164883263, -53.76719214269292, 438.9131476937113, 135.16161830416897, 695.3765266231997, 272.18036773141586, 90.4613773665541, 407.21215468886123, -170.46209973462823, 332.3078923236045]}, "sampler_perf": {"mean_env_wait_ms": 53.51765659542562, "mean_raw_obs_processing_ms": 2.0792543582865535, "mean_inference_ms": 2.4533903192922177, "mean_action_processing_ms": 0.14780301890154812}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 193200, "timers": {"sample_time_ms": 73213.832, "sample_throughput": 57.366, "load_time_ms": 13.272, "load_throughput": 316455.711, "learn_time_ms": 10590.775, "learn_throughput": 396.572, "update_time_ms": 10.307}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 126.8377685546875, "policy_loss": -0.027492817491292953, "vf_loss": 126.86024475097656, "vf_explained_var": 0.9863206148147583, "kl": 0.011143198236823082, "entropy": 0.6408345103263855, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 76.11474609375, "policy_loss": -0.023467235267162323, "vf_loss": 76.13396453857422, "vf_explained_var": 0.9849230647087097, "kl": 0.014226561412215233, "entropy": 0.6969917416572571, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 185.48886108398438, "policy_loss": -0.030084319412708282, "vf_loss": 185.5136260986328, "vf_explained_var": 0.9843713641166687, "kl": 0.01771632768213749, "entropy": 0.7575613856315613, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 149.71524047851562, "policy_loss": -0.03102831356227398, "vf_loss": 149.742431640625, "vf_explained_var": 0.9812784790992737, "kl": 0.008525439538061619, "entropy": 0.5831260681152344, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 193200, "num_steps_trained": 193200}, "done": false, "episodes_total": 1189, "training_iteration": 46, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-40-25", "timestamp": 1624203625, "time_this_iter_s": 80.7078869342804, "time_total_s": 4831.898315906525, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5d858c4d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5d858c3b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d858c170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d858c050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d858c830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d858c950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d858c170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d858c050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d858c830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d858c950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d858c170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d858c050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d858c830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d858c950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d858c170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d858c050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d858c830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d858c950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5d858c5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4831.898315906525, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 48.079130434782606, "ram_util_percent": 87.89391304347822}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 3419.951363170714, "episode_reward_min": -1440.4968580281804, "episode_reward_mean": 852.3595252966529, "episode_len_mean": 297.04, "episodes_this_iter": 13, "policy_reward_min": {"AGENT-2": -282.5578181621812, "AGENT-1": -607.3052282070385, "AGENT-3": -728.1616158804651, "AGENT-0": -332.5202999252551}, "policy_reward_max": {"AGENT-2": 475.9247101171576, "AGENT-1": 1755.144715608718, "AGENT-3": 538.0885419518839, "AGENT-0": 1717.8618411622813}, "policy_reward_mean": {"AGENT-2": 134.93801369841944, "AGENT-1": 306.7582590817297, "AGENT-3": 193.34592262588322, "AGENT-0": 217.3173298906208}, "custom_metrics": {"mean_ego_speed_mean": 36.703435000000006, "mean_ego_speed_min": 21.16725, "mean_ego_speed_max": 50.88325, "distance_travelled_mean": 110.13903, "distance_travelled_min": 58.454, "distance_travelled_max": 124.973}, "hist_stats": {"episode_reward": [-573.9510639229427, 1354.3260597608169, -783.0496013237541, 1396.8294688364754, 692.61561194676, 1071.8558837416942, 2556.3667816404486, 972.0428722145618, 2716.685909668946, 611.9031251574918, 379.47781048303233, -79.42145122287536, -10.3071663172109, 712.7350888652556, 1395.9967294805308, -342.0929049804869, 1591.501252373613, -625.9940480109863, 116.40572008972859, -1241.0811037916892, -546.2052722928714, 1457.006368618685, 1643.0503301428923, 889.6261923598789, 1806.7656759428596, 1206.6863331595182, 689.356990512582, 627.4739563373769, 1162.295951058577, 966.3368985045577, 1457.7388225987072, 579.1652242087279, 1463.6122502167327, -95.5459611486254, 1287.3835076653147, 1858.8149191336672, 186.8389269828957, 1935.5660190481185, 1044.8507185202955, 632.2887385514347, 474.69453874075464, 1754.9722442651448, -297.821235074052, 1712.017287861605, -476.39490062059866, 1765.4919723351509, -498.92928583427164, 1401.6452287126276, 1998.1947581572722, 581.9402733754204, 1771.6556955952703, 1034.0300253089247, 1415.1004249638663, -893.4038856774589, 686.8760016640413, 543.2453507996541, 1153.998899632742, -236.0670663568614, 138.52674487737679, -668.2129075937145, 1309.037062984242, 233.83875460535154, 1114.5452768834084, -513.6001988198939, 1345.0335930084482, 1965.3012360186617, 436.26612791330365, 2831.4097591265104, 1148.651334612195, 839.3917465885607, -1440.4968580281804, -229.5813725802634, 584.2892891374457, 1394.2124290017255, -781.4046022348704, 1441.5461415918592, 1264.8363173165353, 1581.2348445313921, -446.4614443980574, 1558.8232131159875, 591.9797730276629, 2219.8442749592955, 894.228363380825, 391.3784922153982, 1305.8180754196012, 51.09936246022511, 1085.3921150253368, 1122.1890160214948, 313.72154617148345, 1571.5455378309628, 3419.951363170714, 1332.542926181024, 2590.788240122498, 534.7127214538988, 2641.1919813805075, 1734.2894871814829, 1570.3988303069982, 311.34284887170196, -77.23057595097156, 466.3837701171749], "episode_lengths": [374, 274, 98, 249, 285, 197, 248, 186, 447, 197, 454, 416, 253, 448, 220, 104, 239, 109, 187, 202, 106, 219, 436, 214, 453, 183, 493, 502, 480, 350, 244, 162, 208, 216, 265, 463, 227, 444, 191, 473, 453, 455, 548, 220, 110, 217, 88, 224, 422, 189, 443, 199, 416, 441, 475, 245, 453, 76, 193, 129, 228, 346, 238, 79, 154, 446, 206, 468, 175, 156, 456, 436, 441, 226, 101, 243, 404, 251, 105, 400, 138, 411, 196, 396, 462, 114, 452, 233, 376, 214, 491, 218, 427, 195, 451, 160, 418, 448, 421, 412], "policy_AGENT-2_reward": [-155.9355696294448, 152.40488277171647, -214.4815069452349, 195.80529528453422, 419.91920698732696, 184.73431662404056, 475.9247101171576, 81.8683178160966, 147.15184705796756, 36.7857473366839, 162.92986079349612, 110.37659703916898, 130.4713402357347, 187.79560252999846, 151.3605377826858, -55.93269824156747, 257.0858309649723, -117.98716057949629, 131.47266396433594, -282.5578181621812, -165.38160811751314, 218.37355015647907, 257.3618716682284, 213.90419495296533, 314.7127342919033, 220.68269921656776, 185.7519792144172, 200.3268536989779, 247.7101622465369, -131.44512526050121, 181.37842135058602, -51.04826055209071, 244.61819864184338, 84.19019172415571, 109.09981585169812, 278.65046552660243, -195.09995070921562, 396.01572819354664, 141.48591932769574, 188.51884018500635, 166.76145695672247, 439.3116922460197, -116.45823607613951, 50.115663272071814, -61.78235531272009, 336.8152203012829, -144.32953131922346, 233.4585264883546, 409.4492563863156, -16.421073835755102, 330.5086241002889, 76.98573465868974, 257.1684079223151, -3.501658497910121, 202.6711678654945, 185.62616950297001, -7.022586645902384, -44.05129184246848, 162.36292929755618, -150.30002348668847, 111.80935287202203, 185.75726103908184, 57.15666648026575, -160.49887864136545, 292.4160534654418, 395.2200778292452, -36.488148639888294, 459.40041193079014, 218.02571926096164, -8.269715568827063, -52.79086307047885, 120.21020088294037, 191.45871901497614, 170.50201602145273, -184.04791837339567, 200.831199094378, -104.41277417323381, 283.6252974412007, -54.23475137591596, 236.62811294802822, 17.41604955154809, 415.5092810178543, 64.0491053201666, 159.76189532959415, 285.24733898685463, 166.3864508489368, 264.893130342649, 47.28877662538061, 288.86803476595907, 251.4604844296303, -26.51572078802839, 198.28439871975905, 465.7186383113194, -6.107038317139384, 182.86267867011406, 385.6997937919191, 329.293221802973, 161.86598255916707, 98.74030969646208, 174.4137424019902], "policy_AGENT-1_reward": [-68.73812842431676, 629.3909434592596, -177.0404313917163, 657.2579206775173, -87.93218045619514, 199.1147260477653, 790.4496879804869, 263.5860648233737, 1072.483471402705, 94.76645488613698, 81.6279494979691, -95.64379759767323, -117.87983232939526, 231.60431802813488, 636.7755242943061, -91.26090699074905, 650.1428368198731, -117.48383929715447, 131.8990636382836, -332.47734309563054, -107.59942295190717, 650.1865015107946, 488.18771922613917, 92.03189982068913, 559.2149077703444, 243.75106786022087, 227.04266238659284, 186.84926244179036, 375.8809809555055, 633.2160691565884, 647.5365508078798, 325.76649865274294, 635.2840844996458, -113.25540924639922, 644.523651106879, 594.7901210824094, 81.83169704643176, 592.2054448581364, 246.87708603802068, 192.7128126588458, 141.51449543180595, 589.0337426829041, 68.29897862350512, 638.9152673238589, -61.24952213363136, 642.4209547306206, -105.10930826714943, 642.6435465856995, 610.5336410823863, 116.89666574144626, 517.999339828932, 333.93167960080376, 366.9809701007856, -375.92076574592335, 208.17477510468464, 104.7412825787132, 632.3780972263191, -73.98366704581842, 162.79894428657113, -149.76576421274652, 643.856406450474, -83.33062063333152, 640.9968995579002, -96.27118536235787, 313.63128744538295, 573.7599151370055, 35.51389538497834, 976.3470084904952, 260.18589456041826, 391.70834625559536, -607.3052282070385, -173.74372138314487, 161.28220690424416, 646.2069458190017, -217.0236228258087, 642.5023675484921, 755.4466167727595, 645.7401164883263, -53.76719214269292, 438.9131476937113, 135.16161830416897, 695.3765266231997, 272.18036773141586, 90.4613773665541, 407.21215468886123, -170.46209973462823, 332.3078923236045, 645.3240782200139, -148.3788885425824, 640.4909297804604, 1755.144715608718, 637.3571880468986, 853.2114211589055, 104.66348693318756, 1031.0181026425078, 431.0783752555048, 419.62889359191007, 56.87083241872225, -81.84194144949736, 115.4613520725313], "policy_AGENT-3_reward": [-193.89128265950592, 425.02376892688864, -177.60306985199048, 325.1995623431958, -88.49723105302854, 486.6346607959464, 538.0885419518839, 514.9625234563806, 521.3467526069276, 481.0359215450556, -28.57218089578921, -205.1008471180955, -153.93475004039303, 104.96999792986176, 421.38644001093036, -91.82797831428665, 413.1962586691062, -172.83868711936648, -81.3578651799909, -293.5256426086221, -165.4596623316158, 334.5196730626464, 489.3718395021239, 474.5799303934652, 498.10595329984204, 488.3551646758046, 90.22430652436486, 39.41112568854696, 290.4342275684257, -131.59566375644016, 421.2142188726082, -51.034671630895716, 303.98129274838504, -113.82392452922356, 472.8275131606058, 493.07440420566127, 472.2749737132833, 479.0324418685987, 496.84760741364187, 61.97521385970926, -0.9165339503750403, 232.87100184612493, -133.764851873866, 384.2264890576421, -177.1211951359569, 415.60183465511517, -144.53326658207988, 326.17147762024484, 469.894867643523, 463.65702373839446, 523.4334553193146, 515.6119155466989, 513.4156901882859, -511.03597463176493, 72.79326668904001, 66.68999146660676, -6.8846551297572, -43.99814863498802, -101.45366066561829, -181.1493314050311, 406.6504645049971, -83.89382312953391, 325.2344214741541, -160.5370894108358, 484.0809949810311, 532.9124612071748, 447.50843144522366, 524.2456562545666, 485.87608706096034, -8.130469764435833, -728.1616158804651, -296.8095903178614, 39.52537457225529, 440.5986994595966, -163.25882435795796, 437.51145780962315, -104.62874435453799, 418.72982567428744, -145.50152155078197, 527.1793107771982, 479.32643945521755, 503.5848123740499, 527.6830689728608, -19.16547210901051, 327.5227689508424, -111.79502808524171, 222.7390346451454, 347.3035204786123, -148.94451808030934, 393.24089041173096, -26.539472812246952, 332.46214867876, 511.9163770406873, 477.69040211551845, 504.0677888217088, 505.0101768482845, 518.5490600649363, -69.82321775434565, -193.4216897306622, 1.5334123809243643], "policy_AGENT-0_reward": [-155.38608320967597, 147.50646460295238, -213.92459313481214, 218.56669053122994, 449.1258164686562, 201.3721802739422, 751.9038415909205, 111.62596611871106, 975.7038386013439, -0.6849986103846106, 163.4921810873554, 110.9465964537246, 131.0360758168433, 188.36517037726037, 186.47422739260864, -103.07132143388372, 271.07632591966245, -217.6843610149697, -65.6081423329, -332.5202999252551, -107.76457889183496, 253.92664388876372, 408.1288997463997, 109.11016719276003, 434.7320805807701, 253.8974014069256, 186.3380423872073, 200.8867145080607, 248.27058028810853, 596.1616183649102, 207.6096315676323, 355.4816577389709, 279.72867432685905, 47.343180902841446, 60.93252754613239, 492.29992831899455, -172.1677930676026, 468.31240412783706, 159.64010574093757, 189.0818718478727, 167.3351203026018, 493.755807490098, -115.89712574755166, 638.7598682080326, -176.24182803829012, 370.6539626481323, -104.95717966581901, 199.37167801832686, 508.3169930450472, 17.807657731333475, 399.71427634673665, 107.5006955027292, 277.53535675248213, -2.9454868018602554, 203.23679200482144, 186.18790725136398, 535.5280441820826, -74.03395883358662, -85.18146804113248, -186.99778848924825, 146.72083915675086, 215.30593732913462, 91.157289371089, -96.29304540533465, 254.90525711659237, 463.4087818452347, -10.268050277009795, 871.4166824506639, 184.5636337298543, 464.0835856662282, -52.239150870199325, 120.7617382378025, 192.02298864597003, 136.9047677016718, -217.07423667770775, 160.70111713936652, 718.4312190715472, 233.13960492757815, -192.95797932866654, 356.1026416970484, -39.9243342832732, 605.373654944191, 30.315821356380923, 160.32069162826093, 285.83581279304207, 166.9700394311578, 265.45205771393694, 82.27264069748506, 322.17691802841665, 286.353233209141, 1717.8618411622813, 164.4391907356041, 759.9418036115851, -41.53412927766767, 923.243411246178, 412.501141285777, 302.9276548471783, 162.4292516481588, 99.29274553272572, 174.9752632617297]}, "sampler_perf": {"mean_env_wait_ms": 53.25234376078161, "mean_raw_obs_processing_ms": 2.0628652899483906, "mean_inference_ms": 2.444396087137031, "mean_action_processing_ms": 0.14737170882197506}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 197400, "timers": {"sample_time_ms": 74703.337, "sample_throughput": 56.222, "load_time_ms": 13.27, "load_throughput": 316505.746, "learn_time_ms": 10539.343, "learn_throughput": 398.507, "update_time_ms": 10.29}, "info": {"learner": {"AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 68.65003204345703, "policy_loss": -0.025499990209937096, "vf_loss": 68.67205047607422, "vf_explained_var": 0.9896519184112549, "kl": 0.011602265760302544, "entropy": 0.6793940663337708, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 87.94757080078125, "policy_loss": -0.03422052785754204, "vf_loss": 87.9778823852539, "vf_explained_var": 0.9907315969467163, "kl": 0.008711363188922405, "entropy": 0.5507029294967651, "entropy_coeff": 0.0, "model": {}}, "AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 176.322509765625, "policy_loss": -0.032712046056985855, "vf_loss": 176.35073852539062, "vf_explained_var": 0.9881579875946045, "kl": 0.009937633760273457, "entropy": 0.675052285194397, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 291.9945373535156, "policy_loss": -0.032288435846567154, "vf_loss": 292.02239990234375, "vf_explained_var": 0.9792525768280029, "kl": 0.014697184786200523, "entropy": 0.7213402390480042, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 197400, "num_steps_trained": 197400}, "done": false, "episodes_total": 1202, "training_iteration": 47, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-41-57", "timestamp": 1624203717, "time_this_iter_s": 91.29229640960693, "time_total_s": 4923.190612316132, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5d85f5b90>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5d85f5a70>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038b90>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0a70>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038b90>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0a70>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038b90>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0a70>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d85f5ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038b90>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5f0038d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d86e0a70>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5d858cb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4923.190612316132, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 48.36335877862596, "ram_util_percent": 87.91526717557251}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
{"episode_reward_max": 3419.951363170714, "episode_reward_min": -1440.4968580281804, "episode_reward_mean": 940.9285160311298, "episode_len_mean": 298.4, "episodes_this_iter": 16, "policy_reward_min": {"AGENT-2": -214.4815069452349, "AGENT-3": -728.1616158804651, "AGENT-0": -217.07423667770775, "AGENT-1": -607.3052282070385}, "policy_reward_max": {"AGENT-2": 577.4685335084791, "AGENT-3": 542.981274967033, "AGENT-0": 1717.8618411622813, "AGENT-1": 1755.144715608718}, "policy_reward_mean": {"AGENT-2": 154.0837731864518, "AGENT-3": 210.18599050988186, "AGENT-0": 247.69000962528608, "AGENT-1": 328.96874270951025}, "custom_metrics": {"mean_ego_speed_mean": 36.38279250000001, "mean_ego_speed_min": 21.16725, "mean_ego_speed_max": 50.88325, "distance_travelled_mean": 109.693125, "distance_travelled_min": 32.421, "distance_travelled_max": 124.973}, "hist_stats": {"episode_reward": [1693.733316027838, 196.40962719833152, 1500.0997997149566, 944.3356807711887, 1521.8748045858672, -318.6989581348074, 1363.2518725731138, 2301.1076953561446, 1181.6093205142572, 2233.709193476705, 1011.4285902899968, 2351.290858769485, 772.6585265950769, 53.330117252238686, 591.3714523354864, 2002.9144359872712, 966.3368985045577, 1457.7388225987072, 579.1652242087279, 1463.6122502167327, -95.5459611486254, 1287.3835076653147, 1858.8149191336672, 186.8389269828957, 1935.5660190481185, 1044.8507185202955, 632.2887385514347, 474.69453874075464, 1754.9722442651448, -297.821235074052, 1712.017287861605, -476.39490062059866, 1765.4919723351509, -498.92928583427164, 1401.6452287126276, 1998.1947581572722, 581.9402733754204, 1771.6556955952703, 1034.0300253089247, 1415.1004249638663, -893.4038856774589, 686.8760016640413, 543.2453507996541, 1153.998899632742, -236.0670663568614, 138.52674487737679, -668.2129075937145, 1309.037062984242, 233.83875460535154, 1114.5452768834084, -513.6001988198939, 1345.0335930084482, 1965.3012360186617, 436.26612791330365, 2831.4097591265104, 1148.651334612195, 839.3917465885607, -1440.4968580281804, -229.5813725802634, 584.2892891374457, 1394.2124290017255, -781.4046022348704, 1441.5461415918592, 1264.8363173165353, 1581.2348445313921, -446.4614443980574, 1558.8232131159875, 591.9797730276629, 2219.8442749592955, 894.228363380825, 391.3784922153982, 1305.8180754196012, 51.09936246022511, 1085.3921150253368, 1122.1890160214948, 313.72154617148345, 1571.5455378309628, 3419.951363170714, 1332.542926181024, 2590.788240122498, 534.7127214538988, 2641.1919813805075, 1734.2894871814829, 1570.3988303069982, 311.34284887170196, -77.23057595097156, 466.3837701171749, -573.9510639229427, 1354.3260597608169, -783.0496013237541, 1396.8294688364754, 692.61561194676, 1071.8558837416942, 2556.3667816404486, 972.0428722145618, 2716.685909668946, 611.9031251574918, 379.47781048303233, -79.42145122287536, -10.3071663172109], "episode_lengths": [253, 151, 268, 355, 241, 29, 266, 402, 182, 265, 179, 413, 413, 460, 429, 425, 350, 244, 162, 208, 216, 265, 463, 227, 444, 191, 473, 453, 455, 548, 220, 110, 217, 88, 224, 422, 189, 443, 199, 416, 441, 475, 245, 453, 76, 193, 129, 228, 346, 238, 79, 154, 446, 206, 468, 175, 156, 456, 436, 441, 226, 101, 243, 404, 251, 105, 400, 138, 411, 196, 396, 462, 114, 452, 233, 376, 214, 491, 218, 427, 195, 451, 160, 418, 448, 421, 412, 374, 274, 98, 249, 285, 197, 248, 186, 447, 197, 454, 416, 253], "policy_AGENT-2_reward": [289.3611668001823, -31.33609045389497, 210.2023292829749, 577.4685335084791, 212.45799287539967, -54.56023138096778, 181.07551625743088, 434.9905138155, 186.60913730692255, 355.1997434438263, 121.65479741789, 414.09022448220213, 207.66141538900305, 132.50251640059838, 202.16710360502708, 439.7106756399721, -131.44512526050121, 181.37842135058602, -51.04826055209071, 244.61819864184338, 84.19019172415571, 109.09981585169812, 278.65046552660243, -195.09995070921562, 396.01572819354664, 141.48591932769574, 188.51884018500635, 166.76145695672247, 439.3116922460197, -116.45823607613951, 50.115663272071814, -61.78235531272009, 336.8152203012829, -144.32953131922346, 233.4585264883546, 409.4492563863156, -16.421073835755102, 330.5086241002889, 76.98573465868974, 257.1684079223151, -3.501658497910121, 202.6711678654945, 185.62616950297001, -7.022586645902384, -44.05129184246848, 162.36292929755618, -150.30002348668847, 111.80935287202203, 185.75726103908184, 57.15666648026575, -160.49887864136545, 292.4160534654418, 395.2200778292452, -36.488148639888294, 459.40041193079014, 218.02571926096164, -8.269715568827063, -52.79086307047885, 120.21020088294037, 191.45871901497614, 170.50201602145273, -184.04791837339567, 200.831199094378, -104.41277417323381, 283.6252974412007, -54.23475137591596, 236.62811294802822, 17.41604955154809, 415.5092810178543, 64.0491053201666, 159.76189532959415, 285.24733898685463, 166.3864508489368, 264.893130342649, 47.28877662538061, 288.86803476595907, 251.4604844296303, -26.51572078802839, 198.28439871975905, 465.7186383113194, -6.107038317139384, 182.86267867011406, 385.6997937919191, 329.293221802973, 161.86598255916707, 98.74030969646208, 174.4137424019902, -155.9355696294448, 152.40488277171647, -214.4815069452349, 195.80529528453422, 419.91920698732696, 184.73431662404056, 475.9247101171576, 81.8683178160966, 147.15184705796756, 36.7857473366839, 162.92986079349612, 110.37659703916898, 130.4713402357347], "policy_AGENT-3_reward": [436.66046827121784, -31.243250295273565, 421.8045133017196, -121.57621266137637, 411.4128090024485, -54.50293845612886, 409.3630639593068, 542.981274967033, 509.2347514244693, 534.6142562355582, 498.33735645731565, 520.9983993110313, 131.70213046826566, -172.4908125052614, 41.145734520299925, 445.1103261704725, -131.59566375644016, 421.2142188726082, -51.034671630895716, 303.98129274838504, -113.82392452922356, 472.8275131606058, 493.07440420566127, 472.2749737132833, 479.0324418685987, 496.84760741364187, 61.97521385970926, -0.9165339503750403, 232.87100184612493, -133.764851873866, 384.2264890576421, -177.1211951359569, 415.60183465511517, -144.53326658207988, 326.17147762024484, 469.894867643523, 463.65702373839446, 523.4334553193146, 515.6119155466989, 513.4156901882859, -511.03597463176493, 72.79326668904001, 66.68999146660676, -6.8846551297572, -43.99814863498802, -101.45366066561829, -181.1493314050311, 406.6504645049971, -83.89382312953391, 325.2344214741541, -160.5370894108358, 484.0809949810311, 532.9124612071748, 447.50843144522366, 524.2456562545666, 485.87608706096034, -8.130469764435833, -728.1616158804651, -296.8095903178614, 39.52537457225529, 440.5986994595966, -163.25882435795796, 437.51145780962315, -104.62874435453799, 418.72982567428744, -145.50152155078197, 527.1793107771982, 479.32643945521755, 503.5848123740499, 527.6830689728608, -19.16547210901051, 327.5227689508424, -111.79502808524171, 222.7390346451454, 347.3035204786123, -148.94451808030934, 393.24089041173096, -26.539472812246952, 332.46214867876, 511.9163770406873, 477.69040211551845, 504.0677888217088, 505.0101768482845, 518.5490600649363, -69.82321775434565, -193.4216897306622, 1.5334123809243643, -193.89128265950592, 425.02376892688864, -177.60306985199048, 325.1995623431958, -88.49723105302854, 486.6346607959464, 538.0885419518839, 514.9625234563806, 521.3467526069276, 481.0359215450556, -28.57218089578921, -205.1008471180955, -153.93475004039303], "policy_AGENT-0_reward": [303.8375752669172, 145.43704933747327, 218.3895514580718, 609.4536503791616, 236.77148453108902, -104.84609191469549, 125.5735479779511, 614.0084617165037, 221.73203888525774, 648.8050550323343, 156.3658765434645, 661.9200282252059, 208.25535555425517, 133.05673639945974, 202.73956615079246, 570.3256380129689, 596.1616183649102, 207.6096315676323, 355.4816577389709, 279.72867432685905, 47.343180902841446, 60.93252754613239, 492.29992831899455, -172.1677930676026, 468.31240412783706, 159.64010574093757, 189.0818718478727, 167.3351203026018, 493.755807490098, -115.89712574755166, 638.7598682080326, -176.24182803829012, 370.6539626481323, -104.95717966581901, 199.37167801832686, 508.3169930450472, 17.807657731333475, 399.71427634673665, 107.5006955027292, 277.53535675248213, -2.9454868018602554, 203.23679200482144, 186.18790725136398, 535.5280441820826, -74.03395883358662, -85.18146804113248, -186.99778848924825, 146.72083915675086, 215.30593732913462, 91.157289371089, -96.29304540533465, 254.90525711659237, 463.4087818452347, -10.268050277009795, 871.4166824506639, 184.5636337298543, 464.0835856662282, -52.239150870199325, 120.7617382378025, 192.02298864597003, 136.9047677016718, -217.07423667770775, 160.70111713936652, 718.4312190715472, 233.13960492757815, -192.95797932866654, 356.1026416970484, -39.9243342832732, 605.373654944191, 30.315821356380923, 160.32069162826093, 285.83581279304207, 166.9700394311578, 265.45205771393694, 82.27264069748506, 322.17691802841665, 286.353233209141, 1717.8618411622813, 164.4391907356041, 759.9418036115851, -41.53412927766767, 923.243411246178, 412.501141285777, 302.9276548471783, 162.4292516481588, 99.29274553272572, 174.9752632617297, -155.38608320967597, 147.50646460295238, -213.92459313481214, 218.56669053122994, 449.1258164686562, 201.3721802739422, 751.9038415909205, 111.62596611871106, 975.7038386013439, -0.6849986103846106, 163.4921810873554, 110.9465964537246, 131.0360758168433], "policy_AGENT-1_reward": [663.8741056895221, 113.55191861002668, 649.7034056721897, -121.01029045507636, 661.2325181769327, -104.78969638301533, 647.2397443784288, 709.1274448571053, 264.0333928976071, 695.0901387649847, 235.0705598713263, 754.2822067510474, 225.03962518355385, -39.73832304255779, 145.31904805936674, 547.7677961638544, 633.2160691565884, 647.5365508078798, 325.76649865274294, 635.2840844996458, -113.25540924639922, 644.523651106879, 594.7901210824094, 81.83169704643176, 592.2054448581364, 246.87708603802068, 192.7128126588458, 141.51449543180595, 589.0337426829041, 68.29897862350512, 638.9152673238589, -61.24952213363136, 642.4209547306206, -105.10930826714943, 642.6435465856995, 610.5336410823863, 116.89666574144626, 517.999339828932, 333.93167960080376, 366.9809701007856, -375.92076574592335, 208.17477510468464, 104.7412825787132, 632.3780972263191, -73.98366704581842, 162.79894428657113, -149.76576421274652, 643.856406450474, -83.33062063333152, 640.9968995579002, -96.27118536235787, 313.63128744538295, 573.7599151370055, 35.51389538497834, 976.3470084904952, 260.18589456041826, 391.70834625559536, -607.3052282070385, -173.74372138314487, 161.28220690424416, 646.2069458190017, -217.0236228258087, 642.5023675484921, 755.4466167727595, 645.7401164883263, -53.76719214269292, 438.9131476937113, 135.16161830416897, 695.3765266231997, 272.18036773141586, 90.4613773665541, 407.21215468886123, -170.46209973462823, 332.3078923236045, 645.3240782200139, -148.3788885425824, 640.4909297804604, 1755.144715608718, 637.3571880468986, 853.2114211589055, 104.66348693318756, 1031.0181026425078, 431.0783752555048, 419.62889359191007, 56.87083241872225, -81.84194144949736, 115.4613520725313, -68.73812842431676, 629.3909434592596, -177.0404313917163, 657.2579206775173, -87.93218045619514, 199.1147260477653, 790.4496879804869, 263.5860648233737, 1072.483471402705, 94.76645488613698, 81.6279494979691, -95.64379759767323, -117.87983232939526]}, "sampler_perf": {"mean_env_wait_ms": 52.92803593331237, "mean_raw_obs_processing_ms": 2.042165017639147, "mean_inference_ms": 2.4348034831263767, "mean_action_processing_ms": 0.14690666229822505}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 201600, "timers": {"sample_time_ms": 74471.695, "sample_throughput": 56.397, "load_time_ms": 12.661, "load_throughput": 331714.752, "learn_time_ms": 10454.867, "learn_throughput": 401.727, "update_time_ms": 9.871}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 127.08122253417969, "policy_loss": -0.030008357018232346, "vf_loss": 127.10643005371094, "vf_explained_var": 0.9907170534133911, "kl": 0.010717954486608505, "entropy": 0.6513198614120483, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 55.98371124267578, "policy_loss": -0.03059789165854454, "vf_loss": 56.010894775390625, "vf_explained_var": 0.9916015267372131, "kl": 0.011378679424524307, "entropy": 0.6645491123199463, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 9.999999747378752e-05, "total_loss": 197.8167266845703, "policy_loss": -0.03753628209233284, "vf_loss": 197.85069274902344, "vf_explained_var": 0.9871665239334106, "kl": 0.011894091963768005, "entropy": 0.7181099653244019, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 9.999999747378752e-05, "total_loss": 65.77617645263672, "policy_loss": -0.03451411426067352, "vf_loss": 65.80631256103516, "vf_explained_var": 0.9923800230026245, "kl": 0.009713085368275642, "entropy": 0.5688650608062744, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 201600, "num_steps_trained": 201600}, "done": true, "episodes_total": 1218, "training_iteration": 48, "experiment_id": "83b2d516aa8d4945b86cff2787973de8", "date": "2021-06-20_15-43-18", "timestamp": 1624203798, "time_this_iter_s": 81.03257179260254, "time_total_s": 5004.223184108734, "pid": 1155, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd5d85504d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd5d85503b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd5f627a200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8550170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8550050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8550830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8550950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8550170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8550050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8550830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8550950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8550170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8550050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8550830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8550950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd5d8550170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd5d8550050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd5d8550830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd5d8550950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd5f031a290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 32, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 5004.223184108734, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 51.70086956521739, "ram_util_percent": 87.90173913043478}, "trial_id": "77d6d_00000", "experiment_tag": "0"}
