{"episode_reward_max": 792.6584236144089, "episode_reward_min": -893.1340900569483, "episode_reward_mean": -167.48741002921068, "episode_len_mean": 115.0, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-3": -221.94122865958624, "AGENT-0": -244.87290367320165, "AGENT-1": -201.86337899673524, "AGENT-2": -224.45657872742578}, "policy_reward_max": {"AGENT-3": 205.0890439485929, "AGENT-0": 162.9224610072717, "AGENT-1": 212.46113280504932, "AGENT-2": 212.18578585349587}, "policy_reward_mean": {"AGENT-3": -41.18383563804132, "AGENT-0": -45.371447496525256, "AGENT-1": -28.887830069520767, "AGENT-2": -52.04429682512339}, "custom_metrics": {"mean_ego_speed_mean": 41.81508571428571, "mean_ego_speed_min": 37.084, "mean_ego_speed_max": 44.66475, "distance_travelled_mean": 103.66011428571429, "distance_travelled_min": 46.538250000000005, "distance_travelled_max": 124.86500000000001}, "hist_stats": {"episode_reward": [318.2680831901119, 20.520371750042997, -506.2802951080708, 335.2174425722935, -391.7232334272881, -30.021285308916262, -326.5869720733812, 185.62088098128538, 6.95883325529357, -55.98557192341551, -682.3440568662191, -334.85708266252584, -54.60383424275909, -200.48037060858815, 467.63900749288604, -123.00610878976647, 428.44357965513757, -266.5031088679129, 415.7887150609648, -179.63452236879397, 792.6584236144089, -229.19472734577428, -278.9417875009393, -453.616740979682, -643.1281639480507, -225.97475410434205, -62.944613953003696, -651.3998446921582, -50.67725252694372, -356.28654617125653, -308.25855095073894, -551.282085022864, -694.9011381974307, -893.1340900569483, -281.4079508970283], "episode_lengths": [106, 119, 122, 123, 124, 107, 123, 110, 132, 123, 113, 107, 124, 117, 123, 103, 107, 118, 124, 125, 124, 99, 91, 119, 111, 120, 134, 119, 119, 108, 117, 118, 108, 127, 61], "policy_AGENT-3_reward": [86.49607281578491, -5.033543989396634, -127.38511547548893, 72.53949035343557, -115.80806736663773, -12.569146234069148, -86.40203503012297, 55.740097895611235, -59.01214659388922, -1.5995602625067349, -183.4101632448017, -72.06947792675632, -34.374339341033746, -53.81233272031876, 162.9191791365928, -13.72634625222706, 117.42515478850322, -55.56325949519551, 145.80616518876715, -49.95807434015071, 205.0890439485929, -31.272988484934846, -34.510096436054496, -104.70212930791766, -132.2046185052775, -67.25104173905497, -88.17880227364518, -161.5763489521113, -31.89148096286122, -52.545800217405386, -114.1296846858122, -165.12595212699574, -173.5384277503283, -221.94122865958624, -37.85724308415416], "policy_AGENT-0_reward": [93.41020078795056, -8.986705050458035, -171.16268995521176, 94.78991964905984, -103.29642468182277, 19.83148452212487, -77.16198823457566, 58.975462860665, 40.95073100348749, -43.797215253454574, -156.4489093756429, -70.48985896263196, -16.159282893257398, -33.71024334411253, 71.3753760225015, -47.6770975416609, 118.60116558653725, -100.39813413008946, 59.34761647191224, -39.655582191447145, 162.9224610072717, -83.29887526970387, -104.9394076224209, -137.69780608257983, -165.72514211357537, -46.39091174974308, 35.12740529639951, -158.52152493016428, -17.77296626661462, -101.16226439866205, -27.757179470737675, -110.83339897208434, -172.74876843102095, -244.87290367320165, -102.66720499142023], "policy_AGENT-1_reward": [93.13410278875116, 39.541000690936784, -126.7025381969341, 95.17969724683233, -57.08051335150608, 19.851431890109517, -76.75493349126269, 58.775522064271144, 84.01539102849219, -9.127787902816934, -156.41628990382577, -70.67318278870118, 30.14208427333598, -56.74188673296725, 119.34419141243674, -47.94795198242696, 118.65626457656852, -55.27938361414549, 107.74102564929194, -41.61061432238081, 212.46113280504932, -83.36242894995996, -105.03336750123535, -100.57010742347217, -165.6652330083343, -45.08595667462979, 78.25866051778205, -158.353582852844, 30.919687662308977, -101.14534945893007, -52.31436982735085, -110.41329903938298, -174.06409767531622, -201.86337899673524, -102.88799134423525], "policy_AGENT-2_reward": [45.22770679762511, -5.000379901039111, -81.02995148043628, 72.70833532296626, -115.53822802732128, -57.13505548708148, -86.26801531742016, 12.129798160738048, -58.995142182796776, -1.461008504637256, -186.06869434194903, -121.62456298443647, -34.21229628180391, -56.21590781118987, 114.00026092135536, -13.654713013451614, 73.76099470352843, -55.26233162848229, 102.89390775099395, -48.41025151481547, 212.18578585349587, -31.260434641175685, -34.45891594122852, -110.64669816571254, -179.53317032086335, -67.24684394091463, -88.15187749354037, -172.94838795703916, -31.93249295977686, -101.43313209625946, -114.05731696683857, -164.9094348844016, -174.54984434076525, -224.45657872742578, -37.995511477218734]}, "sampler_perf": {"mean_env_wait_ms": 54.215206880628784, "mean_raw_obs_processing_ms": 2.134313595043333, "mean_inference_ms": 3.2290787607859897, "mean_action_processing_ms": 0.13584236832730837}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 4200, "timers": {"sample_time_ms": 90923.775, "sample_throughput": 46.193, "load_time_ms": 907.766, "load_throughput": 4626.744, "learn_time_ms": 10705.4, "learn_throughput": 392.325, "update_time_ms": 7.676}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 18.83831024169922, "policy_loss": -0.006697321776300669, "vf_loss": 18.84259796142578, "vf_explained_var": 0.3188461363315582, "kl": 0.012053689919412136, "entropy": 1.3744710683822632, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 13.040853500366211, "policy_loss": -0.014363947324454784, "vf_loss": 13.052732467651367, "vf_explained_var": 0.4295903444290161, "kl": 0.012423256412148476, "entropy": 1.3740676641464233, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 15.940986633300781, "policy_loss": -0.012489830143749714, "vf_loss": 15.950658798217773, "vf_explained_var": 0.3835548758506775, "kl": 0.014082466252148151, "entropy": 1.3726098537445068, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 12.033291816711426, "policy_loss": -0.01217514555901289, "vf_loss": 12.042898178100586, "vf_explained_var": 0.6243667602539062, "kl": 0.012834257446229458, "entropy": 1.3736505508422852, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 4200, "num_steps_trained": 4200}, "done": false, "episodes_total": 35, "training_iteration": 1, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-18-31", "timestamp": 1624209511, "time_this_iter_s": 105.09963989257812, "time_total_s": 105.09963989257812, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40449bef0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40449b950>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449bb90>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449bd40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40449bf80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445a050>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449bb90>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449bd40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40449bf80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445a050>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449bb90>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449bd40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40449bf80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445a050>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449bb90>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449bd40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40449bf80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445a050>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd40449b830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 105.09963989257812, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 57.156, "ram_util_percent": 83.88266666666667}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 792.6584236144089, "episode_reward_min": -893.1340900569483, "episode_reward_mean": -203.38296802888368, "episode_len_mean": 114.77777777777777, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-3": -225.8501961200352, "AGENT-0": -244.87290367320165, "AGENT-1": -201.86337899673524, "AGENT-2": -225.7054917780764}, "policy_reward_max": {"AGENT-3": 205.0890439485929, "AGENT-0": 162.9224610072717, "AGENT-1": 212.46113280504932, "AGENT-2": 212.18578585349587}, "policy_reward_mean": {"AGENT-3": -49.73659080410731, "AGENT-0": -58.88901105998684, "AGENT-1": -38.511597206949986, "AGENT-2": -56.24576895783956}, "custom_metrics": {"mean_ego_speed_mean": 41.50397569444445, "mean_ego_speed_min": 33.18725, "mean_ego_speed_max": 44.729, "distance_travelled_mean": 101.44330902777779, "distance_travelled_min": 36.627, "distance_travelled_max": 124.86500000000001}, "hist_stats": {"episode_reward": [416.79878676820834, -521.912782014308, 188.74516141568753, -540.9244397241862, 137.6875009412717, -504.00367744936045, 11.71529051361728, -451.462588585252, 165.38228085425806, -217.50773999037253, 192.17450497091622, -95.80639481143376, 155.74411083210333, -356.70761721134954, 274.18476437926813, -352.28260611375094, -287.6544342434999, -255.27851402631566, -474.974350982573, -329.7223964843087, 271.94071344407496, -293.3161052597513, -13.01453429701364, -368.06784203102603, -65.71116278287705, -396.4350117291823, -24.90286371760868, -538.9349642714027, -209.2850658166752, -546.3575327734048, -759.7419601843234, -471.5170233289955, -325.6355146070518, -329.76478877726703, -836.3324865559769, -341.623465907975, -687.0095974994141, 318.2680831901119, 20.520371750042997, -506.2802951080708, 335.2174425722935, -391.7232334272881, -30.021285308916262, -326.5869720733812, 185.62088098128538, 6.95883325529357, -55.98557192341551, -682.3440568662191, -334.85708266252584, -54.60383424275909, -200.48037060858815, 467.63900749288604, -123.00610878976647, 428.44357965513757, -266.5031088679129, 415.7887150609648, -179.63452236879397, 792.6584236144089, -229.19472734577428, -278.9417875009393, -453.616740979682, -643.1281639480507, -225.97475410434205, -62.944613953003696, -651.3998446921582, -50.67725252694372, -356.28654617125653, -308.25855095073894, -551.282085022864, -694.9011381974307, -893.1340900569483, -281.4079508970283], "episode_lengths": [114, 78, 127, 109, 116, 107, 121, 125, 119, 120, 126, 118, 102, 105, 125, 104, 119, 121, 133, 129, 129, 121, 73, 131, 112, 115, 127, 118, 120, 108, 120, 120, 118, 31, 131, 125, 122, 106, 119, 122, 123, 124, 107, 123, 110, 132, 123, 113, 107, 124, 117, 123, 103, 107, 118, 124, 125, 124, 99, 91, 119, 111, 120, 134, 119, 119, 108, 117, 118, 108, 127, 61], "policy_AGENT-3_reward": [88.73518590248928, -159.9606189231763, 80.03065677148508, -129.5602357100129, 23.564838098285538, -128.35808740327448, -0.21904161587862347, -67.17078848468057, 38.99895934192426, -43.097571892376, 32.7986820453131, -27.828460161249865, 1.0287133356077476, -94.69039823089462, 61.11972938192889, -62.06311345891384, -32.699466696477586, -9.006772079596079, -198.55166588367777, -10.340473703210208, 64.84812485665093, -62.002004458614685, -32.06217493500227, -13.021677526238648, -30.044493771840823, -101.84970454187129, -32.17032184930975, -136.9150407308698, -75.32014131427275, -99.9669724220343, -179.4805211403924, -148.95090965068525, -92.45904286817395, -57.35592189191594, -225.8501961200352, -109.14401854896796, -170.58534428432094, 86.49607281578491, -5.033543989396634, -127.38511547548893, 72.53949035343557, -115.80806736663773, -12.569146234069148, -86.40203503012297, 55.740097895611235, -59.01214659388922, -1.5995602625067349, -183.4101632448017, -72.06947792675632, -34.374339341033746, -53.81233272031876, 162.9191791365928, -13.72634625222706, 117.42515478850322, -55.56325949519551, 145.80616518876715, -49.95807434015071, 205.0890439485929, -31.272988484934846, -34.510096436054496, -104.70212930791766, -132.2046185052775, -67.25104173905497, -88.17880227364518, -161.5763489521113, -31.89148096286122, -52.545800217405386, -114.1296846858122, -165.12595212699574, -173.5384277503283, -221.94122865958624, -37.85724308415416], "policy_AGENT-0_reward": [133.3598151436614, -100.90283094967108, 37.70258229470024, -118.7956119363576, 46.60632763872158, -98.899739847572, 5.825479401188177, -152.9578035384514, 43.0920408232931, -90.73200025360217, 41.846693532444526, -44.48760575052333, 76.81454012363335, -61.020187532341865, 75.23672791571849, -113.3715628750623, -135.9459933910319, -142.12102388216593, -236.61131827862908, -177.59982997739232, 26.494973802527014, -107.2268523008205, 25.477458540300248, -193.1403396475817, 19.84597510447516, -85.73858687443752, -3.301019507146364, -156.8080406736243, -29.32949426777758, -148.61844037379686, -224.56830609521356, -89.5266049912724, -70.26820052644287, -107.46581288216188, -212.49508907992686, -85.47464178080499, -196.90381104752313, 93.41020078795056, -8.986705050458035, -171.16268995521176, 94.78991964905984, -103.29642468182277, 19.83148452212487, -77.16198823457566, 58.975462860665, 40.95073100348749, -43.797215253454574, -156.4489093756429, -70.48985896263196, -16.159282893257398, -33.71024334411253, 71.3753760225015, -47.6770975416609, 118.60116558653725, -100.39813413008946, 59.34761647191224, -39.655582191447145, 162.9224610072717, -83.29887526970387, -104.9394076224209, -137.69780608257983, -165.72514211357537, -46.39091174974308, 35.12740529639951, -158.52152493016428, -17.77296626661462, -101.16226439866205, -27.757179470737675, -110.83339897208434, -172.74876843102095, -244.87290367320165, -102.66720499142023], "policy_AGENT-1_reward": [110.67974835421789, -101.07815328458004, 40.16382616541071, -118.85352595872484, 46.40022750527622, -98.82182748268525, 6.193037644425183, -106.5725883368091, 44.153213797731034, -41.792136201191916, 84.78271483522245, 4.3139521902696405, 76.74579522279, -61.24798994146839, 76.5357850279121, -113.31393046614123, -86.38932154369091, -95.11374033759988, -19.59162615931828, -131.286958508332, 90.57645193038829, -62.216383622821915, 25.608908704354963, -148.89605378472885, 19.7359710794018, -101.2869706519927, 42.813813233666295, -108.3091139399302, -29.45256981402775, -148.59416593693948, -177.47236241590744, -142.95403059567022, -70.39746394567594, -107.55166350183418, -172.28170957793884, -37.933055860190564, -149.05705029003903, 93.13410278875116, 39.541000690936784, -126.7025381969341, 95.17969724683233, -57.08051335150608, 19.851431890109517, -76.75493349126269, 58.775522064271144, 84.01539102849219, -9.127787902816934, -156.41628990382577, -70.67318278870118, 30.14208427333598, -56.74188673296725, 119.34419141243674, -47.94795198242696, 118.65626457656852, -55.27938361414549, 107.74102564929194, -41.61061432238081, 212.46113280504932, -83.36242894995996, -105.03336750123535, -100.57010742347217, -165.6652330083343, -45.08595667462979, 78.25866051778205, -158.353582852844, 30.919687662308977, -101.14534945893007, -52.31436982735085, -110.41329903938298, -174.06409767531622, -201.86337899673524, -102.88799134423525], "policy_AGENT-2_reward": [84.02403736783984, -159.97117885688039, 30.848096184091354, -173.715066119091, 21.116107698988415, -177.9240227158286, -0.08418491611733714, -124.76140822531103, 39.138066891309975, -41.8860316432026, 32.74641455793593, -27.80428108993027, 1.1550621500720553, -139.74904150664497, 61.29252205370895, -63.5339993136335, -32.619652612299404, -9.036977726953754, -20.219740660948005, -10.495134295374356, 90.02116285450856, -61.870864877493986, -32.038726606666614, -13.00977107247651, -75.24861519491319, -107.55974966088063, -32.24533559481903, -136.90276892697813, -75.18286042059711, -149.17795404063398, -178.22077053280995, -90.08547809136793, -92.51080726675853, -57.39139050135501, -225.7054917780764, -109.07174971801176, -170.46339187753054, 45.22770679762511, -5.000379901039111, -81.02995148043628, 72.70833532296626, -115.53822802732128, -57.13505548708148, -86.26801531742016, 12.129798160738048, -58.995142182796776, -1.461008504637256, -186.06869434194903, -121.62456298443647, -34.21229628180391, -56.21590781118987, 114.00026092135536, -13.654713013451614, 73.76099470352843, -55.26233162848229, 102.89390775099395, -48.41025151481547, 212.18578585349587, -31.260434641175685, -34.45891594122852, -110.64669816571254, -179.53317032086335, -67.24684394091463, -88.15187749354037, -172.94838795703916, -31.93249295977686, -101.43313209625946, -114.05731696683857, -164.9094348844016, -174.54984434076525, -224.45657872742578, -37.995511477218734]}, "sampler_perf": {"mean_env_wait_ms": 53.80370982420396, "mean_raw_obs_processing_ms": 2.1859112302825046, "mean_inference_ms": 3.013992932560862, "mean_action_processing_ms": 0.13678308416113533}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 8400, "timers": {"sample_time_ms": 89601.459, "sample_throughput": 46.874, "load_time_ms": 461.239, "load_throughput": 9105.899, "learn_time_ms": 9518.45, "learn_throughput": 441.248, "update_time_ms": 8.508}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 16.548978805541992, "policy_loss": -0.010731988586485386, "vf_loss": 16.55698013305664, "vf_explained_var": 0.6320165991783142, "kl": 0.013645383529365063, "entropy": 1.353769302368164, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 11.87552261352539, "policy_loss": -0.01804310828447342, "vf_loss": 11.891292572021484, "vf_explained_var": 0.6622288823127747, "kl": 0.011349903419613838, "entropy": 1.3668770790100098, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 17.296998977661133, "policy_loss": -0.020627375692129135, "vf_loss": 17.315088272094727, "vf_explained_var": 0.639831006526947, "kl": 0.012708882801234722, "entropy": 1.3651455640792847, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 16.397998809814453, "policy_loss": -0.016888776794075966, "vf_loss": 16.41250228881836, "vf_explained_var": 0.6425957083702087, "kl": 0.01193259283900261, "entropy": 1.3617759943008423, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 8400, "num_steps_trained": 8400}, "done": false, "episodes_total": 72, "training_iteration": 2, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-20-08", "timestamp": 1624209608, "time_this_iter_s": 96.65494751930237, "time_total_s": 201.7545874118805, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd408f79e60>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40449b710>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd408f79dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd408f79f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40472c680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445acb0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd408f79dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd408f79f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40472c680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445acb0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd408f79dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd408f79f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40472c680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445acb0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd408f79dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd408f79f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40472c680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445acb0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd40445a320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 201.7545874118805, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 56.77536231884058, "ram_util_percent": 86.00072463768116}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 792.6584236144089, "episode_reward_min": -1337.096817488721, "episode_reward_mean": -268.34046496048376, "episode_len_mean": 117.5, "episodes_this_iter": 33, "policy_reward_min": {"AGENT-3": -309.2248215483799, "AGENT-0": -342.1331157586209, "AGENT-2": -350.5168591067992, "AGENT-1": -335.22202107492}, "policy_reward_max": {"AGENT-3": 205.0890439485929, "AGENT-0": 162.9224610072717, "AGENT-2": 212.18578585349587, "AGENT-1": 212.46113280504932}, "policy_reward_mean": {"AGENT-3": -68.77717046537956, "AGENT-0": -72.27893073281845, "AGENT-2": -72.28516786049455, "AGENT-1": -54.99919590179119}, "custom_metrics": {"mean_ego_speed_mean": 40.762685, "mean_ego_speed_min": 30.631749999999997, "mean_ego_speed_max": 45.119749999999996, "distance_travelled_mean": 101.3653925, "distance_travelled_min": 26.396, "distance_travelled_max": 124.86500000000001}, "hist_stats": {"episode_reward": [-592.8381577188376, -21.783221767908756, -411.1447708957887, 249.26536336188556, -361.45371696637375, -27.55568486276771, -600.8075589806671, -168.23724263005226, -1337.096817488721, -257.2734649675383, -43.957556128266106, -489.42643128357037, -409.01813131549983, -484.6263798363619, -237.6907344449047, -411.75604109066006, -50.110532673269205, -425.56838610215334, 131.09997787091777, -230.2889698693842, -263.04174528445753, -644.4611039850495, -545.4452191798691, -324.38264748607895, 164.20154957192278, -432.22852855454374, -728.6913287747213, -947.6668778441701, -201.16241984368392, -1024.1629168031532, -680.4899308024978, -187.95385688758935, -418.71694532784784, -30.021285308916262, -326.5869720733812, 185.62088098128538, 6.95883325529357, -55.98557192341551, -682.3440568662191, -334.85708266252584, -54.60383424275909, -200.48037060858815, 467.63900749288604, -123.00610878976647, 428.44357965513757, -266.5031088679129, 415.7887150609648, -179.63452236879397, 792.6584236144089, -229.19472734577428, -278.9417875009393, -453.616740979682, -643.1281639480507, -225.97475410434205, -62.944613953003696, -651.3998446921582, -50.67725252694372, -356.28654617125653, -308.25855095073894, -551.282085022864, -694.9011381974307, -893.1340900569483, -281.4079508970283, 416.79878676820834, -521.912782014308, 188.74516141568753, -540.9244397241862, 137.6875009412717, -504.00367744936045, 11.71529051361728, -451.462588585252, 165.38228085425806, -217.50773999037253, 192.17450497091622, -95.80639481143376, 155.74411083210333, -356.70761721134954, 274.18476437926813, -352.28260611375094, -287.6544342434999, -255.27851402631566, -474.974350982573, -329.7223964843087, 271.94071344407496, -293.3161052597513, -13.01453429701364, -368.06784203102603, -65.71116278287705, -396.4350117291823, -24.90286371760868, -538.9349642714027, -209.2850658166752, -546.3575327734048, -759.7419601843234, -471.5170233289955, -325.6355146070518, -329.76478877726703, -836.3324865559769, -341.623465907975, -687.0095974994141], "episode_lengths": [124, 118, 129, 126, 132, 123, 128, 116, 154, 30, 126, 127, 125, 127, 124, 112, 128, 120, 120, 121, 126, 132, 121, 112, 144, 120, 125, 126, 129, 143, 137, 138, 117, 107, 123, 110, 132, 123, 113, 107, 124, 117, 123, 103, 107, 118, 124, 125, 124, 99, 91, 119, 111, 120, 134, 119, 119, 108, 117, 118, 108, 127, 61, 114, 78, 127, 109, 116, 107, 121, 125, 119, 120, 126, 118, 102, 105, 125, 104, 119, 121, 133, 129, 129, 121, 73, 131, 112, 115, 127, 118, 120, 108, 120, 120, 118, 31, 131, 125, 122], "policy_AGENT-3_reward": [-148.54592819219332, -36.54826836380331, -116.97270780452881, 85.29006438196018, -88.40505851065903, -8.142942685055644, -170.95483433230575, -76.4416804260103, -309.2248215483799, -36.51020201904135, -76.64250894495859, -116.47269868132021, -36.19528396313317, -172.74074215282758, -30.88206674338089, -144.75992110615363, -81.93353050953715, -144.79208332913976, 17.0479263309442, -37.60682100171378, -9.097618964288415, -148.59156078436547, -90.11286939362373, -56.4255070409045, -44.59079783523359, -110.4322076637954, -188.14857469372475, -232.78992200123017, -97.32886193860784, -270.18133278761843, -193.45839305932975, -103.39928576894818, -109.88263077162283, -12.569146234069148, -86.40203503012297, 55.740097895611235, -59.01214659388922, -1.5995602625067349, -183.4101632448017, -72.06947792675632, -34.374339341033746, -53.81233272031876, 162.9191791365928, -13.72634625222706, 117.42515478850322, -55.56325949519551, 145.80616518876715, -49.95807434015071, 205.0890439485929, -31.272988484934846, -34.510096436054496, -104.70212930791766, -132.2046185052775, -67.25104173905497, -88.17880227364518, -161.5763489521113, -31.89148096286122, -52.545800217405386, -114.1296846858122, -165.12595212699574, -173.5384277503283, -221.94122865958624, -37.85724308415416, 88.73518590248928, -159.9606189231763, 80.03065677148508, -129.5602357100129, 23.564838098285538, -128.35808740327448, -0.21904161587862347, -67.17078848468057, 38.99895934192426, -43.097571892376, 32.7986820453131, -27.828460161249865, 1.0287133356077476, -94.69039823089462, 61.11972938192889, -62.06311345891384, -32.699466696477586, -9.006772079596079, -198.55166588367777, -10.340473703210208, 64.84812485665093, -62.002004458614685, -32.06217493500227, -13.021677526238648, -30.044493771840823, -101.84970454187129, -32.17032184930975, -136.9150407308698, -75.32014131427275, -99.9669724220343, -179.4805211403924, -148.95090965068525, -92.45904286817395, -57.35592189191594, -225.8501961200352, -109.14401854896796, -170.58534428432094], "policy_AGENT-0_reward": [-148.08058529863817, 24.80630551464601, -74.6525857258599, 14.844436960435452, -112.47286189392369, -53.244834266173996, -213.5404345725455, 15.502328396060008, -342.1331157586209, -92.20271692043436, 65.4283327204319, -158.89872216986902, -191.7788998704841, -74.59744551315833, -53.890964850325915, -74.38503468826467, 40.28445575486672, -71.03813504534018, 48.53898211729234, -79.68176421041832, -109.92479239000147, -194.62628848477456, -134.32078273607132, -91.86289181845885, 106.00541835134207, -106.61820191157891, -175.94502058858907, -267.18590339072244, -25.84497197185798, -264.5256488083677, -172.61591400248136, -11.075292171349567, -103.39642697003981, 19.83148452212487, -77.16198823457566, 58.975462860665, 40.95073100348749, -43.797215253454574, -156.4489093756429, -70.48985896263196, -16.159282893257398, -33.71024334411253, 71.3753760225015, -47.6770975416609, 118.60116558653725, -100.39813413008946, 59.34761647191224, -39.655582191447145, 162.9224610072717, -83.29887526970387, -104.9394076224209, -137.69780608257983, -165.72514211357537, -46.39091174974308, 35.12740529639951, -158.52152493016428, -17.77296626661462, -101.16226439866205, -27.757179470737675, -110.83339897208434, -172.74876843102095, -244.87290367320165, -102.66720499142023, 133.3598151436614, -100.90283094967108, 37.70258229470024, -118.7956119363576, 46.60632763872158, -98.899739847572, 5.825479401188177, -152.9578035384514, 43.0920408232931, -90.73200025360217, 41.846693532444526, -44.48760575052333, 76.81454012363335, -61.020187532341865, 75.23672791571849, -113.3715628750623, -135.9459933910319, -142.12102388216593, -236.61131827862908, -177.59982997739232, 26.494973802527014, -107.2268523008205, 25.477458540300248, -193.1403396475817, 19.84597510447516, -85.73858687443752, -3.301019507146364, -156.8080406736243, -29.32949426777758, -148.61844037379686, -224.56830609521356, -89.5266049912724, -70.26820052644287, -107.46581288216188, -212.49508907992686, -85.47464178080499, -196.90381104752313], "policy_AGENT-2_reward": [-148.53176147189845, -36.578624769369256, -121.93137644456115, 85.53811875822467, -92.0998539887798, 16.60124851756374, -108.38168553290646, -122.77226390959818, -350.5168591067992, -36.459516674207876, -76.6272766842729, -102.35744747143215, -36.293429976519405, -75.16147842302807, -76.46848515151781, -74.94952518113536, -48.44398465336168, -71.60380783401381, 17.111089713844684, -34.16099251143407, -9.12754800037348, -149.7539519095464, -160.81887145073694, -120.22969851851954, -44.51385164103993, -109.24189687404088, -189.41893984248296, -227.34064513134024, -97.37701021997553, -267.5327144847668, -185.6076376982838, -103.45006502171626, -103.95319478518735, -57.13505548708148, -86.26801531742016, 12.129798160738048, -58.995142182796776, -1.461008504637256, -186.06869434194903, -121.62456298443647, -34.21229628180391, -56.21590781118987, 114.00026092135536, -13.654713013451614, 73.76099470352843, -55.26233162848229, 102.89390775099395, -48.41025151481547, 212.18578585349587, -31.260434641175685, -34.45891594122852, -110.64669816571254, -179.53317032086335, -67.24684394091463, -88.15187749354037, -172.94838795703916, -31.93249295977686, -101.43313209625946, -114.05731696683857, -164.9094348844016, -174.54984434076525, -224.45657872742578, -37.995511477218734, 84.02403736783984, -159.97117885688039, 30.848096184091354, -173.715066119091, 21.116107698988415, -177.9240227158286, -0.08418491611733714, -124.76140822531103, 39.138066891309975, -41.8860316432026, 32.74641455793593, -27.80428108993027, 1.1550621500720553, -139.74904150664497, 61.29252205370895, -63.5339993136335, -32.619652612299404, -9.036977726953754, -20.219740660948005, -10.495134295374356, 90.02116285450856, -61.870864877493986, -32.038726606666614, -13.00977107247651, -75.24861519491319, -107.55974966088063, -32.24533559481903, -136.90276892697813, -75.18286042059711, -149.17795404063398, -178.22077053280995, -90.08547809136793, -92.51080726675853, -57.39139050135501, -225.7054917780764, -109.07174971801176, -170.46339187753054], "policy_AGENT-1_reward": [-147.679882756107, 26.537365850617686, -97.58810092083903, 63.59274326126537, -68.47594257301138, 17.230843570898244, -107.93060454290938, 15.474373309496306, -335.22202107492, -92.10102935385464, 43.88389678053359, -111.69756296094897, -144.75051750536272, -162.12671374734776, -76.44921769968026, -117.66156011510661, 39.982526734763056, -138.13435989365937, 48.40197970883626, -78.83939214581814, -134.89178592979445, -151.48930280636276, -160.1926955994369, -55.86455010819576, 147.30078069685422, -105.93622210512866, -175.1787936499248, -220.35040732087705, 19.38842428675779, -221.92322072240032, -128.80798604240292, 29.970786074424456, -101.48469280099826, 19.851431890109517, -76.75493349126269, 58.775522064271144, 84.01539102849219, -9.127787902816934, -156.41628990382577, -70.67318278870118, 30.14208427333598, -56.74188673296725, 119.34419141243674, -47.94795198242696, 118.65626457656852, -55.27938361414549, 107.74102564929194, -41.61061432238081, 212.46113280504932, -83.36242894995996, -105.03336750123535, -100.57010742347217, -165.6652330083343, -45.08595667462979, 78.25866051778205, -158.353582852844, 30.919687662308977, -101.14534945893007, -52.31436982735085, -110.41329903938298, -174.06409767531622, -201.86337899673524, -102.88799134423525, 110.67974835421789, -101.07815328458004, 40.16382616541071, -118.85352595872484, 46.40022750527622, -98.82182748268525, 6.193037644425183, -106.5725883368091, 44.153213797731034, -41.792136201191916, 84.78271483522245, 4.3139521902696405, 76.74579522279, -61.24798994146839, 76.5357850279121, -113.31393046614123, -86.38932154369091, -95.11374033759988, -19.59162615931828, -131.286958508332, 90.57645193038829, -62.216383622821915, 25.608908704354963, -148.89605378472885, 19.7359710794018, -101.2869706519927, 42.813813233666295, -108.3091139399302, -29.45256981402775, -148.59416593693948, -177.47236241590744, -142.95403059567022, -70.39746394567594, -107.55166350183418, -172.28170957793884, -37.933055860190564, -149.05705029003903]}, "sampler_perf": {"mean_env_wait_ms": 53.80362071416351, "mean_raw_obs_processing_ms": 2.2092178136235954, "mean_inference_ms": 2.8945478597215084, "mean_action_processing_ms": 0.1380454994132214}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 12600, "timers": {"sample_time_ms": 90281.559, "sample_throughput": 46.521, "load_time_ms": 313.35, "load_throughput": 13403.53, "learn_time_ms": 9183.587, "learn_throughput": 457.338, "update_time_ms": 8.128}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 13.901717185974121, "policy_loss": -0.02089248225092888, "vf_loss": 13.919831275939941, "vf_explained_var": 0.7599886655807495, "kl": 0.013888180255889893, "entropy": 1.3372046947479248, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 11.986043930053711, "policy_loss": -0.018218619748950005, "vf_loss": 12.000088691711426, "vf_explained_var": 0.7837108373641968, "kl": 0.02086813375353813, "entropy": 1.340179681777954, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 12.204062461853027, "policy_loss": -0.01645989529788494, "vf_loss": 12.2174072265625, "vf_explained_var": 0.6526286602020264, "kl": 0.015574001707136631, "entropy": 1.3454928398132324, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 11.86940860748291, "policy_loss": -0.013875200413167477, "vf_loss": 11.880406379699707, "vf_explained_var": 0.7076441645622253, "kl": 0.01438028272241354, "entropy": 1.3511016368865967, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 12600, "num_steps_trained": 12600}, "done": false, "episodes_total": 105, "training_iteration": 3, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-21-49", "timestamp": 1624209709, "time_this_iter_s": 100.20082378387451, "time_total_s": 301.955411195755, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40445a830>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40445a950>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40445ab00>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40445a290>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40445a0e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445a200>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40445ab00>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40445a290>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40445a0e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445a200>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40445ab00>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40445a290>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40445a0e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445a200>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40445ab00>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40445a290>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40445a0e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445a200>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd40445aef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 301.955411195755, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 56.515172413793096, "ram_util_percent": 86.95310344827584}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 388.44826915177316, "episode_reward_min": -1337.096817488721, "episode_reward_mean": -308.9233242059495, "episode_len_mean": 120.0, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-3": -309.2248215483799, "AGENT-0": -342.1331157586209, "AGENT-1": -335.22202107492, "AGENT-2": -350.5168591067992}, "policy_reward_max": {"AGENT-3": 85.29006438196018, "AGENT-0": 139.1009781637763, "AGENT-1": 147.30078069685422, "AGENT-2": 179.17265823347674}, "policy_reward_mean": {"AGENT-3": -82.18051296809548, "AGENT-0": -81.83528346770417, "AGENT-1": -70.02503315877375, "AGENT-2": -74.882494611376}, "custom_metrics": {"mean_ego_speed_mean": 39.782579999999996, "mean_ego_speed_min": 28.244999999999997, "mean_ego_speed_max": 45.119749999999996, "distance_travelled_mean": 98.91900249999999, "distance_travelled_min": 26.396, "distance_travelled_max": 124.8595}, "hist_stats": {"episode_reward": [52.4818539817668, 168.19183654940161, -109.52362511637789, -572.9942671769448, -560.145527005969, -631.0349286376155, -298.5125454590126, -117.09890682920414, -484.2280743775477, -299.4852938281189, 141.55152450717924, -735.2654182830312, 148.74979950417637, -438.2638792445217, -11.94258870991618, -254.36448362523893, 355.7490214679772, -44.3134170294799, -132.41236980655364, -162.25180858248305, -273.53647877759397, -460.98719643843936, 388.44826915177316, -496.64518054287834, -591.1062195675634, -1023.5480001977292, -228.0656324778305, -566.8684945686982, -328.32542567300175, -149.91092548546106, -394.7262264687316, -396.42577431890606, -414.09453445798704, -527.8585970530054, -567.1899025817911, -504.00367744936045, 11.71529051361728, -451.462588585252, 165.38228085425806, -217.50773999037253, 192.17450497091622, -95.80639481143376, 155.74411083210333, -356.70761721134954, 274.18476437926813, -352.28260611375094, -287.6544342434999, -255.27851402631566, -474.974350982573, -329.7223964843087, 271.94071344407496, -293.3161052597513, -13.01453429701364, -368.06784203102603, -65.71116278287705, -396.4350117291823, -24.90286371760868, -538.9349642714027, -209.2850658166752, -546.3575327734048, -759.7419601843234, -471.5170233289955, -325.6355146070518, -329.76478877726703, -836.3324865559769, -341.623465907975, -687.0095974994141, -592.8381577188376, -21.783221767908756, -411.1447708957887, 249.26536336188556, -361.45371696637375, -27.55568486276771, -600.8075589806671, -168.23724263005226, -1337.096817488721, -257.2734649675383, -43.957556128266106, -489.42643128357037, -409.01813131549983, -484.6263798363619, -237.6907344449047, -411.75604109066006, -50.110532673269205, -425.56838610215334, 131.09997787091777, -230.2889698693842, -263.04174528445753, -644.4611039850495, -545.4452191798691, -324.38264748607895, 164.20154957192278, -432.22852855454374, -728.6913287747213, -947.6668778441701, -201.16241984368392, -1024.1629168031532, -680.4899308024978, -187.95385688758935, -418.71694532784784], "episode_lengths": [124, 128, 110, 98, 139, 126, 126, 72, 121, 128, 125, 110, 137, 122, 124, 55, 130, 127, 124, 119, 120, 138, 126, 126, 133, 115, 125, 137, 107, 129, 126, 113, 117, 146, 122, 107, 121, 125, 119, 120, 126, 118, 102, 105, 125, 104, 119, 121, 133, 129, 129, 121, 73, 131, 112, 115, 127, 118, 120, 108, 120, 120, 118, 31, 131, 125, 122, 124, 118, 129, 126, 132, 123, 128, 116, 154, 30, 126, 127, 125, 127, 124, 112, 128, 120, 120, 121, 126, 132, 121, 112, 144, 120, 125, 126, 129, 143, 137, 138, 117], "policy_AGENT-3_reward": [-36.414276909942004, -34.13141800103122, -50.060386944486936, -168.5113048857469, -260.4389114056181, -93.78908497096009, -134.3096214040184, -50.83035883352532, -187.1885039444902, -73.97343976532535, 25.383865962173836, -206.31089320144582, 82.58245438832611, -151.98916828949555, -23.203273576165806, -37.726819763505944, 18.454363778167348, -6.595355288139796, -18.033238879915075, -11.84970883197953, -109.4828512902308, -98.88014976467525, 83.77783017432667, -159.214572724552, -186.86906830095174, -209.3134159711161, 1.2827627611691703, -94.63897249664448, -42.85684031005544, 61.68044757124021, -99.0799337401487, -103.36175225672791, -65.67022637946478, -167.17294271534905, -181.03274159136117, -128.35808740327448, -0.21904161587862347, -67.17078848468057, 38.99895934192426, -43.097571892376, 32.7986820453131, -27.828460161249865, 1.0287133356077476, -94.69039823089462, 61.11972938192889, -62.06311345891384, -32.699466696477586, -9.006772079596079, -198.55166588367777, -10.340473703210208, 64.84812485665093, -62.002004458614685, -32.06217493500227, -13.021677526238648, -30.044493771840823, -101.84970454187129, -32.17032184930975, -136.9150407308698, -75.32014131427275, -99.9669724220343, -179.4805211403924, -148.95090965068525, -92.45904286817395, -57.35592189191594, -225.8501961200352, -109.14401854896796, -170.58534428432094, -148.54592819219332, -36.54826836380331, -116.97270780452881, 85.29006438196018, -88.40505851065903, -8.142942685055644, -170.95483433230575, -76.4416804260103, -309.2248215483799, -36.51020201904135, -76.64250894495859, -116.47269868132021, -36.19528396313317, -172.74074215282758, -30.88206674338089, -144.75992110615363, -81.93353050953715, -144.79208332913976, 17.0479263309442, -37.60682100171378, -9.097618964288415, -148.59156078436547, -90.11286939362373, -56.4255070409045, -44.59079783523359, -110.4322076637954, -188.14857469372475, -232.78992200123017, -97.32886193860784, -270.18133278761843, -193.45839305932975, -103.39928576894818, -109.88263077162283], "policy_AGENT-0_reward": [40.14723562969875, 130.16366832559092, 15.707413181573752, -117.85530449303425, -26.711033539855944, -180.45460842797897, -21.187311351227933, -7.813195964196132, -224.38788195453017, -94.35783173641707, 22.085142728178383, -161.25613123024107, -28.02321298155577, -72.2798176185916, -6.461907889367687, -89.51970925515064, 139.1009781637763, -18.18057376700603, -49.29212438656865, -93.64692604644785, -30.632378279870778, -135.08555831704524, 108.46352651264597, -199.4380169266886, -113.90231154132277, -254.82337276234654, -96.05520516050598, -133.2904445573163, -96.93697007345591, -116.8963105616554, -96.6355636723848, -94.94627899271588, -106.13759529464457, -133.9850729230435, -105.89526926171789, -98.899739847572, 5.825479401188177, -152.9578035384514, 43.0920408232931, -90.73200025360217, 41.846693532444526, -44.48760575052333, 76.81454012363335, -61.020187532341865, 75.23672791571849, -113.3715628750623, -135.9459933910319, -142.12102388216593, -236.61131827862908, -177.59982997739232, 26.494973802527014, -107.2268523008205, 25.477458540300248, -193.1403396475817, 19.84597510447516, -85.73858687443752, -3.301019507146364, -156.8080406736243, -29.32949426777758, -148.61844037379686, -224.56830609521356, -89.5266049912724, -70.26820052644287, -107.46581288216188, -212.49508907992686, -85.47464178080499, -196.90381104752313, -148.08058529863817, 24.80630551464601, -74.6525857258599, 14.844436960435452, -112.47286189392369, -53.244834266173996, -213.5404345725455, 15.502328396060008, -342.1331157586209, -92.20271692043436, 65.4283327204319, -158.89872216986902, -191.7788998704841, -74.59744551315833, -53.890964850325915, -74.38503468826467, 40.28445575486672, -71.03813504534018, 48.53898211729234, -79.68176421041832, -109.92479239000147, -194.62628848477456, -134.32078273607132, -91.86289181845885, 106.00541835134207, -106.61820191157891, -175.94502058858907, -267.18590339072244, -25.84497197185798, -264.5256488083677, -172.61591400248136, -11.075292171349567, -103.39642697003981], "policy_AGENT-1_reward": [85.23988606364804, 106.3041398681987, 15.60383568335757, -118.09813663298159, -245.728156745948, -175.5935250876053, -121.26421159603709, -7.842330745998625, -36.09465961127023, -51.38196947768891, 68.61831923904188, -161.36869113252132, 11.421991702934198, -141.16193523902868, 40.76338230446961, -89.46977110228858, 19.0210212925568, -12.942201630998278, -47.10249631704101, -44.77273757390685, -102.21287382244262, -131.30823834793455, 115.14240173169522, -68.71570217957229, -175.87172447551555, -255.04341947490104, -96.19806660905627, -169.16232653588892, -96.8928227578339, -116.95567985726808, -92.33357874186757, -94.85892506416778, -120.92703003558127, -95.4227057337572, -173.80846588476322, -98.82182748268525, 6.193037644425183, -106.5725883368091, 44.153213797731034, -41.792136201191916, 84.78271483522245, 4.3139521902696405, 76.74579522279, -61.24798994146839, 76.5357850279121, -113.31393046614123, -86.38932154369091, -95.11374033759988, -19.59162615931828, -131.286958508332, 90.57645193038829, -62.216383622821915, 25.608908704354963, -148.89605378472885, 19.7359710794018, -101.2869706519927, 42.813813233666295, -108.3091139399302, -29.45256981402775, -148.59416593693948, -177.47236241590744, -142.95403059567022, -70.39746394567594, -107.55166350183418, -172.28170957793884, -37.933055860190564, -149.05705029003903, -147.679882756107, 26.537365850617686, -97.58810092083903, 63.59274326126537, -68.47594257301138, 17.230843570898244, -107.93060454290938, 15.474373309496306, -335.22202107492, -92.10102935385464, 43.88389678053359, -111.69756296094897, -144.75051750536272, -162.12671374734776, -76.44921769968026, -117.66156011510661, 39.982526734763056, -138.13435989365937, 48.40197970883626, -78.83939214581814, -134.89178592979445, -151.48930280636276, -160.1926955994369, -55.86455010819576, 147.30078069685422, -105.93622210512866, -175.1787936499248, -220.35040732087705, 19.38842428675779, -221.92322072240032, -128.80798604240292, 29.970786074424456, -101.48469280099826], "policy_AGENT-2_reward": [-36.490990801638, -34.14455364335691, -90.77448703682228, -168.52952116518208, -27.2674253145467, -181.19771015107153, -21.751401107729077, -50.61302128548405, -36.55702886725734, -79.77205284868761, 25.464196577785287, -206.32970271882348, 82.76856639447159, -72.83295809740605, -23.040789548852246, -37.64818350429374, 179.17265823347674, -6.595286343335838, -17.98451022302881, -11.982436130148871, -31.20837538504961, -95.71325000878419, 81.06451073310515, -69.27688871206544, -114.46311524977403, -304.36779198936546, -37.09512346943736, -169.77675097884827, -91.63879253165672, 22.260617362222263, -106.67715031433039, -103.25881800529464, -121.35968274829642, -131.27787568085571, -106.45342584394899, -177.9240227158286, -0.08418491611733714, -124.76140822531103, 39.138066891309975, -41.8860316432026, 32.74641455793593, -27.80428108993027, 1.1550621500720553, -139.74904150664497, 61.29252205370895, -63.5339993136335, -32.619652612299404, -9.036977726953754, -20.219740660948005, -10.495134295374356, 90.02116285450856, -61.870864877493986, -32.038726606666614, -13.00977107247651, -75.24861519491319, -107.55974966088063, -32.24533559481903, -136.90276892697813, -75.18286042059711, -149.17795404063398, -178.22077053280995, -90.08547809136793, -92.51080726675853, -57.39139050135501, -225.7054917780764, -109.07174971801176, -170.46339187753054, -148.53176147189845, -36.578624769369256, -121.93137644456115, 85.53811875822467, -92.0998539887798, 16.60124851756374, -108.38168553290646, -122.77226390959818, -350.5168591067992, -36.459516674207876, -76.6272766842729, -102.35744747143215, -36.293429976519405, -75.16147842302807, -76.46848515151781, -74.94952518113536, -48.44398465336168, -71.60380783401381, 17.111089713844684, -34.16099251143407, -9.12754800037348, -149.7539519095464, -160.81887145073694, -120.22969851851954, -44.51385164103993, -109.24189687404088, -189.41893984248296, -227.34064513134024, -97.37701021997553, -267.5327144847668, -185.6076376982838, -103.45006502171626, -103.95319478518735]}, "sampler_perf": {"mean_env_wait_ms": 53.57577829616831, "mean_raw_obs_processing_ms": 2.24607544190057, "mean_inference_ms": 2.6941510342006505, "mean_action_processing_ms": 0.13930978802764205}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 16800, "timers": {"sample_time_ms": 89744.749, "sample_throughput": 46.799, "load_time_ms": 239.108, "load_throughput": 17565.252, "learn_time_ms": 9131.6, "learn_throughput": 459.941, "update_time_ms": 8.044}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 17.94913101196289, "policy_loss": -0.018326830118894577, "vf_loss": 17.963308334350586, "vf_explained_var": 0.7672818899154663, "kl": 0.02074475586414337, "entropy": 1.3283063173294067, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 17.425519943237305, "policy_loss": -0.020342854782938957, "vf_loss": 17.442359924316406, "vf_explained_var": 0.7107985615730286, "kl": 0.011675071902573109, "entropy": 1.330048680305481, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 20.582578659057617, "policy_loss": -0.016097230836749077, "vf_loss": 20.595239639282227, "vf_explained_var": 0.6407952308654785, "kl": 0.017177646979689598, "entropy": 1.342307209968567, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 16.48448371887207, "policy_loss": -0.01550853531807661, "vf_loss": 16.496244430541992, "vf_explained_var": 0.6806557774543762, "kl": 0.0187542587518692, "entropy": 1.3338844776153564, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 16800, "num_steps_trained": 16800}, "done": false, "episodes_total": 140, "training_iteration": 4, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-23-26", "timestamp": 1624209806, "time_this_iter_s": 97.16058325767517, "time_total_s": 399.1159944534302, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd404392710>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd404392560>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4043929e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd404392a70>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd404392950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404392e60>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4043929e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd404392a70>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd404392950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404392e60>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4043929e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd404392a70>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd404392950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404392e60>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4043929e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd404392a70>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd404392950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404392e60>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd40449b8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 399.1159944534302, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 56.25217391304348, "ram_util_percent": 87.41159420289854}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 768.6056515890336, "episode_reward_min": -1337.096817488721, "episode_reward_mean": -326.3632449261617, "episode_len_mean": 121.39, "episodes_this_iter": 36, "policy_reward_min": {"AGENT-3": -309.2248215483799, "AGENT-0": -342.1331157586209, "AGENT-1": -335.22202107492, "AGENT-2": -350.5168591067992}, "policy_reward_max": {"AGENT-3": 96.0234334322777, "AGENT-0": 227.43288602654877, "AGENT-1": 234.38180983245928, "AGENT-2": 240.91480148883736}, "policy_reward_mean": {"AGENT-3": -90.65204737211678, "AGENT-0": -78.82375718664524, "AGENT-1": -78.19618019438424, "AGENT-2": -78.6912601730155}, "custom_metrics": {"mean_ego_speed_mean": 39.0954975, "mean_ego_speed_min": 28.244999999999997, "mean_ego_speed_max": 45.158, "distance_travelled_mean": 98.38716499999998, "distance_travelled_min": 26.396, "distance_travelled_max": 124.872}, "hist_stats": {"episode_reward": [-466.8667185288411, -361.4563336642548, -45.26359511280411, -440.02822875516654, -548.3012390404988, -369.66801756504435, 263.4266123767271, -556.0912032677151, 324.1037537833633, -514.3869608155159, -98.51373157014208, -900.9048862846294, -352.6370060457641, -560.0073924545303, -249.2179632438194, -24.87035463005153, -181.80642988181418, -32.83383813653378, 11.3073362442588, 60.334379290064845, -446.97740656475236, 768.6056515890336, -535.2706714803242, -412.0893815592926, -247.1356617492043, -645.9803897085554, -614.8647079441519, -21.482622847542814, 3.048831667771964, -671.9247791070752, -581.3146028833396, -311.6696230656442, -826.010643235655, -653.0852816558724, -248.7761023583241, -493.7922252801654, -361.45371696637375, -27.55568486276771, -600.8075589806671, -168.23724263005226, -1337.096817488721, -257.2734649675383, -43.957556128266106, -489.42643128357037, -409.01813131549983, -484.6263798363619, -237.6907344449047, -411.75604109066006, -50.110532673269205, -425.56838610215334, 131.09997787091777, -230.2889698693842, -263.04174528445753, -644.4611039850495, -545.4452191798691, -324.38264748607895, 164.20154957192278, -432.22852855454374, -728.6913287747213, -947.6668778441701, -201.16241984368392, -1024.1629168031532, -680.4899308024978, -187.95385688758935, -418.71694532784784, 52.4818539817668, 168.19183654940161, -109.52362511637789, -572.9942671769448, -560.145527005969, -631.0349286376155, -298.5125454590126, -117.09890682920414, -484.2280743775477, -299.4852938281189, 141.55152450717924, -735.2654182830312, 148.74979950417637, -438.2638792445217, -11.94258870991618, -254.36448362523893, 355.7490214679772, -44.3134170294799, -132.41236980655364, -162.25180858248305, -273.53647877759397, -460.98719643843936, 388.44826915177316, -496.64518054287834, -591.1062195675634, -1023.5480001977292, -228.0656324778305, -566.8684945686982, -328.32542567300175, -149.91092548546106, -394.7262264687316, -396.42577431890606, -414.09453445798704, -527.8585970530054, -567.1899025817911], "episode_lengths": [131, 114, 110, 127, 129, 129, 120, 118, 137, 126, 112, 101, 125, 122, 132, 43, 133, 108, 129, 122, 115, 134, 120, 115, 112, 117, 126, 123, 129, 118, 121, 135, 132, 121, 122, 123, 132, 123, 128, 116, 154, 30, 126, 127, 125, 127, 124, 112, 128, 120, 120, 121, 126, 132, 121, 112, 144, 120, 125, 126, 129, 143, 137, 138, 117, 124, 128, 110, 98, 139, 126, 126, 72, 121, 128, 125, 110, 137, 122, 124, 55, 130, 127, 124, 119, 120, 138, 126, 126, 133, 115, 125, 137, 107, 129, 126, 113, 117, 146, 122], "policy_AGENT-3_reward": [-206.10597193988733, -56.77409150050384, -21.25480487367881, -102.64226565343829, -251.32613650321144, -48.07412910880186, 73.63949117849234, -162.27161231891063, 96.0234334322777, -81.85988872263492, -50.09650428538143, -244.37869729581863, -149.07126859363794, -142.18099544244248, -45.56907667996212, -34.02926222714577, -11.598490525424971, -33.84618840071053, 19.24838345706917, -32.576487764357424, -133.50666526205387, 65.87615424118859, -177.74331080453132, -151.23347702159526, -17.8908275107238, -160.3388178762626, -123.6769148554611, 82.07888611105267, -29.045332399713615, -167.91276508157205, -161.84074143020092, -55.01562056762284, -207.8602388932633, -152.19261450693622, -83.99134746941661, -147.30219998882362, -88.40505851065903, -8.142942685055644, -170.95483433230575, -76.4416804260103, -309.2248215483799, -36.51020201904135, -76.64250894495859, -116.47269868132021, -36.19528396313317, -172.74074215282758, -30.88206674338089, -144.75992110615363, -81.93353050953715, -144.79208332913976, 17.0479263309442, -37.60682100171378, -9.097618964288415, -148.59156078436547, -90.11286939362373, -56.4255070409045, -44.59079783523359, -110.4322076637954, -188.14857469372475, -232.78992200123017, -97.32886193860784, -270.18133278761843, -193.45839305932975, -103.39928576894818, -109.88263077162283, -36.414276909942004, -34.13141800103122, -50.060386944486936, -168.5113048857469, -260.4389114056181, -93.78908497096009, -134.3096214040184, -50.83035883352532, -187.1885039444902, -73.97343976532535, 25.383865962173836, -206.31089320144582, 82.58245438832611, -151.98916828949555, -23.203273576165806, -37.726819763505944, 18.454363778167348, -6.595355288139796, -18.033238879915075, -11.84970883197953, -109.4828512902308, -98.88014976467525, 83.77783017432667, -159.214572724552, -186.86906830095174, -209.3134159711161, 1.2827627611691703, -94.63897249664448, -42.85684031005544, 61.68044757124021, -99.0799337401487, -103.36175225672791, -65.67022637946478, -167.17294271534905, -181.03274159136117], "policy_AGENT-0_reward": [-32.870799244119695, -123.9079975476359, 22.304542693960563, -141.19172246388584, -27.810640732915722, -123.10217341811568, 37.004248927447804, -96.93224217559285, 74.1548744883812, -170.689888619118, 23.347265644894, -206.0483309279841, -31.387183044692872, -141.99660192466897, -84.24420052661046, 21.52866115818238, -80.03073801083917, 3.875758094987532, -19.21119455145389, 0.11319492745877469, -66.72152124184069, 227.43288602654877, -67.24255269119328, -189.8476461099261, -116.64336963894874, -164.39118037880414, -194.9785839864238, 110.30318818994235, 6.409653439524412, -167.90605359598692, -135.50853894516382, -102.86936087128898, -228.91007907236005, -198.11632164783106, -40.715692671643836, -105.10787612752797, -112.47286189392369, -53.244834266173996, -213.5404345725455, 15.502328396060008, -342.1331157586209, -92.20271692043436, 65.4283327204319, -158.89872216986902, -191.7788998704841, -74.59744551315833, -53.890964850325915, -74.38503468826467, 40.28445575486672, -71.03813504534018, 48.53898211729234, -79.68176421041832, -109.92479239000147, -194.62628848477456, -134.32078273607132, -91.86289181845885, 106.00541835134207, -106.61820191157891, -175.94502058858907, -267.18590339072244, -25.84497197185798, -264.5256488083677, -172.61591400248136, -11.075292171349567, -103.39642697003981, 40.14723562969875, 130.16366832559092, 15.707413181573752, -117.85530449303425, -26.711033539855944, -180.45460842797897, -21.187311351227933, -7.813195964196132, -224.38788195453017, -94.35783173641707, 22.085142728178383, -161.25613123024107, -28.02321298155577, -72.2798176185916, -6.461907889367687, -89.51970925515064, 139.1009781637763, -18.18057376700603, -49.29212438656865, -93.64692604644785, -30.632378279870778, -135.08555831704524, 108.46352651264597, -199.4380169266886, -113.90231154132277, -254.82337276234654, -96.05520516050598, -133.2904445573163, -96.93697007345591, -116.8963105616554, -96.6355636723848, -94.94627899271588, -106.13759529464457, -133.9850729230435, -105.89526926171789], "policy_AGENT-1_reward": [-194.46894962721328, -124.0377078885553, 22.35356055095174, -95.61402852351858, -240.91937408324654, -119.05973756750159, 74.20180725812475, -97.19738749139553, 80.81943036642794, -130.70445736962716, 23.2444868565592, -206.27747904239706, -140.24383479232858, -133.2642136715839, -79.42320302802946, 21.61993868985239, -78.79955108263992, -6.177688851136438, -15.297509707329, 46.77672975492731, -66.64530712952698, 234.38180983245928, -67.33410667722107, -35.28811012041036, -116.75704024271849, -156.295519798391, -147.19210070472462, -106.71352328253843, 54.72528741246962, -168.04148918677032, -135.07316411479164, -98.75502361407372, -183.40955095222287, -150.71638147974647, -40.021208024733404, -135.7210500422841, -68.47594257301138, 17.230843570898244, -107.93060454290938, 15.474373309496306, -335.22202107492, -92.10102935385464, 43.88389678053359, -111.69756296094897, -144.75051750536272, -162.12671374734776, -76.44921769968026, -117.66156011510661, 39.982526734763056, -138.13435989365937, 48.40197970883626, -78.83939214581814, -134.89178592979445, -151.48930280636276, -160.1926955994369, -55.86455010819576, 147.30078069685422, -105.93622210512866, -175.1787936499248, -220.35040732087705, 19.38842428675779, -221.92322072240032, -128.80798604240292, 29.970786074424456, -101.48469280099826, 85.23988606364804, 106.3041398681987, 15.60383568335757, -118.09813663298159, -245.728156745948, -175.5935250876053, -121.26421159603709, -7.842330745998625, -36.09465961127023, -51.38196947768891, 68.61831923904188, -161.36869113252132, 11.421991702934198, -141.16193523902868, 40.76338230446961, -89.46977110228858, 19.0210212925568, -12.942201630998278, -47.10249631704101, -44.77273757390685, -102.21287382244262, -131.30823834793455, 115.14240173169522, -68.71570217957229, -175.87172447551555, -255.04341947490104, -96.19806660905627, -169.16232653588892, -96.8928227578339, -116.95567985726808, -92.33357874186757, -94.85892506416778, -120.92703003558127, -95.4227057337572, -173.80846588476322], "policy_AGENT-2_reward": [-33.420997717621105, -56.736536727560015, -68.66689348403759, -100.58021211432357, -28.24508772112547, -79.43197747062513, 78.58106501266221, -199.68996128181595, 73.10601549627637, -131.13272610413566, -95.0089797862139, -244.20037901842937, -31.93471961510478, -142.5655814158351, -39.98148300921723, -33.98969225094049, -11.377650262910016, 3.3142810203257795, 26.56765704597257, 46.02094237203623, -180.10391293133094, 240.91480148883736, -222.95070130737852, -35.720148307360915, 4.155575643186548, -164.95487165509746, -149.0171083975427, -107.15117386599944, -29.04077678450834, -168.06447124274504, -148.8921583931836, -55.02961801265869, -205.8307743178094, -152.05996402135878, -84.04785419252983, -105.66109912152982, -92.0998539887798, 16.60124851756374, -108.38168553290646, -122.77226390959818, -350.5168591067992, -36.459516674207876, -76.6272766842729, -102.35744747143215, -36.293429976519405, -75.16147842302807, -76.46848515151781, -74.94952518113536, -48.44398465336168, -71.60380783401381, 17.111089713844684, -34.16099251143407, -9.12754800037348, -149.7539519095464, -160.81887145073694, -120.22969851851954, -44.51385164103993, -109.24189687404088, -189.41893984248296, -227.34064513134024, -97.37701021997553, -267.5327144847668, -185.6076376982838, -103.45006502171626, -103.95319478518735, -36.490990801638, -34.14455364335691, -90.77448703682228, -168.52952116518208, -27.2674253145467, -181.19771015107153, -21.751401107729077, -50.61302128548405, -36.55702886725734, -79.77205284868761, 25.464196577785287, -206.32970271882348, 82.76856639447159, -72.83295809740605, -23.040789548852246, -37.64818350429374, 179.17265823347674, -6.595286343335838, -17.98451022302881, -11.982436130148871, -31.20837538504961, -95.71325000878419, 81.06451073310515, -69.27688871206544, -114.46311524977403, -304.36779198936546, -37.09512346943736, -169.77675097884827, -91.63879253165672, 22.260617362222263, -106.67715031433039, -103.25881800529464, -121.35968274829642, -131.27787568085571, -106.45342584394899]}, "sampler_perf": {"mean_env_wait_ms": 53.719395064740176, "mean_raw_obs_processing_ms": 2.270080248157677, "mean_inference_ms": 2.6019039380737534, "mean_action_processing_ms": 0.14031020473135702}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 21000, "timers": {"sample_time_ms": 90069.215, "sample_throughput": 46.631, "load_time_ms": 194.215, "load_throughput": 21625.565, "learn_time_ms": 8965.979, "learn_throughput": 468.437, "update_time_ms": 8.555}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 13.402774810791016, "policy_loss": -0.025113262236118317, "vf_loss": 13.4216947555542, "vf_explained_var": 0.8180040717124939, "kl": 0.02064558118581772, "entropy": 1.3356236219406128, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 13.994095802307129, "policy_loss": -0.025592168793082237, "vf_loss": 14.016435623168945, "vf_explained_var": 0.7852616310119629, "kl": 0.010836564935743809, "entropy": 1.309010624885559, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 13.60823917388916, "policy_loss": -0.018909381702542305, "vf_loss": 13.623956680297852, "vf_explained_var": 0.7563415765762329, "kl": 0.015959598124027252, "entropy": 1.339099407196045, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 11.01121997833252, "policy_loss": -0.020079167559742928, "vf_loss": 11.028202056884766, "vf_explained_var": 0.8155273795127869, "kl": 0.015488301403820515, "entropy": 1.3205599784851074, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 21000, "num_steps_trained": 21000}, "done": false, "episodes_total": 176, "training_iteration": 5, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-25-06", "timestamp": 1624209906, "time_this_iter_s": 99.71352529525757, "time_total_s": 498.82951974868774, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40449bd40>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40449b320>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449bf80>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4044e7e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd417ac28c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404392290>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449bf80>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4044e7e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd417ac28c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404392290>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449bf80>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4044e7e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd417ac28c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404392290>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449bf80>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4044e7e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd417ac28c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404392290>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd404392f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 498.82951974868774, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 56.88531468531468, "ram_util_percent": 87.5888111888112}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 768.6056515890336, "episode_reward_min": -1023.5480001977292, "episode_reward_mean": -300.60619055305256, "episode_len_mean": 118.33, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-3": -251.32613650321144, "AGENT-0": -270.02315104496626, "AGENT-1": -255.04341947490104, "AGENT-2": -304.36779198936546}, "policy_reward_max": {"AGENT-3": 119.5469054301516, "AGENT-0": 227.43288602654877, "AGENT-1": 234.38180983245928, "AGENT-2": 240.91480148883736}, "policy_reward_mean": {"AGENT-3": -83.70782971393005, "AGENT-0": -74.43512916156321, "AGENT-1": -75.54712154697833, "AGENT-2": -66.91611013058092}, "custom_metrics": {"mean_ego_speed_mean": 38.63667, "mean_ego_speed_min": 23.905749999999998, "mean_ego_speed_max": 45.158, "distance_travelled_mean": 93.8524575, "distance_travelled_min": 28.756500000000003, "distance_travelled_max": 124.872}, "hist_stats": {"episode_reward": [-14.327857027644145, -347.32096189211364, -248.79339690699038, -491.84482387844054, 126.65432592825255, -352.31625698159974, -103.56406807671999, -261.17357956381153, -380.0469624890515, -347.3104902051274, 160.81741977195733, -402.3600530869212, -101.00114756983152, -435.0939395899302, -387.7715775882813, -499.9702639925033, 468.1975346318988, -187.3709214091785, -206.93614352670335, -550.4811283577951, -136.15035099903898, -411.48428859913054, -266.47225871533306, -511.2152377124364, -257.63434341872414, -161.98429169732395, -586.2842390908885, -385.0879715902245, -556.3512431699094, -453.73671413415633, -638.4267883163704, -558.0884527905444, -648.1771577121664, -310.88293249777655, -251.85571821825414, -348.68343317720604, -86.37060070402671, -484.2280743775477, -299.4852938281189, 141.55152450717924, -735.2654182830312, 148.74979950417637, -438.2638792445217, -11.94258870991618, -254.36448362523893, 355.7490214679772, -44.3134170294799, -132.41236980655364, -162.25180858248305, -273.53647877759397, -460.98719643843936, 388.44826915177316, -496.64518054287834, -591.1062195675634, -1023.5480001977292, -228.0656324778305, -566.8684945686982, -328.32542567300175, -149.91092548546106, -394.7262264687316, -396.42577431890606, -414.09453445798704, -527.8585970530054, -567.1899025817911, -466.8667185288411, -361.4563336642548, -45.26359511280411, -440.02822875516654, -548.3012390404988, -369.66801756504435, 263.4266123767271, -556.0912032677151, 324.1037537833633, -514.3869608155159, -98.51373157014208, -900.9048862846294, -352.6370060457641, -560.0073924545303, -249.2179632438194, -24.87035463005153, -181.80642988181418, -32.83383813653378, 11.3073362442588, 60.334379290064845, -446.97740656475236, 768.6056515890336, -535.2706714803242, -412.0893815592926, -247.1356617492043, -645.9803897085554, -614.8647079441519, -21.482622847542814, 3.048831667771964, -671.9247791070752, -581.3146028833396, -311.6696230656442, -826.010643235655, -653.0852816558724, -248.7761023583241, -493.7922252801654], "episode_lengths": [118, 119, 115, 125, 126, 35, 119, 125, 125, 31, 134, 110, 121, 122, 157, 121, 135, 89, 122, 130, 119, 113, 124, 132, 41, 150, 123, 120, 119, 123, 123, 113, 132, 118, 28, 120, 123, 121, 128, 125, 110, 137, 122, 124, 55, 130, 127, 124, 119, 120, 138, 126, 126, 133, 115, 125, 137, 107, 129, 126, 113, 117, 146, 122, 131, 114, 110, 127, 129, 129, 120, 118, 137, 126, 112, 101, 125, 122, 132, 43, 133, 108, 129, 122, 115, 134, 120, 115, 112, 117, 126, 123, 129, 118, 121, 135, 132, 121, 122, 123], "policy_AGENT-3_reward": [-29.048563179434453, -116.67072725304779, -78.65219176018275, -101.56938156429295, 19.41863220741269, -58.53364592749949, -75.99467134720003, -42.6131624732368, -159.88047287526956, -59.57126292341284, -31.97511138155723, -148.70314101499167, -57.65235546881091, -144.74218656957154, -194.13486527345995, -166.41094905587408, 119.5469054301516, -29.917524202518557, -82.3373393259627, -235.54735549072564, -44.38753892295402, -122.32745300400686, -109.6453071933433, -111.04871398203751, -92.82694123176447, 49.561607248979364, -152.72386740117673, -130.97426642690814, -159.72397117878936, -135.4490771560147, -195.14107531372753, -104.13210289778847, -150.57464157151884, -84.12626783121264, -36.95694522504144, -112.7927122183103, 65.09821389247543, -187.1885039444902, -73.97343976532535, 25.383865962173836, -206.31089320144582, 82.58245438832611, -151.98916828949555, -23.203273576165806, -37.726819763505944, 18.454363778167348, -6.595355288139796, -18.033238879915075, -11.84970883197953, -109.4828512902308, -98.88014976467525, 83.77783017432667, -159.214572724552, -186.86906830095174, -209.3134159711161, 1.2827627611691703, -94.63897249664448, -42.85684031005544, 61.68044757124021, -99.0799337401487, -103.36175225672791, -65.67022637946478, -167.17294271534905, -181.03274159136117, -206.10597193988733, -56.77409150050384, -21.25480487367881, -102.64226565343829, -251.32613650321144, -48.07412910880186, 73.63949117849234, -162.27161231891063, 96.0234334322777, -81.85988872263492, -50.09650428538143, -244.37869729581863, -149.07126859363794, -142.18099544244248, -45.56907667996212, -34.02926222714577, -11.598490525424971, -33.84618840071053, 19.24838345706917, -32.576487764357424, -133.50666526205387, 65.87615424118859, -177.74331080453132, -151.23347702159526, -17.8908275107238, -160.3388178762626, -123.6769148554611, 82.07888611105267, -29.045332399713615, -167.91276508157205, -161.84074143020092, -55.01562056762284, -207.8602388932633, -152.19261450693622, -83.99134746941661, -147.30219998882362], "policy_AGENT-0_reward": [21.22624464808918, -60.16150153525832, -47.09656614774891, -146.65594514811693, 41.39311669276848, -117.61631999836352, 9.00363278845257, -92.69893238281618, -36.998592452600775, -114.24009198100642, 89.7011080826014, -63.37909561767245, 25.928025306747056, -182.7972130318436, 15.769316193008493, -208.36038281373567, 137.08036201432083, -86.8769289165472, -24.399133973589027, -270.02315104496626, -25.693717324391557, -60.20948564968525, -26.31749201061531, -165.21361507079072, -36.05467738629244, -113.49879090984639, -143.70760218352586, -63.09953475199464, -120.24437983984919, -91.40451912641069, -130.07409872941378, -147.46146368906494, -196.09086359603867, -71.74159743522867, -89.0377135763487, -63.292989312936555, 25.156708115623125, -224.38788195453017, -94.35783173641707, 22.085142728178383, -161.25613123024107, -28.02321298155577, -72.2798176185916, -6.461907889367687, -89.51970925515064, 139.1009781637763, -18.18057376700603, -49.29212438656865, -93.64692604644785, -30.632378279870778, -135.08555831704524, 108.46352651264597, -199.4380169266886, -113.90231154132277, -254.82337276234654, -96.05520516050598, -133.2904445573163, -96.93697007345591, -116.8963105616554, -96.6355636723848, -94.94627899271588, -106.13759529464457, -133.9850729230435, -105.89526926171789, -32.870799244119695, -123.9079975476359, 22.304542693960563, -141.19172246388584, -27.810640732915722, -123.10217341811568, 37.004248927447804, -96.93224217559285, 74.1548744883812, -170.689888619118, 23.347265644894, -206.0483309279841, -31.387183044692872, -141.99660192466897, -84.24420052661046, 21.52866115818238, -80.03073801083917, 3.875758094987532, -19.21119455145389, 0.11319492745877469, -66.72152124184069, 227.43288602654877, -67.24255269119328, -189.8476461099261, -116.64336963894874, -164.39118037880414, -194.9785839864238, 110.30318818994235, 6.409653439524412, -167.90605359598692, -135.50853894516382, -102.86936087128898, -228.91007907236005, -198.11632164783106, -40.715692671643836, -105.10787612752797], "policy_AGENT-1_reward": [22.604338954236173, -109.76495122237816, -75.37746552991513, -142.1774390358964, 25.040483419600143, -117.62337951641283, -45.01333902419474, -32.60008726765908, -145.74335415750338, -114.13600179007366, 135.03037736939388, -126.34945000766946, 25.84723758540626, -53.537016041712164, 15.809068456097194, -62.2322089117875, 106.12722795693351, -40.68930314013878, -75.24641535829426, -22.167092858748845, -39.81184218918111, -60.258255844455896, -103.63681469060447, -118.25916524959065, -92.26197442883921, -113.67985929518926, -145.57866447171762, -127.3679211297021, -155.5705802960573, -91.54288870821216, -182.57022923630203, -153.00375634544025, -151.78238277809442, -71.03817869484493, -88.93893072343651, -108.7492714673207, -88.098116318646, -36.09465961127023, -51.38196947768891, 68.61831923904188, -161.36869113252132, 11.421991702934198, -141.16193523902868, 40.76338230446961, -89.46977110228858, 19.0210212925568, -12.942201630998278, -47.10249631704101, -44.77273757390685, -102.21287382244262, -131.30823834793455, 115.14240173169522, -68.71570217957229, -175.87172447551555, -255.04341947490104, -96.19806660905627, -169.16232653588892, -96.8928227578339, -116.95567985726808, -92.33357874186757, -94.85892506416778, -120.92703003558127, -95.4227057337572, -173.80846588476322, -194.46894962721328, -124.0377078885553, 22.35356055095174, -95.61402852351858, -240.91937408324654, -119.05973756750159, 74.20180725812475, -97.19738749139553, 80.81943036642794, -130.70445736962716, 23.2444868565592, -206.27747904239706, -140.24383479232858, -133.2642136715839, -79.42320302802946, 21.61993868985239, -78.79955108263992, -6.177688851136438, -15.297509707329, 46.77672975492731, -66.64530712952698, 234.38180983245928, -67.33410667722107, -35.28811012041036, -116.75704024271849, -156.295519798391, -147.19210070472462, -106.71352328253843, 54.72528741246962, -168.04148918677032, -135.07316411479164, -98.75502361407372, -183.40955095222287, -150.71638147974647, -40.021208024733404, -135.7210500422841], "policy_AGENT-2_reward": [-29.109877450535087, -60.72378188142947, -47.66717346914321, -101.44205813013426, 40.80209360847123, -58.5429115393238, 8.440309506222427, -93.26139744009953, -37.424543003677734, -59.3631335106345, -31.93895429848065, -63.9283664465874, -95.12405499317401, -54.01752394680317, -225.2150969639271, -62.96672321110613, 105.44303923049267, -29.88716514997391, -24.953254868857318, -22.743528963354315, -26.257252562512285, -168.68909410098232, -26.872644820770173, -116.69374341001739, -36.49075037182803, 15.632751258731972, -144.27410503446885, -63.64624928161945, -120.81231185521361, -135.34022914351834, -130.6413850369264, -153.4911298582511, -149.72926976651425, -83.97688853649036, -36.92212869342743, -63.84846017863794, -88.52740639347911, -36.55702886725734, -79.77205284868761, 25.464196577785287, -206.32970271882348, 82.76856639447159, -72.83295809740605, -23.040789548852246, -37.64818350429374, 179.17265823347674, -6.595286343335838, -17.98451022302881, -11.982436130148871, -31.20837538504961, -95.71325000878419, 81.06451073310515, -69.27688871206544, -114.46311524977403, -304.36779198936546, -37.09512346943736, -169.77675097884827, -91.63879253165672, 22.260617362222263, -106.67715031433039, -103.25881800529464, -121.35968274829642, -131.27787568085571, -106.45342584394899, -33.420997717621105, -56.736536727560015, -68.66689348403759, -100.58021211432357, -28.24508772112547, -79.43197747062513, 78.58106501266221, -199.68996128181595, 73.10601549627637, -131.13272610413566, -95.0089797862139, -244.20037901842937, -31.93471961510478, -142.5655814158351, -39.98148300921723, -33.98969225094049, -11.377650262910016, 3.3142810203257795, 26.56765704597257, 46.02094237203623, -180.10391293133094, 240.91480148883736, -222.95070130737852, -35.720148307360915, 4.155575643186548, -164.95487165509746, -149.0171083975427, -107.15117386599944, -29.04077678450834, -168.06447124274504, -148.8921583931836, -55.02961801265869, -205.8307743178094, -152.05996402135878, -84.04785419252983, -105.66109912152982]}, "sampler_perf": {"mean_env_wait_ms": 53.712116421730755, "mean_raw_obs_processing_ms": 2.306101265990599, "mean_inference_ms": 2.5472942838508725, "mean_action_processing_ms": 0.14078415712078435}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 25200, "timers": {"sample_time_ms": 90109.977, "sample_throughput": 46.61, "load_time_ms": 164.572, "load_throughput": 25520.695, "learn_time_ms": 8800.319, "learn_throughput": 477.255, "update_time_ms": 8.31}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 17.373403549194336, "policy_loss": -0.022930564358830452, "vf_loss": 17.390037536621094, "vf_explained_var": 0.8387641906738281, "kl": 0.013989566825330257, "entropy": 1.3300496339797974, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 16.407642364501953, "policy_loss": -0.021794788539409637, "vf_loss": 16.424104690551758, "vf_explained_var": 0.7957541942596436, "kl": 0.017790330573916435, "entropy": 1.296897053718567, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 15.015557289123535, "policy_loss": -0.022295190021395683, "vf_loss": 15.034759521484375, "vf_explained_var": 0.7529370188713074, "kl": 0.015467561781406403, "entropy": 1.3188536167144775, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 14.834097862243652, "policy_loss": -0.022045385092496872, "vf_loss": 14.85295295715332, "vf_explained_var": 0.8128291964530945, "kl": 0.015958771109580994, "entropy": 1.311274766921997, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 25200, "num_steps_trained": 25200}, "done": false, "episodes_total": 213, "training_iteration": 6, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-26-44", "timestamp": 1624210004, "time_this_iter_s": 98.33443236351013, "time_total_s": 597.1639521121979, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd4043e80e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd4043e8200>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4043e87a0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4043e87a0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4043e87a0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4043e87a0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd40445ad40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 597.1639521121979, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 56.949285714285715, "ram_util_percent": 87.63000000000001}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1067.52093898723, "episode_reward_min": -929.6573103410392, "episode_reward_mean": -301.75013565157934, "episode_len_mean": 118.51, "episodes_this_iter": 34, "policy_reward_min": {"AGENT-3": -276.7350579948251, "AGENT-0": -270.02315104496626, "AGENT-2": -256.84141799779707, "AGENT-1": -265.09586830832666}, "policy_reward_max": {"AGENT-3": 234.05362952739972, "AGENT-0": 268.48717523645087, "AGENT-2": 279.4844666604222, "AGENT-1": 285.4956675629562}, "policy_reward_mean": {"AGENT-3": -91.21936762060933, "AGENT-0": -68.45007366400567, "AGENT-2": -67.8202495285594, "AGENT-1": -74.2604448384049}, "custom_metrics": {"mean_ego_speed_mean": 38.38007999999999, "mean_ego_speed_min": 23.905749999999998, "mean_ego_speed_max": 45.158, "distance_travelled_mean": 93.02098, "distance_travelled_min": 28.756500000000003, "distance_travelled_max": 124.872}, "hist_stats": {"episode_reward": [-929.6573103410392, -37.29198086695142, -508.44578761578356, -38.5894399502155, -465.92913438300866, 346.3758810169689, -89.54901424238734, -472.2170430786939, -359.71696145277576, -114.62063813505085, -530.0927367288145, 157.39933681516334, -132.539135708336, -437.12868093798534, -306.5272828014445, 658.3465577143911, -330.45738793100145, 1067.52093898723, -491.0164950037108, -387.30863831988904, -423.61173795327977, 103.81978717559446, -664.1938018013698, -367.9994995975329, -315.03202042500675, -704.7986173038045, -715.448081480407, -389.8120865679205, -21.500968854629058, -773.448955803694, -681.98000267085, -478.54089367070276, -597.3986840059285, -598.4788216850973, -556.0912032677151, 324.1037537833633, -514.3869608155159, -98.51373157014208, -900.9048862846294, -352.6370060457641, -560.0073924545303, -249.2179632438194, -24.87035463005153, -181.80642988181418, -32.83383813653378, 11.3073362442588, 60.334379290064845, -446.97740656475236, 768.6056515890336, -535.2706714803242, -412.0893815592926, -247.1356617492043, -645.9803897085554, -614.8647079441519, -21.482622847542814, 3.048831667771964, -671.9247791070752, -581.3146028833396, -311.6696230656442, -826.010643235655, -653.0852816558724, -248.7761023583241, -493.7922252801654, -14.327857027644145, -347.32096189211364, -248.79339690699038, -491.84482387844054, 126.65432592825255, -352.31625698159974, -103.56406807671999, -261.17357956381153, -380.0469624890515, -347.3104902051274, 160.81741977195733, -402.3600530869212, -101.00114756983152, -435.0939395899302, -387.7715775882813, -499.9702639925033, 468.1975346318988, -187.3709214091785, -206.93614352670335, -550.4811283577951, -136.15035099903898, -411.48428859913054, -266.47225871533306, -511.2152377124364, -257.63434341872414, -161.98429169732395, -586.2842390908885, -385.0879715902245, -556.3512431699094, -453.73671413415633, -638.4267883163704, -558.0884527905444, -648.1771577121664, -310.88293249777655, -251.85571821825414, -348.68343317720604, -86.37060070402671], "episode_lengths": [88, 114, 125, 118, 127, 143, 117, 134, 110, 125, 112, 124, 129, 124, 113, 142, 109, 162, 124, 130, 115, 119, 134, 116, 127, 132, 122, 118, 121, 127, 129, 121, 112, 117, 118, 137, 126, 112, 101, 125, 122, 132, 43, 133, 108, 129, 122, 115, 134, 120, 115, 112, 117, 126, 123, 129, 118, 121, 135, 132, 121, 122, 123, 118, 119, 115, 125, 126, 35, 119, 125, 125, 31, 134, 110, 121, 122, 157, 121, 135, 89, 122, 130, 119, 113, 124, 132, 41, 150, 123, 120, 119, 123, 123, 113, 132, 118, 28, 120, 123], "policy_AGENT-3_reward": [-256.84888372252294, -58.900041834558166, -164.3714642884725, 24.5086298708643, -118.90555835922868, 123.22060738958899, -34.98418607927193, -210.72015172681276, -108.57346390567409, -54.26708215132625, -121.9042102675399, 77.34793446332843, -9.054416818083876, -169.36160333109308, -145.37610828601808, 195.71264604988588, -78.9833196477946, 234.05362952739972, -189.45042281606382, -169.8306605083318, -128.79378452361962, 60.7444529689159, -269.3801063369444, -116.12100370640378, -25.990066263873494, -276.7350579948251, -206.92346325082167, -136.43266225962503, -33.13051248390015, -225.45228743967718, -224.8135394189067, -170.3935183328444, -176.30891125350124, -158.55525677754315, -162.27161231891063, 96.0234334322777, -81.85988872263492, -50.09650428538143, -244.37869729581863, -149.07126859363794, -142.18099544244248, -45.56907667996212, -34.02926222714577, -11.598490525424971, -33.84618840071053, 19.24838345706917, -32.576487764357424, -133.50666526205387, 65.87615424118859, -177.74331080453132, -151.23347702159526, -17.8908275107238, -160.3388178762626, -123.6769148554611, 82.07888611105267, -29.045332399713615, -167.91276508157205, -161.84074143020092, -55.01562056762284, -207.8602388932633, -152.19261450693622, -83.99134746941661, -147.30219998882362, -29.048563179434453, -116.67072725304779, -78.65219176018275, -101.56938156429295, 19.41863220741269, -58.53364592749949, -75.99467134720003, -42.6131624732368, -159.88047287526956, -59.57126292341284, -31.97511138155723, -148.70314101499167, -57.65235546881091, -144.74218656957154, -194.13486527345995, -166.41094905587408, 119.5469054301516, -29.917524202518557, -82.3373393259627, -235.54735549072564, -44.38753892295402, -122.32745300400686, -109.6453071933433, -111.04871398203751, -92.82694123176447, 49.561607248979364, -152.72386740117673, -130.97426642690814, -159.72397117878936, -135.4490771560147, -195.14107531372753, -104.13210289778847, -150.57464157151884, -84.12626783121264, -36.95694522504144, -112.7927122183103, 65.09821389247543], "policy_AGENT-0_reward": [-207.90099249851514, 28.403073621321745, -70.91415804228782, -20.99291805541205, -114.84586427470957, 45.69345481589057, -10.902895107174945, -34.03825898268815, -83.66349365690368, 18.622339701545553, -143.16858532256586, -4.4484576644357645, -58.94155733561231, -212.35543596510468, -120.72855320402924, 149.87439234009534, -64.45402330100927, 268.48717523645087, -224.57613586492556, -30.203201293435885, -63.354857308102176, 14.674196088338933, -68.7249201217073, -70.42096962468077, -64.51123654153675, -81.20166205495451, -154.45384934227388, -60.489042399419795, 22.373877037398564, -177.62865522746333, -121.57768416670228, -75.08515849592719, -133.3062904791829, -148.7254623257798, -96.93224217559285, 74.1548744883812, -170.689888619118, 23.347265644894, -206.0483309279841, -31.387183044692872, -141.99660192466897, -84.24420052661046, 21.52866115818238, -80.03073801083917, 3.875758094987532, -19.21119455145389, 0.11319492745877469, -66.72152124184069, 227.43288602654877, -67.24255269119328, -189.8476461099261, -116.64336963894874, -164.39118037880414, -194.9785839864238, 110.30318818994235, 6.409653439524412, -167.90605359598692, -135.50853894516382, -102.86936087128898, -228.91007907236005, -198.11632164783106, -40.715692671643836, -105.10787612752797, 21.22624464808918, -60.16150153525832, -47.09656614774891, -146.65594514811693, 41.39311669276848, -117.61631999836352, 9.00363278845257, -92.69893238281618, -36.998592452600775, -114.24009198100642, 89.7011080826014, -63.37909561767245, 25.928025306747056, -182.7972130318436, 15.769316193008493, -208.36038281373567, 137.08036201432083, -86.8769289165472, -24.399133973589027, -270.02315104496626, -25.693717324391557, -60.20948564968525, -26.31749201061531, -165.21361507079072, -36.05467738629244, -113.49879090984639, -143.70760218352586, -63.09953475199464, -120.24437983984919, -91.40451912641069, -130.07409872941378, -147.46146368906494, -196.09086359603867, -71.74159743522867, -89.0377135763487, -63.292989312936555, 25.156708115623125], "policy_AGENT-2_reward": [-256.84141799779707, -35.13998079751922, -71.4764202112281, -21.803787960776404, -117.19341447032551, 84.28052015194453, -35.141084467224005, -34.48189681687849, -83.86335854609717, -97.60009457662363, -121.76202325655632, 39.858483421458104, -9.107105062671291, -27.918990205926516, -20.42380438179439, 155.47097229910742, -122.60532508678881, 279.4844666604222, -38.71109521963473, -30.74985059539354, -168.14300846741142, 13.329400918024781, -69.28299685239065, -70.97251536172972, -112.53723795009248, -81.76602894569861, -155.0136456724206, -61.038919126691894, -33.230622489389454, -178.18256701769923, -122.13074540229039, -75.64110376188577, -133.86275461785476, -149.29606805112576, -199.68996128181595, 73.10601549627637, -131.13272610413566, -95.0089797862139, -244.20037901842937, -31.93471961510478, -142.5655814158351, -39.98148300921723, -33.98969225094049, -11.377650262910016, 3.3142810203257795, 26.56765704597257, 46.02094237203623, -180.10391293133094, 240.91480148883736, -222.95070130737852, -35.720148307360915, 4.155575643186548, -164.95487165509746, -149.0171083975427, -107.15117386599944, -29.04077678450834, -168.06447124274504, -148.8921583931836, -55.02961801265869, -205.8307743178094, -152.05996402135878, -84.04785419252983, -105.66109912152982, -29.109877450535087, -60.72378188142947, -47.66717346914321, -101.44205813013426, 40.80209360847123, -58.5429115393238, 8.440309506222427, -93.26139744009953, -37.424543003677734, -59.3631335106345, -31.93895429848065, -63.9283664465874, -95.12405499317401, -54.01752394680317, -225.2150969639271, -62.96672321110613, 105.44303923049267, -29.88716514997391, -24.953254868857318, -22.743528963354315, -26.257252562512285, -168.68909410098232, -26.872644820770173, -116.69374341001739, -36.49075037182803, 15.632751258731972, -144.27410503446885, -63.64624928161945, -120.81231185521361, -135.34022914351834, -130.6413850369264, -153.4911298582511, -149.72926976651425, -83.97688853649036, -36.92212869342743, -63.84846017863794, -88.52740639347911], "policy_AGENT-1_reward": [-208.06601612220337, 28.3449681438042, -201.6837450737951, -20.30136380489124, -114.98429727874462, 93.1812986595449, -8.520848588716392, -192.9767355523143, -83.61664534410123, 18.62419889135363, -143.25791788215244, 44.64137659481285, -55.43605649196854, -27.49265143586086, -19.998816929603134, 157.28854702530228, -64.41471989540865, 285.4956675629562, -38.27884110308681, -156.52492592272796, -63.32008765414684, 15.071737200314855, -256.8057784903277, -110.48501090471872, -111.99347966950452, -265.09586830832666, -199.05712321489074, -131.85146278218352, 22.486289081262072, -192.1854461188541, -213.4580336829506, -157.42111308004544, -153.92072765538947, -141.9020345306491, -97.19738749139553, 80.81943036642794, -130.70445736962716, 23.2444868565592, -206.27747904239706, -140.24383479232858, -133.2642136715839, -79.42320302802946, 21.61993868985239, -78.79955108263992, -6.177688851136438, -15.297509707329, 46.77672975492731, -66.64530712952698, 234.38180983245928, -67.33410667722107, -35.28811012041036, -116.75704024271849, -156.295519798391, -147.19210070472462, -106.71352328253843, 54.72528741246962, -168.04148918677032, -135.07316411479164, -98.75502361407372, -183.40955095222287, -150.71638147974647, -40.021208024733404, -135.7210500422841, 22.604338954236173, -109.76495122237816, -75.37746552991513, -142.1774390358964, 25.040483419600143, -117.62337951641283, -45.01333902419474, -32.60008726765908, -145.74335415750338, -114.13600179007366, 135.03037736939388, -126.34945000766946, 25.84723758540626, -53.537016041712164, 15.809068456097194, -62.2322089117875, 106.12722795693351, -40.68930314013878, -75.24641535829426, -22.167092858748845, -39.81184218918111, -60.258255844455896, -103.63681469060447, -118.25916524959065, -92.26197442883921, -113.67985929518926, -145.57866447171762, -127.3679211297021, -155.5705802960573, -91.54288870821216, -182.57022923630203, -153.00375634544025, -151.78238277809442, -71.03817869484493, -88.93893072343651, -108.7492714673207, -88.098116318646]}, "sampler_perf": {"mean_env_wait_ms": 53.81081105736134, "mean_raw_obs_processing_ms": 2.331130333088031, "mean_inference_ms": 2.5189398212582668, "mean_action_processing_ms": 0.14117879994857163}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 29400, "timers": {"sample_time_ms": 90118.915, "sample_throughput": 46.605, "load_time_ms": 143.309, "load_throughput": 29307.319, "learn_time_ms": 8755.26, "learn_throughput": 479.712, "update_time_ms": 8.249}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 13.894720077514648, "policy_loss": -0.02603154070675373, "vf_loss": 13.915096282958984, "vf_explained_var": 0.8559524416923523, "kl": 0.012567886151373386, "entropy": 1.329235315322876, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 11.597312927246094, "policy_loss": -0.018885931000113487, "vf_loss": 11.612035751342773, "vf_explained_var": 0.8692523837089539, "kl": 0.013880934566259384, "entropy": 1.2806851863861084, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 13.039910316467285, "policy_loss": -0.0211006049066782, "vf_loss": 13.057941436767578, "vf_explained_var": 0.8127970695495605, "kl": 0.015340643003582954, "entropy": 1.3286535739898682, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 9.098472595214844, "policy_loss": -0.016849376261234283, "vf_loss": 9.11182975769043, "vf_explained_var": 0.9000284671783447, "kl": 0.01745734177529812, "entropy": 1.3084378242492676, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 29400, "num_steps_trained": 29400}, "done": false, "episodes_total": 247, "training_iteration": 7, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-28-23", "timestamp": 1624210103, "time_this_iter_s": 98.70180749893188, "time_total_s": 695.8657596111298, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40445ae60>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40445a950>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40445add0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40445ab90>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40445a4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445a200>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40445add0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40445ab90>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40445a4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445a200>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40445add0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40445ab90>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40445a4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445a200>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40445add0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40445ab90>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40445a4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445a200>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd4043e89e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 695.8657596111298, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 56.20140845070423, "ram_util_percent": 87.97535211267606}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1067.52093898723, "episode_reward_min": -956.448498529845, "episode_reward_mean": -298.713100888842, "episode_len_mean": 118.82, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-3": -276.7350579948251, "AGENT-0": -270.02315104496626, "AGENT-2": -256.84141799779707, "AGENT-1": -265.3138340713199}, "policy_reward_max": {"AGENT-3": 234.05362952739972, "AGENT-0": 268.48717523645087, "AGENT-2": 279.4844666604222, "AGENT-1": 285.4956675629562}, "policy_reward_mean": {"AGENT-3": -89.58558398622414, "AGENT-0": -70.04503635739566, "AGENT-2": -61.74428324531749, "AGENT-1": -77.33819729990468}, "custom_metrics": {"mean_ego_speed_mean": 38.401979999999995, "mean_ego_speed_min": 23.905749999999998, "mean_ego_speed_max": 45.01275, "distance_travelled_mean": 93.2637975, "distance_travelled_min": 28.756500000000003, "distance_travelled_max": 124.87775}, "hist_stats": {"episode_reward": [-303.0886357925684, 300.4961553687826, -454.5415600625791, -180.12312165709784, -453.28507167720306, -61.40659766014795, -440.2367303588162, -241.16744430506725, -81.6347409844908, 471.26770537342304, -439.2818040317121, -418.49371748825445, 130.16862385132399, -274.486746673328, -278.2667774908156, 403.15131648067194, -492.8698884789447, 312.731194125691, -417.0941463397045, -339.46616799337966, -333.7018872037083, -160.11778287392534, -185.5280178102493, -150.92971856600835, -403.3340182923622, -146.3077463932432, -759.5614327516157, -414.2305525829916, -850.1791127904219, -840.3218615357189, -956.448498529845, -800.5103435750469, -4.062922129032486, -546.77196161976, -228.85539523257756, -103.56406807671999, -261.17357956381153, -380.0469624890515, -347.3104902051274, 160.81741977195733, -402.3600530869212, -101.00114756983152, -435.0939395899302, -387.7715775882813, -499.9702639925033, 468.1975346318988, -187.3709214091785, -206.93614352670335, -550.4811283577951, -136.15035099903898, -411.48428859913054, -266.47225871533306, -511.2152377124364, -257.63434341872414, -161.98429169732395, -586.2842390908885, -385.0879715902245, -556.3512431699094, -453.73671413415633, -638.4267883163704, -558.0884527905444, -648.1771577121664, -310.88293249777655, -251.85571821825414, -348.68343317720604, -86.37060070402671, -929.6573103410392, -37.29198086695142, -508.44578761578356, -38.5894399502155, -465.92913438300866, 346.3758810169689, -89.54901424238734, -472.2170430786939, -359.71696145277576, -114.62063813505085, -530.0927367288145, 157.39933681516334, -132.539135708336, -437.12868093798534, -306.5272828014445, 658.3465577143911, -330.45738793100145, 1067.52093898723, -491.0164950037108, -387.30863831988904, -423.61173795327977, 103.81978717559446, -664.1938018013698, -367.9994995975329, -315.03202042500675, -704.7986173038045, -715.448081480407, -389.8120865679205, -21.500968854629058, -773.448955803694, -681.98000267085, -478.54089367070276, -597.3986840059285, -598.4788216850973], "episode_lengths": [86, 153, 124, 122, 102, 126, 124, 126, 127, 130, 126, 117, 131, 129, 128, 125, 121, 116, 123, 124, 123, 31, 116, 30, 125, 119, 116, 130, 126, 132, 119, 123, 133, 133, 124, 119, 125, 125, 31, 134, 110, 121, 122, 157, 121, 135, 89, 122, 130, 119, 113, 124, 132, 41, 150, 123, 120, 119, 123, 123, 113, 132, 118, 28, 120, 123, 88, 114, 125, 118, 127, 143, 117, 134, 110, 125, 112, 124, 129, 124, 113, 142, 109, 162, 124, 130, 115, 119, 134, 116, 127, 132, 122, 118, 121, 127, 129, 121, 112, 117], "policy_AGENT-3_reward": [-56.545557555632556, 18.684676973766436, -108.22229533088128, -89.17324004466806, -141.99940722276258, -22.473732191512546, -156.067397493081, -111.82083391512353, -62.94735375987223, 129.69856929636427, -174.08223102168475, -153.77807660885895, 41.70866927136723, -109.92554918281044, -78.14756071659801, 130.13065214308125, -120.87823589977964, 99.08019414644848, -93.723822423667, -61.02585139715818, -135.78352461517412, -10.649186089066276, -63.293539952223114, -10.873317875634903, -130.63170238637107, -46.986996605353305, -155.05198552156486, -100.48646812063723, -196.9825071568067, -214.53524052718743, -223.0817781705342, -160.23262144603808, 82.2238482027357, -126.18312939944661, -81.42347012517281, -75.99467134720003, -42.6131624732368, -159.88047287526956, -59.57126292341284, -31.97511138155723, -148.70314101499167, -57.65235546881091, -144.74218656957154, -194.13486527345995, -166.41094905587408, 119.5469054301516, -29.917524202518557, -82.3373393259627, -235.54735549072564, -44.38753892295402, -122.32745300400686, -109.6453071933433, -111.04871398203751, -92.82694123176447, 49.561607248979364, -152.72386740117673, -130.97426642690814, -159.72397117878936, -135.4490771560147, -195.14107531372753, -104.13210289778847, -150.57464157151884, -84.12626783121264, -36.95694522504144, -112.7927122183103, 65.09821389247543, -256.84888372252294, -58.900041834558166, -164.3714642884725, 24.5086298708643, -118.90555835922868, 123.22060738958899, -34.98418607927193, -210.72015172681276, -108.57346390567409, -54.26708215132625, -121.9042102675399, 77.34793446332843, -9.054416818083876, -169.36160333109308, -145.37610828601808, 195.71264604988588, -78.9833196477946, 234.05362952739972, -189.45042281606382, -169.8306605083318, -128.79378452361962, 60.7444529689159, -269.3801063369444, -116.12100370640378, -25.990066263873494, -276.7350579948251, -206.92346325082167, -136.43266225962503, -33.13051248390015, -225.45228743967718, -224.8135394189067, -170.3935183328444, -176.30891125350124, -158.55525677754315], "policy_AGENT-0_reward": [-95.09230882673134, 122.7286807431782, -101.64784450066108, 21.036039356627732, -96.11539280018403, -8.854970041264973, -45.5569508558709, -81.54369552645343, -6.754111317506127, 114.31103815583688, -51.9568807349538, -192.37741854918906, 13.584747993814936, -34.6492491791536, -59.401377190761586, 60.98428286490829, -112.37758010741092, 71.15509232721024, -135.05057095446628, -107.65033609548905, -36.90289778566435, -69.36894385989875, -31.410729392400665, -64.65067769292668, -70.94199783550697, -15.392034267612988, -250.15918899534628, -106.55784246351614, -250.95736453921103, -206.75487349679167, -242.93517655544017, -240.49843716503767, -98.8900877857408, -167.01907736075646, -33.0727811832391, 9.00363278845257, -92.69893238281618, -36.998592452600775, -114.24009198100642, 89.7011080826014, -63.37909561767245, 25.928025306747056, -182.7972130318436, 15.769316193008493, -208.36038281373567, 137.08036201432083, -86.8769289165472, -24.399133973589027, -270.02315104496626, -25.693717324391557, -60.20948564968525, -26.31749201061531, -165.21361507079072, -36.05467738629244, -113.49879090984639, -143.70760218352586, -63.09953475199464, -120.24437983984919, -91.40451912641069, -130.07409872941378, -147.46146368906494, -196.09086359603867, -71.74159743522867, -89.0377135763487, -63.292989312936555, 25.156708115623125, -207.90099249851514, 28.403073621321745, -70.91415804228782, -20.99291805541205, -114.84586427470957, 45.69345481589057, -10.902895107174945, -34.03825898268815, -83.66349365690368, 18.622339701545553, -143.16858532256586, -4.4484576644357645, -58.94155733561231, -212.35543596510468, -120.72855320402924, 149.87439234009534, -64.45402330100927, 268.48717523645087, -224.57613586492556, -30.203201293435885, -63.354857308102176, 14.674196088338933, -68.7249201217073, -70.42096962468077, -64.51123654153675, -81.20166205495451, -154.45384934227388, -60.489042399419795, 22.373877037398564, -177.62865522746333, -121.57768416670228, -75.08515849592719, -133.3062904791829, -148.7254623257798], "policy_AGENT-2_reward": [-56.40506971240564, 122.14879954631928, -102.21353917877303, -132.91783910994542, -119.07190657234646, -22.493551568351076, -46.0914932641665, -24.1239972786601, -7.337419303423651, 110.6206054948851, -52.504442003745886, -36.382836672858936, 58.34759406467488, -35.19516051289442, -81.64234998245362, 104.20520197101052, -126.09063392758787, 70.5994391548723, -94.54195412575287, -63.51800104168438, -37.45535238197715, -10.774966482485105, -31.968671804761954, -10.78959930116394, -130.6783729481369, -46.968865899119436, -153.17764363863105, -100.49760495177875, -197.0425150666593, -213.97702546577705, -225.11770973254997, -200.10441169877734, 111.48111725213484, -130.34506056534514, -81.38837605858753, 8.440309506222427, -93.26139744009953, -37.424543003677734, -59.3631335106345, -31.93895429848065, -63.9283664465874, -95.12405499317401, -54.01752394680317, -225.2150969639271, -62.96672321110613, 105.44303923049267, -29.88716514997391, -24.953254868857318, -22.743528963354315, -26.257252562512285, -168.68909410098232, -26.872644820770173, -116.69374341001739, -36.49075037182803, 15.632751258731972, -144.27410503446885, -63.64624928161945, -120.81231185521361, -135.34022914351834, -130.6413850369264, -153.4911298582511, -149.72926976651425, -83.97688853649036, -36.92212869342743, -63.84846017863794, -88.52740639347911, -256.84141799779707, -35.13998079751922, -71.4764202112281, -21.803787960776404, -117.19341447032551, 84.28052015194453, -35.141084467224005, -34.48189681687849, -83.86335854609717, -97.60009457662363, -121.76202325655632, 39.858483421458104, -9.107105062671291, -27.918990205926516, -20.42380438179439, 155.47097229910742, -122.60532508678881, 279.4844666604222, -38.71109521963473, -30.74985059539354, -168.14300846741142, 13.329400918024781, -69.28299685239065, -70.97251536172972, -112.53723795009248, -81.76602894569861, -155.0136456724206, -61.038919126691894, -33.230622489389454, -178.18256701769923, -122.13074540229039, -75.64110376188577, -133.86275461785476, -149.29606805112576], "policy_AGENT-1_reward": [-95.0456996977989, 36.93399810551836, -142.45788105226367, 20.931918140887976, -96.09836508191032, -7.5843438590192855, -192.52088874569785, -23.678917584830156, -4.595856603688607, 116.63749242633742, -160.73825027132796, -35.955385657347264, 16.527612521466825, -94.71678779846994, -59.07548960100188, 107.83117950167134, -133.52343854416648, 71.89646849715993, -93.77779883581836, -107.27197945904808, -123.56011242089244, -69.32468644247521, -58.85507666086363, -64.61612369628281, -71.08194512234704, -36.95984962115764, -201.1726145960737, -106.6886370470594, -205.1967260277441, -205.05472204596208, -265.3138340713199, -199.67487326519418, -98.87779979816233, -123.22469429421149, -32.97076786557796, -45.01333902419474, -32.60008726765908, -145.74335415750338, -114.13600179007366, 135.03037736939388, -126.34945000766946, 25.84723758540626, -53.537016041712164, 15.809068456097194, -62.2322089117875, 106.12722795693351, -40.68930314013878, -75.24641535829426, -22.167092858748845, -39.81184218918111, -60.258255844455896, -103.63681469060447, -118.25916524959065, -92.26197442883921, -113.67985929518926, -145.57866447171762, -127.3679211297021, -155.5705802960573, -91.54288870821216, -182.57022923630203, -153.00375634544025, -151.78238277809442, -71.03817869484493, -88.93893072343651, -108.7492714673207, -88.098116318646, -208.06601612220337, 28.3449681438042, -201.6837450737951, -20.30136380489124, -114.98429727874462, 93.1812986595449, -8.520848588716392, -192.9767355523143, -83.61664534410123, 18.62419889135363, -143.25791788215244, 44.64137659481285, -55.43605649196854, -27.49265143586086, -19.998816929603134, 157.28854702530228, -64.41471989540865, 285.4956675629562, -38.27884110308681, -156.52492592272796, -63.32008765414684, 15.071737200314855, -256.8057784903277, -110.48501090471872, -111.99347966950452, -265.09586830832666, -199.05712321489074, -131.85146278218352, 22.486289081262072, -192.1854461188541, -213.4580336829506, -157.42111308004544, -153.92072765538947, -141.9020345306491]}, "sampler_perf": {"mean_env_wait_ms": 53.9972177582585, "mean_raw_obs_processing_ms": 2.350567163710782, "mean_inference_ms": 2.5111515227438836, "mean_action_processing_ms": 0.14174945187318155}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 33600, "timers": {"sample_time_ms": 91206.134, "sample_throughput": 46.05, "load_time_ms": 127.344, "load_throughput": 32981.62, "learn_time_ms": 8873.308, "learn_throughput": 473.33, "update_time_ms": 8.278}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 16.390501022338867, "policy_loss": -0.02502729929983616, "vf_loss": 16.409616470336914, "vf_explained_var": 0.8564915657043457, "kl": 0.013134497217833996, "entropy": 1.3052555322647095, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 15.32461929321289, "policy_loss": -0.01919613778591156, "vf_loss": 15.338617324829102, "vf_explained_var": 0.8406424522399902, "kl": 0.0173280481249094, "entropy": 1.2710013389587402, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 10.09311294555664, "policy_loss": -0.025080299004912376, "vf_loss": 10.114215850830078, "vf_explained_var": 0.8804920315742493, "kl": 0.019887728616595268, "entropy": 1.309190273284912, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 9.635090827941895, "policy_loss": -0.01053931750357151, "vf_loss": 9.641180038452148, "vf_explained_var": 0.9095159769058228, "kl": 0.022242987528443336, "entropy": 1.2729847431182861, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 33600, "num_steps_trained": 33600}, "done": false, "episodes_total": 282, "training_iteration": 8, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-30-12", "timestamp": 1624210212, "time_this_iter_s": 108.55950379371643, "time_total_s": 804.4252634048462, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd404392ef0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd404392290>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd404392320>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40434b0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40434b200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40434b320>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd404392320>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40434b0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40434b200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40434b320>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd404392320>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40434b0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40434b200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40434b320>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd404392320>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40434b0e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40434b200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40434b320>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd4043923b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 804.4252634048462, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 56.582580645161286, "ram_util_percent": 87.92580645161289}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1067.52093898723, "episode_reward_min": -956.448498529845, "episode_reward_mean": -279.68467265208676, "episode_len_mean": 119.14, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-3": -276.7350579948251, "AGENT-0": -250.95736453921103, "AGENT-1": -265.3138340713199, "AGENT-2": -225.11770973254997}, "policy_reward_max": {"AGENT-3": 234.05362952739972, "AGENT-0": 268.48717523645087, "AGENT-1": 285.4956675629562, "AGENT-2": 279.4844666604222}, "policy_reward_mean": {"AGENT-3": -78.09890403793325, "AGENT-0": -71.9549634249399, "AGENT-1": -72.47757136717752, "AGENT-2": -57.15323382203601}, "custom_metrics": {"mean_ego_speed_mean": 39.433745, "mean_ego_speed_min": 29.878999999999998, "mean_ego_speed_max": 46.1015, "distance_travelled_mean": 98.92515999999999, "distance_travelled_min": 27.164749999999998, "distance_travelled_max": 124.87775}, "hist_stats": {"episode_reward": [186.33564671089525, -443.5564737522525, -292.3462609458766, -683.8212167572705, -284.780833961227, -326.3609979639316, 296.4737796058223, -264.17272206220184, -26.94060664764845, -456.79979485123135, 168.92739938802566, -533.9852148421465, 576.6884797633769, -248.60718605990928, 444.42428289771954, -309.53548418848067, -354.0614749779861, -341.2743302759964, 279.90548706591113, -755.9836590509157, 401.93497874290836, -217.14996865701616, -261.8262024922521, -410.20645365137557, 17.03875054292125, -485.78664505731626, -363.79207429784475, -155.0000230127589, -672.8921293663304, -428.3325872197913, -568.9885659439753, -650.4792260005617, -454.13380871373516, -645.9806571073526, -671.9430772014143, -326.6278253656915, -270.00959635310375, -89.54901424238734, -472.2170430786939, -359.71696145277576, -114.62063813505085, -530.0927367288145, 157.39933681516334, -132.539135708336, -437.12868093798534, -306.5272828014445, 658.3465577143911, -330.45738793100145, 1067.52093898723, -491.0164950037108, -387.30863831988904, -423.61173795327977, 103.81978717559446, -664.1938018013698, -367.9994995975329, -315.03202042500675, -704.7986173038045, -715.448081480407, -389.8120865679205, -21.500968854629058, -773.448955803694, -681.98000267085, -478.54089367070276, -597.3986840059285, -598.4788216850973, -303.0886357925684, 300.4961553687826, -454.5415600625791, -180.12312165709784, -453.28507167720306, -61.40659766014795, -440.2367303588162, -241.16744430506725, -81.6347409844908, 471.26770537342304, -439.2818040317121, -418.49371748825445, 130.16862385132399, -274.486746673328, -278.2667774908156, 403.15131648067194, -492.8698884789447, 312.731194125691, -417.0941463397045, -339.46616799337966, -333.7018872037083, -160.11778287392534, -185.5280178102493, -150.92971856600835, -403.3340182923622, -146.3077463932432, -759.5614327516157, -414.2305525829916, -850.1791127904219, -840.3218615357189, -956.448498529845, -800.5103435750469, -4.062922129032486, -546.77196161976, -228.85539523257756], "episode_lengths": [122, 124, 102, 126, 120, 128, 130, 125, 117, 125, 119, 110, 121, 119, 124, 115, 115, 116, 126, 138, 120, 117, 28, 117, 47, 120, 118, 123, 118, 136, 118, 123, 116, 126, 113, 125, 122, 117, 134, 110, 125, 112, 124, 129, 124, 113, 142, 109, 162, 124, 130, 115, 119, 134, 116, 127, 132, 122, 118, 121, 127, 129, 121, 112, 117, 86, 153, 124, 122, 102, 126, 124, 126, 127, 130, 126, 117, 131, 129, 128, 125, 121, 116, 123, 124, 123, 31, 116, 30, 125, 119, 116, 130, 126, 132, 119, 123, 133, 133, 124], "policy_AGENT-3_reward": [74.1583755376353, -114.51068586917486, -30.845310707749494, -169.3349089526457, -113.85554279241778, -58.75728064926196, 94.31112242521652, -95.14721981959104, -37.86149438681765, -107.09053611197399, 86.34017304496149, -140.54274508633952, 127.44283554294752, -9.024150588572994, 101.55524416832262, -54.83612141378783, -32.29473469100947, -130.65483407019775, 91.07850803502544, -152.0758914314944, 81.62048519350641, -10.156455423604887, -36.99124995272852, -80.17825758194883, 27.866538465750068, -137.47558306100586, -112.11155936870158, -68.20660552275045, -164.37577192687166, -149.85064649323132, -159.55714393833384, -151.99353224472696, -115.39159566652641, -169.39933772351466, -161.32421032379432, -106.54107873524546, -54.72206638016821, -34.98418607927193, -210.72015172681276, -108.57346390567409, -54.26708215132625, -121.9042102675399, 77.34793446332843, -9.054416818083876, -169.36160333109308, -145.37610828601808, 195.71264604988588, -78.9833196477946, 234.05362952739972, -189.45042281606382, -169.8306605083318, -128.79378452361962, 60.7444529689159, -269.3801063369444, -116.12100370640378, -25.990066263873494, -276.7350579948251, -206.92346325082167, -136.43266225962503, -33.13051248390015, -225.45228743967718, -224.8135394189067, -170.3935183328444, -176.30891125350124, -158.55525677754315, -56.545557555632556, 18.684676973766436, -108.22229533088128, -89.17324004466806, -141.99940722276258, -22.473732191512546, -156.067397493081, -111.82083391512353, -62.94735375987223, 129.69856929636427, -174.08223102168475, -153.77807660885895, 41.70866927136723, -109.92554918281044, -78.14756071659801, 130.13065214308125, -120.87823589977964, 99.08019414644848, -93.723822423667, -61.02585139715818, -135.78352461517412, -10.649186089066276, -63.293539952223114, -10.873317875634903, -130.63170238637107, -46.986996605353305, -155.05198552156486, -100.48646812063723, -196.9825071568067, -214.53524052718743, -223.0817781705342, -160.23262144603808, 82.2238482027357, -126.18312939944661, -81.42347012517281], "policy_AGENT-0_reward": [52.107682513354945, -110.0613499294253, -115.27055551790056, -169.8083721310861, -34.11762990174007, -128.93572356705846, 67.21109181433275, -60.684823149359794, 19.42142680622801, -144.47686143502438, -4.691182553381047, -103.60805591638216, 118.47586043475967, -139.45398548555738, 84.32498345842109, -98.8830851166206, -134.41902715281282, -104.9026970026203, 65.90570886803083, -234.98912806111127, 76.81976629498507, -98.67335579124374, -93.963688800114, -124.32647983127323, -19.35162780840214, -115.66901495767655, -70.30690096248134, -32.93557034967274, -167.95976168146984, -119.20923155963555, -125.18805025159077, -195.6819025503998, -95.60092143800414, -177.0797736936199, -156.08727136945424, -78.84527585532153, -80.9122378642664, -10.902895107174945, -34.03825898268815, -83.66349365690368, 18.622339701545553, -143.16858532256586, -4.4484576644357645, -58.94155733561231, -212.35543596510468, -120.72855320402924, 149.87439234009534, -64.45402330100927, 268.48717523645087, -224.57613586492556, -30.203201293435885, -63.354857308102176, 14.674196088338933, -68.7249201217073, -70.42096962468077, -64.51123654153675, -81.20166205495451, -154.45384934227388, -60.489042399419795, 22.373877037398564, -177.62865522746333, -121.57768416670228, -75.08515849592719, -133.3062904791829, -148.7254623257798, -95.09230882673134, 122.7286807431782, -101.64784450066108, 21.036039356627732, -96.11539280018403, -8.854970041264973, -45.5569508558709, -81.54369552645343, -6.754111317506127, 114.31103815583688, -51.9568807349538, -192.37741854918906, 13.584747993814936, -34.6492491791536, -59.401377190761586, 60.98428286490829, -112.37758010741092, 71.15509232721024, -135.05057095446628, -107.65033609548905, -36.90289778566435, -69.36894385989875, -31.410729392400665, -64.65067769292668, -70.94199783550697, -15.392034267612988, -250.15918899534628, -106.55784246351614, -250.95736453921103, -206.75487349679167, -242.93517655544017, -240.49843716503767, -98.8900877857408, -167.01907736075646, -33.0727811832391], "policy_AGENT-1_reward": [30.036674002099748, -108.34492811062941, -115.49331013918297, -168.84248387693378, -102.14008490978193, -80.12585626748044, 70.54794619815812, -13.336796904770239, 19.42021089187543, -96.63645256016606, 44.08032951687469, -103.57636075489756, 167.25710287512004, -91.13303216862953, 131.57461469451968, -99.43607667379544, -155.05349659007484, -52.49737037605132, 65.76859250514283, -192.3042383340181, 124.49742000707029, -98.21397041175169, -93.85531136902915, -124.92479372757742, 28.43045341991124, -115.04144723601507, -69.2767044244723, 14.382237615149256, -167.54294781711744, -77.0886236992713, -124.78105756369922, -147.69458147157889, -121.22056280320741, -130.05534966654795, -197.55736633970764, -34.64874487138713, -79.66938391930421, -8.520848588716392, -192.9767355523143, -83.61664534410123, 18.62419889135363, -143.25791788215244, 44.64137659481285, -55.43605649196854, -27.49265143586086, -19.998816929603134, 157.28854702530228, -64.41471989540865, 285.4956675629562, -38.27884110308681, -156.52492592272796, -63.32008765414684, 15.071737200314855, -256.8057784903277, -110.48501090471872, -111.99347966950452, -265.09586830832666, -199.05712321489074, -131.85146278218352, 22.486289081262072, -192.1854461188541, -213.4580336829506, -157.42111308004544, -153.92072765538947, -141.9020345306491, -95.0456996977989, 36.93399810551836, -142.45788105226367, 20.931918140887976, -96.09836508191032, -7.5843438590192855, -192.52088874569785, -23.678917584830156, -4.595856603688607, 116.63749242633742, -160.73825027132796, -35.955385657347264, 16.527612521466825, -94.71678779846994, -59.07548960100188, 107.83117950167134, -133.52343854416648, 71.89646849715993, -93.77779883581836, -107.27197945904808, -123.56011242089244, -69.32468644247521, -58.85507666086363, -64.61612369628281, -71.08194512234704, -36.95984962115764, -201.1726145960737, -106.6886370470594, -205.1967260277441, -205.05472204596208, -265.3138340713199, -199.67487326519418, -98.87779979816233, -123.22469429421149, -32.97076786557796], "policy_AGENT-2_reward": [30.03291465780474, -110.63950984302316, -30.737084581043515, -175.8354517966048, -34.667576357287146, -58.54213748013107, 64.40361916811528, -95.00388218848072, -27.920749958934287, -108.59594474406737, 43.198079379570714, -186.25805308452726, 163.51268091055033, -8.99601781714944, 126.96944057645612, -56.38020098427687, -32.2942165440887, -53.21942882712731, 57.15267765771238, -176.61440122429195, 118.9973072473467, -10.106187030415846, -37.01595237038041, -80.776922510576, -19.906613534337982, -117.6005998026188, -112.09690954218934, -68.2400847554847, -173.01364794087152, -82.18408546765292, -159.4623141903512, -155.10920973385603, -121.9207288059972, -169.44619602367, -156.97422916845795, -106.59272590373754, -54.705908189365076, -35.141084467224005, -34.48189681687849, -83.86335854609717, -97.60009457662363, -121.76202325655632, 39.858483421458104, -9.107105062671291, -27.918990205926516, -20.42380438179439, 155.47097229910742, -122.60532508678881, 279.4844666604222, -38.71109521963473, -30.74985059539354, -168.14300846741142, 13.329400918024781, -69.28299685239065, -70.97251536172972, -112.53723795009248, -81.76602894569861, -155.0136456724206, -61.038919126691894, -33.230622489389454, -178.18256701769923, -122.13074540229039, -75.64110376188577, -133.86275461785476, -149.29606805112576, -56.40506971240564, 122.14879954631928, -102.21353917877303, -132.91783910994542, -119.07190657234646, -22.493551568351076, -46.0914932641665, -24.1239972786601, -7.337419303423651, 110.6206054948851, -52.504442003745886, -36.382836672858936, 58.34759406467488, -35.19516051289442, -81.64234998245362, 104.20520197101052, -126.09063392758787, 70.5994391548723, -94.54195412575287, -63.51800104168438, -37.45535238197715, -10.774966482485105, -31.968671804761954, -10.78959930116394, -130.6783729481369, -46.968865899119436, -153.17764363863105, -100.49760495177875, -197.0425150666593, -213.97702546577705, -225.11770973254997, -200.10441169877734, 111.48111725213484, -130.34506056534514, -81.38837605858753]}, "sampler_perf": {"mean_env_wait_ms": 54.35935686329162, "mean_raw_obs_processing_ms": 2.3616432814500787, "mean_inference_ms": 2.5078418012561823, "mean_action_processing_ms": 0.1425836031022202}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 37800, "timers": {"sample_time_ms": 91942.859, "sample_throughput": 45.681, "load_time_ms": 115.011, "load_throughput": 36518.329, "learn_time_ms": 8924.786, "learn_throughput": 470.6, "update_time_ms": 8.119}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 11.793600082397461, "policy_loss": -0.026687059551477432, "vf_loss": 11.81403923034668, "vf_explained_var": 0.9125146865844727, "kl": 0.013886896893382072, "entropy": 1.3142839670181274, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 11.159262657165527, "policy_loss": -0.024354537948966026, "vf_loss": 11.17929458618164, "vf_explained_var": 0.8912528157234192, "kl": 0.014407116919755936, "entropy": 1.2870055437088013, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0010000000474974513, "total_loss": 7.577368259429932, "policy_loss": -0.024075215682387352, "vf_loss": 7.597150802612305, "vf_explained_var": 0.913522481918335, "kl": 0.02146284282207489, "entropy": 1.3084620237350464, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 6.437006950378418, "policy_loss": -0.02236747555434704, "vf_loss": 6.455306053161621, "vf_explained_var": 0.9292104840278625, "kl": 0.013560669496655464, "entropy": 1.2198805809020996, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 37800, "num_steps_trained": 37800}, "done": false, "episodes_total": 319, "training_iteration": 9, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-31-59", "timestamp": 1624210319, "time_this_iter_s": 107.21598052978516, "time_total_s": 911.6412439346313, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd4043e8830>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd4043e89e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4044e7e60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd417ac28c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40445a950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445a050>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4044e7e60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd417ac28c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40445a950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445a050>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4044e7e60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd417ac28c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40445a950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445a050>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4044e7e60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd417ac28c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40445a950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40445a050>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd40449bd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 911.6412439346313, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 57.64052287581699, "ram_util_percent": 88.20522875816994}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 719.2528405444258, "episode_reward_min": -1213.7518069568514, "episode_reward_mean": -252.7424722741008, "episode_len_mean": 118.51, "episodes_this_iter": 34, "policy_reward_min": {"AGENT-3": -332.8520107714878, "AGENT-0": -365.7308651925102, "AGENT-1": -297.54442377157767, "AGENT-2": -333.2175597618458}, "policy_reward_max": {"AGENT-3": 155.50383656493443, "AGENT-0": 196.01356087455432, "AGENT-1": 198.4971455982123, "AGENT-2": 174.64588970628935}, "policy_reward_mean": {"AGENT-3": -63.69140057794187, "AGENT-0": -74.73594019343965, "AGENT-1": -61.29812070605555, "AGENT-2": -53.01701079666368}, "custom_metrics": {"mean_ego_speed_mean": 40.175607500000005, "mean_ego_speed_min": 31.8215, "mean_ego_speed_max": 46.1015, "distance_travelled_mean": 102.65100999999999, "distance_travelled_min": 27.164749999999998, "distance_travelled_max": 124.87775}, "hist_stats": {"episode_reward": [38.66666133388032, -139.67587373916658, 433.98692998758037, 29.518086507790535, -144.08622623345474, -905.4698917065235, 564.0248777710962, 385.0587585439746, -52.61705799639689, -223.0036964622047, -271.21566865272774, -429.0828301580593, 51.444097175638696, -362.82589372335974, 719.2528405444258, -474.9937621258046, -279.20866497244646, -298.65663348328115, 382.5772664325727, -213.21076630081728, 431.28428126956226, -299.508857234827, -535.3523603478297, -276.7343466540668, -61.02961551248981, -599.7890343222275, 176.54168977762384, -1213.7518069568514, -506.06136788663906, -498.4395266875669, -627.7797137557184, -962.3833094010705, -274.7084070842293, -416.8305370965437, -440.2367303588162, -241.16744430506725, -81.6347409844908, 471.26770537342304, -439.2818040317121, -418.49371748825445, 130.16862385132399, -274.486746673328, -278.2667774908156, 403.15131648067194, -492.8698884789447, 312.731194125691, -417.0941463397045, -339.46616799337966, -333.7018872037083, -160.11778287392534, -185.5280178102493, -150.92971856600835, -403.3340182923622, -146.3077463932432, -759.5614327516157, -414.2305525829916, -850.1791127904219, -840.3218615357189, -956.448498529845, -800.5103435750469, -4.062922129032486, -546.77196161976, -228.85539523257756, 186.33564671089525, -443.5564737522525, -292.3462609458766, -683.8212167572705, -284.780833961227, -326.3609979639316, 296.4737796058223, -264.17272206220184, -26.94060664764845, -456.79979485123135, 168.92739938802566, -533.9852148421465, 576.6884797633769, -248.60718605990928, 444.42428289771954, -309.53548418848067, -354.0614749779861, -341.2743302759964, 279.90548706591113, -755.9836590509157, 401.93497874290836, -217.14996865701616, -261.8262024922521, -410.20645365137557, 17.03875054292125, -485.78664505731626, -363.79207429784475, -155.0000230127589, -672.8921293663304, -428.3325872197913, -568.9885659439753, -650.4792260005617, -454.13380871373516, -645.9806571073526, -671.9430772014143, -326.6278253656915, -270.00959635310375], "episode_lengths": [113, 121, 128, 129, 129, 143, 133, 133, 118, 116, 114, 119, 120, 122, 124, 128, 120, 127, 127, 109, 119, 123, 62, 106, 131, 125, 133, 110, 115, 137, 117, 125, 124, 115, 124, 126, 127, 130, 126, 117, 131, 129, 128, 125, 121, 116, 123, 124, 123, 31, 116, 30, 125, 119, 116, 130, 126, 132, 119, 123, 133, 133, 124, 122, 124, 102, 126, 120, 128, 130, 125, 117, 125, 119, 110, 121, 119, 124, 115, 115, 116, 126, 138, 120, 117, 28, 117, 47, 120, 118, 123, 118, 136, 118, 123, 116, 126, 113, 125, 122], "policy_AGENT-3_reward": [45.90843631829118, -42.475756631643215, 101.00148141141375, 4.950100005588285, -36.44491883802502, -332.8520107714878, 155.50383656493443, 122.642445506688, -46.32233396410286, -65.95934242916351, -72.9540898417002, -111.20555144988715, 49.669687127087165, -64.04127924559802, 150.09624436537004, -150.1114238679261, -121.54940380195089, -73.26533585267292, 115.37857273966371, -9.47014619145456, 128.56517758251724, -9.40397082408947, -160.19621898953818, -8.80219303620787, -74.18242922968832, -103.49254231962887, -31.979269378911567, -285.7541435458639, -171.89132334650625, -154.06693823752602, -141.74161091986838, -210.2158933821871, -82.64707747052108, -145.34711999892062, -156.067397493081, -111.82083391512353, -62.94735375987223, 129.69856929636427, -174.08223102168475, -153.77807660885895, 41.70866927136723, -109.92554918281044, -78.14756071659801, 130.13065214308125, -120.87823589977964, 99.08019414644848, -93.723822423667, -61.02585139715818, -135.78352461517412, -10.649186089066276, -63.293539952223114, -10.873317875634903, -130.63170238637107, -46.986996605353305, -155.05198552156486, -100.48646812063723, -196.9825071568067, -214.53524052718743, -223.0817781705342, -160.23262144603808, 82.2238482027357, -126.18312939944661, -81.42347012517281, 74.1583755376353, -114.51068586917486, -30.845310707749494, -169.3349089526457, -113.85554279241778, -58.75728064926196, 94.31112242521652, -95.14721981959104, -37.86149438681765, -107.09053611197399, 86.34017304496149, -140.54274508633952, 127.44283554294752, -9.024150588572994, 101.55524416832262, -54.83612141378783, -32.29473469100947, -130.65483407019775, 91.07850803502544, -152.0758914314944, 81.62048519350641, -10.156455423604887, -36.99124995272852, -80.17825758194883, 27.866538465750068, -137.47558306100586, -112.11155936870158, -68.20660552275045, -164.37577192687166, -149.85064649323132, -159.55714393833384, -151.99353224472696, -115.39159566652641, -169.39933772351466, -161.32421032379432, -106.54107873524546, -54.72206638016821], "policy_AGENT-0_reward": [-2.3124193466425123, -27.743923163113205, 115.68586095954645, -3.961401073925792, -71.67298156968343, -365.7308651925102, 133.04516702382023, 61.22645208297305, -3.065557818882958, -110.19771479252208, -67.31920172949143, -90.05507089744304, -30.270550205473373, -141.55717174304664, 196.01356087455432, -184.36802218210846, -20.05290088192473, -70.73193853373216, 57.88063355941049, -83.12492892448309, 54.090195386533615, -163.4346235169342, -107.48911606814707, -107.14355859932901, 54.86784497299689, -177.0339966286794, 98.2568395406939, -297.235679877563, -85.6824550204177, -110.46887397870509, -193.437809613362, -280.0342501705825, -78.27923136850734, -67.63418980411582, -45.5569508558709, -81.54369552645343, -6.754111317506127, 114.31103815583688, -51.9568807349538, -192.37741854918906, 13.584747993814936, -34.6492491791536, -59.401377190761586, 60.98428286490829, -112.37758010741092, 71.15509232721024, -135.05057095446628, -107.65033609548905, -36.90289778566435, -69.36894385989875, -31.410729392400665, -64.65067769292668, -70.94199783550697, -15.392034267612988, -250.15918899534628, -106.55784246351614, -250.95736453921103, -206.75487349679167, -242.93517655544017, -240.49843716503767, -98.8900877857408, -167.01907736075646, -33.0727811832391, 52.107682513354945, -110.0613499294253, -115.27055551790056, -169.8083721310861, -34.11762990174007, -128.93572356705846, 67.21109181433275, -60.684823149359794, 19.42142680622801, -144.47686143502438, -4.691182553381047, -103.60805591638216, 118.47586043475967, -139.45398548555738, 84.32498345842109, -98.8830851166206, -134.41902715281282, -104.9026970026203, 65.90570886803083, -234.98912806111127, 76.81976629498507, -98.67335579124374, -93.963688800114, -124.32647983127323, -19.35162780840214, -115.66901495767655, -70.30690096248134, -32.93557034967274, -167.95976168146984, -119.20923155963555, -125.18805025159077, -195.6819025503998, -95.60092143800414, -177.0797736936199, -156.08727136945424, -78.84527585532153, -80.9122378642664], "policy_AGENT-1_reward": [-2.437917950616419, -27.012069577182157, 116.34845684488634, 33.08821362369334, -17.59213292707495, -103.22397724398684, 142.98781609774554, 107.51775524510663, 43.133643779909946, -23.146786958211003, -63.05900394793434, -112.3809891351694, 18.64085444164083, -93.12217814204269, 198.4971455982123, -70.0394879547936, -116.99855077747615, -73.30602999905447, 105.6673096274731, -111.17132030717278, 149.106287660678, -117.23117013857537, -159.6282365819281, -107.19624460226984, 32.41048425242965, -177.34364070321425, 142.1934710953346, -297.54442377157767, -162.3769786534656, -117.15733071677816, -144.7013084520078, -235.7225880059033, -31.234869685865068, -135.7460182491243, -192.52088874569785, -23.678917584830156, -4.595856603688607, 116.63749242633742, -160.73825027132796, -35.955385657347264, 16.527612521466825, -94.71678779846994, -59.07548960100188, 107.83117950167134, -133.52343854416648, 71.89646849715993, -93.77779883581836, -107.27197945904808, -123.56011242089244, -69.32468644247521, -58.85507666086363, -64.61612369628281, -71.08194512234704, -36.95984962115764, -201.1726145960737, -106.6886370470594, -205.1967260277441, -205.05472204596208, -265.3138340713199, -199.67487326519418, -98.87779979816233, -123.22469429421149, -32.97076786557796, 30.036674002099748, -108.34492811062941, -115.49331013918297, -168.84248387693378, -102.14008490978193, -80.12585626748044, 70.54794619815812, -13.336796904770239, 19.42021089187543, -96.63645256016606, 44.08032951687469, -103.57636075489756, 167.25710287512004, -91.13303216862953, 131.57461469451968, -99.43607667379544, -155.05349659007484, -52.49737037605132, 65.76859250514283, -192.3042383340181, 124.49742000707029, -98.21397041175169, -93.85531136902915, -124.92479372757742, 28.43045341991124, -115.04144723601507, -69.2767044244723, 14.382237615149256, -167.54294781711744, -77.0886236992713, -124.78105756369922, -147.69458147157889, -121.22056280320741, -130.05534966654795, -197.55736633970764, -34.64874487138713, -79.66938391930421], "policy_AGENT-2_reward": [-2.491437687152043, -42.44412436722809, 100.95113077173382, -4.558826047565361, -18.376192898671405, -103.66303849853897, 132.4880580845959, 93.67210570920724, -46.36280999332107, -23.699852282308132, -67.8833731336019, -115.44121867555984, 13.404105812383925, -64.10526459267223, 174.64588970628935, -70.47482812097648, -20.607809511094665, -81.3533290978216, 103.65075050602535, -9.44437087770682, 99.5226206398336, -9.439092755228076, -108.03878870821607, -53.59235041626004, -74.12551550822798, -141.91885467070458, -31.9293514794932, -333.2175597618458, -86.11061086624883, -116.74638375455713, -147.89898477048024, -236.4105778423973, -82.54722855933596, -68.10320904438291, -46.0914932641665, -24.1239972786601, -7.337419303423651, 110.6206054948851, -52.504442003745886, -36.382836672858936, 58.34759406467488, -35.19516051289442, -81.64234998245362, 104.20520197101052, -126.09063392758787, 70.5994391548723, -94.54195412575287, -63.51800104168438, -37.45535238197715, -10.774966482485105, -31.968671804761954, -10.78959930116394, -130.6783729481369, -46.968865899119436, -153.17764363863105, -100.49760495177875, -197.0425150666593, -213.97702546577705, -225.11770973254997, -200.10441169877734, 111.48111725213484, -130.34506056534514, -81.38837605858753, 30.03291465780474, -110.63950984302316, -30.737084581043515, -175.8354517966048, -34.667576357287146, -58.54213748013107, 64.40361916811528, -95.00388218848072, -27.920749958934287, -108.59594474406737, 43.198079379570714, -186.25805308452726, 163.51268091055033, -8.99601781714944, 126.96944057645612, -56.38020098427687, -32.2942165440887, -53.21942882712731, 57.15267765771238, -176.61440122429195, 118.9973072473467, -10.106187030415846, -37.01595237038041, -80.776922510576, -19.906613534337982, -117.6005998026188, -112.09690954218934, -68.2400847554847, -173.01364794087152, -82.18408546765292, -159.4623141903512, -155.10920973385603, -121.9207288059972, -169.44619602367, -156.97422916845795, -106.59272590373754, -54.705908189365076]}, "sampler_perf": {"mean_env_wait_ms": 54.81774072373712, "mean_raw_obs_processing_ms": 2.3720635169642352, "mean_inference_ms": 2.5116634404127294, "mean_action_processing_ms": 0.14352759241791846}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 42000, "timers": {"sample_time_ms": 92220.535, "sample_throughput": 45.543, "load_time_ms": 104.852, "load_throughput": 40056.594, "learn_time_ms": 8873.505, "learn_throughput": 473.319, "update_time_ms": 8.114}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 14.080324172973633, "policy_loss": -0.02836265042424202, "vf_loss": 14.102871894836426, "vf_explained_var": 0.9233367443084717, "kl": 0.012923873960971832, "entropy": 1.2927736043930054, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 12.060674667358398, "policy_loss": -0.023921573534607887, "vf_loss": 12.080658912658691, "vf_explained_var": 0.921818196773529, "kl": 0.013125111348927021, "entropy": 1.2431411743164062, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 11.887703895568848, "policy_loss": -0.02855275571346283, "vf_loss": 11.911894798278809, "vf_explained_var": 0.9001811742782593, "kl": 0.014540016651153564, "entropy": 1.299224615097046, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 11.561627388000488, "policy_loss": -0.0252383965998888, "vf_loss": 11.58240032196045, "vf_explained_var": 0.919741690158844, "kl": 0.01488618366420269, "entropy": 1.205242395401001, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 42000, "num_steps_trained": 42000}, "done": false, "episodes_total": 353, "training_iteration": 10, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-33-43", "timestamp": 1624210423, "time_this_iter_s": 103.17361807823181, "time_total_s": 1014.8148620128632, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40434bc20>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40434bb00>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40434b8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40434b7a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40434b680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40434b440>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40434b8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40434b7a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40434b680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40434b440>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40434b8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40434b7a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40434b680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40434b440>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40434b8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40434b7a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40434b680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40434b440>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd40449b9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1014.8148620128632, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 57.363945578231295, "ram_util_percent": 88.2}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 719.2528405444258, "episode_reward_min": -1213.7518069568514, "episode_reward_mean": -234.5152958021455, "episode_len_mean": 117.85, "episodes_this_iter": 36, "policy_reward_min": {"AGENT-3": -332.8520107714878, "AGENT-0": -365.7308651925102, "AGENT-1": -297.54442377157767, "AGENT-2": -333.2175597618458}, "policy_reward_max": {"AGENT-3": 155.50383656493443, "AGENT-0": 196.01356087455432, "AGENT-1": 198.4971455982123, "AGENT-2": 174.64588970628935}, "policy_reward_mean": {"AGENT-3": -57.88738328159326, "AGENT-0": -69.84170912779305, "AGENT-1": -50.28574261978836, "AGENT-2": -56.50046077297084}, "custom_metrics": {"mean_ego_speed_mean": 40.57866500000001, "mean_ego_speed_min": 31.8215, "mean_ego_speed_max": 46.602000000000004, "distance_travelled_mean": 102.90296500000001, "distance_travelled_min": 26.04075, "distance_travelled_max": 124.82425}, "hist_stats": {"episode_reward": [277.5082501927192, -539.5229181716101, -153.581562838328, -145.55878760403772, -21.20921304339584, -523.6477425026634, 383.94995029550296, 215.32884624308014, -220.92890330079257, -264.5439050297375, -359.4717186624593, 267.7621927734308, -540.9051941393988, -228.04813853419583, -433.78488418708093, 271.0112910235582, -433.6288256954766, 218.08781806762576, -199.19395599722708, -220.15455476369442, -441.5786535571246, 188.46157410573196, -425.5941900288189, 237.98193177719872, -352.06744578090405, -772.6641430324953, -679.6695947845633, -596.7822250284894, -259.9518688386478, -339.0234463592476, 1.6578448048696366, -288.2076483956573, -655.3192178997259, -139.44407008859187, -662.5859913570597, -776.5601857305171, -264.17272206220184, -26.94060664764845, -456.79979485123135, 168.92739938802566, -533.9852148421465, 576.6884797633769, -248.60718605990928, 444.42428289771954, -309.53548418848067, -354.0614749779861, -341.2743302759964, 279.90548706591113, -755.9836590509157, 401.93497874290836, -217.14996865701616, -261.8262024922521, -410.20645365137557, 17.03875054292125, -485.78664505731626, -363.79207429784475, -155.0000230127589, -672.8921293663304, -428.3325872197913, -568.9885659439753, -650.4792260005617, -454.13380871373516, -645.9806571073526, -671.9430772014143, -326.6278253656915, -270.00959635310375, 38.66666133388032, -139.67587373916658, 433.98692998758037, 29.518086507790535, -144.08622623345474, -905.4698917065235, 564.0248777710962, 385.0587585439746, -52.61705799639689, -223.0036964622047, -271.21566865272774, -429.0828301580593, 51.444097175638696, -362.82589372335974, 719.2528405444258, -474.9937621258046, -279.20866497244646, -298.65663348328115, 382.5772664325727, -213.21076630081728, 431.28428126956226, -299.508857234827, -535.3523603478297, -276.7343466540668, -61.02961551248981, -599.7890343222275, 176.54168977762384, -1213.7518069568514, -506.06136788663906, -498.4395266875669, -627.7797137557184, -962.3833094010705, -274.7084070842293, -416.8305370965437], "episode_lengths": [122, 107, 130, 128, 103, 69, 107, 128, 125, 31, 119, 131, 109, 117, 130, 121, 106, 153, 118, 113, 106, 117, 124, 127, 128, 124, 138, 117, 133, 106, 121, 103, 123, 133, 127, 119, 125, 117, 125, 119, 110, 121, 119, 124, 115, 115, 116, 126, 138, 120, 117, 28, 117, 47, 120, 118, 123, 118, 136, 118, 123, 116, 126, 113, 125, 122, 113, 121, 128, 129, 129, 143, 133, 133, 118, 116, 114, 119, 120, 122, 124, 128, 120, 127, 127, 109, 119, 123, 62, 106, 131, 125, 133, 110, 115, 137, 117, 125, 124, 115], "policy_AGENT-3_reward": [89.75231896645468, -144.12648293391564, -18.870035573236375, -10.013183869295975, -1.140403685995623, -164.75978537177204, 121.40666840695559, 30.26971908896379, -45.334864895765335, -36.52487010959975, -79.63438405843374, 99.87564242783499, -151.84920489427464, -14.322969700988075, -23.14173048297463, 113.34277888728685, -149.533883635908, -5.050500594447364, -40.630760943455655, -77.59881051576073, -178.9960422857363, 94.93827754012506, -91.29498145493068, 81.1617873320846, -69.1424118463542, -186.1224856697782, -180.2054111799834, -145.9569956981373, -107.13001410457417, -48.65133745182221, -37.82379768289944, -48.44263233170546, -163.5805767392221, -87.60996731164205, -172.6974276821284, -184.74418866835325, -95.14721981959104, -37.86149438681765, -107.09053611197399, 86.34017304496149, -140.54274508633952, 127.44283554294752, -9.024150588572994, 101.55524416832262, -54.83612141378783, -32.29473469100947, -130.65483407019775, 91.07850803502544, -152.0758914314944, 81.62048519350641, -10.156455423604887, -36.99124995272852, -80.17825758194883, 27.866538465750068, -137.47558306100586, -112.11155936870158, -68.20660552275045, -164.37577192687166, -149.85064649323132, -159.55714393833384, -151.99353224472696, -115.39159566652641, -169.39933772351466, -161.32421032379432, -106.54107873524546, -54.72206638016821, 45.90843631829118, -42.475756631643215, 101.00148141141375, 4.950100005588285, -36.44491883802502, -332.8520107714878, 155.50383656493443, 122.642445506688, -46.32233396410286, -65.95934242916351, -72.9540898417002, -111.20555144988715, 49.669687127087165, -64.04127924559802, 150.09624436537004, -150.1114238679261, -121.54940380195089, -73.26533585267292, 115.37857273966371, -9.47014619145456, 128.56517758251724, -9.40397082408947, -160.19621898953818, -8.80219303620787, -74.18242922968832, -103.49254231962887, -31.979269378911567, -285.7541435458639, -171.89132334650625, -154.06693823752602, -141.74161091986838, -210.2158933821871, -82.64707747052108, -145.34711999892062], "policy_AGENT-0_reward": [63.53450418935767, -103.88500315807326, -80.90409586185021, -88.48387882606656, 15.09740316206766, -97.10138376366368, 87.77451360800045, 70.41840518937012, -41.41082377745732, -95.72575630461384, -123.12633524953287, 27.3879019514576, -94.28830724746098, -122.87033050031422, -214.24541212791826, 38.20598913953124, -67.55877379033723, 95.54895919985904, -82.71389618355292, -36.38903065142017, -66.86022674531111, -0.14405092361303673, -142.50026912486743, 36.4425160789887, -124.9542467516859, -191.70357631367588, -182.34204578497722, -150.01784627754648, -22.749208933757764, -97.70694196979849, 49.84467535947134, -95.20473021014575, -161.83629708350043, 21.569151531381745, -195.70234514281103, -227.64607640897054, -60.684823149359794, 19.42142680622801, -144.47686143502438, -4.691182553381047, -103.60805591638216, 118.47586043475967, -139.45398548555738, 84.32498345842109, -98.8830851166206, -134.41902715281282, -104.9026970026203, 65.90570886803083, -234.98912806111127, 76.81976629498507, -98.67335579124374, -93.963688800114, -124.32647983127323, -19.35162780840214, -115.66901495767655, -70.30690096248134, -32.93557034967274, -167.95976168146984, -119.20923155963555, -125.18805025159077, -195.6819025503998, -95.60092143800414, -177.0797736936199, -156.08727136945424, -78.84527585532153, -80.9122378642664, -2.3124193466425123, -27.743923163113205, 115.68586095954645, -3.961401073925792, -71.67298156968343, -365.7308651925102, 133.04516702382023, 61.22645208297305, -3.065557818882958, -110.19771479252208, -67.31920172949143, -90.05507089744304, -30.270550205473373, -141.55717174304664, 196.01356087455432, -184.36802218210846, -20.05290088192473, -70.73193853373216, 57.88063355941049, -83.12492892448309, 54.090195386533615, -163.4346235169342, -107.48911606814707, -107.14355859932901, 54.86784497299689, -177.0339966286794, 98.2568395406939, -297.235679877563, -85.6824550204177, -110.46887397870509, -193.437809613362, -280.0342501705825, -78.27923136850734, -67.63418980411582], "policy_AGENT-1_reward": [64.84907334097842, -104.19236495624993, -34.88327554130913, -2.5007578457254587, 15.19617060645803, -96.97488043208168, 87.54087533192703, 44.79387276850324, -67.74633616763336, -95.74969454142234, -75.78013106876439, 73.89362828572759, -94.20763439420406, -76.48910770715703, -173.31532792401967, 38.10208315237625, -67.48630711820394, 132.68326674549655, -33.92317069460552, -69.22205761262938, -66.75038921778338, 48.066341427057026, -92.92868716333578, 38.85809982248016, -80.1329942650562, -191.84461382059726, -137.07197694663068, -149.2834375264351, -22.88708246299711, -97.59594338334543, 27.421135879529196, -95.15289185521601, -160.53047367665968, 14.023492311092925, -147.24356406957435, -180.19367688710523, -13.336796904770239, 19.42021089187543, -96.63645256016606, 44.08032951687469, -103.57636075489756, 167.25710287512004, -91.13303216862953, 131.57461469451968, -99.43607667379544, -155.05349659007484, -52.49737037605132, 65.76859250514283, -192.3042383340181, 124.49742000707029, -98.21397041175169, -93.85531136902915, -124.92479372757742, 28.43045341991124, -115.04144723601507, -69.2767044244723, 14.382237615149256, -167.54294781711744, -77.0886236992713, -124.78105756369922, -147.69458147157889, -121.22056280320741, -130.05534966654795, -197.55736633970764, -34.64874487138713, -79.66938391930421, -2.437917950616419, -27.012069577182157, 116.34845684488634, 33.08821362369334, -17.59213292707495, -103.22397724398684, 142.98781609774554, 107.51775524510663, 43.133643779909946, -23.146786958211003, -63.05900394793434, -112.3809891351694, 18.64085444164083, -93.12217814204269, 198.4971455982123, -70.0394879547936, -116.99855077747615, -73.30602999905447, 105.6673096274731, -111.17132030717278, 149.106287660678, -117.23117013857537, -159.6282365819281, -107.19624460226984, 32.41048425242965, -177.34364070321425, 142.1934710953346, -297.54442377157767, -162.3769786534656, -117.15733071677816, -144.7013084520078, -235.7225880059033, -31.234869685865068, -135.7460182491243], "policy_AGENT-2_reward": [59.37235369592822, -187.31906712337155, -18.924155861932206, -44.560967062949665, -50.362383125925895, -164.811692935146, 87.22789294862042, 69.84684919624299, -66.43687845993676, -36.54358407410163, -80.93086828572822, 66.60502010841051, -200.5600476034591, -14.365730625736582, -23.082413652168306, 81.36043984436364, -149.04986115102753, -5.093907283282583, -41.92612817561305, -36.94465598388415, -128.97199530829397, 45.60100606216311, -98.87025228568523, 81.5195285436456, -77.83779291780814, -202.99346722844348, -180.0501608729714, -151.52394552637006, -107.1855633373187, -95.06922355428134, -37.78416875123149, -49.40739399859026, -169.37187040034365, -87.42674661942442, -146.942654462546, -183.9762437660885, -95.00388218848072, -27.920749958934287, -108.59594474406737, 43.198079379570714, -186.25805308452726, 163.51268091055033, -8.99601781714944, 126.96944057645612, -56.38020098427687, -32.2942165440887, -53.21942882712731, 57.15267765771238, -176.61440122429195, 118.9973072473467, -10.106187030415846, -37.01595237038041, -80.776922510576, -19.906613534337982, -117.6005998026188, -112.09690954218934, -68.2400847554847, -173.01364794087152, -82.18408546765292, -159.4623141903512, -155.10920973385603, -121.9207288059972, -169.44619602367, -156.97422916845795, -106.59272590373754, -54.705908189365076, -2.491437687152043, -42.44412436722809, 100.95113077173382, -4.558826047565361, -18.376192898671405, -103.66303849853897, 132.4880580845959, 93.67210570920724, -46.36280999332107, -23.699852282308132, -67.8833731336019, -115.44121867555984, 13.404105812383925, -64.10526459267223, 174.64588970628935, -70.47482812097648, -20.607809511094665, -81.3533290978216, 103.65075050602535, -9.44437087770682, 99.5226206398336, -9.439092755228076, -108.03878870821607, -53.59235041626004, -74.12551550822798, -141.91885467070458, -31.9293514794932, -333.2175597618458, -86.11061086624883, -116.74638375455713, -147.89898477048024, -236.4105778423973, -82.54722855933596, -68.10320904438291]}, "sampler_perf": {"mean_env_wait_ms": 55.093774307271836, "mean_raw_obs_processing_ms": 2.375889420736682, "mean_inference_ms": 2.5032646262612803, "mean_action_processing_ms": 0.14403714846221172}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 46200, "timers": {"sample_time_ms": 92434.249, "sample_throughput": 45.438, "load_time_ms": 15.559, "load_throughput": 269944.264, "learn_time_ms": 8753.676, "learn_throughput": 479.798, "update_time_ms": 8.249}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 14.36872673034668, "policy_loss": -0.025026986375451088, "vf_loss": 14.388334274291992, "vf_explained_var": 0.9219478368759155, "kl": 0.012042896822094917, "entropy": 1.3085333108901978, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 14.290387153625488, "policy_loss": -0.0255252867937088, "vf_loss": 14.311720848083496, "vf_explained_var": 0.9041439890861511, "kl": 0.013969472609460354, "entropy": 1.2464994192123413, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 13.741595268249512, "policy_loss": -0.024837898090481758, "vf_loss": 13.760052680969238, "vf_explained_var": 0.8941077589988708, "kl": 0.021269485354423523, "entropy": 1.2877197265625, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 14.458206176757812, "policy_loss": -0.023842182010412216, "vf_loss": 14.476975440979004, "vf_explained_var": 0.8903933763504028, "kl": 0.016911059617996216, "entropy": 1.244831919670105, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 46200, "num_steps_trained": 46200}, "done": false, "episodes_total": 389, "training_iteration": 11, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-35-26", "timestamp": 1624210526, "time_this_iter_s": 102.61675977706909, "time_total_s": 1117.4316217899323, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40449b200>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40449bb90>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40434bef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40434bd40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8ef0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40434bef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40434bd40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8ef0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40434bef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40434bd40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8ef0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40434bef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40434bd40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8ef0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd40434b3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1117.4316217899323, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 56.85646258503401, "ram_util_percent": 88.17074829931974}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 719.2528405444258, "episode_reward_min": -1220.1680969634779, "episode_reward_mean": -233.98619041440568, "episode_len_mean": 118.22, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-3": -332.8520107714878, "AGENT-0": -365.7308651925102, "AGENT-1": -311.7837237647874, "AGENT-2": -333.2175597618458}, "policy_reward_max": {"AGENT-3": 168.9166566167544, "AGENT-0": 196.01356087455432, "AGENT-1": 198.4971455982123, "AGENT-2": 174.64588970628935}, "policy_reward_mean": {"AGENT-3": -58.09294538064225, "AGENT-0": -66.9995799578942, "AGENT-1": -48.6591121611336, "AGENT-2": -60.2345529147356}, "custom_metrics": {"mean_ego_speed_mean": 40.460392500000005, "mean_ego_speed_min": 32.2895, "mean_ego_speed_max": 46.602000000000004, "distance_travelled_mean": 100.80003500000001, "distance_travelled_min": 26.04075, "distance_travelled_max": 124.91999999999999}, "hist_stats": {"episode_reward": [-9.63730562835115, -294.97134835683124, 540.0657984430437, -257.40834643224383, 509.27905686126564, -40.69930444713047, 454.1789787521829, -61.93504792923863, -64.174093930484, -519.5563326083812, -59.000781589466854, -315.9096946005316, 350.86243883840586, -374.71827841130437, 149.19615103880395, -371.61473784827217, -150.2605567906177, -315.80850729689803, 270.43239312826233, -366.92239410704724, 321.6942666077374, -327.79423656484005, -92.15167416296005, -447.49519482425944, -994.7722385730885, -1220.1680969634779, -357.969207715302, -537.9148867395174, -1004.637099640832, -459.6633480748896, -74.66293528238354, -354.03282458992607, -677.1770709070294, -218.32565113146205, -340.59770688849073, -905.4698917065235, 564.0248777710962, 385.0587585439746, -52.61705799639689, -223.0036964622047, -271.21566865272774, -429.0828301580593, 51.444097175638696, -362.82589372335974, 719.2528405444258, -474.9937621258046, -279.20866497244646, -298.65663348328115, 382.5772664325727, -213.21076630081728, 431.28428126956226, -299.508857234827, -535.3523603478297, -276.7343466540668, -61.02961551248981, -599.7890343222275, 176.54168977762384, -1213.7518069568514, -506.06136788663906, -498.4395266875669, -627.7797137557184, -962.3833094010705, -274.7084070842293, -416.8305370965437, 277.5082501927192, -539.5229181716101, -153.581562838328, -145.55878760403772, -21.20921304339584, -523.6477425026634, 383.94995029550296, 215.32884624308014, -220.92890330079257, -264.5439050297375, -359.4717186624593, 267.7621927734308, -540.9051941393988, -228.04813853419583, -433.78488418708093, 271.0112910235582, -433.6288256954766, 218.08781806762576, -199.19395599722708, -220.15455476369442, -441.5786535571246, 188.46157410573196, -425.5941900288189, 237.98193177719872, -352.06744578090405, -772.6641430324953, -679.6695947845633, -596.7822250284894, -259.9518688386478, -339.0234463592476, 1.6578448048696366, -288.2076483956573, -655.3192178997259, -139.44407008859187, -662.5859913570597, -776.5601857305171], "episode_lengths": [131, 115, 122, 120, 129, 124, 130, 128, 108, 111, 55, 116, 117, 101, 129, 122, 112, 119, 123, 105, 134, 126, 120, 118, 123, 99, 105, 121, 129, 118, 128, 99, 121, 126, 130, 143, 133, 133, 118, 116, 114, 119, 120, 122, 124, 128, 120, 127, 127, 109, 119, 123, 62, 106, 131, 125, 133, 110, 115, 137, 117, 125, 124, 115, 122, 107, 130, 128, 103, 69, 107, 128, 125, 31, 119, 131, 109, 117, 130, 121, 106, 153, 118, 113, 106, 117, 124, 127, 128, 124, 138, 117, 133, 106, 121, 103, 123, 133, 127, 119], "policy_AGENT-3_reward": [-32.223874858799824, -107.87255752950148, 168.9166566167544, -56.25270567144113, 147.57294436020334, -40.563852907320054, 132.11086468059892, -40.25115234525072, -30.64100530049576, -138.2842502381468, -47.344551507925914, -121.79175411262923, 96.69706791561792, -126.21727598062346, 71.6362775960047, -83.72195646994395, -58.61194053743604, -79.30049217476494, 100.54232453618476, -95.97794296226886, 102.49045385956107, -13.542664536670927, -2.8560576422166406, -135.8851285953681, -229.95385378432786, -284.77043577197554, -53.30532671640757, -125.57748759735618, -245.01357059786767, -116.81402276685994, -35.18243475540889, -32.24155896745395, -143.20155109547548, -88.018504025315, -124.06458524737128, -332.8520107714878, 155.50383656493443, 122.642445506688, -46.32233396410286, -65.95934242916351, -72.9540898417002, -111.20555144988715, 49.669687127087165, -64.04127924559802, 150.09624436537004, -150.1114238679261, -121.54940380195089, -73.26533585267292, 115.37857273966371, -9.47014619145456, 128.56517758251724, -9.40397082408947, -160.19621898953818, -8.80219303620787, -74.18242922968832, -103.49254231962887, -31.979269378911567, -285.7541435458639, -171.89132334650625, -154.06693823752602, -141.74161091986838, -210.2158933821871, -82.64707747052108, -145.34711999892062, 89.75231896645468, -144.12648293391564, -18.870035573236375, -10.013183869295975, -1.140403685995623, -164.75978537177204, 121.40666840695559, 30.26971908896379, -45.334864895765335, -36.52487010959975, -79.63438405843374, 99.87564242783499, -151.84920489427464, -14.322969700988075, -23.14173048297463, 113.34277888728685, -149.533883635908, -5.050500594447364, -40.630760943455655, -77.59881051576073, -178.9960422857363, 94.93827754012506, -91.29498145493068, 81.1617873320846, -69.1424118463542, -186.1224856697782, -180.2054111799834, -145.9569956981373, -107.13001410457417, -48.65133745182221, -37.82379768289944, -48.44263233170546, -163.5805767392221, -87.60996731164205, -172.6974276821284, -184.74418866835325], "policy_AGENT-0_reward": [5.699660996153639, -43.55633251966281, 123.60026943856016, -81.51157289813275, 120.5001052453438, 18.449792170855922, 108.21375655274367, -12.927734579102399, 20.352274875724216, -99.89065295612298, 17.84906210954653, -41.00620237772043, 68.36748851552252, -61.21555817261533, -21.71322054099391, -126.76742903544647, -20.78972541059049, -116.6872739277562, 57.09945558113283, -62.63237738406794, 93.33618589940667, -173.2851909540282, -32.216725297721844, -92.25676520765322, -283.56015861325284, -311.5248238697098, -102.19943781515856, -168.5097460107498, -279.6317147334584, -145.57715062850184, -24.487308557618793, -120.3057117571596, -217.91195512805822, -43.49774029021502, -68.54965469849546, -365.7308651925102, 133.04516702382023, 61.22645208297305, -3.065557818882958, -110.19771479252208, -67.31920172949143, -90.05507089744304, -30.270550205473373, -141.55717174304664, 196.01356087455432, -184.36802218210846, -20.05290088192473, -70.73193853373216, 57.88063355941049, -83.12492892448309, 54.090195386533615, -163.4346235169342, -107.48911606814707, -107.14355859932901, 54.86784497299689, -177.0339966286794, 98.2568395406939, -297.235679877563, -85.6824550204177, -110.46887397870509, -193.437809613362, -280.0342501705825, -78.27923136850734, -67.63418980411582, 63.53450418935767, -103.88500315807326, -80.90409586185021, -88.48387882606656, 15.09740316206766, -97.10138376366368, 87.77451360800045, 70.41840518937012, -41.41082377745732, -95.72575630461384, -123.12633524953287, 27.3879019514576, -94.28830724746098, -122.87033050031422, -214.24541212791826, 38.20598913953124, -67.55877379033723, 95.54895919985904, -82.71389618355292, -36.38903065142017, -66.86022674531111, -0.14405092361303673, -142.50026912486743, 36.4425160789887, -124.9542467516859, -191.70357631367588, -182.34204578497722, -150.01784627754648, -22.749208933757764, -97.70694196979849, 49.84467535947134, -95.20473021014575, -161.83629708350043, 21.569151531381745, -195.70234514281103, -227.64607640897054], "policy_AGENT-1_reward": [49.27574116647403, -99.54018638486063, 123.50317983466499, -37.556370406843946, 124.09580366514454, 21.84772495888756, 108.59137034886572, 31.371330182994317, 20.298413662292997, -99.73317294392147, 17.887660089812112, -111.5589451298749, 118.10304171034248, -61.190910807780924, 74.1509509585938, -77.21671867610328, -49.518046127502906, -59.62609220942208, 57.20131451006893, -62.78071680861838, 67.46035433909859, -127.39165160647592, -54.490129546030595, -126.54145510943172, -237.14611165365696, -311.7837237647874, -102.18113716278714, -121.90930271823366, -234.26557846335504, -98.48445095899483, 20.10465727069438, -120.46617993172083, -142.6378363952779, 1.2596273494164807, -24.208565519894687, -103.22397724398684, 142.98781609774554, 107.51775524510663, 43.133643779909946, -23.146786958211003, -63.05900394793434, -112.3809891351694, 18.64085444164083, -93.12217814204269, 198.4971455982123, -70.0394879547936, -116.99855077747615, -73.30602999905447, 105.6673096274731, -111.17132030717278, 149.106287660678, -117.23117013857537, -159.6282365819281, -107.19624460226984, 32.41048425242965, -177.34364070321425, 142.1934710953346, -297.54442377157767, -162.3769786534656, -117.15733071677816, -144.7013084520078, -235.7225880059033, -31.234869685865068, -135.7460182491243, 64.84907334097842, -104.19236495624993, -34.88327554130913, -2.5007578457254587, 15.19617060645803, -96.97488043208168, 87.54087533192703, 44.79387276850324, -67.74633616763336, -95.74969454142234, -75.78013106876439, 73.89362828572759, -94.20763439420406, -76.48910770715703, -173.31532792401967, 38.10208315237625, -67.48630711820394, 132.68326674549655, -33.92317069460552, -69.22205761262938, -66.75038921778338, 48.066341427057026, -92.92868716333578, 38.85809982248016, -80.1329942650562, -191.84461382059726, -137.07197694663068, -149.2834375264351, -22.88708246299711, -97.59594338334543, 27.421135879529196, -95.15289185521601, -160.53047367665968, 14.023492311092925, -147.24356406957435, -180.19367688710523], "policy_AGENT-2_reward": [-32.3888329321789, -44.002271922806365, 124.04569255306366, -82.08769745582606, 117.11020359057406, -40.43296866955368, 105.2629871699738, -40.12749118788, -74.1837771680054, -181.6482564701899, -47.39295228089953, -41.552792980307075, 67.69484069692297, -126.09453345028504, 25.12214302519908, -83.90863366677844, -21.34084471508828, -60.19464898495487, 55.5892985008761, -145.53135695209212, 58.40727250967075, -13.574729467665026, -2.5887616769909556, -92.8118459118063, -244.1121145218506, -312.08911355700485, -100.28330602094921, -121.91835041317759, -245.7262358461507, -98.7877237205331, -35.09784924005028, -81.01937393359191, -173.42572828821713, -88.06903416534894, -123.77490142272941, -103.66303849853897, 132.4880580845959, 93.67210570920724, -46.36280999332107, -23.699852282308132, -67.8833731336019, -115.44121867555984, 13.404105812383925, -64.10526459267223, 174.64588970628935, -70.47482812097648, -20.607809511094665, -81.3533290978216, 103.65075050602535, -9.44437087770682, 99.5226206398336, -9.439092755228076, -108.03878870821607, -53.59235041626004, -74.12551550822798, -141.91885467070458, -31.9293514794932, -333.2175597618458, -86.11061086624883, -116.74638375455713, -147.89898477048024, -236.4105778423973, -82.54722855933596, -68.10320904438291, 59.37235369592822, -187.31906712337155, -18.924155861932206, -44.560967062949665, -50.362383125925895, -164.811692935146, 87.22789294862042, 69.84684919624299, -66.43687845993676, -36.54358407410163, -80.93086828572822, 66.60502010841051, -200.5600476034591, -14.365730625736582, -23.082413652168306, 81.36043984436364, -149.04986115102753, -5.093907283282583, -41.92612817561305, -36.94465598388415, -128.97199530829397, 45.60100606216311, -98.87025228568523, 81.5195285436456, -77.83779291780814, -202.99346722844348, -180.0501608729714, -151.52394552637006, -107.1855633373187, -95.06922355428134, -37.78416875123149, -49.40739399859026, -169.37187040034365, -87.42674661942442, -146.942654462546, -183.9762437660885]}, "sampler_perf": {"mean_env_wait_ms": 55.16059505707583, "mean_raw_obs_processing_ms": 2.3751382895256934, "mean_inference_ms": 2.492424166495184, "mean_action_processing_ms": 0.14410623069169987}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 50400, "timers": {"sample_time_ms": 92570.525, "sample_throughput": 45.371, "load_time_ms": 15.556, "load_throughput": 269985.223, "learn_time_ms": 8841.554, "learn_throughput": 475.03, "update_time_ms": 8.025}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 11.956764221191406, "policy_loss": -0.031181268393993378, "vf_loss": 11.980005264282227, "vf_explained_var": 0.9519596099853516, "kl": 0.017646947875618935, "entropy": 1.2905477285385132, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 8.951452255249023, "policy_loss": -0.025521252304315567, "vf_loss": 8.972031593322754, "vf_explained_var": 0.9520859718322754, "kl": 0.016471294686198235, "entropy": 1.236694097518921, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 10.348118782043457, "policy_loss": -0.03116648830473423, "vf_loss": 10.3720064163208, "vf_explained_var": 0.9374751448631287, "kl": 0.01617165096104145, "entropy": 1.230190634727478, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 11.269963264465332, "policy_loss": -0.026464169844985008, "vf_loss": 11.291117668151855, "vf_explained_var": 0.9369159936904907, "kl": 0.01769835129380226, "entropy": 1.2407149076461792, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 50400, "num_steps_trained": 50400}, "done": false, "episodes_total": 424, "training_iteration": 12, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-37-05", "timestamp": 1624210625, "time_this_iter_s": 98.89464473724365, "time_total_s": 1216.326266527176, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd4042b80e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd4042b8200>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042b8440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042b8560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042b8680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042b87a0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042b8440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042b8560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042b8680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042b87a0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042b8440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042b8560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042b8680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042b87a0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042b8440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042b8560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042b8680>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042b87a0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd40445a200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1216.326266527176, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 57.53617021276597, "ram_util_percent": 88.2}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 540.0657984430437, "episode_reward_min": -1220.1680969634779, "episode_reward_mean": -232.17455722502802, "episode_len_mean": 118.21, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-3": -284.77043577197554, "AGENT-0": -311.5248238697098, "AGENT-1": -311.7837237647874, "AGENT-2": -312.08911355700485}, "policy_reward_max": {"AGENT-3": 168.9166566167544, "AGENT-0": 125.83223182003816, "AGENT-1": 132.68326674549655, "AGENT-2": 124.04569255306366}, "policy_reward_mean": {"AGENT-3": -55.904725084816, "AGENT-0": -64.45071003280529, "AGENT-1": -48.366749853193554, "AGENT-2": -63.452372254213245}, "custom_metrics": {"mean_ego_speed_mean": 40.455905, "mean_ego_speed_min": 29.764, "mean_ego_speed_max": 48.324999999999996, "distance_travelled_mean": 101.6898475, "distance_travelled_min": 26.04075, "distance_travelled_max": 124.91999999999999}, "hist_stats": {"episode_reward": [-228.88830694554744, 85.36085712102681, -184.03626381820015, -417.90155225834997, 274.4487494070676, -157.87234715092944, -18.810758578770493, -185.2513821751021, 342.1202967960125, -149.1330458630964, -255.45077281821378, -286.86965608999805, -414.09317428905763, 277.25186712637213, -655.5275329597748, 493.89371888456753, -509.3011325557126, 234.8331253505405, -378.80340426267276, 224.2025709490485, -157.55647589307267, 278.6896113282307, -488.0043767809139, 24.626098674247366, 16.18332869347438, 50.242558556580086, -345.42465950793803, -753.237734270807, -445.25178917386665, -615.346602393577, -648.7781530718191, -257.20333273372637, -475.330929708609, -529.7217289982945, -290.79017053808553, -374.60065889309584, -476.7066366556966, -220.92890330079257, -264.5439050297375, -359.4717186624593, 267.7621927734308, -540.9051941393988, -228.04813853419583, -433.78488418708093, 271.0112910235582, -433.6288256954766, 218.08781806762576, -199.19395599722708, -220.15455476369442, -441.5786535571246, 188.46157410573196, -425.5941900288189, 237.98193177719872, -352.06744578090405, -772.6641430324953, -679.6695947845633, -596.7822250284894, -259.9518688386478, -339.0234463592476, 1.6578448048696366, -288.2076483956573, -655.3192178997259, -139.44407008859187, -662.5859913570597, -776.5601857305171, -9.63730562835115, -294.97134835683124, 540.0657984430437, -257.40834643224383, 509.27905686126564, -40.69930444713047, 454.1789787521829, -61.93504792923863, -64.174093930484, -519.5563326083812, -59.000781589466854, -315.9096946005316, 350.86243883840586, -374.71827841130437, 149.19615103880395, -371.61473784827217, -150.2605567906177, -315.80850729689803, 270.43239312826233, -366.92239410704724, 321.6942666077374, -327.79423656484005, -92.15167416296005, -447.49519482425944, -994.7722385730885, -1220.1680969634779, -357.969207715302, -537.9148867395174, -1004.637099640832, -459.6633480748896, -74.66293528238354, -354.03282458992607, -677.1770709070294, -218.32565113146205, -340.59770688849073], "episode_lengths": [118, 123, 110, 120, 120, 108, 128, 130, 116, 111, 121, 123, 126, 119, 128, 125, 122, 129, 109, 125, 130, 121, 119, 137, 127, 133, 105, 125, 115, 145, 117, 35, 123, 110, 107, 109, 119, 125, 31, 119, 131, 109, 117, 130, 121, 106, 153, 118, 113, 106, 117, 124, 127, 128, 124, 138, 117, 133, 106, 121, 103, 123, 133, 127, 119, 131, 115, 122, 120, 129, 124, 130, 128, 108, 111, 55, 116, 117, 101, 129, 122, 112, 119, 123, 105, 134, 126, 120, 118, 123, 99, 105, 121, 129, 118, 128, 99, 121, 126, 130], "policy_AGENT-3_reward": [-90.0913651259441, -20.908472421640898, -86.19331955397085, -140.6574769494448, 104.42399512815611, -40.47687740747064, -33.141702033868874, -0.5745126177145017, 63.77713216271656, -38.5275236223648, -105.07028730968293, -60.46760124775665, -22.12375979172656, 125.73958646939965, -238.2002858752645, 120.34175550840888, -118.78645584951045, 79.06099240102188, -99.83242724019962, 84.86262000333912, -26.921367860170573, 80.7178137380608, -156.7305870477727, 34.24100625731664, -37.29961562170689, -32.45399671680384, -121.83612761245125, -125.75994144799756, -92.04302848330445, -221.92915055665267, -141.37427078938632, -35.51455475698303, -58.04015861948781, -95.3140992995523, -26.316362671420634, -92.32503629927284, -118.50937643725405, -45.334864895765335, -36.52487010959975, -79.63438405843374, 99.87564242783499, -151.84920489427464, -14.322969700988075, -23.14173048297463, 113.34277888728685, -149.533883635908, -5.050500594447364, -40.630760943455655, -77.59881051576073, -178.9960422857363, 94.93827754012506, -91.29498145493068, 81.1617873320846, -69.1424118463542, -186.1224856697782, -180.2054111799834, -145.9569956981373, -107.13001410457417, -48.65133745182221, -37.82379768289944, -48.44263233170546, -163.5805767392221, -87.60996731164205, -172.6974276821284, -184.74418866835325, -32.223874858799824, -107.87255752950148, 168.9166566167544, -56.25270567144113, 147.57294436020334, -40.563852907320054, 132.11086468059892, -40.25115234525072, -30.64100530049576, -138.2842502381468, -47.344551507925914, -121.79175411262923, 96.69706791561792, -126.21727598062346, 71.6362775960047, -83.72195646994395, -58.61194053743604, -79.30049217476494, 100.54232453618476, -95.97794296226886, 102.49045385956107, -13.542664536670927, -2.8560576422166406, -135.8851285953681, -229.95385378432786, -284.77043577197554, -53.30532671640757, -125.57748759735618, -245.01357059786767, -116.81402276685994, -35.18243475540889, -32.24155896745395, -143.20155109547548, -88.018504025315, -124.06458524737128], "policy_AGENT-0_reward": [-35.08651502803875, 6.161792165978767, 13.911007102796102, -74.09433474535159, 57.32269945965893, -40.25918251585041, 16.410158181629193, -93.77553621602422, 107.62172199568953, -38.72160232346032, -28.22753390043435, -104.71574569160691, -207.65947762768565, 36.27981794064004, -70.64171817812135, 125.83223182003816, -160.42413928568698, 37.81811082328897, -67.64869493671081, 0.663937283745625, -72.86001953518871, 37.42239927662148, -90.20646391809211, -42.701654634235034, 23.435214153626404, 35.7243068143569, -63.21474014134379, -270.1777449383064, -134.20738237857816, -106.02715238693365, -206.38324556862005, -93.04411837006174, -99.21916789885718, -145.68425809321013, -96.5324853640823, -96.31941011606352, -118.40063028447341, -41.41082377745732, -95.72575630461384, -123.12633524953287, 27.3879019514576, -94.28830724746098, -122.87033050031422, -214.24541212791826, 38.20598913953124, -67.55877379033723, 95.54895919985904, -82.71389618355292, -36.38903065142017, -66.86022674531111, -0.14405092361303673, -142.50026912486743, 36.4425160789887, -124.9542467516859, -191.70357631367588, -182.34204578497722, -150.01784627754648, -22.749208933757764, -97.70694196979849, 49.84467535947134, -95.20473021014575, -161.83629708350043, 21.569151531381745, -195.70234514281103, -227.64607640897054, 5.699660996153639, -43.55633251966281, 123.60026943856016, -81.51157289813275, 120.5001052453438, 18.449792170855922, 108.21375655274367, -12.927734579102399, 20.352274875724216, -99.89065295612298, 17.84906210954653, -41.00620237772043, 68.36748851552252, -61.21555817261533, -21.71322054099391, -126.76742903544647, -20.78972541059049, -116.6872739277562, 57.09945558113283, -62.63237738406794, 93.33618589940667, -173.2851909540282, -32.216725297721844, -92.25676520765322, -283.56015861325284, -311.5248238697098, -102.19943781515856, -168.5097460107498, -279.6317147334584, -145.57715062850184, -24.487308557618793, -120.3057117571596, -217.91195512805822, -43.49774029021502, -68.54965469849546], "policy_AGENT-1_reward": [-68.19402071190746, 51.91549556169966, 13.99956365426818, -128.502166565061, 57.42693244747788, -36.32738321224942, -17.93624217035427, -45.10053840247708, 86.0702203935738, -32.60279465464567, -93.37207603570228, -55.9361625882135, -162.29972641816923, 35.86294833865161, -70.63767231446883, 127.49182734160335, -113.02163861681335, 43.10691464250353, -67.63130886655895, 93.28521053897485, -25.871783685873616, 80.48914178141695, -150.29286655113984, 33.103846838471256, 67.29518941536446, 79.22417722724452, -96.61157436602365, -125.19690335960837, -84.22181994583994, -65.505485124783, -140.8109358110629, -93.17710661377896, -158.79627465769713, -142.4824620352846, -96.4776867998045, -89.07683732961458, -118.29942350563174, -67.74633616763336, -95.74969454142234, -75.78013106876439, 73.89362828572759, -94.20763439420406, -76.48910770715703, -173.31532792401967, 38.10208315237625, -67.48630711820394, 132.68326674549655, -33.92317069460552, -69.22205761262938, -66.75038921778338, 48.066341427057026, -92.92868716333578, 38.85809982248016, -80.1329942650562, -191.84461382059726, -137.07197694663068, -149.2834375264351, -22.88708246299711, -97.59594338334543, 27.421135879529196, -95.15289185521601, -160.53047367665968, 14.023492311092925, -147.24356406957435, -180.19367688710523, 49.27574116647403, -99.54018638486063, 123.50317983466499, -37.556370406843946, 124.09580366514454, 21.84772495888756, 108.59137034886572, 31.371330182994317, 20.298413662292997, -99.73317294392147, 17.887660089812112, -111.5589451298749, 118.10304171034248, -61.190910807780924, 74.1509509585938, -77.21671867610328, -49.518046127502906, -59.62609220942208, 57.20131451006893, -62.78071680861838, 67.46035433909859, -127.39165160647592, -54.490129546030595, -126.54145510943172, -237.14611165365696, -311.7837237647874, -102.18113716278714, -121.90930271823366, -234.26557846335504, -98.48445095899483, 20.10465727069438, -120.46617993172083, -142.6378363952779, 1.2596273494164807, -24.208565519894687], "policy_AGENT-2_reward": [-35.516406079657244, 48.19204181498942, -125.75351502129351, -74.64757399849229, 55.275122371775225, -40.808904015358856, 15.857027443823256, -45.800794938886305, 84.6512222440326, -39.28112526262531, -28.780875572394244, -65.75014656242098, -22.01021045147617, 79.36951437768067, -276.0478565919196, 120.22790421451673, -117.06889880370161, 74.84710748372599, -143.69097321920322, 45.39080312298883, -31.9033048118399, 80.06025653213139, -90.77445926390928, -0.01709978730555406, -37.24745925380968, -32.25192876821751, -63.76221738811958, -232.10314452489524, -134.77955836614427, -221.884814325208, -160.20970090275003, -35.4675529929026, -159.27532853256702, -146.2409095702474, -71.46363570277819, -96.8793751481451, -121.49720642833745, -66.43687845993676, -36.54358407410163, -80.93086828572822, 66.60502010841051, -200.5600476034591, -14.365730625736582, -23.082413652168306, 81.36043984436364, -149.04986115102753, -5.093907283282583, -41.92612817561305, -36.94465598388415, -128.97199530829397, 45.60100606216311, -98.87025228568523, 81.5195285436456, -77.83779291780814, -202.99346722844348, -180.0501608729714, -151.52394552637006, -107.1855633373187, -95.06922355428134, -37.78416875123149, -49.40739399859026, -169.37187040034365, -87.42674661942442, -146.942654462546, -183.9762437660885, -32.3888329321789, -44.002271922806365, 124.04569255306366, -82.08769745582606, 117.11020359057406, -40.43296866955368, 105.2629871699738, -40.12749118788, -74.1837771680054, -181.6482564701899, -47.39295228089953, -41.552792980307075, 67.69484069692297, -126.09453345028504, 25.12214302519908, -83.90863366677844, -21.34084471508828, -60.19464898495487, 55.5892985008761, -145.53135695209212, 58.40727250967075, -13.574729467665026, -2.5887616769909556, -92.8118459118063, -244.1121145218506, -312.08911355700485, -100.28330602094921, -121.91835041317759, -245.7262358461507, -98.7877237205331, -35.09784924005028, -81.01937393359191, -173.42572828821713, -88.06903416534894, -123.77490142272941]}, "sampler_perf": {"mean_env_wait_ms": 55.31700550555665, "mean_raw_obs_processing_ms": 2.375893772385683, "mean_inference_ms": 2.4848385835517863, "mean_action_processing_ms": 0.14443304826033285}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 54600, "timers": {"sample_time_ms": 93156.599, "sample_throughput": 45.085, "load_time_ms": 15.172, "load_throughput": 276827.386, "learn_time_ms": 8843.615, "learn_throughput": 474.919, "update_time_ms": 8.097}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 16.382783889770508, "policy_loss": -0.030212141573429108, "vf_loss": 16.40679931640625, "vf_explained_var": 0.9278517365455627, "kl": 0.013769774697721004, "entropy": 1.2915184497833252, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 14.847372055053711, "policy_loss": -0.026333892717957497, "vf_loss": 14.868058204650879, "vf_explained_var": 0.9162365794181824, "kl": 0.018831804394721985, "entropy": 1.2132558822631836, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 11.868171691894531, "policy_loss": -0.03251134976744652, "vf_loss": 11.893779754638672, "vf_explained_var": 0.9296614527702332, "kl": 0.015339843928813934, "entropy": 1.2194890975952148, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 11.301215171813965, "policy_loss": -0.025844447314739227, "vf_loss": 11.321737289428711, "vf_explained_var": 0.9422339797019958, "kl": 0.017741702497005463, "entropy": 1.2462238073349, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 54600, "num_steps_trained": 54600}, "done": false, "episodes_total": 461, "training_iteration": 13, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-38-51", "timestamp": 1624210731, "time_this_iter_s": 106.0786542892456, "time_total_s": 1322.4049208164215, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40449b0e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40449b830>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449be60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449b290>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40449b320>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40434b3b0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449be60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449b290>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40449b320>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40434b3b0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449be60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449b290>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40449b320>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40434b3b0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449be60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449b290>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40449b320>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40434b3b0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd4042b89e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1322.4049208164215, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 58.10723684210526, "ram_util_percent": 87.52236842105263}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 578.2332293148935, "episode_reward_min": -1220.1680969634779, "episode_reward_mean": -199.52458587752128, "episode_len_mean": 119.04, "episodes_this_iter": 33, "policy_reward_min": {"AGENT-3": -284.77043577197554, "AGENT-0": -311.5248238697098, "AGENT-1": -311.7837237647874, "AGENT-2": -312.08911355700485}, "policy_reward_max": {"AGENT-3": 177.30831887125314, "AGENT-0": 133.2745210420796, "AGENT-1": 137.0175826522555, "AGENT-2": 130.63280674930448}, "policy_reward_mean": {"AGENT-3": -50.45828326619019, "AGENT-0": -52.709021613333064, "AGENT-1": -38.23798982855772, "AGENT-2": -58.11929116944031}, "custom_metrics": {"mean_ego_speed_mean": 41.04472, "mean_ego_speed_min": 29.764, "mean_ego_speed_max": 48.324999999999996, "distance_travelled_mean": 101.05721999999997, "distance_travelled_min": 32.359249999999996, "distance_travelled_max": 124.91999999999999}, "hist_stats": {"episode_reward": [151.19128137626552, -611.3668217622336, 139.7207425292993, -161.30700274105604, 51.042951277687386, 138.50465263208054, 467.8795800266811, -57.32323411982416, 459.7227477094076, -152.7734950894228, 98.29818019410526, -378.5511147525574, 578.2332293148935, -445.179368235548, -16.604135198253683, -210.68863002595978, -191.30026807888822, -362.37492376174924, 324.4712130248759, -360.8146118895439, -98.23514350109518, -530.6653338692701, -333.44590666639033, -511.59553627982956, 123.8537987398234, 50.44199585902122, -639.2221016594293, -286.1252663458884, -24.14591954741108, -429.40399296970844, -382.1205285231786, -417.33050068288554, -335.6076559859455, -40.69930444713047, 454.1789787521829, -61.93504792923863, -64.174093930484, -519.5563326083812, -59.000781589466854, -315.9096946005316, 350.86243883840586, -374.71827841130437, 149.19615103880395, -371.61473784827217, -150.2605567906177, -315.80850729689803, 270.43239312826233, -366.92239410704724, 321.6942666077374, -327.79423656484005, -92.15167416296005, -447.49519482425944, -994.7722385730885, -1220.1680969634779, -357.969207715302, -537.9148867395174, -1004.637099640832, -459.6633480748896, -74.66293528238354, -354.03282458992607, -677.1770709070294, -218.32565113146205, -340.59770688849073, -228.88830694554744, 85.36085712102681, -184.03626381820015, -417.90155225834997, 274.4487494070676, -157.87234715092944, -18.810758578770493, -185.2513821751021, 342.1202967960125, -149.1330458630964, -255.45077281821378, -286.86965608999805, -414.09317428905763, 277.25186712637213, -655.5275329597748, 493.89371888456753, -509.3011325557126, 234.8331253505405, -378.80340426267276, 224.2025709490485, -157.55647589307267, 278.6896113282307, -488.0043767809139, 24.626098674247366, 16.18332869347438, 50.242558556580086, -345.42465950793803, -753.237734270807, -445.25178917386665, -615.346602393577, -648.7781530718191, -257.20333273372637, -475.330929708609, -529.7217289982945, -290.79017053808553, -374.60065889309584, -476.7066366556966], "episode_lengths": [128, 109, 122, 126, 135, 115, 124, 123, 128, 112, 129, 106, 124, 111, 132, 149, 122, 104, 124, 129, 124, 122, 113, 121, 125, 132, 130, 105, 126, 119, 111, 123, 116, 124, 130, 128, 108, 111, 55, 116, 117, 101, 129, 122, 112, 119, 123, 105, 134, 126, 120, 118, 123, 99, 105, 121, 129, 118, 128, 99, 121, 126, 130, 118, 123, 110, 120, 120, 108, 128, 130, 116, 111, 121, 123, 126, 119, 128, 125, 122, 129, 109, 125, 130, 121, 119, 137, 127, 133, 105, 125, 115, 145, 117, 35, 123, 110, 107, 109, 119], "policy_AGENT-3_reward": [45.68859488440639, -185.8453373197543, 62.90991765658177, -82.8437376932688, -34.91005396269401, -31.00996858113136, 116.25411817321407, -40.324054210941185, 126.68680388068418, -53.58620923061751, 67.6687689040042, -105.2091685167213, 177.30831887125314, -140.81120730046115, -11.944365529196936, -49.41384901566077, -4.6399208172369555, -117.34902897695318, 107.27815683905933, -67.28871347840419, 10.4741343971966, -109.45713838165129, -99.6699641542903, -126.62395240871219, -30.499190508020924, -38.902935658323585, -160.01038584282992, -25.636526049491913, -35.532694741547765, -110.4545873852827, -119.05700114906777, -130.7327894555101, -74.43315221037837, -40.563852907320054, 132.11086468059892, -40.25115234525072, -30.64100530049576, -138.2842502381468, -47.344551507925914, -121.79175411262923, 96.69706791561792, -126.21727598062346, 71.6362775960047, -83.72195646994395, -58.61194053743604, -79.30049217476494, 100.54232453618476, -95.97794296226886, 102.49045385956107, -13.542664536670927, -2.8560576422166406, -135.8851285953681, -229.95385378432786, -284.77043577197554, -53.30532671640757, -125.57748759735618, -245.01357059786767, -116.81402276685994, -35.18243475540889, -32.24155896745395, -143.20155109547548, -88.018504025315, -124.06458524737128, -90.0913651259441, -20.908472421640898, -86.19331955397085, -140.6574769494448, 104.42399512815611, -40.47687740747064, -33.141702033868874, -0.5745126177145017, 63.77713216271656, -38.5275236223648, -105.07028730968293, -60.46760124775665, -22.12375979172656, 125.73958646939965, -238.2002858752645, 120.34175550840888, -118.78645584951045, 79.06099240102188, -99.83242724019962, 84.86262000333912, -26.921367860170573, 80.7178137380608, -156.7305870477727, 34.24100625731664, -37.29961562170689, -32.45399671680384, -121.83612761245125, -125.75994144799756, -92.04302848330445, -221.92915055665267, -141.37427078938632, -35.51455475698303, -58.04015861948781, -95.3140992995523, -26.316362671420634, -92.32503629927284, -118.50937643725405], "policy_AGENT-0_reward": [7.8952528137063, -96.13129524579507, 26.17900662198516, -21.516384831393125, 39.786005424469145, 111.45531004746046, 119.00850899204173, -11.70536409923416, 112.00896130423807, -33.590137167181204, -18.110715436118245, -61.77818829878689, 133.2745210420796, -96.163982050499, -5.123907851347826, -58.996618800080256, -80.09975636572678, -63.32024278206754, 87.72768651277582, -112.9277253789547, -83.2953649813143, -154.92229330905985, -67.87153897635096, -125.76566158388901, 70.71603238652914, 42.99299805178164, -137.28140909234514, -94.94740457166736, 0.2242866719438723, -104.99828334013478, -72.81365431213598, -101.92076903773591, -117.78423439028603, 18.449792170855922, 108.21375655274367, -12.927734579102399, 20.352274875724216, -99.89065295612298, 17.84906210954653, -41.00620237772043, 68.36748851552252, -61.21555817261533, -21.71322054099391, -126.76742903544647, -20.78972541059049, -116.6872739277562, 57.09945558113283, -62.63237738406794, 93.33618589940667, -173.2851909540282, -32.216725297721844, -92.25676520765322, -283.56015861325284, -311.5248238697098, -102.19943781515856, -168.5097460107498, -279.6317147334584, -145.57715062850184, -24.487308557618793, -120.3057117571596, -217.91195512805822, -43.49774029021502, -68.54965469849546, -35.08651502803875, 6.161792165978767, 13.911007102796102, -74.09433474535159, 57.32269945965893, -40.25918251585041, 16.410158181629193, -93.77553621602422, 107.62172199568953, -38.72160232346032, -28.22753390043435, -104.71574569160691, -207.65947762768565, 36.27981794064004, -70.64171817812135, 125.83223182003816, -160.42413928568698, 37.81811082328897, -67.64869493671081, 0.663937283745625, -72.86001953518871, 37.42239927662148, -90.20646391809211, -42.701654634235034, 23.435214153626404, 35.7243068143569, -63.21474014134379, -270.1777449383064, -134.20738237857816, -106.02715238693365, -206.38324556862005, -93.04411837006174, -99.21916789885718, -145.68425809321013, -96.5324853640823, -96.31941011606352, -118.40063028447341], "policy_AGENT-1_reward": [51.78503256506283, -96.13267662515693, 26.278347839190598, 25.793148761548604, 81.20146921082026, 89.0502687408853, 119.66987690873088, 34.96399494280033, 113.67313062067596, -31.447357338449116, 25.513824542815023, -61.95494560197738, 137.0175826522555, -111.47528622358352, -3.09306389726726, -52.81678432728152, -101.87375890387952, -63.40488477262697, 68.3525661396289, -111.71584122101741, -35.99851123237548, -155.05334824897946, -97.48473687499161, -125.6666463114748, 114.23108256942021, 85.26882233330915, -159.44511944627507, -94.98813259116018, 46.71061454671639, -103.95252504244154, -116.87338371975592, -53.9543750895599, -72.011665447062, 21.84772495888756, 108.59137034886572, 31.371330182994317, 20.298413662292997, -99.73317294392147, 17.887660089812112, -111.5589451298749, 118.10304171034248, -61.190910807780924, 74.1509509585938, -77.21671867610328, -49.518046127502906, -59.62609220942208, 57.20131451006893, -62.78071680861838, 67.46035433909859, -127.39165160647592, -54.490129546030595, -126.54145510943172, -237.14611165365696, -311.7837237647874, -102.18113716278714, -121.90930271823366, -234.26557846335504, -98.48445095899483, 20.10465727069438, -120.46617993172083, -142.6378363952779, 1.2596273494164807, -24.208565519894687, -68.19402071190746, 51.91549556169966, 13.99956365426818, -128.502166565061, 57.42693244747788, -36.32738321224942, -17.93624217035427, -45.10053840247708, 86.0702203935738, -32.60279465464567, -93.37207603570228, -55.9361625882135, -162.29972641816923, 35.86294833865161, -70.63767231446883, 127.49182734160335, -113.02163861681335, 43.10691464250353, -67.63130886655895, 93.28521053897485, -25.871783685873616, 80.48914178141695, -150.29286655113984, 33.103846838471256, 67.29518941536446, 79.22417722724452, -96.61157436602365, -125.19690335960837, -84.22181994583994, -65.505485124783, -140.8109358110629, -93.17710661377896, -158.79627465769713, -142.4824620352846, -96.4776867998045, -89.07683732961458, -118.29942350563174], "policy_AGENT-2_reward": [45.82240111308973, -233.2575125715274, 24.353470411541913, -82.74002897794286, -35.034469394908, -30.99095757513385, 112.94707595269446, -40.257810752449174, 107.35385190380956, -34.14979135317496, 23.226302183404684, -149.6088123350718, 130.63280674930448, -96.72889266100412, 3.557202079558394, -49.46137788293729, -4.686831992044908, -118.30076723010148, 61.112803533412084, -68.88233181116753, 10.58459831539794, -111.23255392957972, -68.41966666075702, -133.53927597575358, -30.59412570810509, -38.91688886774585, -182.48518727797938, -70.55320313356906, -35.54812602452351, -109.99859720184898, -73.376489342219, -130.72256710007963, -71.37860393821971, -40.43296866955368, 105.2629871699738, -40.12749118788, -74.1837771680054, -181.6482564701899, -47.39295228089953, -41.552792980307075, 67.69484069692297, -126.09453345028504, 25.12214302519908, -83.90863366677844, -21.34084471508828, -60.19464898495487, 55.5892985008761, -145.53135695209212, 58.40727250967075, -13.574729467665026, -2.5887616769909556, -92.8118459118063, -244.1121145218506, -312.08911355700485, -100.28330602094921, -121.91835041317759, -245.7262358461507, -98.7877237205331, -35.09784924005028, -81.01937393359191, -173.42572828821713, -88.06903416534894, -123.77490142272941, -35.516406079657244, 48.19204181498942, -125.75351502129351, -74.64757399849229, 55.275122371775225, -40.808904015358856, 15.857027443823256, -45.800794938886305, 84.6512222440326, -39.28112526262531, -28.780875572394244, -65.75014656242098, -22.01021045147617, 79.36951437768067, -276.0478565919196, 120.22790421451673, -117.06889880370161, 74.84710748372599, -143.69097321920322, 45.39080312298883, -31.9033048118399, 80.06025653213139, -90.77445926390928, -0.01709978730555406, -37.24745925380968, -32.25192876821751, -63.76221738811958, -232.10314452489524, -134.77955836614427, -221.884814325208, -160.20970090275003, -35.4675529929026, -159.27532853256702, -146.2409095702474, -71.46363570277819, -96.8793751481451, -121.49720642833745]}, "sampler_perf": {"mean_env_wait_ms": 55.40699188100774, "mean_raw_obs_processing_ms": 2.376403156673027, "mean_inference_ms": 2.4778671526157856, "mean_action_processing_ms": 0.1445937114419852}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 58800, "timers": {"sample_time_ms": 93342.995, "sample_throughput": 44.995, "load_time_ms": 15.111, "load_throughput": 277945.096, "learn_time_ms": 8869.318, "learn_throughput": 473.543, "update_time_ms": 8.07}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 12.423384666442871, "policy_loss": -0.03917969390749931, "vf_loss": 12.455224990844727, "vf_explained_var": 0.9547086954116821, "kl": 0.016305768862366676, "entropy": 1.273970603942871, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 16.16478157043457, "policy_loss": -0.026209058240056038, "vf_loss": 16.186094284057617, "vf_explained_var": 0.9284208416938782, "kl": 0.016317440196871758, "entropy": 1.1944321393966675, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 11.538850784301758, "policy_loss": -0.023407328873872757, "vf_loss": 11.553436279296875, "vf_explained_var": 0.9354878067970276, "kl": 0.019604885950684547, "entropy": 1.2105144262313843, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 14.273521423339844, "policy_loss": -0.030589425936341286, "vf_loss": 14.299287796020508, "vf_explained_var": 0.9270814657211304, "kl": 0.016073819249868393, "entropy": 1.2152827978134155, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 58800, "num_steps_trained": 58800}, "done": false, "episodes_total": 494, "training_iteration": 14, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-40-31", "timestamp": 1624210831, "time_this_iter_s": 99.27448320388794, "time_total_s": 1421.6794040203094, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd4043925f0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd4042b8e60>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042b8b00>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042b88c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd290>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042b8b00>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042b88c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd290>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042b8b00>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042b88c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd290>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042b8b00>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042b88c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd290>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd417ac28c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1421.6794040203094, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 57.20352112676057, "ram_util_percent": 87.50915492957749}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1072.383857173517, "episode_reward_min": -841.4074565457873, "episode_reward_mean": -179.60612050428045, "episode_len_mean": 120.07, "episodes_this_iter": 36, "policy_reward_min": {"AGENT-3": -238.2002858752645, "AGENT-0": -270.1777449383064, "AGENT-2": -276.0478565919196, "AGENT-1": -221.65961014071408}, "policy_reward_max": {"AGENT-3": 230.83882945908778, "AGENT-0": 287.3602419595356, "AGENT-2": 286.79670467655325, "AGENT-1": 267.38808107833955}, "policy_reward_mean": {"AGENT-3": -44.80555176343014, "AGENT-0": -48.375660589784154, "AGENT-2": -51.55001702518602, "AGENT-1": -34.87489112588018}, "custom_metrics": {"mean_ego_speed_mean": 41.7155125, "mean_ego_speed_min": 29.764, "mean_ego_speed_max": 48.2475, "distance_travelled_mean": 102.2641825, "distance_travelled_min": 32.359249999999996, "distance_travelled_max": 124.90125}, "hist_stats": {"episode_reward": [-178.11522175286132, 529.3197116168005, -556.4352977574567, -368.9857691429408, -486.2451925820142, 573.4703861222, -198.1032606916918, 498.03859209966737, -456.5125785842236, -21.95580681628731, -58.1680885270057, 53.26906035779421, 620.6802075046604, -609.2574402322847, 1072.383857173517, -521.1758427914872, -244.10877004965636, 57.670346191557634, -401.7538716425986, 8.640160234260968, -570.7811645048905, -446.34519830867015, -413.6756956193106, 402.08190123653935, -619.0139531394782, -672.0692328527496, -608.0865415694785, -538.00591013653, -27.20244450966086, -312.517402803629, -430.69350789761944, -375.67140269954575, -138.98804150328513, -188.81014141480324, -841.4074565457873, -370.1089880343426, -18.810758578770493, -185.2513821751021, 342.1202967960125, -149.1330458630964, -255.45077281821378, -286.86965608999805, -414.09317428905763, 277.25186712637213, -655.5275329597748, 493.89371888456753, -509.3011325557126, 234.8331253505405, -378.80340426267276, 224.2025709490485, -157.55647589307267, 278.6896113282307, -488.0043767809139, 24.626098674247366, 16.18332869347438, 50.242558556580086, -345.42465950793803, -753.237734270807, -445.25178917386665, -615.346602393577, -648.7781530718191, -257.20333273372637, -475.330929708609, -529.7217289982945, -290.79017053808553, -374.60065889309584, -476.7066366556966, 151.19128137626552, -611.3668217622336, 139.7207425292993, -161.30700274105604, 51.042951277687386, 138.50465263208054, 467.8795800266811, -57.32323411982416, 459.7227477094076, -152.7734950894228, 98.29818019410526, -378.5511147525574, 578.2332293148935, -445.179368235548, -16.604135198253683, -210.68863002595978, -191.30026807888822, -362.37492376174924, 324.4712130248759, -360.8146118895439, -98.23514350109518, -530.6653338692701, -333.44590666639033, -511.59553627982956, 123.8537987398234, 50.44199585902122, -639.2221016594293, -286.1252663458884, -24.14591954741108, -429.40399296970844, -382.1205285231786, -417.33050068288554, -335.6076559859455], "episode_lengths": [116, 128, 125, 132, 115, 130, 123, 124, 104, 104, 124, 106, 113, 107, 165, 105, 129, 123, 92, 123, 128, 139, 106, 126, 119, 110, 105, 120, 117, 118, 127, 100, 138, 124, 119, 115, 128, 130, 116, 111, 121, 123, 126, 119, 128, 125, 122, 129, 109, 125, 130, 121, 119, 137, 127, 133, 105, 125, 115, 145, 117, 35, 123, 110, 107, 109, 119, 128, 109, 122, 126, 135, 115, 124, 123, 128, 112, 129, 106, 124, 111, 132, 149, 122, 104, 124, 129, 124, 122, 113, 121, 125, 132, 130, 105, 126, 119, 111, 123, 116], "policy_AGENT-3_reward": [-48.48526966417502, 150.98423608865122, -130.76003118962956, -20.839428342685814, -96.76642533776072, 148.53645126295766, -19.52492985539795, 121.34706470020103, -128.61713034122985, -10.201420287769931, -45.665267468101646, 14.578913616473047, 178.55661842068656, -174.5396459049695, 230.83882945908778, -79.45361172025706, -63.67614199598524, -32.156627796136526, -136.73086683503652, -34.00426289859125, -235.4421967893147, -34.465371611143425, -119.76616071092202, 152.67158264697878, -133.07046758354622, -167.0721070919861, -131.77576068698636, -124.41525188845564, -29.868256203979488, -101.24465005039605, -119.51350423576781, -74.4164223156514, -52.33468288086573, -51.00641745207956, -176.72100069369682, -123.26712046574046, -33.141702033868874, -0.5745126177145017, 63.77713216271656, -38.5275236223648, -105.07028730968293, -60.46760124775665, -22.12375979172656, 125.73958646939965, -238.2002858752645, 120.34175550840888, -118.78645584951045, 79.06099240102188, -99.83242724019962, 84.86262000333912, -26.921367860170573, 80.7178137380608, -156.7305870477727, 34.24100625731664, -37.29961562170689, -32.45399671680384, -121.83612761245125, -125.75994144799756, -92.04302848330445, -221.92915055665267, -141.37427078938632, -35.51455475698303, -58.04015861948781, -95.3140992995523, -26.316362671420634, -92.32503629927284, -118.50937643725405, 45.68859488440639, -185.8453373197543, 62.90991765658177, -82.8437376932688, -34.91005396269401, -31.00996858113136, 116.25411817321407, -40.324054210941185, 126.68680388068418, -53.58620923061751, 67.6687689040042, -105.2091685167213, 177.30831887125314, -140.81120730046115, -11.944365529196936, -49.41384901566077, -4.6399208172369555, -117.34902897695318, 107.27815683905933, -67.28871347840419, 10.4741343971966, -109.45713838165129, -99.6699641542903, -126.62395240871219, -30.499190508020924, -38.902935658323585, -160.01038584282992, -25.636526049491913, -35.532694741547765, -110.4545873852827, -119.05700114906777, -130.7327894555101, -74.43315221037837], "policy_AGENT-0_reward": [-55.26806549466981, 128.80089783710736, -169.32816904204174, -169.57265291771247, -146.02538800778018, 143.45485741257008, -105.6259482129487, 126.411263214922, -98.99646944310504, 21.4756032100186, -5.469378722235696, 34.970884245533384, 131.67825645434584, -130.28519070152043, 287.3602419595356, -131.1611204525624, -63.19395406690401, 38.9942023447035, -64.14021881966517, 15.247511593920812, -56.94639595254728, -193.47228346298152, -65.56816986082016, 69.22050268114157, -193.70890414365118, -167.10687562525476, -147.9932349202626, -168.65870737747863, -6.9073018514677855, -59.48975789780188, -119.76656484898673, -124.33204762170982, -39.92924397890859, -65.9711417432638, -267.0971267688469, -63.784582465853326, 16.410158181629193, -93.77553621602422, 107.62172199568953, -38.72160232346032, -28.22753390043435, -104.71574569160691, -207.65947762768565, 36.27981794064004, -70.64171817812135, 125.83223182003816, -160.42413928568698, 37.81811082328897, -67.64869493671081, 0.663937283745625, -72.86001953518871, 37.42239927662148, -90.20646391809211, -42.701654634235034, 23.435214153626404, 35.7243068143569, -63.21474014134379, -270.1777449383064, -134.20738237857816, -106.02715238693365, -206.38324556862005, -93.04411837006174, -99.21916789885718, -145.68425809321013, -96.5324853640823, -96.31941011606352, -118.40063028447341, 7.8952528137063, -96.13129524579507, 26.17900662198516, -21.516384831393125, 39.786005424469145, 111.45531004746046, 119.00850899204173, -11.70536409923416, 112.00896130423807, -33.590137167181204, -18.110715436118245, -61.77818829878689, 133.2745210420796, -96.163982050499, -5.123907851347826, -58.996618800080256, -80.09975636572678, -63.32024278206754, 87.72768651277582, -112.9277253789547, -83.2953649813143, -154.92229330905985, -67.87153897635096, -125.76566158388901, 70.71603238652914, 42.99299805178164, -137.28140909234514, -94.94740457166736, 0.2242866719438723, -104.99828334013478, -72.81365431213598, -101.92076903773591, -117.78423439028603], "policy_AGENT-2_reward": [-38.38563823125534, 119.72109581568188, -126.15107612495206, -20.721003924864586, -146.77844290101274, 136.0161845012815, -59.544574548501515, 121.47268266642124, -129.92917068967196, -54.68754540209681, -45.52449417216028, -30.96885544402097, 178.9351522591303, -174.20787651867988, 286.79670467655325, -179.45261187946676, -63.76082977515346, -32.17389150433533, -136.78413380416748, -33.92277849756639, -57.37740622151156, -34.51714074932687, -162.90433816107634, 111.11355540741133, -146.76171261120533, -170.72901812803747, -180.00828795584218, -123.28570400202955, -29.919560471759183, -60.0468085785883, -119.48083790809608, -52.322404433154006, -52.38118936139303, -51.00315887069364, -175.92971894252875, -64.3377688253988, 15.857027443823256, -45.800794938886305, 84.6512222440326, -39.28112526262531, -28.780875572394244, -65.75014656242098, -22.01021045147617, 79.36951437768067, -276.0478565919196, 120.22790421451673, -117.06889880370161, 74.84710748372599, -143.69097321920322, 45.39080312298883, -31.9033048118399, 80.06025653213139, -90.77445926390928, -0.01709978730555406, -37.24745925380968, -32.25192876821751, -63.76221738811958, -232.10314452489524, -134.77955836614427, -221.884814325208, -160.20970090275003, -35.4675529929026, -159.27532853256702, -146.2409095702474, -71.46363570277819, -96.8793751481451, -121.49720642833745, 45.82240111308973, -233.2575125715274, 24.353470411541913, -82.74002897794286, -35.034469394908, -30.99095757513385, 112.94707595269446, -40.257810752449174, 107.35385190380956, -34.14979135317496, 23.226302183404684, -149.6088123350718, 130.63280674930448, -96.72889266100412, 3.557202079558394, -49.46137788293729, -4.686831992044908, -118.30076723010148, 61.112803533412084, -68.88233181116753, 10.58459831539794, -111.23255392957972, -68.41966666075702, -133.53927597575358, -30.59412570810509, -38.91688886774585, -182.48518727797938, -70.55320313356906, -35.54812602452351, -109.99859720184898, -73.376489342219, -130.72256710007963, -71.37860393821971], "policy_AGENT-1_reward": [-35.97624836276097, 129.81348187535983, -130.1960214008334, -157.8526839576779, -96.67493633546049, 145.46289294539082, -13.407808074843492, 128.80758151812262, -98.96980811021655, 21.45755566356078, 38.49105183549186, 34.68811793980868, 131.51018037049795, -130.22472710711477, 267.38808107833955, -131.10849873920085, -53.477844211613615, 83.00666314732595, -64.09865218372941, 61.31969003649781, -221.0151655415171, -183.89040248521803, -65.43702688649218, 69.07626050100745, -145.47286880107546, -167.16123200747126, -148.30925800638764, -121.64624686856577, 39.49267401754563, -91.73618627684279, -71.93260090476926, -124.60052832903065, 5.657074717882064, -20.829423348766163, -221.65961014071408, -118.71951627734968, -17.93624217035427, -45.10053840247708, 86.0702203935738, -32.60279465464567, -93.37207603570228, -55.9361625882135, -162.29972641816923, 35.86294833865161, -70.63767231446883, 127.49182734160335, -113.02163861681335, 43.10691464250353, -67.63130886655895, 93.28521053897485, -25.871783685873616, 80.48914178141695, -150.29286655113984, 33.103846838471256, 67.29518941536446, 79.22417722724452, -96.61157436602365, -125.19690335960837, -84.22181994583994, -65.505485124783, -140.8109358110629, -93.17710661377896, -158.79627465769713, -142.4824620352846, -96.4776867998045, -89.07683732961458, -118.29942350563174, 51.78503256506283, -96.13267662515693, 26.278347839190598, 25.793148761548604, 81.20146921082026, 89.0502687408853, 119.66987690873088, 34.96399494280033, 113.67313062067596, -31.447357338449116, 25.513824542815023, -61.95494560197738, 137.0175826522555, -111.47528622358352, -3.09306389726726, -52.81678432728152, -101.87375890387952, -63.40488477262697, 68.3525661396289, -111.71584122101741, -35.99851123237548, -155.05334824897946, -97.48473687499161, -125.6666463114748, 114.23108256942021, 85.26882233330915, -159.44511944627507, -94.98813259116018, 46.71061454671639, -103.95252504244154, -116.87338371975592, -53.9543750895599, -72.011665447062]}, "sampler_perf": {"mean_env_wait_ms": 55.385938749967444, "mean_raw_obs_processing_ms": 2.3756036551239963, "mean_inference_ms": 2.4682284634866454, "mean_action_processing_ms": 0.14462547544709362}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 63000, "timers": {"sample_time_ms": 92908.902, "sample_throughput": 45.206, "load_time_ms": 15.168, "load_throughput": 276894.395, "learn_time_ms": 8928.51, "learn_throughput": 470.403, "update_time_ms": 7.825}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 18.231847763061523, "policy_loss": -0.029784755781292915, "vf_loss": 18.255367279052734, "vf_explained_var": 0.9425365328788757, "kl": 0.0139198899269104, "entropy": 1.2774348258972168, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 15.371068000793457, "policy_loss": -0.0202732365578413, "vf_loss": 15.385453224182129, "vf_explained_var": 0.9377328157424927, "kl": 0.019623201340436935, "entropy": 1.1775435209274292, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 16.89238739013672, "policy_loss": -0.03236180916428566, "vf_loss": 16.917638778686523, "vf_explained_var": 0.9231042861938477, "kl": 0.015795117244124413, "entropy": 1.2154844999313354, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 18.907533645629883, "policy_loss": -0.025584304705262184, "vf_loss": 18.927490234375, "vf_explained_var": 0.9232606887817383, "kl": 0.01876051351428032, "entropy": 1.2069815397262573, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 63000, "num_steps_trained": 63000}, "done": false, "episodes_total": 530, "training_iteration": 15, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-42-07", "timestamp": 1624210927, "time_this_iter_s": 95.97104239463806, "time_total_s": 1517.6504464149475, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40445a4d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40449bb90>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449b0e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449bd40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042b89e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd4d0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449b0e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449bd40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042b89e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd4d0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449b0e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449bd40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042b89e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd4d0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449b0e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449bd40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042b89e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd4d0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd4042bd5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1517.6504464149475, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 55.88613138686131, "ram_util_percent": 87.60656934306571}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1072.383857173517, "episode_reward_min": -841.4074565457873, "episode_reward_mean": -151.76105072889675, "episode_len_mean": 119.5, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-3": -235.4421967893147, "AGENT-0": -267.0971267688469, "AGENT-2": -182.48518727797938, "AGENT-1": -221.65961014071408}, "policy_reward_max": {"AGENT-3": 230.83882945908778, "AGENT-0": 287.3602419595356, "AGENT-2": 286.79670467655325, "AGENT-1": 267.38808107833955}, "policy_reward_mean": {"AGENT-3": -38.114554361745014, "AGENT-0": -43.81062376722729, "AGENT-2": -40.55757159067825, "AGENT-1": -29.278301009246164}, "custom_metrics": {"mean_ego_speed_mean": 41.96623749999999, "mean_ego_speed_min": 32.87625, "mean_ego_speed_max": 48.2475, "distance_travelled_mean": 102.39179250000001, "distance_travelled_min": 64.63675, "distance_travelled_max": 124.90125}, "hist_stats": {"episode_reward": [-356.41359467316846, 82.80357187149528, 334.12891350265744, -390.6731076413101, 373.09191205266706, -569.2343925209378, 920.2878117797418, -275.7077653127199, 290.7022227066997, 12.087626531041394, 402.9124271511304, -124.50577332522298, 100.70318956711543, -108.76943694924785, 463.2893651178174, -308.155533876387, 234.7132462848188, -392.1175563494957, -98.84874661563364, -360.572480607109, 599.6907489286054, -206.59460809561023, -403.3514180430892, -647.530653287979, -733.1078090315496, -23.717428190109317, -412.43748800394286, -605.3043666742793, -59.694684436378274, 41.7321560681127, -506.07333213243606, -445.77881974864533, 0.3327552333703636, -640.2184697510938, -654.074236441106, 51.042951277687386, 138.50465263208054, 467.8795800266811, -57.32323411982416, 459.7227477094076, -152.7734950894228, 98.29818019410526, -378.5511147525574, 578.2332293148935, -445.179368235548, -16.604135198253683, -210.68863002595978, -191.30026807888822, -362.37492376174924, 324.4712130248759, -360.8146118895439, -98.23514350109518, -530.6653338692701, -333.44590666639033, -511.59553627982956, 123.8537987398234, 50.44199585902122, -639.2221016594293, -286.1252663458884, -24.14591954741108, -429.40399296970844, -382.1205285231786, -417.33050068288554, -335.6076559859455, -178.11522175286132, 529.3197116168005, -556.4352977574567, -368.9857691429408, -486.2451925820142, 573.4703861222, -198.1032606916918, 498.03859209966737, -456.5125785842236, -21.95580681628731, -58.1680885270057, 53.26906035779421, 620.6802075046604, -609.2574402322847, 1072.383857173517, -521.1758427914872, -244.10877004965636, 57.670346191557634, -401.7538716425986, 8.640160234260968, -570.7811645048905, -446.34519830867015, -413.6756956193106, 402.08190123653935, -619.0139531394782, -672.0692328527496, -608.0865415694785, -538.00591013653, -27.20244450966086, -312.517402803629, -430.69350789761944, -375.67140269954575, -138.98804150328513, -188.81014141480324, -841.4074565457873, -370.1089880343426], "episode_lengths": [120, 60, 122, 120, 122, 118, 151, 116, 129, 132, 127, 92, 121, 113, 132, 116, 127, 103, 77, 119, 138, 118, 115, 125, 124, 126, 99, 117, 123, 128, 116, 110, 129, 115, 117, 135, 115, 124, 123, 128, 112, 129, 106, 124, 111, 132, 149, 122, 104, 124, 129, 124, 122, 113, 121, 125, 132, 130, 105, 126, 119, 111, 123, 116, 116, 128, 125, 132, 115, 130, 123, 124, 104, 104, 124, 106, 113, 107, 165, 105, 129, 123, 92, 123, 128, 139, 106, 126, 119, 110, 105, 120, 117, 118, 127, 100, 138, 124, 119, 115], "policy_AGENT-3_reward": [-115.28271284677803, 20.839800585523278, 79.06624230914406, -60.95544281744287, 124.52111853328645, -106.44655828560667, 228.5821195180571, -58.26385986608131, 83.53185705700955, -31.03243567375964, 139.7883158860968, -8.347069046556408, 33.83406563343878, -14.45061527074504, 123.20483431672304, -54.79942407018978, 105.38117115741032, -109.30060338861755, 2.9143844476679135, -115.0441849094788, 153.25121601093173, -45.38488065657943, -37.01552028650951, -153.61790230121773, -183.77119924404354, -37.136701604968316, -97.01223050456382, -174.89660492275493, -48.813144565532504, -44.31368082486888, -133.48628753727675, -111.12146530520087, -36.40072678259544, -167.35524972669285, -152.00877058879365, -34.91005396269401, -31.00996858113136, 116.25411817321407, -40.324054210941185, 126.68680388068418, -53.58620923061751, 67.6687689040042, -105.2091685167213, 177.30831887125314, -140.81120730046115, -11.944365529196936, -49.41384901566077, -4.6399208172369555, -117.34902897695318, 107.27815683905933, -67.28871347840419, 10.4741343971966, -109.45713838165129, -99.6699641542903, -126.62395240871219, -30.499190508020924, -38.902935658323585, -160.01038584282992, -25.636526049491913, -35.532694741547765, -110.4545873852827, -119.05700114906777, -130.7327894555101, -74.43315221037837, -48.48526966417502, 150.98423608865122, -130.76003118962956, -20.839428342685814, -96.76642533776072, 148.53645126295766, -19.52492985539795, 121.34706470020103, -128.61713034122985, -10.201420287769931, -45.665267468101646, 14.578913616473047, 178.55661842068656, -174.5396459049695, 230.83882945908778, -79.45361172025706, -63.67614199598524, -32.156627796136526, -136.73086683503652, -34.00426289859125, -235.4421967893147, -34.465371611143425, -119.76616071092202, 152.67158264697878, -133.07046758354622, -167.0721070919861, -131.77576068698636, -124.41525188845564, -29.868256203979488, -101.24465005039605, -119.51350423576781, -74.4164223156514, -52.33468288086573, -51.00641745207956, -176.72100069369682, -123.26712046574046], "policy_AGENT-0_reward": [-68.53869304701983, 20.59685598353903, 87.10668523654611, -158.05499210717235, 84.01766839555063, -197.16957713936733, 215.44404754959234, -104.9058449560456, 59.6692217715802, 14.516514158417749, 59.293119176796985, -53.86956509195261, -8.539774923771688, -60.614008636356346, 106.07634025070865, -99.93994605652645, 27.875923499063724, -62.70859612637326, -52.32386067712124, -157.4075255339524, 145.07445855087954, -82.70072494004087, -186.55231881277345, -192.64109528719945, -207.9016996255158, 0.863900595867733, -108.86805754140178, -107.88017808891522, -4.510402756190068, 42.13672866851984, -123.90359676982469, -111.7695580136699, 14.920888150425306, -142.02737287961963, -197.41972486062798, 39.786005424469145, 111.45531004746046, 119.00850899204173, -11.70536409923416, 112.00896130423807, -33.590137167181204, -18.110715436118245, -61.77818829878689, 133.2745210420796, -96.163982050499, -5.123907851347826, -58.996618800080256, -80.09975636572678, -63.32024278206754, 87.72768651277582, -112.9277253789547, -83.2953649813143, -154.92229330905985, -67.87153897635096, -125.76566158388901, 70.71603238652914, 42.99299805178164, -137.28140909234514, -94.94740457166736, 0.2242866719438723, -104.99828334013478, -72.81365431213598, -101.92076903773591, -117.78423439028603, -55.26806549466981, 128.80089783710736, -169.32816904204174, -169.57265291771247, -146.02538800778018, 143.45485741257008, -105.6259482129487, 126.411263214922, -98.99646944310504, 21.4756032100186, -5.469378722235696, 34.970884245533384, 131.67825645434584, -130.28519070152043, 287.3602419595356, -131.1611204525624, -63.19395406690401, 38.9942023447035, -64.14021881966517, 15.247511593920812, -56.94639595254728, -193.47228346298152, -65.56816986082016, 69.22050268114157, -193.70890414365118, -167.10687562525476, -147.9932349202626, -168.65870737747863, -6.9073018514677855, -59.48975789780188, -119.76656484898673, -124.33204762170982, -39.92924397890859, -65.9711417432638, -267.0971267688469, -63.784582465853326], "policy_AGENT-2_reward": [-69.09592429511048, 20.874954298933027, 79.15739829238821, -111.02017322343508, 79.85700792449913, -114.52139363549453, 246.49477965431907, -56.19043325020297, 83.51856424102502, -31.025816291788537, 96.29541956489757, -8.39060022438492, 37.390267541737785, -17.147946321941266, 123.16348457765869, -53.94411696214009, 68.60771840317167, -157.3899321670615, 3.0985679377609685, -44.28191140487762, 153.5469044836564, -45.25983466068087, -36.8104839719814, -154.25737244855407, -179.45797281714968, -37.174199716248054, -97.6703284759815, -108.42869168223464, -48.86524506658616, -44.26303914324232, -126.10561807384192, -111.23340564971048, -36.37289662704145, -167.27030469571727, -156.18929443960653, -35.034469394908, -30.99095757513385, 112.94707595269446, -40.257810752449174, 107.35385190380956, -34.14979135317496, 23.226302183404684, -149.6088123350718, 130.63280674930448, -96.72889266100412, 3.557202079558394, -49.46137788293729, -4.686831992044908, -118.30076723010148, 61.112803533412084, -68.88233181116753, 10.58459831539794, -111.23255392957972, -68.41966666075702, -133.53927597575358, -30.59412570810509, -38.91688886774585, -182.48518727797938, -70.55320313356906, -35.54812602452351, -109.99859720184898, -73.376489342219, -130.72256710007963, -71.37860393821971, -38.38563823125534, 119.72109581568188, -126.15107612495206, -20.721003924864586, -146.77844290101274, 136.0161845012815, -59.544574548501515, 121.47268266642124, -129.92917068967196, -54.68754540209681, -45.52449417216028, -30.96885544402097, 178.9351522591303, -174.20787651867988, 286.79670467655325, -179.45261187946676, -63.76082977515346, -32.17389150433533, -136.78413380416748, -33.92277849756639, -57.37740622151156, -34.51714074932687, -162.90433816107634, 111.11355540741133, -146.76171261120533, -170.72901812803747, -180.00828795584218, -123.28570400202955, -29.919560471759183, -60.0468085785883, -119.48083790809608, -52.322404433154006, -52.38118936139303, -51.00315887069364, -175.92971894252875, -64.3377688253988], "policy_AGENT-1_reward": [-103.49626448426027, 20.49196100349981, 88.79858766457893, -60.64249949325989, 84.69611719933147, -151.0968634604689, 229.76686505777346, -56.34762724038975, 63.98257963708485, 59.62936433817196, 107.53557252333901, -53.89853896232904, 38.01863131571072, -16.556866720205182, 110.84470597272689, -99.47204678753059, 32.848433225172776, -62.718424667443344, -52.53783832394116, -43.83885875880017, 147.81816988313727, -33.24916783830902, -142.97309497182476, -147.01428325100773, -161.97693734483946, 49.729572535239356, -108.88687148199608, -214.0988919803749, 42.494107951930516, 88.17214736770404, -122.57782975149217, -111.65439078006429, 58.18549049258203, -163.56554244906428, -148.45644655207752, 81.20146921082026, 89.0502687408853, 119.66987690873088, 34.96399494280033, 113.67313062067596, -31.447357338449116, 25.513824542815023, -61.95494560197738, 137.0175826522555, -111.47528622358352, -3.09306389726726, -52.81678432728152, -101.87375890387952, -63.40488477262697, 68.3525661396289, -111.71584122101741, -35.99851123237548, -155.05334824897946, -97.48473687499161, -125.6666463114748, 114.23108256942021, 85.26882233330915, -159.44511944627507, -94.98813259116018, 46.71061454671639, -103.95252504244154, -116.87338371975592, -53.9543750895599, -72.011665447062, -35.97624836276097, 129.81348187535983, -130.1960214008334, -157.8526839576779, -96.67493633546049, 145.46289294539082, -13.407808074843492, 128.80758151812262, -98.96980811021655, 21.45755566356078, 38.49105183549186, 34.68811793980868, 131.51018037049795, -130.22472710711477, 267.38808107833955, -131.10849873920085, -53.477844211613615, 83.00666314732595, -64.09865218372941, 61.31969003649781, -221.0151655415171, -183.89040248521803, -65.43702688649218, 69.07626050100745, -145.47286880107546, -167.16123200747126, -148.30925800638764, -121.64624686856577, 39.49267401754563, -91.73618627684279, -71.93260090476926, -124.60052832903065, 5.657074717882064, -20.829423348766163, -221.65961014071408, -118.71951627734968]}, "sampler_perf": {"mean_env_wait_ms": 55.22937824232047, "mean_raw_obs_processing_ms": 2.3705598148723697, "mean_inference_ms": 2.4559878374747424, "mean_action_processing_ms": 0.14437712737321462}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 67200, "timers": {"sample_time_ms": 93133.228, "sample_throughput": 45.097, "load_time_ms": 15.639, "load_throughput": 268566.824, "learn_time_ms": 8995.422, "learn_throughput": 466.904, "update_time_ms": 8.156}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 14.642282485961914, "policy_loss": -0.025838667526841164, "vf_loss": 14.660074234008789, "vf_explained_var": 0.9535170197486877, "kl": 0.017878571525216103, "entropy": 1.2547837495803833, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 15.10922908782959, "policy_loss": -0.025577273219823837, "vf_loss": 15.12889575958252, "vf_explained_var": 0.9407707452774048, "kl": 0.019706401973962784, "entropy": 1.1726762056350708, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 16.84031105041504, "policy_loss": -0.030942190438508987, "vf_loss": 16.864206314086914, "vf_explained_var": 0.9212578535079956, "kl": 0.015663743019104004, "entropy": 1.2111958265304565, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 15.417820930480957, "policy_loss": -0.024258408695459366, "vf_loss": 15.436871528625488, "vf_explained_var": 0.9464923739433289, "kl": 0.017352063208818436, "entropy": 1.210549235343933, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 67200, "num_steps_trained": 67200}, "done": false, "episodes_total": 565, "training_iteration": 16, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-43-48", "timestamp": 1624211028, "time_this_iter_s": 101.25044512748718, "time_total_s": 1618.9008915424347, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd4042bd950>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd4042bd830>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd0e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd200>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd404254200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404254320>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd0e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd200>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd404254200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404254320>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd0e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd200>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd404254200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404254320>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd0e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd200>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd404254200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404254320>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd4043e88c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1618.9008915424347, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 56.0551724137931, "ram_util_percent": 87.21793103448277}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1072.383857173517, "episode_reward_min": -848.0118187134354, "episode_reward_mean": -166.65339768647493, "episode_len_mean": 117.49, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-3": -235.4421967893147, "AGENT-0": -267.0971267688469, "AGENT-2": -207.39635433958912, "AGENT-1": -221.65961014071408}, "policy_reward_max": {"AGENT-3": 230.83882945908778, "AGENT-0": 287.3602419595356, "AGENT-2": 286.79670467655325, "AGENT-1": 267.38808107833955}, "policy_reward_mean": {"AGENT-3": -41.63539928382501, "AGENT-0": -51.42651637148015, "AGENT-2": -40.60874237673682, "AGENT-1": -32.98273965443293}, "custom_metrics": {"mean_ego_speed_mean": 42.23018500000001, "mean_ego_speed_min": 33.6005, "mean_ego_speed_max": 47.84925, "distance_travelled_mean": 104.40391249999999, "distance_travelled_min": 40.585750000000004, "distance_travelled_max": 124.90125}, "hist_stats": {"episode_reward": [-21.00768406394105, 377.32420483718636, -238.5482200524181, 727.9775803704364, -141.4617607809754, 110.95820228070218, 35.97869028079955, 339.11733550672017, -123.91549960716748, 104.72397176500482, -219.9574308195149, -181.04332183937962, -452.07070680697285, 214.89232677699997, -209.54041427154917, 613.9216423664038, -251.9896168443982, 90.44382608906834, 73.44637425461751, 729.2411439431684, -418.50559463183174, 195.49695854945912, 32.59594670767991, 369.673927603728, -796.8059698581508, -489.39344193204903, -848.0118187134354, -539.7341512081838, -413.8081227351724, -546.1572694958874, -684.5275975154187, -597.9319423751025, -825.0405548654528, -304.23774401560746, 20.12072198741717, -572.7496206898629, -706.82443644724, -456.5125785842236, -21.95580681628731, -58.1680885270057, 53.26906035779421, 620.6802075046604, -609.2574402322847, 1072.383857173517, -521.1758427914872, -244.10877004965636, 57.670346191557634, -401.7538716425986, 8.640160234260968, -570.7811645048905, -446.34519830867015, -413.6756956193106, 402.08190123653935, -619.0139531394782, -672.0692328527496, -608.0865415694785, -538.00591013653, -27.20244450966086, -312.517402803629, -430.69350789761944, -375.67140269954575, -138.98804150328513, -188.81014141480324, -841.4074565457873, -370.1089880343426, -356.41359467316846, 82.80357187149528, 334.12891350265744, -390.6731076413101, 373.09191205266706, -569.2343925209378, 920.2878117797418, -275.7077653127199, 290.7022227066997, 12.087626531041394, 402.9124271511304, -124.50577332522298, 100.70318956711543, -108.76943694924785, 463.2893651178174, -308.155533876387, 234.7132462848188, -392.1175563494957, -98.84874661563364, -360.572480607109, 599.6907489286054, -206.59460809561023, -403.3514180430892, -647.530653287979, -733.1078090315496, -23.717428190109317, -412.43748800394286, -605.3043666742793, -59.694684436378274, 41.7321560681127, -506.07333213243606, -445.77881974864533, 0.3327552333703636, -640.2184697510938, -654.074236441106], "episode_lengths": [128, 120, 122, 147, 116, 112, 108, 119, 112, 124, 128, 126, 105, 104, 118, 126, 116, 100, 120, 124, 120, 130, 124, 119, 121, 117, 121, 34, 129, 118, 119, 123, 119, 112, 127, 101, 117, 104, 104, 124, 106, 113, 107, 165, 105, 129, 123, 92, 123, 128, 139, 106, 126, 119, 110, 105, 120, 117, 118, 127, 100, 138, 124, 119, 115, 120, 60, 122, 120, 122, 118, 151, 116, 129, 132, 127, 92, 121, 113, 132, 116, 127, 103, 77, 119, 138, 118, 115, 125, 124, 126, 99, 117, 123, 128, 116, 110, 129, 115, 117], "policy_AGENT-3_reward": [-53.46174231379853, 112.15269142074996, -50.99307062302773, 181.46255417326662, -29.961337440800225, 81.29755137900848, 5.203849966045264, 58.48527723627127, -22.171762074216453, 69.45343625299242, -83.4837091177726, -18.861381401267728, -141.93897584301482, 62.72716982259893, -38.63260880922981, 193.84574038231057, -52.32965120599739, 30.09983847627818, 28.136031103755954, 136.1425345648563, -169.55089666407142, 89.42061917805447, 6.782510259485832, 113.01520156642172, -200.57991987410145, -151.71594947477325, -191.05051146861348, -159.87121224788908, -130.3737781130188, -139.71891648716522, -159.29387824195572, -147.0091533371001, -173.7713725220162, -94.2124192098734, -30.24154880995847, -130.1673039616778, -158.25328758630917, -128.61713034122985, -10.201420287769931, -45.665267468101646, 14.578913616473047, 178.55661842068656, -174.5396459049695, 230.83882945908778, -79.45361172025706, -63.67614199598524, -32.156627796136526, -136.73086683503652, -34.00426289859125, -235.4421967893147, -34.465371611143425, -119.76616071092202, 152.67158264697878, -133.07046758354622, -167.0721070919861, -131.77576068698636, -124.41525188845564, -29.868256203979488, -101.24465005039605, -119.51350423576781, -74.4164223156514, -52.33468288086573, -51.00641745207956, -176.72100069369682, -123.26712046574046, -115.28271284677803, 20.839800585523278, 79.06624230914406, -60.95544281744287, 124.52111853328645, -106.44655828560667, 228.5821195180571, -58.26385986608131, 83.53185705700955, -31.03243567375964, 139.7883158860968, -8.347069046556408, 33.83406563343878, -14.45061527074504, 123.20483431672304, -54.79942407018978, 105.38117115741032, -109.30060338861755, 2.9143844476679135, -115.0441849094788, 153.25121601093173, -45.38488065657943, -37.01552028650951, -153.61790230121773, -183.77119924404354, -37.136701604968316, -97.01223050456382, -174.89660492275493, -48.813144565532504, -44.31368082486888, -133.48628753727675, -111.12146530520087, -36.40072678259544, -167.35524972669285, -152.00877058879365], "policy_AGENT-0_reward": [19.292803429964565, 76.60490430152154, -92.36749270520622, 171.9260123275561, -67.62322604986143, -5.841130880593411, 9.946941100175078, 122.61874876546011, -66.60373219705448, -16.216937206979622, -48.704335470377416, -73.4525894599136, -84.25472582718778, 69.30523560844054, -90.74293826068242, 108.60893153355097, -97.61888586765039, 39.7307102102553, -5.046110795777146, 208.5471365368905, -212.32696814133465, 8.524800475540374, 32.38323305502474, 71.20319661152283, -196.690642809435, -95.6155352588593, -248.35040120018203, -109.99887563477077, -99.37799214152463, -157.98078536065955, -207.23213644525157, -180.71557413293908, -262.66591248054453, -62.050959563579895, 17.932859003056805, -156.0419154428555, -214.07111665317626, -98.99646944310504, 21.4756032100186, -5.469378722235696, 34.970884245533384, 131.67825645434584, -130.28519070152043, 287.3602419595356, -131.1611204525624, -63.19395406690401, 38.9942023447035, -64.14021881966517, 15.247511593920812, -56.94639595254728, -193.47228346298152, -65.56816986082016, 69.22050268114157, -193.70890414365118, -167.10687562525476, -147.9932349202626, -168.65870737747863, -6.9073018514677855, -59.48975789780188, -119.76656484898673, -124.33204762170982, -39.92924397890859, -65.9711417432638, -267.0971267688469, -63.784582465853326, -68.53869304701983, 20.59685598353903, 87.10668523654611, -158.05499210717235, 84.01766839555063, -197.16957713936733, 215.44404754959234, -104.9058449560456, 59.6692217715802, 14.516514158417749, 59.293119176796985, -53.86956509195261, -8.539774923771688, -60.614008636356346, 106.07634025070865, -99.93994605652645, 27.875923499063724, -62.70859612637326, -52.32386067712124, -157.4075255339524, 145.07445855087954, -82.70072494004087, -186.55231881277345, -192.64109528719945, -207.9016996255158, 0.863900595867733, -108.86805754140178, -107.88017808891522, -4.510402756190068, 42.13672866851984, -123.90359676982469, -111.7695580136699, 14.920888150425306, -142.02737287961963, -197.41972486062798], "policy_AGENT-2_reward": [-53.30945160606708, 112.09520625588473, -47.802604047438486, 190.13347086810353, -22.249919543921244, 41.467903612953855, 9.382278206058048, 58.73456616119053, -17.317762214918275, 22.032804489664507, -83.52115340485842, -18.918957953377156, -141.63312073904208, 13.874288125431228, -38.6211845198696, 155.9501054713295, -51.59790321657896, -19.125255996108702, 34.7119448117402, 247.84332656305153, -18.548995094902928, 43.451607163279036, 5.6094798121658505, 114.38662004546359, -203.49702740709924, -96.16559136860162, -207.39635433958912, -159.8987766101746, -130.33414213790792, -135.2300147947271, -159.1856949761174, -135.1017670905013, -173.53282360473466, -62.607222616474075, -30.263430043208036, -130.5498859963203, -168.20510104762863, -129.92917068967196, -54.68754540209681, -45.52449417216028, -30.96885544402097, 178.9351522591303, -174.20787651867988, 286.79670467655325, -179.45261187946676, -63.76082977515346, -32.17389150433533, -136.78413380416748, -33.92277849756639, -57.37740622151156, -34.51714074932687, -162.90433816107634, 111.11355540741133, -146.76171261120533, -170.72901812803747, -180.00828795584218, -123.28570400202955, -29.919560471759183, -60.0468085785883, -119.48083790809608, -52.322404433154006, -52.38118936139303, -51.00315887069364, -175.92971894252875, -64.3377688253988, -69.09592429511048, 20.874954298933027, 79.15739829238821, -111.02017322343508, 79.85700792449913, -114.52139363549453, 246.49477965431907, -56.19043325020297, 83.51856424102502, -31.025816291788537, 96.29541956489757, -8.39060022438492, 37.390267541737785, -17.147946321941266, 123.16348457765869, -53.94411696214009, 68.60771840317167, -157.3899321670615, 3.0985679377609685, -44.28191140487762, 153.5469044836564, -45.25983466068087, -36.8104839719814, -154.25737244855407, -179.45797281714968, -37.174199716248054, -97.6703284759815, -108.42869168223464, -48.86524506658616, -44.26303914324232, -126.10561807384192, -111.23340564971048, -36.37289662704145, -167.27030469571727, -156.18929443960653], "policy_AGENT-1_reward": [66.47070642596016, 76.47140285902974, -47.385052676745666, 184.45554300151008, -21.62727774639231, -5.966121830666765, 11.445621008521039, 99.27874334379811, -17.822243120978083, 29.454668229327847, -4.248232826506541, -69.81039302482127, -84.24388439772811, 68.98563322052895, -41.54368268176738, 155.5168649792117, -50.44317655417134, 39.738533398643696, 15.644509134898609, 136.7081462783698, -18.07873473152245, 54.09993173258518, -12.179276418996558, 71.06890938031887, -196.0383797675155, -145.89636582981458, -201.21455170505033, -109.96528671534935, -53.72221034272098, -113.22755285333608, -158.81588785209456, -135.10544781456133, -215.07044625815735, -85.3671426256799, 62.692841837526835, -155.99051528900904, -166.29493116012566, -98.96980811021655, 21.45755566356078, 38.49105183549186, 34.68811793980868, 131.51018037049795, -130.22472710711477, 267.38808107833955, -131.10849873920085, -53.477844211613615, 83.00666314732595, -64.09865218372941, 61.31969003649781, -221.0151655415171, -183.89040248521803, -65.43702688649218, 69.07626050100745, -145.47286880107546, -167.16123200747126, -148.30925800638764, -121.64624686856577, 39.49267401754563, -91.73618627684279, -71.93260090476926, -124.60052832903065, 5.657074717882064, -20.829423348766163, -221.65961014071408, -118.71951627734968, -103.49626448426027, 20.49196100349981, 88.79858766457893, -60.64249949325989, 84.69611719933147, -151.0968634604689, 229.76686505777346, -56.34762724038975, 63.98257963708485, 59.62936433817196, 107.53557252333901, -53.89853896232904, 38.01863131571072, -16.556866720205182, 110.84470597272689, -99.47204678753059, 32.848433225172776, -62.718424667443344, -52.53783832394116, -43.83885875880017, 147.81816988313727, -33.24916783830902, -142.97309497182476, -147.01428325100773, -161.97693734483946, 49.729572535239356, -108.88687148199608, -214.0988919803749, 42.494107951930516, 88.17214736770404, -122.57782975149217, -111.65439078006429, 58.18549049258203, -163.56554244906428, -148.45644655207752]}, "sampler_perf": {"mean_env_wait_ms": 55.21423518954531, "mean_raw_obs_processing_ms": 2.3675969956927396, "mean_inference_ms": 2.448883173897974, "mean_action_processing_ms": 0.14438218761734456}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 71400, "timers": {"sample_time_ms": 93759.666, "sample_throughput": 44.795, "load_time_ms": 15.626, "load_throughput": 268782.775, "learn_time_ms": 9143.918, "learn_throughput": 459.322, "update_time_ms": 8.179}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 13.591205596923828, "policy_loss": -0.031814225018024445, "vf_loss": 13.615360260009766, "vf_explained_var": 0.9608887434005737, "kl": 0.017019636929035187, "entropy": 1.2392655611038208, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 14.35567569732666, "policy_loss": -0.02660658396780491, "vf_loss": 14.376264572143555, "vf_explained_var": 0.9398602843284607, "kl": 0.020063189789652824, "entropy": 1.210667610168457, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 8.458499908447266, "policy_loss": -0.025881648063659668, "vf_loss": 8.474349021911621, "vf_explained_var": 0.9619359374046326, "kl": 0.022296801209449768, "entropy": 1.2210538387298584, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0010000000474974513, "total_loss": 8.845927238464355, "policy_loss": -0.021845627576112747, "vf_loss": 8.860288619995117, "vf_explained_var": 0.9646255373954773, "kl": 0.024946248158812523, "entropy": 1.213625431060791, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 71400, "num_steps_trained": 71400}, "done": false, "episodes_total": 602, "training_iteration": 17, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-45-35", "timestamp": 1624211135, "time_this_iter_s": 106.45304846763611, "time_total_s": 1725.3539400100708, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd4042b89e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40449b050>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449bc20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449bb00>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40434b3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40434bd40>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449bc20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449bb00>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40434b3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40434bd40>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449bc20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449bb00>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40434b3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40434bd40>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449bc20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449bb00>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40434b3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40434bd40>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd4042bd560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1725.3539400100708, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 56.905921052631584, "ram_util_percent": 87.2309210526316}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 975.3411481993969, "episode_reward_min": -848.0118187134354, "episode_reward_mean": -162.52053355878562, "episode_len_mean": 117.67, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-3": -200.57991987410145, "AGENT-0": -262.66591248054453, "AGENT-2": -207.39635433958912, "AGENT-1": -231.97335319799132}, "policy_reward_max": {"AGENT-3": 230.56224156234794, "AGENT-0": 234.5126194540327, "AGENT-2": 267.6208047640177, "AGENT-1": 247.37787988624154}, "policy_reward_mean": {"AGENT-3": -38.749638169291345, "AGENT-0": -51.80468050891537, "AGENT-2": -37.04195879951594, "AGENT-1": -34.924256081062964}, "custom_metrics": {"mean_ego_speed_mean": 42.36895749999999, "mean_ego_speed_min": 33.6005, "mean_ego_speed_max": 47.84925, "distance_travelled_mean": 108.01878249999999, "distance_travelled_min": 40.585750000000004, "distance_travelled_max": 124.88}, "hist_stats": {"episode_reward": [-313.7704025312639, 772.5890560960397, 42.5463631927111, 448.0276641454413, -192.02050058086414, -75.85067823617572, -195.14192530839168, 568.8321888712836, -246.93711752878608, 1.2345727332949465, -257.1862939946025, 796.7200734910454, -84.72172970131025, -16.15559998417123, -367.4798396504651, 136.1481177120302, -456.4495500262838, 975.3411481993969, -150.09496813132878, -214.43409979800214, -344.190103229093, 176.41562744284613, -459.9069044071972, -839.1344874026418, -793.2096445044824, -602.6246811661413, -216.1361886095857, -655.9442559333123, -359.8347085909001, -499.9824473964562, -433.4121600445581, -505.4569048214663, -417.4399706526026, -520.6461387961288, -543.9999312027973, -275.7077653127199, 290.7022227066997, 12.087626531041394, 402.9124271511304, -124.50577332522298, 100.70318956711543, -108.76943694924785, 463.2893651178174, -308.155533876387, 234.7132462848188, -392.1175563494957, -98.84874661563364, -360.572480607109, 599.6907489286054, -206.59460809561023, -403.3514180430892, -647.530653287979, -733.1078090315496, -23.717428190109317, -412.43748800394286, -605.3043666742793, -59.694684436378274, 41.7321560681127, -506.07333213243606, -445.77881974864533, 0.3327552333703636, -640.2184697510938, -654.074236441106, -21.00768406394105, 377.32420483718636, -238.5482200524181, 727.9775803704364, -141.4617607809754, 110.95820228070218, 35.97869028079955, 339.11733550672017, -123.91549960716748, 104.72397176500482, -219.9574308195149, -181.04332183937962, -452.07070680697285, 214.89232677699997, -209.54041427154917, 613.9216423664038, -251.9896168443982, 90.44382608906834, 73.44637425461751, 729.2411439431684, -418.50559463183174, 195.49695854945912, 32.59594670767991, 369.673927603728, -796.8059698581508, -489.39344193204903, -848.0118187134354, -539.7341512081838, -413.8081227351724, -546.1572694958874, -684.5275975154187, -597.9319423751025, -825.0405548654528, -304.23774401560746, 20.12072198741717, -572.7496206898629, -706.82443644724], "episode_lengths": [120, 133, 127, 127, 109, 126, 114, 122, 109, 103, 119, 112, 116, 124, 114, 119, 124, 153, 91, 120, 124, 120, 118, 114, 120, 113, 121, 125, 114, 114, 116, 112, 118, 118, 108, 116, 129, 132, 127, 92, 121, 113, 132, 116, 127, 103, 77, 119, 138, 118, 115, 125, 124, 126, 99, 117, 123, 128, 116, 110, 129, 115, 117, 128, 120, 122, 147, 116, 112, 108, 119, 112, 124, 128, 126, 105, 104, 118, 126, 116, 100, 120, 124, 120, 130, 124, 119, 121, 117, 121, 34, 129, 118, 119, 123, 119, 112, 127, 101, 117], "policy_AGENT-3_reward": [-69.65519620587189, 230.56224156234794, -32.58990847465784, 138.13119196038562, -45.92042474531695, -16.50765645934133, -52.61803732225057, 138.7294974400095, -80.0206975566157, 0.9442046067571481, -54.32102613828276, 210.49343894480748, -9.440893682165402, 14.666346250454712, -180.95177930371156, 58.846373231955106, -164.91527487181781, 225.8298440951046, -12.727559407466961, -27.396615990052208, -73.84924600686612, 99.30149079042688, -151.40740251849098, -187.41119868065476, -187.4093011318434, -140.18990130378052, -18.906656636723252, -162.91601170976972, -94.54446172331785, -137.76917341706493, -96.70293192951047, -132.9345824584244, -69.84254542316307, -125.20663464707896, -135.22723445384221, -58.26385986608131, 83.53185705700955, -31.03243567375964, 139.7883158860968, -8.347069046556408, 33.83406563343878, -14.45061527074504, 123.20483431672304, -54.79942407018978, 105.38117115741032, -109.30060338861755, 2.9143844476679135, -115.0441849094788, 153.25121601093173, -45.38488065657943, -37.01552028650951, -153.61790230121773, -183.77119924404354, -37.136701604968316, -97.01223050456382, -174.89660492275493, -48.813144565532504, -44.31368082486888, -133.48628753727675, -111.12146530520087, -36.40072678259544, -167.35524972669285, -152.00877058879365, -53.46174231379853, 112.15269142074996, -50.99307062302773, 181.46255417326662, -29.961337440800225, 81.29755137900848, 5.203849966045264, 58.48527723627127, -22.171762074216453, 69.45343625299242, -83.4837091177726, -18.861381401267728, -141.93897584301482, 62.72716982259893, -38.63260880922981, 193.84574038231057, -52.32965120599739, 30.09983847627818, 28.136031103755954, 136.1425345648563, -169.55089666407142, 89.42061917805447, 6.782510259485832, 113.01520156642172, -200.57991987410145, -151.71594947477325, -191.05051146861348, -159.87121224788908, -130.3737781130188, -139.71891648716522, -159.29387824195572, -147.0091533371001, -173.7713725220162, -94.2124192098734, -30.24154880995847, -130.1673039616778, -158.25328758630917], "policy_AGENT-0_reward": [-110.83976899912895, 176.89692497901777, 31.619324401227615, 103.25201570709834, -51.628857193440965, -22.239055820639685, -49.33503844978978, 144.94103238861535, -47.36985982565091, 24.244127402965933, -98.30481433730198, 211.96603006698038, -32.914379932658825, -28.694134717220923, -154.61348940428945, 25.69445656740265, -69.7412074583883, 234.5126194540327, -62.28424835291837, -78.35858511896487, -120.92728815544822, 11.6980875563142, -81.37874299471594, -231.8383749038291, -229.47255589323336, -134.75539591824233, -8.038877718584553, -193.38736289436014, -74.20473128702636, -106.41578129654948, -143.9741542499344, -109.95351595758945, -110.57621087993999, -164.2754966999519, -138.74857717233755, -104.9058449560456, 59.6692217715802, 14.516514158417749, 59.293119176796985, -53.86956509195261, -8.539774923771688, -60.614008636356346, 106.07634025070865, -99.93994605652645, 27.875923499063724, -62.70859612637326, -52.32386067712124, -157.4075255339524, 145.07445855087954, -82.70072494004087, -186.55231881277345, -192.64109528719945, -207.9016996255158, 0.863900595867733, -108.86805754140178, -107.88017808891522, -4.510402756190068, 42.13672866851984, -123.90359676982469, -111.7695580136699, 14.920888150425306, -142.02737287961963, -197.41972486062798, 19.292803429964565, 76.60490430152154, -92.36749270520622, 171.9260123275561, -67.62322604986143, -5.841130880593411, 9.946941100175078, 122.61874876546011, -66.60373219705448, -16.216937206979622, -48.704335470377416, -73.4525894599136, -84.25472582718778, 69.30523560844054, -90.74293826068242, 108.60893153355097, -97.61888586765039, 39.7307102102553, -5.046110795777146, 208.5471365368905, -212.32696814133465, 8.524800475540374, 32.38323305502474, 71.20319661152283, -196.690642809435, -95.6155352588593, -248.35040120018203, -109.99887563477077, -99.37799214152463, -157.98078536065955, -207.23213644525157, -180.71557413293908, -262.66591248054453, -62.050959563579895, 17.932859003056805, -156.0419154428555, -214.07111665317626], "policy_AGENT-2_reward": [-67.09074639794736, 182.81189746555512, -32.55790142521383, 99.79877271259363, -52.21078061666307, -16.54329369153857, -49.88541091234051, 138.25459680903128, -47.925411596684086, -48.24323112113261, -52.416575433169285, 162.30373461658462, -9.31598226585177, 25.72941357415202, -16.172104427235563, 24.326269910471872, -70.30887434536592, 267.6208047640177, -12.695928925064036, -27.366242709056863, -75.22996589732448, 53.84856371986044, -81.9411396666163, -187.91156062016623, -188.47421565620238, -143.13518604132844, -94.8502969607903, -153.32803449969046, -95.2524594486905, -127.7891553288635, -96.40736551462544, -131.16757909536508, -118.89462115670231, -115.41916733360227, -139.30764631171326, -56.19043325020297, 83.51856424102502, -31.025816291788537, 96.29541956489757, -8.39060022438492, 37.390267541737785, -17.147946321941266, 123.16348457765869, -53.94411696214009, 68.60771840317167, -157.3899321670615, 3.0985679377609685, -44.28191140487762, 153.5469044836564, -45.25983466068087, -36.8104839719814, -154.25737244855407, -179.45797281714968, -37.174199716248054, -97.6703284759815, -108.42869168223464, -48.86524506658616, -44.26303914324232, -126.10561807384192, -111.23340564971048, -36.37289662704145, -167.27030469571727, -156.18929443960653, -53.30945160606708, 112.09520625588473, -47.802604047438486, 190.13347086810353, -22.249919543921244, 41.467903612953855, 9.382278206058048, 58.73456616119053, -17.317762214918275, 22.032804489664507, -83.52115340485842, -18.918957953377156, -141.63312073904208, 13.874288125431228, -38.6211845198696, 155.9501054713295, -51.59790321657896, -19.125255996108702, 34.7119448117402, 247.84332656305153, -18.548995094902928, 43.451607163279036, 5.6094798121658505, 114.38662004546359, -203.49702740709924, -96.16559136860162, -207.39635433958912, -159.8987766101746, -130.33414213790792, -135.2300147947271, -159.1856949761174, -135.1017670905013, -173.53282360473466, -62.607222616474075, -30.263430043208036, -130.5498859963203, -168.20510104762863], "policy_AGENT-1_reward": [-66.18469092831592, 182.31799208911917, 76.07484869135502, 106.84568376536386, -42.26043802544295, -20.560672264656084, -43.30343862401095, 146.90706223362778, -71.6211485498354, 24.28947184470442, -52.14387808584879, 211.95686986267268, -33.0504738206343, -27.857225091557225, -15.742466515228465, 27.28101800220051, -151.48419335071173, 247.37787988624154, -62.38723144587939, -81.31265597992812, -74.1836031694545, 11.56748537624464, -145.17961922737373, -231.97335319799132, -187.853571823203, -184.5441979027895, -94.34035729348737, -146.3128468294916, -95.8330561318654, -128.00833735397848, -96.3277083504874, -131.40122731008728, -118.12659319279703, -115.74484011549569, -130.71647326490404, -56.34762724038975, 63.98257963708485, 59.62936433817196, 107.53557252333901, -53.89853896232904, 38.01863131571072, -16.556866720205182, 110.84470597272689, -99.47204678753059, 32.848433225172776, -62.718424667443344, -52.53783832394116, -43.83885875880017, 147.81816988313727, -33.24916783830902, -142.97309497182476, -147.01428325100773, -161.97693734483946, 49.729572535239356, -108.88687148199608, -214.0988919803749, 42.494107951930516, 88.17214736770404, -122.57782975149217, -111.65439078006429, 58.18549049258203, -163.56554244906428, -148.45644655207752, 66.47070642596016, 76.47140285902974, -47.385052676745666, 184.45554300151008, -21.62727774639231, -5.966121830666765, 11.445621008521039, 99.27874334379811, -17.822243120978083, 29.454668229327847, -4.248232826506541, -69.81039302482127, -84.24388439772811, 68.98563322052895, -41.54368268176738, 155.5168649792117, -50.44317655417134, 39.738533398643696, 15.644509134898609, 136.7081462783698, -18.07873473152245, 54.09993173258518, -12.179276418996558, 71.06890938031887, -196.0383797675155, -145.89636582981458, -201.21455170505033, -109.96528671534935, -53.72221034272098, -113.22755285333608, -158.81588785209456, -135.10544781456133, -215.07044625815735, -85.3671426256799, 62.692841837526835, -155.99051528900904, -166.29493116012566]}, "sampler_perf": {"mean_env_wait_ms": 55.25723332161808, "mean_raw_obs_processing_ms": 2.366124339319815, "mean_inference_ms": 2.4441671062109633, "mean_action_processing_ms": 0.14433646441855547}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 75600, "timers": {"sample_time_ms": 93202.069, "sample_throughput": 45.063, "load_time_ms": 15.586, "load_throughput": 269478.054, "learn_time_ms": 9141.332, "learn_throughput": 459.452, "update_time_ms": 8.117}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 14.743412971496582, "policy_loss": -0.03313456103205681, "vf_loss": 14.770007133483887, "vf_explained_var": 0.9542450308799744, "kl": 0.014530076645314693, "entropy": 1.2263423204421997, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 12.413595199584961, "policy_loss": -0.02567465975880623, "vf_loss": 12.430575370788574, "vf_explained_var": 0.9539182782173157, "kl": 0.019320236518979073, "entropy": 1.213718295097351, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 11.811363220214844, "policy_loss": -0.033267680555582047, "vf_loss": 11.835164070129395, "vf_explained_var": 0.951433539390564, "kl": 0.014022556133568287, "entropy": 1.1948031187057495, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 8.914812088012695, "policy_loss": -0.02813720703125, "vf_loss": 8.936054229736328, "vf_explained_var": 0.9707847833633423, "kl": 0.015320885926485062, "entropy": 1.1797107458114624, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 75600, "num_steps_trained": 75600}, "done": false, "episodes_total": 637, "training_iteration": 18, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-47-18", "timestamp": 1624211238, "time_this_iter_s": 102.95750212669373, "time_total_s": 1828.3114421367645, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd404254b00>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd4042549e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042547a0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd404254680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd404254440>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042540e0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042547a0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd404254680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd404254440>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042540e0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042547a0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd404254680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd404254440>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042540e0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042547a0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd404254680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd404254440>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042540e0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd4042bdb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1828.3114421367645, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 55.76734693877552, "ram_util_percent": 87.22244897959185}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 975.3411481993969, "episode_reward_min": -848.0118187134354, "episode_reward_mean": -167.67030158842215, "episode_len_mean": 117.16, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-3": -200.57991987410145, "AGENT-0": -262.66591248054453, "AGENT-1": -231.97335319799132, "AGENT-2": -207.39635433958912}, "policy_reward_max": {"AGENT-3": 230.56224156234794, "AGENT-0": 234.5126194540327, "AGENT-1": 247.37787988624154, "AGENT-2": 267.6208047640177}, "policy_reward_mean": {"AGENT-3": -38.99902375545112, "AGENT-0": -50.88234966051521, "AGENT-1": -38.624745465093305, "AGENT-2": -39.16418270736252}, "custom_metrics": {"mean_ego_speed_mean": 42.52661749999999, "mean_ego_speed_min": 34.994749999999996, "mean_ego_speed_max": 47.84925, "distance_travelled_mean": 108.04454, "distance_travelled_min": 40.585750000000004, "distance_travelled_max": 124.85875}, "hist_stats": {"episode_reward": [268.1454403754048, -138.46720998448043, 656.3546128979068, -156.0925349165057, 690.3461349974945, -571.487069781221, 775.9462319803589, 785.8807770265184, -26.930347005778398, -506.1782795626611, 846.1713933937774, 541.6030529376567, -435.9637948650587, -175.91895590193147, -332.8165133732058, -98.28105529852579, -239.5944139609543, -166.6275499328644, -319.717243655472, 187.85837630889046, -281.4655760863032, -7.0278464140839745, -409.3638017148796, -53.90875913749065, -460.3812508296325, -831.7722678966371, -826.0203918779586, -292.0789460424049, -551.9945604431957, -261.8320751158184, -203.6071082885956, -503.3824754891619, -511.60698229007403, -623.8540187378269, -290.08765069047257, 339.11733550672017, -123.91549960716748, 104.72397176500482, -219.9574308195149, -181.04332183937962, -452.07070680697285, 214.89232677699997, -209.54041427154917, 613.9216423664038, -251.9896168443982, 90.44382608906834, 73.44637425461751, 729.2411439431684, -418.50559463183174, 195.49695854945912, 32.59594670767991, 369.673927603728, -796.8059698581508, -489.39344193204903, -848.0118187134354, -539.7341512081838, -413.8081227351724, -546.1572694958874, -684.5275975154187, -597.9319423751025, -825.0405548654528, -304.23774401560746, 20.12072198741717, -572.7496206898629, -706.82443644724, -313.7704025312639, 772.5890560960397, 42.5463631927111, 448.0276641454413, -192.02050058086414, -75.85067823617572, -195.14192530839168, 568.8321888712836, -246.93711752878608, 1.2345727332949465, -257.1862939946025, 796.7200734910454, -84.72172970131025, -16.15559998417123, -367.4798396504651, 136.1481177120302, -456.4495500262838, 975.3411481993969, -150.09496813132878, -214.43409979800214, -344.190103229093, 176.41562744284613, -459.9069044071972, -839.1344874026418, -793.2096445044824, -602.6246811661413, -216.1361886095857, -655.9442559333123, -359.8347085909001, -499.9824473964562, -433.4121600445581, -505.4569048214663, -417.4399706526026, -520.6461387961288, -543.9999312027973], "episode_lengths": [118, 112, 127, 126, 125, 103, 140, 106, 102, 119, 143, 143, 114, 127, 110, 120, 116, 104, 116, 116, 113, 102, 105, 95, 118, 120, 122, 99, 114, 133, 128, 119, 116, 119, 116, 119, 112, 124, 128, 126, 105, 104, 118, 126, 116, 100, 120, 124, 120, 130, 124, 119, 121, 117, 121, 34, 129, 118, 119, 123, 119, 112, 127, 101, 117, 120, 133, 127, 127, 109, 126, 114, 122, 109, 103, 119, 112, 116, 124, 114, 119, 124, 153, 91, 120, 124, 120, 118, 114, 120, 113, 121, 125, 114, 114, 116, 112, 118, 118, 108], "policy_AGENT-3_reward": [100.08913172300318, -21.90460635867366, 191.5084176057304, -57.98630281032731, 186.3151363187545, -137.6087929330779, 157.34263084194498, 189.23557373552734, -8.85740014337585, -118.13266884601722, 210.68275726724795, 169.7630785042712, -134.53688903700566, 1.695306334792086, -35.60801688006213, -15.57443849327085, -54.94487480719406, -48.695164572828254, -68.83856851247452, 104.20887469069118, -97.67962483563561, -3.171529251088086, -115.18620006962487, 1.0989412915545032, -149.20661018502102, -199.82184564398122, -185.15379721585862, -36.770807622471516, -137.17385441635136, -110.56200056290419, -92.91652047455997, -119.07008847910186, -118.24371844067439, -154.16130057482957, -41.03900176939102, 58.48527723627127, -22.171762074216453, 69.45343625299242, -83.4837091177726, -18.861381401267728, -141.93897584301482, 62.72716982259893, -38.63260880922981, 193.84574038231057, -52.32965120599739, 30.09983847627818, 28.136031103755954, 136.1425345648563, -169.55089666407142, 89.42061917805447, 6.782510259485832, 113.01520156642172, -200.57991987410145, -151.71594947477325, -191.05051146861348, -159.87121224788908, -130.3737781130188, -139.71891648716522, -159.29387824195572, -147.0091533371001, -173.7713725220162, -94.2124192098734, -30.24154880995847, -130.1673039616778, -158.25328758630917, -69.65519620587189, 230.56224156234794, -32.58990847465784, 138.13119196038562, -45.92042474531695, -16.50765645934133, -52.61803732225057, 138.7294974400095, -80.0206975566157, 0.9442046067571481, -54.32102613828276, 210.49343894480748, -9.440893682165402, 14.666346250454712, -180.95177930371156, 58.846373231955106, -164.91527487181781, 225.8298440951046, -12.727559407466961, -27.396615990052208, -73.84924600686612, 99.30149079042688, -151.40740251849098, -187.41119868065476, -187.4093011318434, -140.18990130378052, -18.906656636723252, -162.91601170976972, -94.54446172331785, -137.76917341706493, -96.70293192951047, -132.9345824584244, -69.84254542316307, -125.20663464707896, -135.22723445384221], "policy_AGENT-0_reward": [57.13500684160477, -54.936712064654294, 155.14778777057685, -42.34620780870833, 169.68893168268494, -123.38200677426583, 201.27166385049244, 215.4788864443437, 19.992903071459843, -161.67733611504178, 201.54704723489087, 94.45176903023108, -63.493959309846, -93.37807882547534, -85.61077276351159, -32.92722352486678, -101.93056149098182, -48.7422207371299, -113.25150149556819, 14.346766474940708, -136.652190638084, 23.30930632263633, -65.79616699089618, -24.299187677993274, -61.60633316943983, -242.08469231528127, -240.91028977824345, -121.11277980327642, -140.82351988427672, -16.66588858101743, -31.0124949075182, -159.07377047459246, -112.97024760399785, -186.81512054047516, -82.75566584076512, 122.61874876546011, -66.60373219705448, -16.216937206979622, -48.704335470377416, -73.4525894599136, -84.25472582718778, 69.30523560844054, -90.74293826068242, 108.60893153355097, -97.61888586765039, 39.7307102102553, -5.046110795777146, 208.5471365368905, -212.32696814133465, 8.524800475540374, 32.38323305502474, 71.20319661152283, -196.690642809435, -95.6155352588593, -248.35040120018203, -109.99887563477077, -99.37799214152463, -157.98078536065955, -207.23213644525157, -180.71557413293908, -262.66591248054453, -62.050959563579895, 17.932859003056805, -156.0419154428555, -214.07111665317626, -110.83976899912895, 176.89692497901777, 31.619324401227615, 103.25201570709834, -51.628857193440965, -22.239055820639685, -49.33503844978978, 144.94103238861535, -47.36985982565091, 24.244127402965933, -98.30481433730198, 211.96603006698038, -32.914379932658825, -28.694134717220923, -154.61348940428945, 25.69445656740265, -69.7412074583883, 234.5126194540327, -62.28424835291837, -78.35858511896487, -120.92728815544822, 11.6980875563142, -81.37874299471594, -231.8383749038291, -229.47255589323336, -134.75539591824233, -8.038877718584553, -193.38736289436014, -74.20473128702636, -106.41578129654948, -143.9741542499344, -109.95351595758945, -110.57621087993999, -164.2754966999519, -138.74857717233755], "policy_AGENT-1_reward": [57.81142155800711, -6.025607474697366, 157.9620107921229, 2.274618168748173, 171.3760953236991, -123.32323552943043, 216.62531416399935, 215.21271953373233, 20.022448822591958, -113.18284564891054, 213.6763138557384, 107.45087979460953, -173.87888592058005, -85.8863067990129, -85.70172304674063, -34.15311063377408, -56.25856931697768, -48.876225546124914, -68.65879192364476, 14.220833451450616, -23.320247404922416, 23.35408676923264, -65.91358393124507, -24.250016840218564, -187.40915670086667, -194.62186323395812, -194.8402736127864, -121.25007361864584, -132.62275794028065, -24.290501049152468, 13.202963286397226, -112.60283412489308, -161.50001225766275, -138.61412172733498, -82.75796121917769, 99.27874334379811, -17.822243120978083, 29.454668229327847, -4.248232826506541, -69.81039302482127, -84.24388439772811, 68.98563322052895, -41.54368268176738, 155.5168649792117, -50.44317655417134, 39.738533398643696, 15.644509134898609, 136.7081462783698, -18.07873473152245, 54.09993173258518, -12.179276418996558, 71.06890938031887, -196.0383797675155, -145.89636582981458, -201.21455170505033, -109.96528671534935, -53.72221034272098, -113.22755285333608, -158.81588785209456, -135.10544781456133, -215.07044625815735, -85.3671426256799, 62.692841837526835, -155.99051528900904, -166.29493116012566, -66.18469092831592, 182.31799208911917, 76.07484869135502, 106.84568376536386, -42.26043802544295, -20.560672264656084, -43.30343862401095, 146.90706223362778, -71.6211485498354, 24.28947184470442, -52.14387808584879, 211.95686986267268, -33.0504738206343, -27.857225091557225, -15.742466515228465, 27.28101800220051, -151.48419335071173, 247.37787988624154, -62.38723144587939, -81.31265597992812, -74.1836031694545, 11.56748537624464, -145.17961922737373, -231.97335319799132, -187.853571823203, -184.5441979027895, -94.34035729348737, -146.3128468294916, -95.8330561318654, -128.00833735397848, -96.3277083504874, -131.40122731008728, -118.12659319279703, -115.74484011549569, -130.71647326490404], "policy_AGENT-2_reward": [53.10988025278955, -55.6002840864552, 151.73639672947667, -58.034642466218074, 162.96597167235558, -187.17303454444743, 200.70662312392176, 165.95359731291478, -58.088298756454314, -113.18542895269127, 220.26527503590043, 169.93732560854565, -64.0540605976268, 1.6501233877647863, -125.89600068289165, -15.626282646614124, -26.460408345800683, -20.313939076781367, -68.96838172378395, 55.081901691807595, -23.813513207661245, -50.519710254864776, -162.4678507231137, -6.458495910833271, -62.15915077430521, -195.24386670341676, -205.1160312710697, -12.94528499801131, -141.37442820228716, -110.31368492274447, -92.88105619291474, -112.63578241057462, -118.89300398773855, -144.26347589518815, -83.53502186113896, 58.73456616119053, -17.317762214918275, 22.032804489664507, -83.52115340485842, -18.918957953377156, -141.63312073904208, 13.874288125431228, -38.6211845198696, 155.9501054713295, -51.59790321657896, -19.125255996108702, 34.7119448117402, 247.84332656305153, -18.548995094902928, 43.451607163279036, 5.6094798121658505, 114.38662004546359, -203.49702740709924, -96.16559136860162, -207.39635433958912, -159.8987766101746, -130.33414213790792, -135.2300147947271, -159.1856949761174, -135.1017670905013, -173.53282360473466, -62.607222616474075, -30.263430043208036, -130.5498859963203, -168.20510104762863, -67.09074639794736, 182.81189746555512, -32.55790142521383, 99.79877271259363, -52.21078061666307, -16.54329369153857, -49.88541091234051, 138.25459680903128, -47.925411596684086, -48.24323112113261, -52.416575433169285, 162.30373461658462, -9.31598226585177, 25.72941357415202, -16.172104427235563, 24.326269910471872, -70.30887434536592, 267.6208047640177, -12.695928925064036, -27.366242709056863, -75.22996589732448, 53.84856371986044, -81.9411396666163, -187.91156062016623, -188.47421565620238, -143.13518604132844, -94.8502969607903, -153.32803449969046, -95.2524594486905, -127.7891553288635, -96.40736551462544, -131.16757909536508, -118.89462115670231, -115.41916733360227, -139.30764631171326]}, "sampler_perf": {"mean_env_wait_ms": 55.275913366147435, "mean_raw_obs_processing_ms": 2.364123955481078, "mean_inference_ms": 2.4378161564475147, "mean_action_processing_ms": 0.144216622939039}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 79800, "timers": {"sample_time_ms": 92360.766, "sample_throughput": 45.474, "load_time_ms": 15.436, "load_throughput": 272091.537, "learn_time_ms": 9154.64, "learn_throughput": 458.784, "update_time_ms": 8.285}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 14.96245002746582, "policy_loss": -0.0281783826649189, "vf_loss": 14.982614517211914, "vf_explained_var": 0.9603822231292725, "kl": 0.017802130430936813, "entropy": 1.2095593214035034, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 15.034317016601562, "policy_loss": -0.02842683158814907, "vf_loss": 15.056136131286621, "vf_explained_var": 0.9481086134910583, "kl": 0.014683262445032597, "entropy": 1.222636342048645, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 14.881813049316406, "policy_loss": -0.030097654089331627, "vf_loss": 14.90392017364502, "vf_explained_var": 0.9471290707588196, "kl": 0.011838245205581188, "entropy": 1.2034319639205933, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 12.849514961242676, "policy_loss": -0.02539242058992386, "vf_loss": 12.865917205810547, "vf_explained_var": 0.9595176577568054, "kl": 0.019980253651738167, "entropy": 1.1507521867752075, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 79800, "num_steps_trained": 79800}, "done": false, "episodes_total": 672, "training_iteration": 19, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-48-57", "timestamp": 1624211337, "time_this_iter_s": 98.93969750404358, "time_total_s": 1927.251139640808, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40445a7a0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40445a830>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449b290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449bb00>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8c20>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449b290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449bb00>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8c20>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449b290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449bb00>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8c20>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40449b290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40449bb00>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8c20>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd404254050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1927.251139640808, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 56.3669014084507, "ram_util_percent": 86.81197183098591}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 975.3411481993969, "episode_reward_min": -839.1344874026418, "episode_reward_mean": -172.91958330071577, "episode_len_mean": 115.53, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-3": -199.82184564398122, "AGENT-0": -242.08469231528127, "AGENT-2": -231.64776347901437, "AGENT-1": -231.97335319799132}, "policy_reward_max": {"AGENT-3": 225.8298440951046, "AGENT-0": 234.5126194540327, "AGENT-2": 267.6208047640177, "AGENT-1": 247.37787988624154}, "policy_reward_mean": {"AGENT-3": -39.053784548763275, "AGENT-0": -51.10188960893945, "AGENT-2": -39.08191592481032, "AGENT-1": -43.681993218202734}, "custom_metrics": {"mean_ego_speed_mean": 42.351497499999994, "mean_ego_speed_min": 34.994749999999996, "mean_ego_speed_max": 48.87025, "distance_travelled_mean": 106.26401, "distance_travelled_min": 36.84825000000001, "distance_travelled_max": 124.84175}, "hist_stats": {"episode_reward": [-251.2742500375142, 657.9387986309505, -353.4672434036, 394.80065739643175, -174.8645730886492, -80.78004497825746, -408.6471072611917, 512.1067195111677, -139.77352123554326, 650.8257892304282, -287.50368050112934, -5.63822338589172, -420.31129727510097, -383.18970481057795, 349.51002502279465, -414.3736064185568, -191.5755902176809, -405.6569030035777, 561.703214755927, -391.18924065898733, 159.41456242987482, -518.3010014500265, 302.58349974413926, -276.32055383160565, -20.1213722560993, -647.1556566490033, -788.1185461666057, -247.86838459115035, -566.6077106342349, -562.0385023571181, -656.7413072518677, -544.9135890369208, -165.70307051456706, -604.5934858873771, -145.50129107057188, -12.181397487148864, -361.59208483513623, 568.8321888712836, -246.93711752878608, 1.2345727332949465, -257.1862939946025, 796.7200734910454, -84.72172970131025, -16.15559998417123, -367.4798396504651, 136.1481177120302, -456.4495500262838, 975.3411481993969, -150.09496813132878, -214.43409979800214, -344.190103229093, 176.41562744284613, -459.9069044071972, -839.1344874026418, -793.2096445044824, -602.6246811661413, -216.1361886095857, -655.9442559333123, -359.8347085909001, -499.9824473964562, -433.4121600445581, -505.4569048214663, -417.4399706526026, -520.6461387961288, -543.9999312027973, 268.1454403754048, -138.46720998448043, 656.3546128979068, -156.0925349165057, 690.3461349974945, -571.487069781221, 775.9462319803589, 785.8807770265184, -26.930347005778398, -506.1782795626611, 846.1713933937774, 541.6030529376567, -435.9637948650587, -175.91895590193147, -332.8165133732058, -98.28105529852579, -239.5944139609543, -166.6275499328644, -319.717243655472, 187.85837630889046, -281.4655760863032, -7.0278464140839745, -409.3638017148796, -53.90875913749065, -460.3812508296325, -831.7722678966371, -826.0203918779586, -292.0789460424049, -551.9945604431957, -261.8320751158184, -203.6071082885956, -503.3824754891619, -511.60698229007403, -623.8540187378269, -290.08765069047257], "episode_lengths": [118, 113, 118, 118, 107, 111, 118, 121, 113, 123, 37, 103, 118, 121, 121, 106, 52, 115, 127, 105, 130, 118, 122, 119, 103, 123, 111, 110, 116, 116, 121, 119, 100, 129, 127, 119, 118, 122, 109, 103, 119, 112, 116, 124, 114, 119, 124, 153, 91, 120, 124, 120, 118, 114, 120, 113, 121, 125, 114, 114, 116, 112, 118, 118, 108, 118, 112, 127, 126, 125, 103, 140, 106, 102, 119, 143, 143, 114, 127, 110, 120, 116, 104, 116, 116, 113, 102, 105, 95, 118, 120, 122, 99, 114, 133, 128, 119, 116, 119, 116], "policy_AGENT-3_reward": [-57.92766601287751, 200.5978115294577, -135.04200075971175, 132.1087028459769, -45.55430650583289, -62.0530314548775, -51.30072598521436, 147.94138862601096, -40.36146649283169, 192.2432597078198, -45.3293961166371, 0.5737039975226417, -108.80534753800954, -128.56416081412632, 117.20426801268427, -148.68400173899062, -20.4867983555885, -144.27652373572994, 206.52148916530152, -89.70554444408835, 32.76878018971585, -172.031311738674, 103.86244452777967, -78.11261208312565, -6.15647917528138, -161.27972271967093, -185.16398770370208, -32.4353262828405, -130.32599384589207, -95.22076753848282, -146.76923676822324, -131.1629167898446, 4.501426171007417, -153.03868109364697, -81.85314805840564, -41.96563685691171, -103.91023078697609, 138.7294974400095, -80.0206975566157, 0.9442046067571481, -54.32102613828276, 210.49343894480748, -9.440893682165402, 14.666346250454712, -180.95177930371156, 58.846373231955106, -164.91527487181781, 225.8298440951046, -12.727559407466961, -27.396615990052208, -73.84924600686612, 99.30149079042688, -151.40740251849098, -187.41119868065476, -187.4093011318434, -140.18990130378052, -18.906656636723252, -162.91601170976972, -94.54446172331785, -137.76917341706493, -96.70293192951047, -132.9345824584244, -69.84254542316307, -125.20663464707896, -135.22723445384221, 100.08913172300318, -21.90460635867366, 191.5084176057304, -57.98630281032731, 186.3151363187545, -137.6087929330779, 157.34263084194498, 189.23557373552734, -8.85740014337585, -118.13266884601722, 210.68275726724795, 169.7630785042712, -134.53688903700566, 1.695306334792086, -35.60801688006213, -15.57443849327085, -54.94487480719406, -48.695164572828254, -68.83856851247452, 104.20887469069118, -97.67962483563561, -3.171529251088086, -115.18620006962487, 1.0989412915545032, -149.20661018502102, -199.82184564398122, -185.15379721585862, -36.770807622471516, -137.17385441635136, -110.56200056290419, -92.91652047455997, -119.07008847910186, -118.24371844067439, -154.16130057482957, -41.03900176939102], "policy_AGENT-0_reward": [-95.07414394172406, 136.34089033968397, -47.328920910204076, 89.89092269364123, -45.22022932871711, 7.051043977856608, -133.8633097031415, 122.81463377059356, -32.8620219855464, 153.85636995464236, -98.37498680196356, 20.817281601382394, -101.3901793535591, -67.10583035207368, 78.80560007013268, -72.19889913790465, -75.34984325708243, -186.4998465368002, 74.22161759925467, -82.93171069580617, 40.86368912367872, -66.64901866223713, 66.23610349997743, -120.22059433109376, 20.62770973004939, -190.99759900737124, -185.57954061107463, -91.51263118866663, -178.0321133475196, -135.00743746952304, -187.4989395334718, -169.1145141753458, -100.0044654367536, -177.67254645380012, -12.593314896430712, 13.331758281408284, -122.9076522935656, 144.94103238861535, -47.36985982565091, 24.244127402965933, -98.30481433730198, 211.96603006698038, -32.914379932658825, -28.694134717220923, -154.61348940428945, 25.69445656740265, -69.7412074583883, 234.5126194540327, -62.28424835291837, -78.35858511896487, -120.92728815544822, 11.6980875563142, -81.37874299471594, -231.8383749038291, -229.47255589323336, -134.75539591824233, -8.038877718584553, -193.38736289436014, -74.20473128702636, -106.41578129654948, -143.9741542499344, -109.95351595758945, -110.57621087993999, -164.2754966999519, -138.74857717233755, 57.13500684160477, -54.936712064654294, 155.14778777057685, -42.34620780870833, 169.68893168268494, -123.38200677426583, 201.27166385049244, 215.4788864443437, 19.992903071459843, -161.67733611504178, 201.54704723489087, 94.45176903023108, -63.493959309846, -93.37807882547534, -85.61077276351159, -32.92722352486678, -101.93056149098182, -48.7422207371299, -113.25150149556819, 14.346766474940708, -136.652190638084, 23.30930632263633, -65.79616699089618, -24.299187677993274, -61.60633316943983, -242.08469231528127, -240.91028977824345, -121.11277980327642, -140.82351988427672, -16.66588858101743, -31.0124949075182, -159.07377047459246, -112.97024760399785, -186.81512054047516, -82.75566584076512], "policy_AGENT-2_reward": [-49.245544256820445, 184.86036229879338, -47.88123123236301, 83.0402967078295, -45.80535592597689, 6.499335841824532, -89.29197544332607, 117.21337427082986, -33.8100522434432, 148.5337357666206, -45.315125805692006, -47.85568029089545, -108.59653964397033, -67.67113614793172, 73.99023807712196, -72.76298302947752, -20.34297501016149, -37.65451265631385, 158.74426773880631, -135.55027513681856, 2.49705206171695, -67.20009323176336, 62.0977147172226, -39.20847701173053, -55.349247743405115, -151.383162174006, -231.64776347901437, -32.354280180066574, -129.2038182574101, -166.16845133340942, -161.52425341455947, -122.0532337588875, 29.786328164950667, -140.05767202519604, -81.88532243753718, -41.951099258217, -57.600651657080775, 138.25459680903128, -47.925411596684086, -48.24323112113261, -52.416575433169285, 162.30373461658462, -9.31598226585177, 25.72941357415202, -16.172104427235563, 24.326269910471872, -70.30887434536592, 267.6208047640177, -12.695928925064036, -27.366242709056863, -75.22996589732448, 53.84856371986044, -81.9411396666163, -187.91156062016623, -188.47421565620238, -143.13518604132844, -94.8502969607903, -153.32803449969046, -95.2524594486905, -127.7891553288635, -96.40736551462544, -131.16757909536508, -118.89462115670231, -115.41916733360227, -139.30764631171326, 53.10988025278955, -55.6002840864552, 151.73639672947667, -58.034642466218074, 162.96597167235558, -187.17303454444743, 200.70662312392176, 165.95359731291478, -58.088298756454314, -113.18542895269127, 220.26527503590043, 169.93732560854565, -64.0540605976268, 1.6501233877647863, -125.89600068289165, -15.626282646614124, -26.460408345800683, -20.313939076781367, -68.96838172378395, 55.081901691807595, -23.813513207661245, -50.519710254864776, -162.4678507231137, -6.458495910833271, -62.15915077430521, -195.24386670341676, -205.1160312710697, -12.94528499801131, -141.37442820228716, -110.31368492274447, -92.88105619291474, -112.63578241057462, -118.89300398773855, -144.26347589518815, -83.53502186113896], "policy_AGENT-1_reward": [-49.02689582609236, 136.13973446301546, -123.21509050132104, 89.76073514898381, -38.2846813281223, -32.277393343060936, -134.19109612950967, 124.13732284373339, -32.73998051372209, 156.1924238013451, -98.48417177683655, 20.826471306098767, -101.519230739562, -119.8485774964465, 79.50991886285588, -120.72772251218377, -75.39597359484853, -37.22602007473367, 122.21584025256492, -83.0017103822741, 83.28504105476324, -212.42057781735213, 70.3872369991597, -38.77887040565534, 20.756644932537867, -143.4951727479554, -185.7272543728145, -91.56614693957667, -129.04578518341242, -165.64184601570307, -160.94887753561284, -122.58292431284325, -99.9863594137715, -133.82458631473358, 30.830494321801766, 58.40358034657154, -77.1735500975136, 146.90706223362778, -71.6211485498354, 24.28947184470442, -52.14387808584879, 211.95686986267268, -33.0504738206343, -27.857225091557225, -15.742466515228465, 27.28101800220051, -151.48419335071173, 247.37787988624154, -62.38723144587939, -81.31265597992812, -74.1836031694545, 11.56748537624464, -145.17961922737373, -231.97335319799132, -187.853571823203, -184.5441979027895, -94.34035729348737, -146.3128468294916, -95.8330561318654, -128.00833735397848, -96.3277083504874, -131.40122731008728, -118.12659319279703, -115.74484011549569, -130.71647326490404, 57.81142155800711, -6.025607474697366, 157.9620107921229, 2.274618168748173, 171.3760953236991, -123.32323552943043, 216.62531416399935, 215.21271953373233, 20.022448822591958, -113.18284564891054, 213.6763138557384, 107.45087979460953, -173.87888592058005, -85.8863067990129, -85.70172304674063, -34.15311063377408, -56.25856931697768, -48.876225546124914, -68.65879192364476, 14.220833451450616, -23.320247404922416, 23.35408676923264, -65.91358393124507, -24.250016840218564, -187.40915670086667, -194.62186323395812, -194.8402736127864, -121.25007361864584, -132.62275794028065, -24.290501049152468, 13.202963286397226, -112.60283412489308, -161.50001225766275, -138.61412172733498, -82.75796121917769]}, "sampler_perf": {"mean_env_wait_ms": 55.224996975872024, "mean_raw_obs_processing_ms": 2.359862328948733, "mean_inference_ms": 2.4298264788480743, "mean_action_processing_ms": 0.14397586642457078}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 84000, "timers": {"sample_time_ms": 91813.298, "sample_throughput": 45.745, "load_time_ms": 15.45, "load_throughput": 271850.1, "learn_time_ms": 9167.178, "learn_throughput": 458.156, "update_time_ms": 8.236}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 20.460819244384766, "policy_loss": -0.029595360159873962, "vf_loss": 20.482847213745117, "vf_explained_var": 0.9521016478538513, "kl": 0.016812484711408615, "entropy": 1.212975263595581, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 19.993804931640625, "policy_loss": -0.026819486171007156, "vf_loss": 20.013010025024414, "vf_explained_var": 0.9374695420265198, "kl": 0.01692025549709797, "entropy": 1.1984655857086182, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 12.435227394104004, "policy_loss": -0.029437685385346413, "vf_loss": 12.456419944763184, "vf_explained_var": 0.9630709290504456, "kl": 0.012211019173264503, "entropy": 1.1724222898483276, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 12.997751235961914, "policy_loss": -0.02333056926727295, "vf_loss": 13.014203071594238, "vf_explained_var": 0.9646177887916565, "kl": 0.015283790417015553, "entropy": 1.121399998664856, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 84000, "num_steps_trained": 84000}, "done": false, "episodes_total": 709, "training_iteration": 20, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-50-35", "timestamp": 1624211435, "time_this_iter_s": 97.8242735862732, "time_total_s": 2025.0754132270813, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40428c560>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40428c680>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40428c8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40428c9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40428cb00>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40428cc20>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40428c8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40428c9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40428cb00>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40428cc20>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40428c8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40428c9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40428cb00>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40428cc20>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40428c8c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40428c9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40428cb00>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40428cc20>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd40434bd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2025.0754132270813, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 56.89142857142858, "ram_util_percent": 86.80142857142854}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1365.44499026117, "episode_reward_min": -831.7722678966371, "episode_reward_mean": -148.4304819067389, "episode_len_mean": 116.53, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-3": -267.1321023710938, "AGENT-0": -242.08469231528127, "AGENT-1": -251.4589964766492, "AGENT-2": -231.64776347901437}, "policy_reward_max": {"AGENT-3": 327.9346596905772, "AGENT-0": 362.5447785375789, "AGENT-1": 362.3997690070743, "AGENT-2": 349.5675409837192}, "policy_reward_mean": {"AGENT-3": -36.0149056566698, "AGENT-0": -42.30068901858448, "AGENT-1": -35.68226360549593, "AGENT-2": -34.432623625988626}, "custom_metrics": {"mean_ego_speed_mean": 42.31583500000001, "mean_ego_speed_min": 36.126, "mean_ego_speed_max": 48.87025, "distance_travelled_mean": 105.77862999999998, "distance_travelled_min": 36.84825000000001, "distance_travelled_max": 124.83100000000002}, "hist_stats": {"episode_reward": [797.4445507019506, -235.3957959053569, 1365.44499026117, 548.9905966305114, -598.8438666412642, 329.63460775729425, 13.874367727653862, 479.8983199635937, -42.06343578289922, 1322.7634773088482, -502.7504321540648, -453.99802513814916, 8.410670923423709, -257.5192337558746, -354.6134973462869, 863.6365174924902, -529.2216843434373, -441.8452757835585, 822.1233640915924, -637.433714862337, 465.059168153428, -131.41388230978546, 630.6342514797085, -530.9402047836429, -515.3331441871757, -577.8626112949809, -583.9490949523247, -594.0565650247737, -477.96032162956124, -635.3455603617637, -657.4889446465938, 81.87255326663276, -272.3385812235033, -644.6444092693392, -411.7994065173898, 785.8807770265184, -26.930347005778398, -506.1782795626611, 846.1713933937774, 541.6030529376567, -435.9637948650587, -175.91895590193147, -332.8165133732058, -98.28105529852579, -239.5944139609543, -166.6275499328644, -319.717243655472, 187.85837630889046, -281.4655760863032, -7.0278464140839745, -409.3638017148796, -53.90875913749065, -460.3812508296325, -831.7722678966371, -826.0203918779586, -292.0789460424049, -551.9945604431957, -261.8320751158184, -203.6071082885956, -503.3824754891619, -511.60698229007403, -623.8540187378269, -290.08765069047257, -251.2742500375142, 657.9387986309505, -353.4672434036, 394.80065739643175, -174.8645730886492, -80.78004497825746, -408.6471072611917, 512.1067195111677, -139.77352123554326, 650.8257892304282, -287.50368050112934, -5.63822338589172, -420.31129727510097, -383.18970481057795, 349.51002502279465, -414.3736064185568, -191.5755902176809, -405.6569030035777, 561.703214755927, -391.18924065898733, 159.41456242987482, -518.3010014500265, 302.58349974413926, -276.32055383160565, -20.1213722560993, -647.1556566490033, -788.1185461666057, -247.86838459115035, -566.6077106342349, -562.0385023571181, -656.7413072518677, -544.9135890369208, -165.70307051456706, -604.5934858873771, -145.50129107057188, -12.181397487148864, -361.59208483513623], "episode_lengths": [140, 114, 175, 136, 113, 120, 125, 125, 147, 149, 114, 111, 101, 96, 106, 138, 111, 119, 133, 130, 126, 79, 118, 113, 116, 119, 114, 120, 119, 113, 115, 136, 106, 117, 118, 106, 102, 119, 143, 143, 114, 127, 110, 120, 116, 104, 116, 116, 113, 102, 105, 95, 118, 120, 122, 99, 114, 133, 128, 119, 116, 119, 116, 118, 113, 118, 118, 107, 111, 118, 121, 113, 123, 37, 103, 118, 121, 121, 106, 52, 115, 127, 105, 130, 118, 122, 119, 103, 123, 111, 110, 116, 116, 121, 119, 100, 129, 127, 119, 118], "policy_AGENT-3_reward": [218.07206024579722, -65.95967490041114, 327.9346596905772, 149.3600913144573, -151.29173207839986, 107.3106428358627, -46.62353903005133, 148.1260615832324, -57.708670173023194, 248.25138878047548, -115.7038924410802, -122.21341095998143, -1.730917698898307, -58.62773556504712, -87.47940733828298, 170.07120914890152, -78.6583498481103, -137.82600760404742, 206.3893218552165, -267.1321023710938, 142.0110610949918, -13.635628807133045, 166.37319611608143, -124.6019554355626, -148.29485526614548, -148.312913545115, -156.4362278696524, -139.650190471523, -121.24869717885814, -160.89218322113612, -156.10330033735914, -30.400852947002996, -7.731843839237112, -154.56668856280106, -104.70534521006482, 189.23557373552734, -8.85740014337585, -118.13266884601722, 210.68275726724795, 169.7630785042712, -134.53688903700566, 1.695306334792086, -35.60801688006213, -15.57443849327085, -54.94487480719406, -48.695164572828254, -68.83856851247452, 104.20887469069118, -97.67962483563561, -3.171529251088086, -115.18620006962487, 1.0989412915545032, -149.20661018502102, -199.82184564398122, -185.15379721585862, -36.770807622471516, -137.17385441635136, -110.56200056290419, -92.91652047455997, -119.07008847910186, -118.24371844067439, -154.16130057482957, -41.03900176939102, -57.92766601287751, 200.5978115294577, -135.04200075971175, 132.1087028459769, -45.55430650583289, -62.0530314548775, -51.30072598521436, 147.94138862601096, -40.36146649283169, 192.2432597078198, -45.3293961166371, 0.5737039975226417, -108.80534753800954, -128.56416081412632, 117.20426801268427, -148.68400173899062, -20.4867983555885, -144.27652373572994, 206.52148916530152, -89.70554444408835, 32.76878018971585, -172.031311738674, 103.86244452777967, -78.11261208312565, -6.15647917528138, -161.27972271967093, -185.16398770370208, -32.4353262828405, -130.32599384589207, -95.22076753848282, -146.76923676822324, -131.1629167898446, 4.501426171007417, -153.03868109364697, -81.85314805840564, -41.96563685691171, -103.91023078697609], "policy_AGENT-0_reward": [168.3463406296596, -57.11594598349856, 342.4116300310298, 132.52011810627593, -194.01977645541652, 75.41187969064846, 32.157443997431834, 112.0182772577559, 14.121638687930108, 362.5447785375789, -112.632592198565, -106.28969149674707, 30.19073996805022, -82.58579537630287, -65.8577444460283, 229.26953305198612, -134.15930968926202, -88.46144196548084, 202.2995611976431, -59.143084283179576, 108.05645986462936, -51.92406681701059, 123.70885757928696, -167.3398529075571, -114.27966828331574, -147.0783659287564, -118.5025535190189, -180.93264931512644, -118.7972646070042, -136.54162126236722, -166.32058118399502, 51.241746111352676, -107.14544661656497, -195.28515776235096, -104.35930381330711, 215.4788864443437, 19.992903071459843, -161.67733611504178, 201.54704723489087, 94.45176903023108, -63.493959309846, -93.37807882547534, -85.61077276351159, -32.92722352486678, -101.93056149098182, -48.7422207371299, -113.25150149556819, 14.346766474940708, -136.652190638084, 23.30930632263633, -65.79616699089618, -24.299187677993274, -61.60633316943983, -242.08469231528127, -240.91028977824345, -121.11277980327642, -140.82351988427672, -16.66588858101743, -31.0124949075182, -159.07377047459246, -112.97024760399785, -186.81512054047516, -82.75566584076512, -95.07414394172406, 136.34089033968397, -47.328920910204076, 89.89092269364123, -45.22022932871711, 7.051043977856608, -133.8633097031415, 122.81463377059356, -32.8620219855464, 153.85636995464236, -98.37498680196356, 20.817281601382394, -101.3901793535591, -67.10583035207368, 78.80560007013268, -72.19889913790465, -75.34984325708243, -186.4998465368002, 74.22161759925467, -82.93171069580617, 40.86368912367872, -66.64901866223713, 66.23610349997743, -120.22059433109376, 20.62770973004939, -190.99759900737124, -185.57954061107463, -91.51263118866663, -178.0321133475196, -135.00743746952304, -187.4989395334718, -169.1145141753458, -100.0044654367536, -177.67254645380012, -12.593314896430712, 13.331758281408284, -122.9076522935656], "policy_AGENT-1_reward": [213.78987123930182, -54.631649313392955, 353.25019831640816, 135.72879341278087, -126.4902954867245, 76.42292272196222, 74.9440784700504, 113.68420021719186, 59.28853826106701, 362.3997690070743, -161.1052965075696, -118.64453474251053, 30.000860774023586, -82.7477691049744, -66.06411007045998, 233.08168702693112, -134.12152816192207, -126.52809172535737, 206.3688897593186, -251.4589964766492, 110.4568125671923, -52.22348769486334, 173.291551366259, -119.39810650687787, -137.9298807781311, -134.8085446096511, -141.84917018999568, -133.94998815165974, -118.4244864959555, -200.8145737541497, -166.16031903758852, 91.46228795501342, -107.18789352273286, -146.88890191716794, -82.83452937045095, 215.21271953373233, 20.022448822591958, -113.18284564891054, 213.6763138557384, 107.45087979460953, -173.87888592058005, -85.8863067990129, -85.70172304674063, -34.15311063377408, -56.25856931697768, -48.876225546124914, -68.65879192364476, 14.220833451450616, -23.320247404922416, 23.35408676923264, -65.91358393124507, -24.250016840218564, -187.40915670086667, -194.62186323395812, -194.8402736127864, -121.25007361864584, -132.62275794028065, -24.290501049152468, 13.202963286397226, -112.60283412489308, -161.50001225766275, -138.61412172733498, -82.75796121917769, -49.02689582609236, 136.13973446301546, -123.21509050132104, 89.76073514898381, -38.2846813281223, -32.277393343060936, -134.19109612950967, 124.13732284373339, -32.73998051372209, 156.1924238013451, -98.48417177683655, 20.826471306098767, -101.519230739562, -119.8485774964465, 79.50991886285588, -120.72772251218377, -75.39597359484853, -37.22602007473367, 122.21584025256492, -83.0017103822741, 83.28504105476324, -212.42057781735213, 70.3872369991597, -38.77887040565534, 20.756644932537867, -143.4951727479554, -185.7272543728145, -91.56614693957667, -129.04578518341242, -165.64184601570307, -160.94887753561284, -122.58292431284325, -99.9863594137715, -133.82458631473358, 30.830494321801766, 58.40358034657154, -77.1735500975136], "policy_AGENT-2_reward": [197.23627858719195, -57.688525708054364, 341.8485022231554, 131.38159379699675, -127.04206262072353, 70.48916250882131, -46.60361570977688, 106.06978090541381, -57.76494255887323, 349.5675409837192, -113.30865100684993, -106.8503879389099, -50.05001211975177, -33.557933709550355, -135.2122354915156, 231.21408826467186, -182.2824966441424, -89.0297344886728, 207.065591279414, -59.69953173141435, 104.53483462661428, -13.630698990778505, 167.26064641808125, -119.60028993364496, -114.82873985958364, -147.662787211458, -167.1611433736579, -139.52373708646473, -119.48987334774306, -137.09718212411047, -168.90474408765112, -30.43062785273033, -50.27339724496814, -147.90366102701907, -119.90022812356682, 165.95359731291478, -58.088298756454314, -113.18542895269127, 220.26527503590043, 169.93732560854565, -64.0540605976268, 1.6501233877647863, -125.89600068289165, -15.626282646614124, -26.460408345800683, -20.313939076781367, -68.96838172378395, 55.081901691807595, -23.813513207661245, -50.519710254864776, -162.4678507231137, -6.458495910833271, -62.15915077430521, -195.24386670341676, -205.1160312710697, -12.94528499801131, -141.37442820228716, -110.31368492274447, -92.88105619291474, -112.63578241057462, -118.89300398773855, -144.26347589518815, -83.53502186113896, -49.245544256820445, 184.86036229879338, -47.88123123236301, 83.0402967078295, -45.80535592597689, 6.499335841824532, -89.29197544332607, 117.21337427082986, -33.8100522434432, 148.5337357666206, -45.315125805692006, -47.85568029089545, -108.59653964397033, -67.67113614793172, 73.99023807712196, -72.76298302947752, -20.34297501016149, -37.65451265631385, 158.74426773880631, -135.55027513681856, 2.49705206171695, -67.20009323176336, 62.0977147172226, -39.20847701173053, -55.349247743405115, -151.383162174006, -231.64776347901437, -32.354280180066574, -129.2038182574101, -166.16845133340942, -161.52425341455947, -122.0532337588875, 29.786328164950667, -140.05767202519604, -81.88532243753718, -41.951099258217, -57.600651657080775]}, "sampler_perf": {"mean_env_wait_ms": 55.16294717819493, "mean_raw_obs_processing_ms": 2.3566335468400106, "mean_inference_ms": 2.421885940149927, "mean_action_processing_ms": 0.14377035243741418}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 88200, "timers": {"sample_time_ms": 91392.326, "sample_throughput": 45.956, "load_time_ms": 15.589, "load_throughput": 269422.414, "learn_time_ms": 9072.927, "learn_throughput": 462.916, "update_time_ms": 8.007}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 16.218313217163086, "policy_loss": -0.023727620020508766, "vf_loss": 16.234615325927734, "vf_explained_var": 0.9676112532615662, "kl": 0.01649446040391922, "entropy": 1.2207528352737427, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 14.149285316467285, "policy_loss": -0.0208665132522583, "vf_loss": 14.161713600158691, "vf_explained_var": 0.9628811478614807, "kl": 0.018752845004200935, "entropy": 1.1989470720291138, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 10.904094696044922, "policy_loss": -0.03136371448636055, "vf_loss": 10.926534652709961, "vf_explained_var": 0.972517192363739, "kl": 0.013220823369920254, "entropy": 1.2036290168762207, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 8.66240119934082, "policy_loss": -0.02965899556875229, "vf_loss": 8.6824312210083, "vf_explained_var": 0.9790191650390625, "kl": 0.021395426243543625, "entropy": 1.1283977031707764, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 88200, "num_steps_trained": 88200}, "done": false, "episodes_total": 744, "training_iteration": 21, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-52-15", "timestamp": 1624211535, "time_this_iter_s": 97.4568521976471, "time_total_s": 2122.5322654247284, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd404254c20>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40428c290>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdf80>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bda70>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdc20>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdf80>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bda70>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdc20>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdf80>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bda70>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdc20>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdf80>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bda70>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdc20>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd40428ce60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2122.5322654247284, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 56.242957746478865, "ram_util_percent": 87.96971830985915}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1365.44499026117, "episode_reward_min": -830.8782353080608, "episode_reward_mean": -126.98847693491716, "episode_len_mean": 118.58, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-3": -267.1321023710938, "AGENT-0": -234.2275165068041, "AGENT-1": -251.4589964766492, "AGENT-2": -232.22363256821848}, "policy_reward_max": {"AGENT-3": 343.21826932245943, "AGENT-0": 362.5447785375789, "AGENT-1": 362.3997690070743, "AGENT-2": 368.26840565062076}, "policy_reward_mean": {"AGENT-3": -31.31810884678521, "AGENT-0": -36.136462869760074, "AGENT-1": -27.60201028485676, "AGENT-2": -31.931894933515036}, "custom_metrics": {"mean_ego_speed_mean": 42.26003250000001, "mean_ego_speed_min": 35.96925, "mean_ego_speed_max": 48.39075, "distance_travelled_mean": 107.1685425, "distance_travelled_min": 36.84825000000001, "distance_travelled_max": 124.84425}, "hist_stats": {"episode_reward": [647.5301085441919, -197.20268572488934, 349.3896988608893, -173.64394367955083, 229.98458501485248, -62.812743827455385, 1206.2512033512742, -63.773587218796536, 379.5516057382168, -85.44721144006317, 1195.240134581472, -201.37529594181393, -310.11816381715914, -388.0076855760848, -430.8339229196131, 86.8756216011181, 340.74603126981157, -564.6748308295549, 661.8789967068677, -404.67038204753146, 474.1862756455794, -337.49068318022535, -351.33194721297787, -491.37386736723477, -726.095714846872, -429.2710695680225, -47.41761451899105, -534.8516374964554, -608.4723774695707, -568.0883279849018, -197.7726037305096, -531.8690159521512, -454.34899566604264, -700.8032484935463, -830.8782353080608, 512.1067195111677, -139.77352123554326, 650.8257892304282, -287.50368050112934, -5.63822338589172, -420.31129727510097, -383.18970481057795, 349.51002502279465, -414.3736064185568, -191.5755902176809, -405.6569030035777, 561.703214755927, -391.18924065898733, 159.41456242987482, -518.3010014500265, 302.58349974413926, -276.32055383160565, -20.1213722560993, -647.1556566490033, -788.1185461666057, -247.86838459115035, -566.6077106342349, -562.0385023571181, -656.7413072518677, -544.9135890369208, -165.70307051456706, -604.5934858873771, -145.50129107057188, -12.181397487148864, -361.59208483513623, 797.4445507019506, -235.3957959053569, 1365.44499026117, 548.9905966305114, -598.8438666412642, 329.63460775729425, 13.874367727653862, 479.8983199635937, -42.06343578289922, 1322.7634773088482, -502.7504321540648, -453.99802513814916, 8.410670923423709, -257.5192337558746, -354.6134973462869, 863.6365174924902, -529.2216843434373, -441.8452757835585, 822.1233640915924, -637.433714862337, 465.059168153428, -131.41388230978546, 630.6342514797085, -530.9402047836429, -515.3331441871757, -577.8626112949809, -583.9490949523247, -594.0565650247737, -477.96032162956124, -635.3455603617637, -657.4889446465938, 81.87255326663276, -272.3385812235033, -644.6444092693392, -411.7994065173898], "episode_lengths": [124, 109, 120, 106, 132, 131, 142, 128, 125, 108, 160, 131, 117, 117, 130, 128, 117, 123, 123, 103, 119, 109, 118, 106, 116, 108, 151, 114, 119, 117, 142, 118, 115, 114, 123, 121, 113, 123, 37, 103, 118, 121, 121, 106, 52, 115, 127, 105, 130, 118, 122, 119, 103, 123, 111, 110, 116, 116, 121, 119, 100, 129, 127, 119, 118, 140, 114, 175, 136, 113, 120, 125, 125, 147, 149, 114, 111, 101, 96, 106, 138, 111, 119, 133, 130, 126, 79, 118, 113, 116, 119, 114, 120, 119, 113, 115, 136, 106, 117, 118], "policy_AGENT-3_reward": [182.9900781407932, -51.576141125416356, 113.10034771779432, -11.55302634558812, 89.81894344525176, -72.8119373657452, 343.21826932245943, -46.279384520922896, 119.70172229002422, -27.96227601181897, 167.62911369159582, -26.31286326985659, -65.01630359598876, -113.57063299473948, -30.868808608834218, 41.780998158288135, 122.67704361621274, -190.60644351997092, 187.03496629509846, -115.79920948364389, 134.66662468261475, -34.76199652285397, -98.25140797968642, -78.32107204666121, -182.02527980779266, -113.09417972312043, -50.599026968681976, -138.95786809179026, -128.02758763417202, -174.15721833200416, -96.20295417379864, -131.45788465573818, -102.6126680383573, -144.9500410359377, -194.99381987127103, 147.94138862601096, -40.36146649283169, 192.2432597078198, -45.3293961166371, 0.5737039975226417, -108.80534753800954, -128.56416081412632, 117.20426801268427, -148.68400173899062, -20.4867983555885, -144.27652373572994, 206.52148916530152, -89.70554444408835, 32.76878018971585, -172.031311738674, 103.86244452777967, -78.11261208312565, -6.15647917528138, -161.27972271967093, -185.16398770370208, -32.4353262828405, -130.32599384589207, -95.22076753848282, -146.76923676822324, -131.1629167898446, 4.501426171007417, -153.03868109364697, -81.85314805840564, -41.96563685691171, -103.91023078697609, 218.07206024579722, -65.95967490041114, 327.9346596905772, 149.3600913144573, -151.29173207839986, 107.3106428358627, -46.62353903005133, 148.1260615832324, -57.708670173023194, 248.25138878047548, -115.7038924410802, -122.21341095998143, -1.730917698898307, -58.62773556504712, -87.47940733828298, 170.07120914890152, -78.6583498481103, -137.82600760404742, 206.3893218552165, -267.1321023710938, 142.0110610949918, -13.635628807133045, 166.37319611608143, -124.6019554355626, -148.29485526614548, -148.312913545115, -156.4362278696524, -139.650190471523, -121.24869717885814, -160.89218322113612, -156.10330033735914, -30.400852947002996, -7.731843839237112, -154.56668856280106, -104.70534521006482], "policy_AGENT-0_reward": [156.83356119485276, -50.04385556876272, 78.84032995652645, -47.94460361874572, 24.191770906787596, 40.56902220817983, 295.1068122699997, -8.3995144652933, 89.83277318292363, -19.610021417251332, 325.68243356804385, -56.11573359057278, -111.0170173690998, -85.08342121278801, -188.099870971764, -1.045250088306858, 42.166971080396884, -70.94042833439356, 186.7968372336731, -65.26662119694748, 114.2845635142732, -84.39469203159007, -138.71734592022213, -145.55452632453833, -188.6841232812872, -106.11109656387829, 7.373350391906605, -133.61794543499067, -169.43834150106844, -113.00625409148753, -24.87991094495673, -164.60535303199634, -148.67090100895473, -234.2275165068041, -232.44853691180344, 122.81463377059356, -32.8620219855464, 153.85636995464236, -98.37498680196356, 20.817281601382394, -101.3901793535591, -67.10583035207368, 78.80560007013268, -72.19889913790465, -75.34984325708243, -186.4998465368002, 74.22161759925467, -82.93171069580617, 40.86368912367872, -66.64901866223713, 66.23610349997743, -120.22059433109376, 20.62770973004939, -190.99759900737124, -185.57954061107463, -91.51263118866663, -178.0321133475196, -135.00743746952304, -187.4989395334718, -169.1145141753458, -100.0044654367536, -177.67254645380012, -12.593314896430712, 13.331758281408284, -122.9076522935656, 168.3463406296596, -57.11594598349856, 342.4116300310298, 132.52011810627593, -194.01977645541652, 75.41187969064846, 32.157443997431834, 112.0182772577559, 14.121638687930108, 362.5447785375789, -112.632592198565, -106.28969149674707, 30.19073996805022, -82.58579537630287, -65.8577444460283, 229.26953305198612, -134.15930968926202, -88.46144196548084, 202.2995611976431, -59.143084283179576, 108.05645986462936, -51.92406681701059, 123.70885757928696, -167.3398529075571, -114.27966828331574, -147.0783659287564, -118.5025535190189, -180.93264931512644, -118.7972646070042, -136.54162126236722, -166.32058118399502, 51.241746111352676, -107.14544661656497, -195.28515776235096, -104.35930381330711], "policy_AGENT-1_reward": [158.1211136683825, -44.96393493527553, 81.6912521490952, -56.766025686166174, 67.56770488133131, 42.182720432535326, 258.6916829880008, 37.2227875916103, 91.24913827631127, -17.694402939527134, 333.6601816712123, -101.3497158259836, -111.08326628589805, -103.71412999509471, -181.0073676078714, 5.68854187821727, 91.73465446760613, -70.9043264069725, 146.2559409863686, -65.25403197390966, 116.25349235087123, -84.35486918791457, -56.91803838409432, -145.703472319186, -175.7555740495876, -103.38832271326154, 46.46796684656386, -128.10320942837905, -155.28601590631965, -167.36283126357966, 19.410473677551416, -118.0335577008559, -101.65874883712664, -185.50218206459402, -187.91260078940658, 124.13732284373339, -32.73998051372209, 156.1924238013451, -98.48417177683655, 20.826471306098767, -101.519230739562, -119.8485774964465, 79.50991886285588, -120.72772251218377, -75.39597359484853, -37.22602007473367, 122.21584025256492, -83.0017103822741, 83.28504105476324, -212.42057781735213, 70.3872369991597, -38.77887040565534, 20.756644932537867, -143.4951727479554, -185.7272543728145, -91.56614693957667, -129.04578518341242, -165.64184601570307, -160.94887753561284, -122.58292431284325, -99.9863594137715, -133.82458631473358, 30.830494321801766, 58.40358034657154, -77.1735500975136, 213.78987123930182, -54.631649313392955, 353.25019831640816, 135.72879341278087, -126.4902954867245, 76.42292272196222, 74.9440784700504, 113.68420021719186, 59.28853826106701, 362.3997690070743, -161.1052965075696, -118.64453474251053, 30.000860774023586, -82.7477691049744, -66.06411007045998, 233.08168702693112, -134.12152816192207, -126.52809172535737, 206.3688897593186, -251.4589964766492, 110.4568125671923, -52.22348769486334, 173.291551366259, -119.39810650687787, -137.9298807781311, -134.8085446096511, -141.84917018999568, -133.94998815165974, -118.4244864959555, -200.8145737541497, -166.16031903758852, 91.46228795501342, -107.18789352273286, -146.88890191716794, -82.83452937045095], "policy_AGENT-2_reward": [149.58535554016348, -50.618754095434646, 75.75776903747293, -57.38028802905092, 48.40616578148176, -72.75254910242518, 309.234438770815, -46.31747582419085, 78.7679719889581, -20.180511071465872, 368.26840565062076, -17.596983255400797, -23.00157656617251, -85.63950137346228, -30.85787573114341, 40.4513316529195, 84.1673621055954, -232.22363256821848, 141.79125219172826, -158.35051939303037, 108.98159509781979, -133.97912543786651, -57.44515492897506, -121.79479667684876, -179.6307377082039, -106.6774705677623, -50.65990478877947, -134.17261454129584, -155.72043242801033, -113.56202429783062, -96.10021228930567, -117.77222056356095, -101.40667778160396, -136.12350888621086, -215.52327773557926, 117.21337427082986, -33.8100522434432, 148.5337357666206, -45.315125805692006, -47.85568029089545, -108.59653964397033, -67.67113614793172, 73.99023807712196, -72.76298302947752, -20.34297501016149, -37.65451265631385, 158.74426773880631, -135.55027513681856, 2.49705206171695, -67.20009323176336, 62.0977147172226, -39.20847701173053, -55.349247743405115, -151.383162174006, -231.64776347901437, -32.354280180066574, -129.2038182574101, -166.16845133340942, -161.52425341455947, -122.0532337588875, 29.786328164950667, -140.05767202519604, -81.88532243753718, -41.951099258217, -57.600651657080775, 197.23627858719195, -57.688525708054364, 341.8485022231554, 131.38159379699675, -127.04206262072353, 70.48916250882131, -46.60361570977688, 106.06978090541381, -57.76494255887323, 349.5675409837192, -113.30865100684993, -106.8503879389099, -50.05001211975177, -33.557933709550355, -135.2122354915156, 231.21408826467186, -182.2824966441424, -89.0297344886728, 207.065591279414, -59.69953173141435, 104.53483462661428, -13.630698990778505, 167.26064641808125, -119.60028993364496, -114.82873985958364, -147.662787211458, -167.1611433736579, -139.52373708646473, -119.48987334774306, -137.09718212411047, -168.90474408765112, -30.43062785273033, -50.27339724496814, -147.90366102701907, -119.90022812356682]}, "sampler_perf": {"mean_env_wait_ms": 55.10627667825381, "mean_raw_obs_processing_ms": 2.3522797496471464, "mean_inference_ms": 2.415584184435783, "mean_action_processing_ms": 0.14356874244872916}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 92400, "timers": {"sample_time_ms": 91207.518, "sample_throughput": 46.049, "load_time_ms": 15.598, "load_throughput": 269267.57, "learn_time_ms": 9062.98, "learn_throughput": 463.424, "update_time_ms": 8.054}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 13.941337585449219, "policy_loss": -0.02912338264286518, "vf_loss": 13.962814331054688, "vf_explained_var": 0.9745664596557617, "kl": 0.016992216929793358, "entropy": 1.1749773025512695, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 18.290361404418945, "policy_loss": -0.03199588879942894, "vf_loss": 18.316131591796875, "vf_explained_var": 0.9556580781936646, "kl": 0.01383344829082489, "entropy": 1.1705690622329712, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 8.811385154724121, "policy_loss": -0.03758611902594566, "vf_loss": 8.83996295928955, "vf_explained_var": 0.9792349934577942, "kl": 0.013346455991268158, "entropy": 1.221561074256897, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 8.497060775756836, "policy_loss": -0.02922784350812435, "vf_loss": 8.51587963104248, "vf_explained_var": 0.9812058210372925, "kl": 0.015419998206198215, "entropy": 1.1064668893814087, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 92400, "num_steps_trained": 92400}, "done": false, "episodes_total": 779, "training_iteration": 22, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-53-52", "timestamp": 1624211632, "time_this_iter_s": 96.94998073577881, "time_total_s": 2219.482246160507, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40445a830>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd4043e8dd0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4043e89e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8cb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8f80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40419f050>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4043e89e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8cb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8f80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40419f050>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4043e89e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8cb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8f80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40419f050>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4043e89e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8cb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4043e8f80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40419f050>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd4042b8f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2219.482246160507, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 58.14710144927537, "ram_util_percent": 87.98695652173913}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1322.7634773088482, "episode_reward_min": -830.8782353080608, "episode_reward_mean": -157.1986443073398, "episode_len_mean": 116.66, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-3": -267.1321023710938, "AGENT-0": -234.2275165068041, "AGENT-2": -232.22363256821848, "AGENT-1": -251.4589964766492}, "policy_reward_max": {"AGENT-3": 343.21826932245943, "AGENT-0": 362.5447785375789, "AGENT-2": 368.26840565062076, "AGENT-1": 362.3997690070743}, "policy_reward_mean": {"AGENT-3": -38.11204410341347, "AGENT-0": -43.92392741976878, "AGENT-2": -41.34207606901044, "AGENT-1": -33.82059671514705}, "custom_metrics": {"mean_ego_speed_mean": 42.749787500000004, "mean_ego_speed_min": 35.96925, "mean_ego_speed_max": 48.927749999999996, "distance_travelled_mean": 106.93648249999998, "distance_travelled_min": 40.41975, "distance_travelled_max": 124.856}, "hist_stats": {"episode_reward": [-246.94036852309884, -69.20763087007185, -206.60126163977262, 577.6255132213909, 8.515171985008472, -91.61107908753866, -8.283632026274923, -241.78741845188193, 485.94995301308387, -269.52156948158887, 605.2898128010139, 43.715936215504335, 421.19238038862846, -423.0959240775108, -26.07265010346868, -444.2974873326826, 482.5567790309995, -312.3770566365349, 300.75653195683793, -233.96184253318253, 2.35587659270318, -400.11605315885333, -318.299131970603, -172.530964936467, 228.53558363456406, -355.95577295200025, -705.0643451204378, -513.0767004365813, -561.6682112835637, -623.2943349743051, -136.93340748680197, -450.085223544211, -720.770004427395, -767.9161869152613, -745.541188006226, -634.1649454119265, -498.01234499395036, 479.8983199635937, -42.06343578289922, 1322.7634773088482, -502.7504321540648, -453.99802513814916, 8.410670923423709, -257.5192337558746, -354.6134973462869, 863.6365174924902, -529.2216843434373, -441.8452757835585, 822.1233640915924, -637.433714862337, 465.059168153428, -131.41388230978546, 630.6342514797085, -530.9402047836429, -515.3331441871757, -577.8626112949809, -583.9490949523247, -594.0565650247737, -477.96032162956124, -635.3455603617637, -657.4889446465938, 81.87255326663276, -272.3385812235033, -644.6444092693392, -411.7994065173898, 647.5301085441919, -197.20268572488934, 349.3896988608893, -173.64394367955083, 229.98458501485248, -62.812743827455385, 1206.2512033512742, -63.773587218796536, 379.5516057382168, -85.44721144006317, 1195.240134581472, -201.37529594181393, -310.11816381715914, -388.0076855760848, -430.8339229196131, 86.8756216011181, 340.74603126981157, -564.6748308295549, 661.8789967068677, -404.67038204753146, 474.1862756455794, -337.49068318022535, -351.33194721297787, -491.37386736723477, -726.095714846872, -429.2710695680225, -47.41761451899105, -534.8516374964554, -608.4723774695707, -568.0883279849018, -197.7726037305096, -531.8690159521512, -454.34899566604264, -700.8032484935463, -830.8782353080608], "episode_lengths": [115, 102, 123, 101, 102, 119, 102, 114, 118, 116, 118, 129, 130, 109, 100, 115, 123, 103, 101, 118, 126, 110, 98, 41, 113, 108, 118, 116, 115, 116, 103, 112, 104, 122, 105, 112, 117, 125, 147, 149, 114, 111, 101, 96, 106, 138, 111, 119, 133, 130, 126, 79, 118, 113, 116, 119, 114, 120, 119, 113, 115, 136, 106, 117, 118, 124, 109, 120, 106, 132, 131, 142, 128, 125, 108, 160, 131, 117, 117, 130, 128, 117, 123, 123, 103, 119, 109, 118, 106, 116, 108, 151, 114, 119, 117, 142, 118, 115, 114, 123], "policy_AGENT-3_reward": [-34.9904276362506, -31.924312096538397, -87.76530871210579, 134.41911837644327, -5.6774288634596495, 7.373098822887121, -9.373624710807732, -92.80006624380118, 143.19508792701757, -35.032248586455516, 158.1458436221758, -30.397553816914684, 141.6745423264399, -125.36189195300325, -14.604624422517398, -126.56346691499948, 161.77665457196454, -104.5146183185334, 85.6851584060312, -70.29714435449287, 15.802103459048134, -114.68823783585906, -85.62575640128024, -14.365488282180804, 110.80874375602332, -101.11745475313329, -162.07691573217267, -132.2173156210351, -125.24742716843004, -127.41632485412808, 12.611729901544452, -104.3890991574343, -194.87004876825102, -180.20178902317863, -151.79115673984413, -160.53995808596426, -128.25593998163504, 148.1260615832324, -57.708670173023194, 248.25138878047548, -115.7038924410802, -122.21341095998143, -1.730917698898307, -58.62773556504712, -87.47940733828298, 170.07120914890152, -78.6583498481103, -137.82600760404742, 206.3893218552165, -267.1321023710938, 142.0110610949918, -13.635628807133045, 166.37319611608143, -124.6019554355626, -148.29485526614548, -148.312913545115, -156.4362278696524, -139.650190471523, -121.24869717885814, -160.89218322113612, -156.10330033735914, -30.400852947002996, -7.731843839237112, -154.56668856280106, -104.70534521006482, 182.9900781407932, -51.576141125416356, 113.10034771779432, -11.55302634558812, 89.81894344525176, -72.8119373657452, 343.21826932245943, -46.279384520922896, 119.70172229002422, -27.96227601181897, 167.62911369159582, -26.31286326985659, -65.01630359598876, -113.57063299473948, -30.868808608834218, 41.780998158288135, 122.67704361621274, -190.60644351997092, 187.03496629509846, -115.79920948364389, 134.66662468261475, -34.76199652285397, -98.25140797968642, -78.32107204666121, -182.02527980779266, -113.09417972312043, -50.599026968681976, -138.95786809179026, -128.02758763417202, -174.15721833200416, -96.20295417379864, -131.45788465573818, -102.6126680383573, -144.9500410359377, -194.99381987127103], "policy_AGENT-0_reward": [-117.71253449809939, 20.775006344415814, -40.071598770539225, 140.84680224958262, 33.83987672158079, -78.78281654348322, 27.502702985606568, -49.93303876217378, 116.31993806829178, -126.87553684937743, 129.99253404425838, 29.331335855840088, 71.18195704108348, -65.13253159431217, 25.938833634560872, -97.92772419276471, 78.46726583955825, -76.67210708906308, 89.34244863123901, -47.50261985972422, -23.7505526929247, -87.14442646969917, -101.71555346290445, -71.9502360094208, 23.315351203045132, -78.43288995982178, -212.78026137100926, -159.0966079661459, -177.8246182983093, -206.8567854190592, -94.04119852248874, -147.5216452437324, -136.31857496709577, -218.09881847222292, -197.8161994570209, -160.42615112455445, -154.4327119043262, 112.0182772577559, 14.121638687930108, 362.5447785375789, -112.632592198565, -106.28969149674707, 30.19073996805022, -82.58579537630287, -65.8577444460283, 229.26953305198612, -134.15930968926202, -88.46144196548084, 202.2995611976431, -59.143084283179576, 108.05645986462936, -51.92406681701059, 123.70885757928696, -167.3398529075571, -114.27966828331574, -147.0783659287564, -118.5025535190189, -180.93264931512644, -118.7972646070042, -136.54162126236722, -166.32058118399502, 51.241746111352676, -107.14544661656497, -195.28515776235096, -104.35930381330711, 156.83356119485276, -50.04385556876272, 78.84032995652645, -47.94460361874572, 24.191770906787596, 40.56902220817983, 295.1068122699997, -8.3995144652933, 89.83277318292363, -19.610021417251332, 325.68243356804385, -56.11573359057278, -111.0170173690998, -85.08342121278801, -188.099870971764, -1.045250088306858, 42.166971080396884, -70.94042833439356, 186.7968372336731, -65.26662119694748, 114.2845635142732, -84.39469203159007, -138.71734592022213, -145.55452632453833, -188.6841232812872, -106.11109656387829, 7.373350391906605, -133.61794543499067, -169.43834150106844, -113.00625409148753, -24.87991094495673, -164.60535303199634, -148.67090100895473, -234.2275165068041, -232.44853691180344], "policy_AGENT-2_reward": [-71.70816962689021, -78.66635697254391, -87.75314442190835, 161.82535541417434, -53.18346827248834, -31.81480010029407, -53.96966329933023, -6.815049075929988, 110.01510236852866, -79.10006136488926, 154.36425669025869, -30.41015498660523, 92.35086634875165, -167.48890545243694, -63.32024402495446, -98.4873392061071, 115.91253457837558, -54.360317837308536, 36.46064464547679, -69.87395303415637, 15.811589174310903, -87.69260122045371, -28.930239759210092, -14.294361897586782, 71.17604032840693, -78.99574762735361, -166.21056219017382, -110.435797860914, -129.19594429810368, -162.1693911200297, 38.47386524675771, -99.04142872234235, -195.19299230449877, -196.30736437789116, -198.16503974022635, -160.9868833611589, -107.50114824090207, 106.06978090541381, -57.76494255887323, 349.5675409837192, -113.30865100684993, -106.8503879389099, -50.05001211975177, -33.557933709550355, -135.2122354915156, 231.21408826467186, -182.2824966441424, -89.0297344886728, 207.065591279414, -59.69953173141435, 104.53483462661428, -13.630698990778505, 167.26064641808125, -119.60028993364496, -114.82873985958364, -147.662787211458, -167.1611433736579, -139.52373708646473, -119.48987334774306, -137.09718212411047, -168.90474408765112, -30.43062785273033, -50.27339724496814, -147.90366102701907, -119.90022812356682, 149.58535554016348, -50.618754095434646, 75.75776903747293, -57.38028802905092, 48.40616578148176, -72.75254910242518, 309.234438770815, -46.31747582419085, 78.7679719889581, -20.180511071465872, 368.26840565062076, -17.596983255400797, -23.00157656617251, -85.63950137346228, -30.85787573114341, 40.4513316529195, 84.1673621055954, -232.22363256821848, 141.79125219172826, -158.35051939303037, 108.98159509781979, -133.97912543786651, -57.44515492897506, -121.79479667684876, -179.6307377082039, -106.6774705677623, -50.65990478877947, -134.17261454129584, -155.72043242801033, -113.56202429783062, -96.10021228930567, -117.77222056356095, -101.40667778160396, -136.12350888621086, -215.52327773557926], "policy_AGENT-1_reward": [-22.52923676185888, 20.608031854594667, 8.988790264781178, 140.53423718119112, 33.53619239937572, 11.613438733351456, 27.55695299825648, -92.23926436997695, 116.41982464924607, -28.513722680866714, 162.7871784443216, 75.1923091631842, 115.985014672353, -65.11259507775827, 25.913384709442305, -121.31895701881116, 126.40032404110147, -76.83001339162989, 89.26828027409108, -46.28812528480921, -5.507263347731007, -110.59078763284114, -102.02758234720815, -71.92087874727862, 23.235448347088905, -97.4096806116913, -163.99660582708108, -111.32697898848633, -129.40022151872054, -126.85183358108753, -93.97780411261542, -99.1330504207014, -194.38838838754918, -173.3082150419681, -197.7687920691347, -152.2119528402487, -107.82254486708706, 113.68420021719186, 59.28853826106701, 362.3997690070743, -161.1052965075696, -118.64453474251053, 30.000860774023586, -82.7477691049744, -66.06411007045998, 233.08168702693112, -134.12152816192207, -126.52809172535737, 206.3688897593186, -251.4589964766492, 110.4568125671923, -52.22348769486334, 173.291551366259, -119.39810650687787, -137.9298807781311, -134.8085446096511, -141.84917018999568, -133.94998815165974, -118.4244864959555, -200.8145737541497, -166.16031903758852, 91.46228795501342, -107.18789352273286, -146.88890191716794, -82.83452937045095, 158.1211136683825, -44.96393493527553, 81.6912521490952, -56.766025686166174, 67.56770488133131, 42.182720432535326, 258.6916829880008, 37.2227875916103, 91.24913827631127, -17.694402939527134, 333.6601816712123, -101.3497158259836, -111.08326628589805, -103.71412999509471, -181.0073676078714, 5.68854187821727, 91.73465446760613, -70.9043264069725, 146.2559409863686, -65.25403197390966, 116.25349235087123, -84.35486918791457, -56.91803838409432, -145.703472319186, -175.7555740495876, -103.38832271326154, 46.46796684656386, -128.10320942837905, -155.28601590631965, -167.36283126357966, 19.410473677551416, -118.0335577008559, -101.65874883712664, -185.50218206459402, -187.91260078940658]}, "sampler_perf": {"mean_env_wait_ms": 55.05914134183506, "mean_raw_obs_processing_ms": 2.3482267692340586, "mean_inference_ms": 2.4093202660787774, "mean_action_processing_ms": 0.14338058878955626}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 96600, "timers": {"sample_time_ms": 90368.308, "sample_throughput": 46.476, "load_time_ms": 15.724, "load_throughput": 267101.677, "learn_time_ms": 9136.865, "learn_throughput": 459.676, "update_time_ms": 8.008}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 16.420757293701172, "policy_loss": -0.03562704846262932, "vf_loss": 16.449729919433594, "vf_explained_var": 0.9640689492225647, "kl": 0.01478719525039196, "entropy": 1.1900393962860107, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 16.16499900817871, "policy_loss": -0.027743635699152946, "vf_loss": 16.18593406677246, "vf_explained_var": 0.956713080406189, "kl": 0.015122774988412857, "entropy": 1.1525133848190308, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 16.529211044311523, "policy_loss": -0.033927127718925476, "vf_loss": 16.55484962463379, "vf_explained_var": 0.9548713564872742, "kl": 0.012279028072953224, "entropy": 1.1855202913284302, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 15.457457542419434, "policy_loss": -0.024045147001743317, "vf_loss": 15.472311019897461, "vf_explained_var": 0.9592751264572144, "kl": 0.013615909963846207, "entropy": 1.0791571140289307, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 96600, "num_steps_trained": 96600}, "done": false, "episodes_total": 816, "training_iteration": 23, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-55-31", "timestamp": 1624211731, "time_this_iter_s": 98.43080019950867, "time_total_s": 2317.913046360016, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40428c200>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40434b3b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd5f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdb90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd5f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdb90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd5f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdb90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd440>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd5f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdb90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd40419f320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2317.913046360016, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 55.968085106382986, "ram_util_percent": 88.1099290780142}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1195.240134581472, "episode_reward_min": -830.8782353080608, "episode_reward_mean": -150.99564896182858, "episode_len_mean": 114.68, "episodes_this_iter": 38, "policy_reward_min": {"AGENT-3": -194.99381987127103, "AGENT-0": -236.62751727369678, "AGENT-1": -197.7687920691347, "AGENT-2": -232.22363256821848}, "policy_reward_max": {"AGENT-3": 291.1396358983433, "AGENT-0": 325.68243356804385, "AGENT-1": 355.50246774898795, "AGENT-2": 368.26840565062076}, "policy_reward_mean": {"AGENT-3": -32.51907768110328, "AGENT-0": -48.461514089368045, "AGENT-1": -32.39049969251163, "AGENT-2": -37.62455749884556}, "custom_metrics": {"mean_ego_speed_mean": 43.12228500000001, "mean_ego_speed_min": 34.30175, "mean_ego_speed_max": 49.86275, "distance_travelled_mean": 105.26352749999998, "distance_travelled_min": 26.041999999999998, "distance_travelled_max": 124.856}, "hist_stats": {"episode_reward": [104.8935693683949, -250.63045089991786, 456.6467723332005, 60.54281115138396, 211.0861976886867, -74.8635447691411, -58.11628418604934, -235.2345805526173, 249.38747975871686, 111.60266550011046, 768.3641822275044, -550.0197438805267, 332.0805775665481, -470.29070900632223, 936.2931282719536, -176.54839762615768, 429.39808730842265, -376.36650337591317, 990.2203493478851, 216.9092214880533, 378.44244291142536, -83.17778334681599, 399.457138514338, -373.71576239332023, 1055.84191229163, -536.1872374192789, -346.29394858539075, -95.60727896647016, -250.5924160807091, -803.6523202189486, -402.3986472157232, -438.7744822647171, -571.7046438427332, -578.8681044354706, -607.8928963128587, -508.6966700984571, -364.86732599753987, -274.7199427711078, 1195.240134581472, -201.37529594181393, -310.11816381715914, -388.0076855760848, -430.8339229196131, 86.8756216011181, 340.74603126981157, -564.6748308295549, 661.8789967068677, -404.67038204753146, 474.1862756455794, -337.49068318022535, -351.33194721297787, -491.37386736723477, -726.095714846872, -429.2710695680225, -47.41761451899105, -534.8516374964554, -608.4723774695707, -568.0883279849018, -197.7726037305096, -531.8690159521512, -454.34899566604264, -700.8032484935463, -830.8782353080608, -246.94036852309884, -69.20763087007185, -206.60126163977262, 577.6255132213909, 8.515171985008472, -91.61107908753866, -8.283632026274923, -241.78741845188193, 485.94995301308387, -269.52156948158887, 605.2898128010139, 43.715936215504335, 421.19238038862846, -423.0959240775108, -26.07265010346868, -444.2974873326826, 482.5567790309995, -312.3770566365349, 300.75653195683793, -233.96184253318253, 2.35587659270318, -400.11605315885333, -318.299131970603, -172.530964936467, 228.53558363456406, -355.95577295200025, -705.0643451204378, -513.0767004365813, -561.6682112835637, -623.2943349743051, -136.93340748680197, -450.085223544211, -720.770004427395, -767.9161869152613, -745.541188006226, -634.1649454119265, -498.01234499395036], "episode_lengths": [122, 106, 115, 129, 118, 122, 102, 27, 118, 105, 132, 109, 128, 119, 129, 114, 116, 108, 138, 130, 116, 118, 116, 46, 158, 127, 114, 125, 113, 116, 110, 117, 116, 112, 121, 108, 108, 108, 160, 131, 117, 117, 130, 128, 117, 123, 123, 103, 119, 109, 118, 106, 116, 108, 151, 114, 119, 117, 142, 118, 115, 114, 123, 115, 102, 123, 101, 102, 119, 102, 114, 118, 116, 118, 129, 130, 109, 100, 115, 123, 103, 101, 118, 126, 110, 98, 41, 113, 108, 118, 116, 115, 116, 103, 112, 104, 122, 105, 112, 117], "policy_AGENT-3_reward": [70.41053283741506, -82.55254947415929, 168.83399577689428, -32.61420493568797, 83.73480282219712, -49.50044863835373, -28.703223925676415, -30.2266252709832, 106.2176445676441, 25.711539787392507, 200.2352375003194, -194.35234198513655, 120.37368513846513, -134.68173997627923, 265.67291658678147, -24.12232351821216, 112.90271834508266, -108.21218023168005, 265.2540456161233, 81.60170723532143, 146.88404460663799, -11.737144752390419, 134.16790458642768, -123.13646696123197, 291.1396358983433, -122.2679522942193, -121.60649042729378, -66.85224633195318, -73.48007657103803, -180.88637267309198, -88.3243062413485, -99.50313438880984, -89.83493615845411, -108.8589262567885, -116.46247662948622, -141.19820035350014, -90.60323132225939, -67.91851232141833, 167.62911369159582, -26.31286326985659, -65.01630359598876, -113.57063299473948, -30.868808608834218, 41.780998158288135, 122.67704361621274, -190.60644351997092, 187.03496629509846, -115.79920948364389, 134.66662468261475, -34.76199652285397, -98.25140797968642, -78.32107204666121, -182.02527980779266, -113.09417972312043, -50.599026968681976, -138.95786809179026, -128.02758763417202, -174.15721833200416, -96.20295417379864, -131.45788465573818, -102.6126680383573, -144.9500410359377, -194.99381987127103, -34.9904276362506, -31.924312096538397, -87.76530871210579, 134.41911837644327, -5.6774288634596495, 7.373098822887121, -9.373624710807732, -92.80006624380118, 143.19508792701757, -35.032248586455516, 158.1458436221758, -30.397553816914684, 141.6745423264399, -125.36189195300325, -14.604624422517398, -126.56346691499948, 161.77665457196454, -104.5146183185334, 85.6851584060312, -70.29714435449287, 15.802103459048134, -114.68823783585906, -85.62575640128024, -14.365488282180804, 110.80874375602332, -101.11745475313329, -162.07691573217267, -132.2173156210351, -125.24742716843004, -127.41632485412808, 12.611729901544452, -104.3890991574343, -194.87004876825102, -180.20178902317863, -151.79115673984413, -160.53995808596426, -128.25593998163504], "policy_AGENT-0_reward": [-18.9588988542085, -44.554335189434795, 80.97443875063081, 62.10436320376325, 42.84365094394258, -10.109831815142805, 22.257656293711218, -87.4114164359999, 15.21606805227595, 28.051656916674037, 185.4984411138404, -170.12015033198315, 43.53925307721724, -105.62186375931027, 221.54048327960797, -89.03811228181775, 90.94588244776071, -81.33960297848455, 235.83655004942776, 44.060147951728894, 63.346545897924145, -31.350312424210895, 58.35151364528877, -63.728394467393144, 64.07573859764912, -147.70010916965805, -53.53697498242989, 18.704827130729065, -42.26509167322697, -236.62751727369678, -87.97516045674053, -140.31267164045022, -217.18548565651943, -151.60988952058517, -165.8616819368124, -114.7196161546248, -93.3234813416722, -42.563610534207534, 325.68243356804385, -56.11573359057278, -111.0170173690998, -85.08342121278801, -188.099870971764, -1.045250088306858, 42.166971080396884, -70.94042833439356, 186.7968372336731, -65.26662119694748, 114.2845635142732, -84.39469203159007, -138.71734592022213, -145.55452632453833, -188.6841232812872, -106.11109656387829, 7.373350391906605, -133.61794543499067, -169.43834150106844, -113.00625409148753, -24.87991094495673, -164.60535303199634, -148.67090100895473, -234.2275165068041, -232.44853691180344, -117.71253449809939, 20.775006344415814, -40.071598770539225, 140.84680224958262, 33.83987672158079, -78.78281654348322, 27.502702985606568, -49.93303876217378, 116.31993806829178, -126.87553684937743, 129.99253404425838, 29.331335855840088, 71.18195704108348, -65.13253159431217, 25.938833634560872, -97.92772419276471, 78.46726583955825, -76.67210708906308, 89.34244863123901, -47.50261985972422, -23.7505526929247, -87.14442646969917, -101.71555346290445, -71.9502360094208, 23.315351203045132, -78.43288995982178, -212.78026137100926, -159.0966079661459, -177.8246182983093, -206.8567854190592, -94.04119852248874, -147.5216452437324, -136.31857496709577, -218.09881847222292, -197.8161994570209, -160.42615112455445, -154.4327119043262], "policy_AGENT-1_reward": [29.42319722696687, -78.42046639431987, 80.84642841846977, 63.47823874843042, 44.902172440051714, 34.16941614429313, 22.142439553169282, -87.39482722004269, 63.92571223427067, 30.342172956458892, 193.53163804586248, -92.49528037656017, 88.79345462961646, -123.7981423269239, 225.68900181295788, -39.45996907142545, 90.8192589469532, -104.92287093416799, 242.46606031036376, 1.2968735894022103, 63.214637744609476, -28.483355368010216, 106.82013396442946, -122.57235079218131, 355.50246774898795, -144.0183490774867, -117.0609185974268, 19.447752133515355, -67.02993440696093, -192.68541720732625, -88.45073705623548, -99.08626026457847, -89.27626505905253, -158.9171680971029, -159.14123455843782, -137.5052629913079, -87.05305040007971, -81.83306964393896, 333.6601816712123, -101.3497158259836, -111.08326628589805, -103.71412999509471, -181.0073676078714, 5.68854187821727, 91.73465446760613, -70.9043264069725, 146.2559409863686, -65.25403197390966, 116.25349235087123, -84.35486918791457, -56.91803838409432, -145.703472319186, -175.7555740495876, -103.38832271326154, 46.46796684656386, -128.10320942837905, -155.28601590631965, -167.36283126357966, 19.410473677551416, -118.0335577008559, -101.65874883712664, -185.50218206459402, -187.91260078940658, -22.52923676185888, 20.608031854594667, 8.988790264781178, 140.53423718119112, 33.53619239937572, 11.613438733351456, 27.55695299825648, -92.23926436997695, 116.41982464924607, -28.513722680866714, 162.7871784443216, 75.1923091631842, 115.985014672353, -65.11259507775827, 25.913384709442305, -121.31895701881116, 126.40032404110147, -76.83001339162989, 89.26828027409108, -46.28812528480921, -5.507263347731007, -110.59078763284114, -102.02758234720815, -71.92087874727862, 23.235448347088905, -97.4096806116913, -163.99660582708108, -111.32697898848633, -129.40022151872054, -126.85183358108753, -93.97780411261542, -99.1330504207014, -194.38838838754918, -173.3082150419681, -197.7687920691347, -152.2119528402487, -107.82254486708706], "policy_AGENT-2_reward": [24.018738158221524, -45.10309984200355, 125.99190938720548, -32.42558586512171, 39.60557148249552, -49.422680459937624, -73.81315610725346, -30.201711625591514, 64.02805490452604, 27.49729583958498, 189.09886556748245, -93.05197118684708, 79.37418472124989, -106.18896294380887, 223.3907265926054, -23.9279927547023, 134.73022756862616, -81.89184923158052, 246.66369337196915, 89.9504927116007, 104.99721466225375, -11.60697080220448, 100.11758631819177, -64.278550172514, 345.1240700466498, -122.2008268779147, -54.08956457823991, -66.90761189876143, -67.81731342948277, -193.45301306483427, -137.6484434613987, -99.872415970879, -175.40795696870708, -159.48212056099425, -166.42750318812233, -115.2735905990238, -93.8875629335285, -82.40475027154271, 368.26840565062076, -17.596983255400797, -23.00157656617251, -85.63950137346228, -30.85787573114341, 40.4513316529195, 84.1673621055954, -232.22363256821848, 141.79125219172826, -158.35051939303037, 108.98159509781979, -133.97912543786651, -57.44515492897506, -121.79479667684876, -179.6307377082039, -106.6774705677623, -50.65990478877947, -134.17261454129584, -155.72043242801033, -113.56202429783062, -96.10021228930567, -117.77222056356095, -101.40667778160396, -136.12350888621086, -215.52327773557926, -71.70816962689021, -78.66635697254391, -87.75314442190835, 161.82535541417434, -53.18346827248834, -31.81480010029407, -53.96966329933023, -6.815049075929988, 110.01510236852866, -79.10006136488926, 154.36425669025869, -30.41015498660523, 92.35086634875165, -167.48890545243694, -63.32024402495446, -98.4873392061071, 115.91253457837558, -54.360317837308536, 36.46064464547679, -69.87395303415637, 15.811589174310903, -87.69260122045371, -28.930239759210092, -14.294361897586782, 71.17604032840693, -78.99574762735361, -166.21056219017382, -110.435797860914, -129.19594429810368, -162.1693911200297, 38.47386524675771, -99.04142872234235, -195.19299230449877, -196.30736437789116, -198.16503974022635, -160.9868833611589, -107.50114824090207]}, "sampler_perf": {"mean_env_wait_ms": 54.982071576060896, "mean_raw_obs_processing_ms": 2.346092113846639, "mean_inference_ms": 2.4033405888667, "mean_action_processing_ms": 0.14316938711327104}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 100800, "timers": {"sample_time_ms": 90093.715, "sample_throughput": 46.618, "load_time_ms": 15.551, "load_throughput": 270073.387, "learn_time_ms": 9059.78, "learn_throughput": 463.587, "update_time_ms": 7.972}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 16.95454216003418, "policy_loss": -0.02967751957476139, "vf_loss": 16.977006912231445, "vf_explained_var": 0.9715102910995483, "kl": 0.01602221466600895, "entropy": 1.179197072982788, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 18.763633728027344, "policy_loss": -0.024313732981681824, "vf_loss": 18.7802677154541, "vf_explained_var": 0.9580969214439392, "kl": 0.01707146130502224, "entropy": 1.124377727508545, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 7.55049467086792, "policy_loss": -0.039098240435123444, "vf_loss": 7.579580783843994, "vf_explained_var": 0.9845225214958191, "kl": 0.014833406545221806, "entropy": 1.1806186437606812, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 8.408843040466309, "policy_loss": -0.025648966431617737, "vf_loss": 8.425968170166016, "vf_explained_var": 0.9836645126342773, "kl": 0.012628172524273396, "entropy": 1.0764765739440918, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 100800, "num_steps_trained": 100800}, "done": false, "episodes_total": 854, "training_iteration": 24, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-57-07", "timestamp": 1624211827, "time_this_iter_s": 95.76071810722351, "time_total_s": 2413.6737644672394, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40419f9e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40419f7a0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40419f560>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40419f440>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40419f200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40419f0e0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40419f560>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40419f440>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40419f200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40419f0e0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40419f560>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40419f440>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40419f200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40419f0e0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40419f560>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40419f440>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40419f200>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40419f0e0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd40419fdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2413.6737644672394, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 56.25328467153285, "ram_util_percent": 87.98540145985402}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1055.84191229163, "episode_reward_min": -803.6523202189486, "episode_reward_mean": -79.16268239326672, "episode_len_mean": 115.39, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-3": -194.87004876825102, "AGENT-0": -236.62751727369678, "AGENT-2": -198.16503974022635, "AGENT-1": -197.7687920691347}, "policy_reward_max": {"AGENT-3": 291.1396358983433, "AGENT-0": 235.83655004942776, "AGENT-2": 345.1240700466498, "AGENT-1": 355.50246774898795}, "policy_reward_mean": {"AGENT-3": -15.282564463240274, "AGENT-0": -26.681642954099807, "AGENT-2": -20.55976069684712, "AGENT-1": -16.638714279079476}, "custom_metrics": {"mean_ego_speed_mean": 43.236824999999996, "mean_ego_speed_min": 34.30175, "mean_ego_speed_max": 49.86275, "distance_travelled_mean": 103.62514499999999, "distance_travelled_min": 26.041999999999998, "distance_travelled_max": 124.835}, "hist_stats": {"episode_reward": [-129.92892646617122, 953.0091221238886, 4.144152357696911, 214.50179968338378, -251.65189495547327, 732.6637725706373, -303.5288925053772, 280.1657269172327, -17.50998891132685, 798.61120673965, -311.5691634402802, -386.17330445395424, 447.0938947075258, 5.0929826860154055, 205.55682514241346, 314.37222062734224, 361.26987414646584, -482.60857905797104, 714.5668152099278, 591.9498710554152, 539.4085105615837, -183.1334475248302, 482.6055716280686, -443.9801807764069, -632.7129545306308, -87.24288260162652, 122.4978547860833, -297.9543640807003, -455.68557061124704, -387.2786099781051, -571.1257382415063, -369.18587329281553, -366.9200549625433, -38.72249989251361, -279.9814997868794, 605.2898128010139, 43.715936215504335, 421.19238038862846, -423.0959240775108, -26.07265010346868, -444.2974873326826, 482.5567790309995, -312.3770566365349, 300.75653195683793, -233.96184253318253, 2.35587659270318, -400.11605315885333, -318.299131970603, -172.530964936467, 228.53558363456406, -355.95577295200025, -705.0643451204378, -513.0767004365813, -561.6682112835637, -623.2943349743051, -136.93340748680197, -450.085223544211, -720.770004427395, -767.9161869152613, -745.541188006226, -634.1649454119265, -498.01234499395036, 104.8935693683949, -250.63045089991786, 456.6467723332005, 60.54281115138396, 211.0861976886867, -74.8635447691411, -58.11628418604934, -235.2345805526173, 249.38747975871686, 111.60266550011046, 768.3641822275044, -550.0197438805267, 332.0805775665481, -470.29070900632223, 936.2931282719536, -176.54839762615768, 429.39808730842265, -376.36650337591317, 990.2203493478851, 216.9092214880533, 378.44244291142536, -83.17778334681599, 399.457138514338, -373.71576239332023, 1055.84191229163, -536.1872374192789, -346.29394858539075, -95.60727896647016, -250.5924160807091, -803.6523202189486, -402.3986472157232, -438.7744822647171, -571.7046438427332, -578.8681044354706, -607.8928963128587, -508.6966700984571, -364.86732599753987, -274.7199427711078], "episode_lengths": [107, 146, 139, 104, 112, 129, 112, 119, 148, 130, 111, 107, 105, 125, 103, 147, 117, 123, 126, 153, 122, 117, 117, 119, 116, 116, 155, 97, 127, 112, 117, 112, 106, 125, 100, 118, 129, 130, 109, 100, 115, 123, 103, 101, 118, 126, 110, 98, 41, 113, 108, 118, 116, 115, 116, 103, 112, 104, 122, 105, 112, 117, 122, 106, 115, 129, 118, 122, 102, 27, 118, 105, 132, 109, 128, 119, 129, 114, 116, 108, 138, 130, 116, 118, 116, 46, 158, 127, 114, 125, 113, 116, 110, 117, 116, 112, 121, 108, 108, 108], "policy_AGENT-3_reward": [-33.090346427180975, 221.8456506734346, -48.094999431210255, 58.96519089563777, -27.62394130976656, 208.52825445720296, -113.0517351608498, 79.61641340020122, -46.55101149129005, 231.13533797112623, -116.22561953232423, -105.5568686025241, 120.6577130354848, 21.07889254751637, 62.03098260643351, -6.2932592130476745, 127.07335117109888, -175.07503213142846, 202.69560265775465, 120.99016539925056, 170.72050313994808, -22.929216690137316, 160.49896541111923, -107.42169778264348, -161.2049321622947, 78.09055336613842, -27.793555873781106, -55.919499951594375, -131.27889086217579, -105.77637739596032, -155.6557478992228, -124.96281464120625, -51.00762314927386, -54.41837844543354, -39.71933842686161, 158.1458436221758, -30.397553816914684, 141.6745423264399, -125.36189195300325, -14.604624422517398, -126.56346691499948, 161.77665457196454, -104.5146183185334, 85.6851584060312, -70.29714435449287, 15.802103459048134, -114.68823783585906, -85.62575640128024, -14.365488282180804, 110.80874375602332, -101.11745475313329, -162.07691573217267, -132.2173156210351, -125.24742716843004, -127.41632485412808, 12.611729901544452, -104.3890991574343, -194.87004876825102, -180.20178902317863, -151.79115673984413, -160.53995808596426, -128.25593998163504, 70.41053283741506, -82.55254947415929, 168.83399577689428, -32.61420493568797, 83.73480282219712, -49.50044863835373, -28.703223925676415, -30.2266252709832, 106.2176445676441, 25.711539787392507, 200.2352375003194, -194.35234198513655, 120.37368513846513, -134.68173997627923, 265.67291658678147, -24.12232351821216, 112.90271834508266, -108.21218023168005, 265.2540456161233, 81.60170723532143, 146.88404460663799, -11.737144752390419, 134.16790458642768, -123.13646696123197, 291.1396358983433, -122.2679522942193, -121.60649042729378, -66.85224633195318, -73.48007657103803, -180.88637267309198, -88.3243062413485, -99.50313438880984, -89.83493615845411, -108.8589262567885, -116.46247662948622, -141.19820035350014, -90.60323132225939, -67.91851232141833], "policy_AGENT-0_reward": [-33.624084537843544, 235.20490904055953, 48.91657506008443, 71.97207492001272, -122.70936266344566, 173.15771697640253, -26.819248423096948, 36.77154374121109, 17.24307123226076, 185.14437379663528, -41.450707469668025, -63.57427904365102, 125.23363541740176, -21.034874445377344, 65.15805568094633, 157.42403644820376, 47.47290070882435, -69.68847472862757, 168.3090163286295, 148.71702717315793, 92.5743277933716, -68.62817946403156, 76.54861384784198, -141.17339124556094, -158.55132819483836, 38.670648497772554, 86.75517974899667, -104.80322662344761, -127.02005947685097, -89.38438571473317, -134.92179551468473, -61.849623248945846, -110.346835888385, 30.37059023321488, -111.78925601886749, 129.99253404425838, 29.331335855840088, 71.18195704108348, -65.13253159431217, 25.938833634560872, -97.92772419276471, 78.46726583955825, -76.67210708906308, 89.34244863123901, -47.50261985972422, -23.7505526929247, -87.14442646969917, -101.71555346290445, -71.9502360094208, 23.315351203045132, -78.43288995982178, -212.78026137100926, -159.0966079661459, -177.8246182983093, -206.8567854190592, -94.04119852248874, -147.5216452437324, -136.31857496709577, -218.09881847222292, -197.8161994570209, -160.42615112455445, -154.4327119043262, -18.9588988542085, -44.554335189434795, 80.97443875063081, 62.10436320376325, 42.84365094394258, -10.109831815142805, 22.257656293711218, -87.4114164359999, 15.21606805227595, 28.051656916674037, 185.4984411138404, -170.12015033198315, 43.53925307721724, -105.62186375931027, 221.54048327960797, -89.03811228181775, 90.94588244776071, -81.33960297848455, 235.83655004942776, 44.060147951728894, 63.346545897924145, -31.350312424210895, 58.35151364528877, -63.728394467393144, 64.07573859764912, -147.70010916965805, -53.53697498242989, 18.704827130729065, -42.26509167322697, -236.62751727369678, -87.97516045674053, -140.31267164045022, -217.18548565651943, -151.60988952058517, -165.8616819368124, -114.7196161546248, -93.3234813416722, -42.563610534207534], "policy_AGENT-2_reward": [-34.186266273219196, 247.97524573549543, -48.12039212863634, 11.535248683735311, -74.89761490519793, 173.57621160631118, -51.170967532898224, 78.66275261113162, -46.47858895705057, 191.16364765579902, -41.889642271583796, -153.5583378524591, 76.0618621191843, 21.176195088123638, 13.221909313520776, -6.332082325357101, 89.68835365861914, -70.25267174088498, 169.3790241930691, 161.53699007030266, 133.98124671481656, -22.817692207968182, 119.44267696616298, -98.08428415160175, -159.10820161844612, -102.22043056013413, -27.810882042492093, -32.556744694147355, -73.18081163372001, -89.94066340771421, -135.48133469290278, -62.39233797108116, -95.15865291065843, -54.36121213995902, -16.6704283704644, 154.36425669025869, -30.41015498660523, 92.35086634875165, -167.48890545243694, -63.32024402495446, -98.4873392061071, 115.91253457837558, -54.360317837308536, 36.46064464547679, -69.87395303415637, 15.811589174310903, -87.69260122045371, -28.930239759210092, -14.294361897586782, 71.17604032840693, -78.99574762735361, -166.21056219017382, -110.435797860914, -129.19594429810368, -162.1693911200297, 38.47386524675771, -99.04142872234235, -195.19299230449877, -196.30736437789116, -198.16503974022635, -160.9868833611589, -107.50114824090207, 24.018738158221524, -45.10309984200355, 125.99190938720548, -32.42558586512171, 39.60557148249552, -49.422680459937624, -73.81315610725346, -30.201711625591514, 64.02805490452604, 27.49729583958498, 189.09886556748245, -93.05197118684708, 79.37418472124989, -106.18896294380887, 223.3907265926054, -23.9279927547023, 134.73022756862616, -81.89184923158052, 246.66369337196915, 89.9504927116007, 104.99721466225375, -11.60697080220448, 100.11758631819177, -64.278550172514, 345.1240700466498, -122.2008268779147, -54.08956457823991, -66.90761189876143, -67.81731342948277, -193.45301306483427, -137.6484434613987, -99.872415970879, -175.40795696870708, -159.48212056099425, -166.42750318812233, -115.2735905990238, -93.8875629335285, -82.40475027154271], "policy_AGENT-1_reward": [-29.02822922792771, 247.9833166743991, 51.44296885745908, 72.02928518399783, -26.420976077062804, 177.40158953072077, -112.48694138853241, 85.11501716468864, 58.27654030475288, 191.16784731608976, -112.00319416670379, -63.48381895531996, 125.1406841354549, -16.127230504247308, 65.14587754151277, 169.57352571754305, 97.03526860792356, -167.59240045702998, 174.18317203047485, 160.70568841270406, 142.13243291344727, -68.75835916269317, 126.1153154029443, -97.30080759660075, -153.84849255505154, -101.78365390540299, 91.3471129533598, -104.67489281151117, -124.20580863849989, -102.17718345969762, -145.06686013469587, -119.98109743158224, -110.40694301422586, 39.686500459664074, -111.8024769706862, 162.7871784443216, 75.1923091631842, 115.985014672353, -65.11259507775827, 25.913384709442305, -121.31895701881116, 126.40032404110147, -76.83001339162989, 89.26828027409108, -46.28812528480921, -5.507263347731007, -110.59078763284114, -102.02758234720815, -71.92087874727862, 23.235448347088905, -97.4096806116913, -163.99660582708108, -111.32697898848633, -129.40022151872054, -126.85183358108753, -93.97780411261542, -99.1330504207014, -194.38838838754918, -173.3082150419681, -197.7687920691347, -152.2119528402487, -107.82254486708706, 29.42319722696687, -78.42046639431987, 80.84642841846977, 63.47823874843042, 44.902172440051714, 34.16941614429313, 22.142439553169282, -87.39482722004269, 63.92571223427067, 30.342172956458892, 193.53163804586248, -92.49528037656017, 88.79345462961646, -123.7981423269239, 225.68900181295788, -39.45996907142545, 90.8192589469532, -104.92287093416799, 242.46606031036376, 1.2968735894022103, 63.214637744609476, -28.483355368010216, 106.82013396442946, -122.57235079218131, 355.50246774898795, -144.0183490774867, -117.0609185974268, 19.447752133515355, -67.02993440696093, -192.68541720732625, -88.45073705623548, -99.08626026457847, -89.27626505905253, -158.9171680971029, -159.14123455843782, -137.5052629913079, -87.05305040007971, -81.83306964393896]}, "sampler_perf": {"mean_env_wait_ms": 54.87308417062115, "mean_raw_obs_processing_ms": 2.343755132553454, "mean_inference_ms": 2.396996525786275, "mean_action_processing_ms": 0.14292497907300372}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 105000, "timers": {"sample_time_ms": 89954.194, "sample_throughput": 46.69, "load_time_ms": 15.424, "load_throughput": 272306.04, "learn_time_ms": 9009.876, "learn_throughput": 466.155, "update_time_ms": 7.915}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 16.29819679260254, "policy_loss": -0.03777768090367317, "vf_loss": 16.32900619506836, "vf_explained_var": 0.9771708846092224, "kl": 0.01548334863036871, "entropy": 1.1156820058822632, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 16.61848258972168, "policy_loss": -0.03139067068696022, "vf_loss": 16.642902374267578, "vf_explained_var": 0.9638772010803223, "kl": 0.015486878342926502, "entropy": 1.1343172788619995, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 12.218276977539062, "policy_loss": -0.026832252740859985, "vf_loss": 12.236223220825195, "vf_explained_var": 0.9783267378807068, "kl": 0.013170026242733002, "entropy": 1.1715583801269531, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 11.907949447631836, "policy_loss": -0.02230852097272873, "vf_loss": 11.922173500061035, "vf_explained_var": 0.9783331751823425, "kl": 0.011981791816651821, "entropy": 1.0711479187011719, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 105000, "num_steps_trained": 105000}, "done": false, "episodes_total": 889, "training_iteration": 25, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_17-58-41", "timestamp": 1624211921, "time_this_iter_s": 94.06945753097534, "time_total_s": 2507.7432219982147, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40428cef0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40428ce60>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd050>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd440>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd5f0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd050>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd440>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd5f0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd050>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd440>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd5f0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd050>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd440>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd4d0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd5f0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd40419fef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2507.7432219982147, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 55.651111111111106, "ram_util_percent": 87.56962962962965}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1260.0498949708006, "episode_reward_min": -803.6523202189486, "episode_reward_mean": -25.98101126949978, "episode_len_mean": 118.16, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-3": -194.35234198513655, "AGENT-0": -236.62751727369678, "AGENT-1": -192.68541720732625, "AGENT-2": -193.45301306483427}, "policy_reward_max": {"AGENT-3": 291.1396358983433, "AGENT-0": 307.7347619446505, "AGENT-1": 355.50246774898795, "AGENT-2": 345.1240700466498}, "policy_reward_mean": {"AGENT-3": -0.8736144044877497, "AGENT-0": -13.060677117174741, "AGENT-1": -3.89384125098095, "AGENT-2": -8.152878496856351}, "custom_metrics": {"mean_ego_speed_mean": 43.551705, "mean_ego_speed_min": 34.30175, "mean_ego_speed_max": 49.83675, "distance_travelled_mean": 106.2131075, "distance_travelled_min": 40.79325, "distance_travelled_max": 124.85749999999999}, "hist_stats": {"episode_reward": [783.7674382736196, -398.964114488248, -83.57853860203696, -503.7685910529208, 957.4219838790004, -127.34807078704196, 1260.0498949708006, -432.41325910992674, 757.1595267016047, -108.4438309316312, 259.6114161118781, -604.6893575618685, -17.551608135026555, 805.7488318834058, -368.2443091565534, 448.22970473290013, -202.813817079801, 250.36080351340726, 143.34950571819687, 159.88418185712592, 33.515869645996396, 303.8383240387844, -361.44871122235304, -485.98167971108535, -442.06594956468035, -346.5141003955077, -284.56837377561794, -472.4390454807573, -5.825448889145086, -485.43198462572406, -515.3951514371403, -153.77995512637037, -476.741092386481, -335.23583379199306, -376.0339311858863, 249.38747975871686, 111.60266550011046, 768.3641822275044, -550.0197438805267, 332.0805775665481, -470.29070900632223, 936.2931282719536, -176.54839762615768, 429.39808730842265, -376.36650337591317, 990.2203493478851, 216.9092214880533, 378.44244291142536, -83.17778334681599, 399.457138514338, -373.71576239332023, 1055.84191229163, -536.1872374192789, -346.29394858539075, -95.60727896647016, -250.5924160807091, -803.6523202189486, -402.3986472157232, -438.7744822647171, -571.7046438427332, -578.8681044354706, -607.8928963128587, -508.6966700984571, -364.86732599753987, -274.7199427711078, -129.92892646617122, 953.0091221238886, 4.144152357696911, 214.50179968338378, -251.65189495547327, 732.6637725706373, -303.5288925053772, 280.1657269172327, -17.50998891132685, 798.61120673965, -311.5691634402802, -386.17330445395424, 447.0938947075258, 5.0929826860154055, 205.55682514241346, 314.37222062734224, 361.26987414646584, -482.60857905797104, 714.5668152099278, 591.9498710554152, 539.4085105615837, -183.1334475248302, 482.6055716280686, -443.9801807764069, -632.7129545306308, -87.24288260162652, 122.4978547860833, -297.9543640807003, -455.68557061124704, -387.2786099781051, -571.1257382415063, -369.18587329281553, -366.9200549625433, -38.72249989251361, -279.9814997868794], "episode_lengths": [125, 118, 103, 102, 140, 106, 164, 115, 133, 105, 112, 102, 123, 121, 104, 113, 122, 116, 126, 115, 126, 118, 114, 117, 101, 114, 111, 104, 137, 121, 112, 117, 118, 114, 111, 118, 105, 132, 109, 128, 119, 129, 114, 116, 108, 138, 130, 116, 118, 116, 46, 158, 127, 114, 125, 113, 116, 110, 117, 116, 112, 121, 108, 108, 108, 107, 146, 139, 104, 112, 129, 112, 119, 148, 130, 111, 107, 105, 125, 103, 147, 117, 123, 126, 153, 122, 117, 117, 119, 116, 116, 155, 97, 127, 112, 117, 112, 106, 125, 100], "policy_AGENT-3_reward": [229.968831136527, -71.52709332047137, -38.57369083701054, -123.12249010097362, 245.25381716745198, -22.554850517403978, 283.20458841428456, -98.98484981226505, 242.2750475369583, -32.34710619470665, 87.20333153838372, -164.21924722357602, 9.691794459941367, 195.72046099795116, -87.84312718964472, 168.02422395721518, -30.81974085620089, 100.1882777613186, -9.578931410640845, 41.90866865783268, -8.46242350892826, 131.55294084048742, -92.82346590888615, -118.22207070996089, -74.27547252436132, -77.47775895358018, -75.33922058681956, -82.07078184482481, -35.09881517340598, -128.29425814862537, -151.19696883477883, 49.683959285981985, -90.31517704857481, -74.00795464079117, -125.28059748276517, 106.2176445676441, 25.711539787392507, 200.2352375003194, -194.35234198513655, 120.37368513846513, -134.68173997627923, 265.67291658678147, -24.12232351821216, 112.90271834508266, -108.21218023168005, 265.2540456161233, 81.60170723532143, 146.88404460663799, -11.737144752390419, 134.16790458642768, -123.13646696123197, 291.1396358983433, -122.2679522942193, -121.60649042729378, -66.85224633195318, -73.48007657103803, -180.88637267309198, -88.3243062413485, -99.50313438880984, -89.83493615845411, -108.8589262567885, -116.46247662948622, -141.19820035350014, -90.60323132225939, -67.91851232141833, -33.090346427180975, 221.8456506734346, -48.094999431210255, 58.96519089563777, -27.62394130976656, 208.52825445720296, -113.0517351608498, 79.61641340020122, -46.55101149129005, 231.13533797112623, -116.22561953232423, -105.5568686025241, 120.6577130354848, 21.07889254751637, 62.03098260643351, -6.2932592130476745, 127.07335117109888, -175.07503213142846, 202.69560265775465, 120.99016539925056, 170.72050313994808, -22.929216690137316, 160.49896541111923, -107.42169778264348, -161.2049321622947, 78.09055336613842, -27.793555873781106, -55.919499951594375, -131.27889086217579, -105.77637739596032, -155.6557478992228, -124.96281464120625, -51.00762314927386, -54.41837844543354, -39.71933842686161], "policy_AGENT-0_reward": [184.4702297677935, -156.34641048052356, 17.963917059065498, -103.9813525229985, 227.25983465602553, -19.513226100214037, 307.7347619446505, -141.8545985887202, 49.69984605574149, -26.782298038959535, 43.03000115703303, -138.04318669496496, -24.906836219627696, 172.29164494021887, -71.44292649698326, 78.5356374588809, -71.59045246001939, 19.90368691276303, 77.47308855571436, -0.871723599963282, 22.550905519711343, 42.73661570932582, -64.17111662585349, -153.27473963649737, -123.36031570665529, -119.08391257150501, -52.595302221772144, -131.2560132737517, 11.366820460525304, -115.17703318833277, -109.01273006720112, 10.170975255753056, -131.57812992462303, -118.19220735003367, -50.78373092124863, 15.21606805227595, 28.051656916674037, 185.4984411138404, -170.12015033198315, 43.53925307721724, -105.62186375931027, 221.54048327960797, -89.03811228181775, 90.94588244776071, -81.33960297848455, 235.83655004942776, 44.060147951728894, 63.346545897924145, -31.350312424210895, 58.35151364528877, -63.728394467393144, 64.07573859764912, -147.70010916965805, -53.53697498242989, 18.704827130729065, -42.26509167322697, -236.62751727369678, -87.97516045674053, -140.31267164045022, -217.18548565651943, -151.60988952058517, -165.8616819368124, -114.7196161546248, -93.3234813416722, -42.563610534207534, -33.624084537843544, 235.20490904055953, 48.91657506008443, 71.97207492001272, -122.70936266344566, 173.15771697640253, -26.819248423096948, 36.77154374121109, 17.24307123226076, 185.14437379663528, -41.450707469668025, -63.57427904365102, 125.23363541740176, -21.034874445377344, 65.15805568094633, 157.42403644820376, 47.47290070882435, -69.68847472862757, 168.3090163286295, 148.71702717315793, 92.5743277933716, -68.62817946403156, 76.54861384784198, -141.17339124556094, -158.55132819483836, 38.670648497772554, 86.75517974899667, -104.80322662344761, -127.02005947685097, -89.38438571473317, -134.92179551468473, -61.849623248945846, -110.346835888385, 30.37059023321488, -111.78925601886749], "policy_AGENT-1_reward": [187.1683691112976, -60.420300259022454, 18.0987207663567, -103.97661415202815, 237.51092355056622, -65.21144258592982, 324.01717914733086, -95.42812958241134, 235.4452518620175, -21.965291551028244, 42.903516420945195, -138.14427383560826, -21.137169417599914, 219.83599239618346, -71.55078724877811, 78.40679585609462, -69.51885613487629, 67.75120084288592, 84.97577897794004, 59.708004961428315, 27.928615520111112, 42.855668023095774, -139.72697318841284, -107.23384378775363, -123.32427739078611, -74.66671127204881, -53.53638412962588, -131.26269149410658, 52.95120385151647, -120.67575782494941, -145.62438711165137, -106.60260312223969, -127.14512754993034, -72.44687178106724, -74.7351576039002, 63.92571223427067, 30.342172956458892, 193.53163804586248, -92.49528037656017, 88.79345462961646, -123.7981423269239, 225.68900181295788, -39.45996907142545, 90.8192589469532, -104.92287093416799, 242.46606031036376, 1.2968735894022103, 63.214637744609476, -28.483355368010216, 106.82013396442946, -122.57235079218131, 355.50246774898795, -144.0183490774867, -117.0609185974268, 19.447752133515355, -67.02993440696093, -192.68541720732625, -88.45073705623548, -99.08626026457847, -89.27626505905253, -158.9171680971029, -159.14123455843782, -137.5052629913079, -87.05305040007971, -81.83306964393896, -29.02822922792771, 247.9833166743991, 51.44296885745908, 72.02928518399783, -26.420976077062804, 177.40158953072077, -112.48694138853241, 85.11501716468864, 58.27654030475288, 191.16784731608976, -112.00319416670379, -63.48381895531996, 125.1406841354549, -16.127230504247308, 65.14587754151277, 169.57352571754305, 97.03526860792356, -167.59240045702998, 174.18317203047485, 160.70568841270406, 142.13243291344727, -68.75835916269317, 126.1153154029443, -97.30080759660075, -153.84849255505154, -101.78365390540299, 91.3471129533598, -104.67489281151117, -124.20580863849989, -102.17718345969762, -145.06686013469587, -119.98109743158224, -110.40694301422586, 39.686500459664074, -111.8024769706862], "policy_AGENT-2_reward": [182.16000825800123, -110.67031042823083, -81.06748559044868, -172.6881342769205, 247.39740850495608, -20.068551583494447, 345.0933654645345, -96.14568112653009, 229.73938124688766, -27.349135146936785, 86.47456699551606, -164.28264980771928, 18.8006030422597, 217.90073354905243, -137.4074682211471, 123.2630474607091, -30.88476762870451, 62.517637996439674, -9.52043040481664, 59.1392318378281, -8.501227884897734, 86.69309946587552, -64.72715549920032, -107.25102557687383, -121.10588394287717, -75.2857175983737, -103.09746683740045, -127.84955886807471, -35.044658027780734, -121.28493546381628, -109.56106542350904, -107.03228654586587, -127.70265786335241, -70.5888000201007, -125.23444517797166, 64.02805490452604, 27.49729583958498, 189.09886556748245, -93.05197118684708, 79.37418472124989, -106.18896294380887, 223.3907265926054, -23.9279927547023, 134.73022756862616, -81.89184923158052, 246.66369337196915, 89.9504927116007, 104.99721466225375, -11.60697080220448, 100.11758631819177, -64.278550172514, 345.1240700466498, -122.2008268779147, -54.08956457823991, -66.90761189876143, -67.81731342948277, -193.45301306483427, -137.6484434613987, -99.872415970879, -175.40795696870708, -159.48212056099425, -166.42750318812233, -115.2735905990238, -93.8875629335285, -82.40475027154271, -34.186266273219196, 247.97524573549543, -48.12039212863634, 11.535248683735311, -74.89761490519793, 173.57621160631118, -51.170967532898224, 78.66275261113162, -46.47858895705057, 191.16364765579902, -41.889642271583796, -153.5583378524591, 76.0618621191843, 21.176195088123638, 13.221909313520776, -6.332082325357101, 89.68835365861914, -70.25267174088498, 169.3790241930691, 161.53699007030266, 133.98124671481656, -22.817692207968182, 119.44267696616298, -98.08428415160175, -159.10820161844612, -102.22043056013413, -27.810882042492093, -32.556744694147355, -73.18081163372001, -89.94066340771421, -135.48133469290278, -62.39233797108116, -95.15865291065843, -54.36121213995902, -16.6704283704644]}, "sampler_perf": {"mean_env_wait_ms": 55.420203600413544, "mean_raw_obs_processing_ms": 2.3655644932544986, "mean_inference_ms": 2.4127577587760154, "mean_action_processing_ms": 0.1441023044775848}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 109200, "timers": {"sample_time_ms": 97241.941, "sample_throughput": 43.191, "load_time_ms": 16.244, "load_throughput": 258562.6, "learn_time_ms": 9695.053, "learn_throughput": 433.211, "update_time_ms": 8.345}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 18.588998794555664, "policy_loss": -0.03640076518058777, "vf_loss": 18.618398666381836, "vf_explained_var": 0.9740912318229675, "kl": 0.01555693056434393, "entropy": 1.1106828451156616, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 18.586971282958984, "policy_loss": -0.030203118920326233, "vf_loss": 18.609941482543945, "vf_explained_var": 0.9642030000686646, "kl": 0.016074858605861664, "entropy": 1.1352437734603882, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 12.620597839355469, "policy_loss": -0.028136881068348885, "vf_loss": 12.638269424438477, "vf_explained_var": 0.9785945415496826, "kl": 0.015506458468735218, "entropy": 1.1801729202270508, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 14.314560890197754, "policy_loss": -0.02419349178671837, "vf_loss": 14.330418586730957, "vf_explained_var": 0.9756173491477966, "kl": 0.012349440716207027, "entropy": 1.0251415967941284, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 109200, "num_steps_trained": 109200}, "done": false, "episodes_total": 924, "training_iteration": 26, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-01-42", "timestamp": 1624212102, "time_this_iter_s": 181.01710438728333, "time_total_s": 2688.760326385498, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40420e5f0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40420e4d0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40420e290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40420e170>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420ecb0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420edd0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40420e290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40420e170>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420ecb0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420edd0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40420e290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40420e170>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420ecb0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420edd0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40420e290>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40420e170>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420ecb0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420edd0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd40420ea70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2688.760326385498, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 59.762403100775195, "ram_util_percent": 87.59534883720931}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1260.0498949708006, "episode_reward_min": -749.5110238893512, "episode_reward_mean": -44.4777487823993, "episode_len_mean": 117.44, "episodes_this_iter": 38, "policy_reward_min": {"AGENT-3": -192.34942331812155, "AGENT-0": -184.71865844939768, "AGENT-1": -185.60928448790662, "AGENT-2": -212.98830333199248}, "policy_reward_max": {"AGENT-3": 359.234991084874, "AGENT-0": 307.7347619446505, "AGENT-1": 324.01717914733086, "AGENT-2": 345.0933654645345}, "policy_reward_mean": {"AGENT-3": -3.7792636977598617, "AGENT-0": -18.55359901019639, "AGENT-1": -9.17854353034017, "AGENT-2": -12.966342544102938}, "custom_metrics": {"mean_ego_speed_mean": 43.369255, "mean_ego_speed_min": 36.769999999999996, "mean_ego_speed_max": 49.83675, "distance_travelled_mean": 104.42429249999998, "distance_travelled_min": 37.5435, "distance_travelled_max": 124.85749999999999}, "hist_stats": {"episode_reward": [301.80753142411, -127.36670628185135, 429.3930953019282, -436.802260281509, 168.52193964357895, -507.09992732294313, -131.57901932384394, -316.46976800374046, 530.8670115565144, -341.4206588476263, 144.985959725712, -313.22317192603805, 392.51601238458255, 1258.6805191802584, -155.42675407914558, 444.4036796126826, -154.300005483288, 625.978935337624, 21.827899446561375, 557.2536702451742, -157.27198684752082, 304.7870630421955, -186.75124823747686, 338.88341280577407, 30.013123971621077, 447.33641914573656, -730.2248526467679, -749.5110238893512, -420.2333366921182, -448.7273160453251, -64.48270781465266, -588.1838366358149, -345.96307071245417, -276.4849263977471, -355.93762710874336, -520.086313536163, -391.43467145014415, -570.9516034757969, -17.50998891132685, 798.61120673965, -311.5691634402802, -386.17330445395424, 447.0938947075258, 5.0929826860154055, 205.55682514241346, 314.37222062734224, 361.26987414646584, -482.60857905797104, 714.5668152099278, 591.9498710554152, 539.4085105615837, -183.1334475248302, 482.6055716280686, -443.9801807764069, -632.7129545306308, -87.24288260162652, 122.4978547860833, -297.9543640807003, -455.68557061124704, -387.2786099781051, -571.1257382415063, -369.18587329281553, -366.9200549625433, -38.72249989251361, -279.9814997868794, 783.7674382736196, -398.964114488248, -83.57853860203696, -503.7685910529208, 957.4219838790004, -127.34807078704196, 1260.0498949708006, -432.41325910992674, 757.1595267016047, -108.4438309316312, 259.6114161118781, -604.6893575618685, -17.551608135026555, 805.7488318834058, -368.2443091565534, 448.22970473290013, -202.813817079801, 250.36080351340726, 143.34950571819687, 159.88418185712592, 33.515869645996396, 303.8383240387844, -361.44871122235304, -485.98167971108535, -442.06594956468035, -346.5141003955077, -284.56837377561794, -472.4390454807573, -5.825448889145086, -485.43198462572406, -515.3951514371403, -153.77995512637037, -476.741092386481, -335.23583379199306, -376.0339311858863], "episode_lengths": [114, 125, 119, 118, 115, 33, 116, 89, 142, 118, 138, 108, 127, 155, 113, 118, 116, 118, 118, 124, 121, 121, 52, 122, 104, 124, 107, 117, 114, 118, 128, 126, 105, 132, 122, 117, 121, 116, 148, 130, 111, 107, 105, 125, 103, 147, 117, 123, 126, 153, 122, 117, 117, 119, 116, 116, 155, 97, 127, 112, 117, 112, 106, 125, 100, 125, 118, 103, 102, 140, 106, 164, 115, 133, 105, 112, 102, 123, 121, 104, 113, 122, 116, 126, 115, 126, 118, 114, 117, 101, 114, 111, 104, 137, 121, 112, 117, 118, 114, 111], "policy_AGENT-3_reward": [107.64543478500619, -37.62299215638722, 140.05788856743243, -100.96978478436343, 88.08151772907522, -152.32938633765846, -25.697689861861488, -29.02188672904893, 169.1666395046298, -48.46578900351632, -4.820096760153454, -79.24319086625611, 110.0340964829206, 359.234991084874, -27.720432127009033, 149.503723944626, -15.316133692026623, 167.00447936219808, -23.313256672894784, 136.97137004391885, -8.977312400580892, 114.16032113709052, -10.299910412926284, 131.05867392305538, -18.996410311645327, 144.08326098229213, -165.44033095597104, -190.43419681643635, -96.09573237400848, -88.42983798791383, -45.68612811168161, -163.29430922720383, -37.94920647740991, -109.88265178795973, -93.45610641159786, -104.0571808766092, -104.48144284167267, -192.34942331812155, -46.55101149129005, 231.13533797112623, -116.22561953232423, -105.5568686025241, 120.6577130354848, 21.07889254751637, 62.03098260643351, -6.2932592130476745, 127.07335117109888, -175.07503213142846, 202.69560265775465, 120.99016539925056, 170.72050313994808, -22.929216690137316, 160.49896541111923, -107.42169778264348, -161.2049321622947, 78.09055336613842, -27.793555873781106, -55.919499951594375, -131.27889086217579, -105.77637739596032, -155.6557478992228, -124.96281464120625, -51.00762314927386, -54.41837844543354, -39.71933842686161, 229.968831136527, -71.52709332047137, -38.57369083701054, -123.12249010097362, 245.25381716745198, -22.554850517403978, 283.20458841428456, -98.98484981226505, 242.2750475369583, -32.34710619470665, 87.20333153838372, -164.21924722357602, 9.691794459941367, 195.72046099795116, -87.84312718964472, 168.02422395721518, -30.81974085620089, 100.1882777613186, -9.578931410640845, 41.90866865783268, -8.46242350892826, 131.55294084048742, -92.82346590888615, -118.22207070996089, -74.27547252436132, -77.47775895358018, -75.33922058681956, -82.07078184482481, -35.09881517340598, -128.29425814862537, -151.19696883477883, 49.683959285981985, -90.31517704857481, -74.00795464079117, -125.28059748276517], "policy_AGENT-0_reward": [66.12254153854241, -48.94042341985539, 97.04475934026483, -142.4095761262314, -5.211508610606643, -101.27228147386826, -64.5204373216649, -129.06816260996703, 89.38038423045454, -144.60573704503105, 55.400836120854166, -83.73226274195588, 84.86675386349545, 278.6817090655835, -74.88420967790317, 68.06508525648472, -85.96579693959781, 161.23284177726475, 12.523473428947959, 140.01869608806248, -70.25300498713852, 37.35559142354037, -83.04505794612874, 55.55920365216272, 52.10557401675905, 98.45886553897826, -175.84738572787515, -184.71865844939768, -138.7644396644248, -129.24659587955915, -7.362366761305815, -154.29140327044558, -112.93501302789666, -51.59102212107776, -107.66872651694402, -143.9096697456478, -92.49199683722519, -96.21526205162704, 17.24307123226076, 185.14437379663528, -41.450707469668025, -63.57427904365102, 125.23363541740176, -21.034874445377344, 65.15805568094633, 157.42403644820376, 47.47290070882435, -69.68847472862757, 168.3090163286295, 148.71702717315793, 92.5743277933716, -68.62817946403156, 76.54861384784198, -141.17339124556094, -158.55132819483836, 38.670648497772554, 86.75517974899667, -104.80322662344761, -127.02005947685097, -89.38438571473317, -134.92179551468473, -61.849623248945846, -110.346835888385, 30.37059023321488, -111.78925601886749, 184.4702297677935, -156.34641048052356, 17.963917059065498, -103.9813525229985, 227.25983465602553, -19.513226100214037, 307.7347619446505, -141.8545985887202, 49.69984605574149, -26.782298038959535, 43.03000115703303, -138.04318669496496, -24.906836219627696, 172.29164494021887, -71.44292649698326, 78.5356374588809, -71.59045246001939, 19.90368691276303, 77.47308855571436, -0.871723599963282, 22.550905519711343, 42.73661570932582, -64.17111662585349, -153.27473963649737, -123.36031570665529, -119.08391257150501, -52.595302221772144, -131.2560132737517, 11.366820460525304, -115.17703318833277, -109.01273006720112, 10.170975255753056, -131.57812992462303, -118.19220735003367, -50.78373092124863], "policy_AGENT-1_reward": [67.06387295372984, -3.2186038241350374, 99.33417170717502, -95.99833668008914, 43.05190003430684, -101.16963316470856, -15.687733834269235, -129.37967585824651, 103.12420889399716, -49.04250145793337, 99.17272847165101, -74.41086316051735, 87.64505545849357, 294.8720836699429, -25.767045723299475, 116.14567339925588, -37.65516069555904, 160.51423586914837, -22.75346614316384, 142.8452270109767, -69.09780766604885, 76.85281036897447, -82.9997984684831, 55.109751055570236, -18.431662610770797, 106.4762298883745, -175.94883263092905, -184.59320873512064, -92.64718923736214, -115.29555749086364, 34.24630373589436, -107.33549692986522, -112.8833510151187, -5.100415073271288, -61.671172244365486, -135.8437445290207, -98.28838018639804, -185.60928448790662, 58.27654030475288, 191.16784731608976, -112.00319416670379, -63.48381895531996, 125.1406841354549, -16.127230504247308, 65.14587754151277, 169.57352571754305, 97.03526860792356, -167.59240045702998, 174.18317203047485, 160.70568841270406, 142.13243291344727, -68.75835916269317, 126.1153154029443, -97.30080759660075, -153.84849255505154, -101.78365390540299, 91.3471129533598, -104.67489281151117, -124.20580863849989, -102.17718345969762, -145.06686013469587, -119.98109743158224, -110.40694301422586, 39.686500459664074, -111.8024769706862, 187.1683691112976, -60.420300259022454, 18.0987207663567, -103.97661415202815, 237.51092355056622, -65.21144258592982, 324.01717914733086, -95.42812958241134, 235.4452518620175, -21.965291551028244, 42.903516420945195, -138.14427383560826, -21.137169417599914, 219.83599239618346, -71.55078724877811, 78.40679585609462, -69.51885613487629, 67.75120084288592, 84.97577897794004, 59.708004961428315, 27.928615520111112, 42.855668023095774, -139.72697318841284, -107.23384378775363, -123.32427739078611, -74.66671127204881, -53.53638412962588, -131.26269149410658, 52.95120385151647, -120.67575782494941, -145.62438711165137, -106.60260312223969, -127.14512754993034, -72.44687178106724, -74.7351576039002], "policy_AGENT-2_reward": [60.975682146831105, -37.5846868814738, 92.95627568705599, -97.42456269082575, 42.60003049080382, -152.32862634670778, -25.67315830604835, -29.000042806477957, 169.19577892743294, -99.3066313411459, -4.767508106639788, -75.83685515730924, 109.9701065796732, 325.89173535985736, -27.0550665509338, 110.68919701231533, -15.362914156104496, 137.22737832901208, 55.37114883367199, 137.41837710221535, -8.943861793752653, 76.41834011259004, -10.406481409938744, 97.15578417498526, 15.335622877278162, 98.31806273609135, -212.98830333199248, -189.7649598883968, -92.72597541632274, -115.75532468698856, -45.680516677559645, -163.2626272083002, -82.19550019202879, -109.91083741543865, -93.14162193583593, -136.2757183848858, -96.17285158484833, -96.77763361814127, -46.47858895705057, 191.16364765579902, -41.889642271583796, -153.5583378524591, 76.0618621191843, 21.176195088123638, 13.221909313520776, -6.332082325357101, 89.68835365861914, -70.25267174088498, 169.3790241930691, 161.53699007030266, 133.98124671481656, -22.817692207968182, 119.44267696616298, -98.08428415160175, -159.10820161844612, -102.22043056013413, -27.810882042492093, -32.556744694147355, -73.18081163372001, -89.94066340771421, -135.48133469290278, -62.39233797108116, -95.15865291065843, -54.36121213995902, -16.6704283704644, 182.16000825800123, -110.67031042823083, -81.06748559044868, -172.6881342769205, 247.39740850495608, -20.068551583494447, 345.0933654645345, -96.14568112653009, 229.73938124688766, -27.349135146936785, 86.47456699551606, -164.28264980771928, 18.8006030422597, 217.90073354905243, -137.4074682211471, 123.2630474607091, -30.88476762870451, 62.517637996439674, -9.52043040481664, 59.1392318378281, -8.501227884897734, 86.69309946587552, -64.72715549920032, -107.25102557687383, -121.10588394287717, -75.2857175983737, -103.09746683740045, -127.84955886807471, -35.044658027780734, -121.28493546381628, -109.56106542350904, -107.03228654586587, -127.70265786335241, -70.5888000201007, -125.23444517797166]}, "sampler_perf": {"mean_env_wait_ms": 56.75662518633759, "mean_raw_obs_processing_ms": 2.4227164852145524, "mean_inference_ms": 2.453045337253177, "mean_action_processing_ms": 0.14709760462851043}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 113400, "timers": {"sample_time_ms": 105074.574, "sample_throughput": 39.972, "load_time_ms": 16.567, "load_throughput": 253513.962, "learn_time_ms": 10061.384, "learn_throughput": 417.438, "update_time_ms": 8.823}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 19.175565719604492, "policy_loss": -0.030384967103600502, "vf_loss": 19.197349548339844, "vf_explained_var": 0.9738218188285828, "kl": 0.01911512017250061, "entropy": 1.108299732208252, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 18.892902374267578, "policy_loss": -0.029499974101781845, "vf_loss": 18.91573715209961, "vf_explained_var": 0.9640331864356995, "kl": 0.014810871332883835, "entropy": 1.1374672651290894, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 16.78015899658203, "policy_loss": -0.031978655606508255, "vf_loss": 16.800661087036133, "vf_explained_var": 0.9753307104110718, "kl": 0.01700296439230442, "entropy": 1.1960829496383667, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 17.903308868408203, "policy_loss": -0.025210537016391754, "vf_loss": 17.921260833740234, "vf_explained_var": 0.9746766686439514, "kl": 0.010749902576208115, "entropy": 1.0653022527694702, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 113400, "num_steps_trained": 113400}, "done": false, "episodes_total": 962, "training_iteration": 27, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-04-51", "timestamp": 1624212291, "time_this_iter_s": 188.4658908843994, "time_total_s": 2877.2262172698975, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40419fd40>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40419fc20>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40428c3b0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40472c5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40449b170>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40449b290>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40428c3b0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40472c5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40449b170>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40449b290>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40428c3b0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40472c5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40449b170>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40449b290>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40428c3b0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40472c5f0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40449b170>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40449b290>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd40420eef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2877.2262172698975, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 60.35724907063198, "ram_util_percent": 87.75055762081783}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1260.0498949708006, "episode_reward_min": -749.5110238893512, "episode_reward_mean": -69.41530911871502, "episode_len_mean": 118.37, "episodes_this_iter": 33, "policy_reward_min": {"AGENT-3": -192.34942331812155, "AGENT-0": -196.3083201414169, "AGENT-2": -212.98830333199248, "AGENT-1": -185.60928448790662}, "policy_reward_max": {"AGENT-3": 359.234991084874, "AGENT-0": 307.7347619446505, "AGENT-2": 345.0933654645345, "AGENT-1": 324.01717914733086}, "policy_reward_mean": {"AGENT-3": -7.376221920192701, "AGENT-0": -29.567647600801866, "AGENT-2": -16.965519252138915, "AGENT-1": -15.505920345581607}, "custom_metrics": {"mean_ego_speed_mean": 43.33549000000002, "mean_ego_speed_min": 36.14075, "mean_ego_speed_max": 49.83675, "distance_travelled_mean": 107.60373249999999, "distance_travelled_min": 37.5435, "distance_travelled_max": 124.85749999999999}, "hist_stats": {"episode_reward": [-151.54728535606094, 728.564634269874, 570.371518969787, -374.2724775160862, -205.07671509439186, -332.2695399004404, 930.285960729219, -518.1891210126814, -74.79547681768835, -317.12197573757385, 67.96794152778939, -25.27287759039665, 518.4443220358785, 132.60904373229675, 315.4576801542385, -246.91717746469644, 301.2025658778567, -205.10068246266403, 530.1394525422247, -407.0724554649369, 551.3807488909626, -74.5125900800874, -526.3442949793316, -266.96980996280416, 73.09934577045766, -699.9152739907406, -389.21911371081416, -348.0074275828574, -634.335611387919, -742.1608580921045, -476.5305837231364, 104.71678986517449, -403.59366770039225, 1260.0498949708006, -432.41325910992674, 757.1595267016047, -108.4438309316312, 259.6114161118781, -604.6893575618685, -17.551608135026555, 805.7488318834058, -368.2443091565534, 448.22970473290013, -202.813817079801, 250.36080351340726, 143.34950571819687, 159.88418185712592, 33.515869645996396, 303.8383240387844, -361.44871122235304, -485.98167971108535, -442.06594956468035, -346.5141003955077, -284.56837377561794, -472.4390454807573, -5.825448889145086, -485.43198462572406, -515.3951514371403, -153.77995512637037, -476.741092386481, -335.23583379199306, -376.0339311858863, 301.80753142411, -127.36670628185135, 429.3930953019282, -436.802260281509, 168.52193964357895, -507.09992732294313, -131.57901932384394, -316.46976800374046, 530.8670115565144, -341.4206588476263, 144.985959725712, -313.22317192603805, 392.51601238458255, 1258.6805191802584, -155.42675407914558, 444.4036796126826, -154.300005483288, 625.978935337624, 21.827899446561375, 557.2536702451742, -157.27198684752082, 304.7870630421955, -186.75124823747686, 338.88341280577407, 30.013123971621077, 447.33641914573656, -730.2248526467679, -749.5110238893512, -420.2333366921182, -448.7273160453251, -64.48270781465266, -588.1838366358149, -345.96307071245417, -276.4849263977471, -355.93762710874336, -520.086313536163, -391.43467145014415, -570.9516034757969], "episode_lengths": [142, 137, 126, 114, 151, 116, 146, 117, 74, 116, 138, 116, 125, 125, 110, 114, 127, 120, 125, 113, 122, 128, 111, 136, 131, 115, 124, 118, 118, 115, 118, 131, 121, 164, 115, 133, 105, 112, 102, 123, 121, 104, 113, 122, 116, 126, 115, 126, 118, 114, 117, 101, 114, 111, 104, 137, 121, 112, 117, 118, 114, 111, 114, 125, 119, 118, 115, 33, 116, 89, 142, 118, 138, 108, 127, 155, 113, 118, 116, 118, 118, 124, 121, 121, 52, 122, 104, 124, 107, 117, 114, 118, 128, 126, 105, 132, 122, 117, 121, 116], "policy_AGENT-3_reward": [-75.88727346422809, 182.5623817423641, 153.0786912330205, -57.035753860978545, 58.348550612635016, -47.25110753344964, 233.40601710308985, -120.41797097484782, 14.960744268575766, -68.65790037264708, 62.83821415448865, -10.556307337039133, 162.26751450709222, -9.304449343881686, 116.38599845340502, -45.72825881810296, 113.51146599231437, -31.2514700470839, 148.96327244972633, -81.18989549217147, 148.39639914974478, -7.010784454889923, -110.18724964407662, -111.51515564383156, -40.54109671645429, -175.80645198607775, -104.04279344486496, -50.70489056027349, -131.92249025908106, -188.18186449311995, -132.6224178430206, -32.55120681092208, -95.42155622590744, 283.20458841428456, -98.98484981226505, 242.2750475369583, -32.34710619470665, 87.20333153838372, -164.21924722357602, 9.691794459941367, 195.72046099795116, -87.84312718964472, 168.02422395721518, -30.81974085620089, 100.1882777613186, -9.578931410640845, 41.90866865783268, -8.46242350892826, 131.55294084048742, -92.82346590888615, -118.22207070996089, -74.27547252436132, -77.47775895358018, -75.33922058681956, -82.07078184482481, -35.09881517340598, -128.29425814862537, -151.19696883477883, 49.683959285981985, -90.31517704857481, -74.00795464079117, -125.28059748276517, 107.64543478500619, -37.62299215638722, 140.05788856743243, -100.96978478436343, 88.08151772907522, -152.32938633765846, -25.697689861861488, -29.02188672904893, 169.1666395046298, -48.46578900351632, -4.820096760153454, -79.24319086625611, 110.0340964829206, 359.234991084874, -27.720432127009033, 149.503723944626, -15.316133692026623, 167.00447936219808, -23.313256672894784, 136.97137004391885, -8.977312400580892, 114.16032113709052, -10.299910412926284, 131.05867392305538, -18.996410311645327, 144.08326098229213, -165.44033095597104, -190.43419681643635, -96.09573237400848, -88.42983798791383, -45.68612811168161, -163.29430922720383, -37.94920647740991, -109.88265178795973, -93.45610641159786, -104.0571808766092, -104.48144284167267, -192.34942331812155], "policy_AGENT-0_reward": [-21.21837458278377, 166.34455570286124, 138.15555477939293, -153.42620782164855, -167.35130565357125, -141.0200522001386, 219.90035122026208, -161.4656240523258, -52.16672158785468, -112.12178260367864, -31.752040956663173, -2.2690833730837454, 88.7947102417551, 97.41342347492048, 110.19876019748756, -102.60015739963508, 47.26194911628826, -73.00256193555023, 120.75008754686228, -109.24966114236923, 136.0446598670456, -32.39165897640185, -82.54986560681027, 2.505152280380336, 77.17939146609784, -176.85833031569283, -121.32357828219327, -91.7427860585571, -196.3083201414169, -183.03963171546968, -165.40379761397247, 84.81772221685918, -128.25158294220762, 307.7347619446505, -141.8545985887202, 49.69984605574149, -26.782298038959535, 43.03000115703303, -138.04318669496496, -24.906836219627696, 172.29164494021887, -71.44292649698326, 78.5356374588809, -71.59045246001939, 19.90368691276303, 77.47308855571436, -0.871723599963282, 22.550905519711343, 42.73661570932582, -64.17111662585349, -153.27473963649737, -123.36031570665529, -119.08391257150501, -52.595302221772144, -131.2560132737517, 11.366820460525304, -115.17703318833277, -109.01273006720112, 10.170975255753056, -131.57812992462303, -118.19220735003367, -50.78373092124863, 66.12254153854241, -48.94042341985539, 97.04475934026483, -142.4095761262314, -5.211508610606643, -101.27228147386826, -64.5204373216649, -129.06816260996703, 89.38038423045454, -144.60573704503105, 55.400836120854166, -83.73226274195588, 84.86675386349545, 278.6817090655835, -74.88420967790317, 68.06508525648472, -85.96579693959781, 161.23284177726475, 12.523473428947959, 140.01869608806248, -70.25300498713852, 37.35559142354037, -83.04505794612874, 55.55920365216272, 52.10557401675905, 98.45886553897826, -175.84738572787515, -184.71865844939768, -138.7644396644248, -129.24659587955915, -7.362366761305815, -154.29140327044558, -112.93501302789666, -51.59102212107776, -107.66872651694402, -143.9096697456478, -92.49199683722519, -96.21526205162704], "policy_AGENT-2_reward": [-75.94550602564873, 182.5718987432813, 136.75801420459294, -107.04488568484406, 58.33100343810593, -96.40463662685599, 243.71589160378446, -118.53378889175923, 14.90085346142181, -68.48234164734679, 62.962583278274465, -10.612367586644194, 133.38090465500753, -9.337975790182007, 68.11049451355478, -45.54378857635086, 89.62896766652523, -28.774286630731087, 125.79460802099884, -132.58748698308295, 129.61432343371914, -7.046273754087265, -167.02039813918665, -111.57357473855978, -40.58554015125249, -177.42231426373476, -83.75393826821617, -103.14648794146986, -153.36060958702583, -188.2760434672896, -59.92248836091745, -32.59746412365652, -95.29517546918566, 345.0933654645345, -96.14568112653009, 229.73938124688766, -27.349135146936785, 86.47456699551606, -164.28264980771928, 18.8006030422597, 217.90073354905243, -137.4074682211471, 123.2630474607091, -30.88476762870451, 62.517637996439674, -9.52043040481664, 59.1392318378281, -8.501227884897734, 86.69309946587552, -64.72715549920032, -107.25102557687383, -121.10588394287717, -75.2857175983737, -103.09746683740045, -127.84955886807471, -35.044658027780734, -121.28493546381628, -109.56106542350904, -107.03228654586587, -127.70265786335241, -70.5888000201007, -125.23444517797166, 60.975682146831105, -37.5846868814738, 92.95627568705599, -97.42456269082575, 42.60003049080382, -152.32862634670778, -25.67315830604835, -29.000042806477957, 169.19577892743294, -99.3066313411459, -4.767508106639788, -75.83685515730924, 109.9701065796732, 325.89173535985736, -27.0550665509338, 110.68919701231533, -15.362914156104496, 137.22737832901208, 55.37114883367199, 137.41837710221535, -8.943861793752653, 76.41834011259004, -10.406481409938744, 97.15578417498526, 15.335622877278162, 98.31806273609135, -212.98830333199248, -189.7649598883968, -92.72597541632274, -115.75532468698856, -45.680516677559645, -163.2626272083002, -82.19550019202879, -109.91083741543865, -93.14162193583593, -136.2757183848858, -96.17285158484833, -96.77763361814127], "policy_AGENT-1_reward": [21.503868716599627, 197.08579808136722, 142.37925875278052, -56.76563014861523, -154.40496349156146, -47.59374353999636, 233.26370080208218, -117.77173709374867, -52.49035295983126, -67.85995111390062, -26.080814948310714, -1.8351192936295817, 134.00119263202336, 53.83804539144005, 20.762426989791003, -53.04497267060762, 50.80018310272871, -72.07236384929887, 134.63148452463724, -84.0454118473131, 137.325366440453, -28.063872894708215, -166.5867815892585, -46.38623186079348, 77.04659117206663, -169.8281774252358, -80.09880371553999, -102.41326302255716, -152.74419140039504, -182.6633184162253, -118.58187990522549, 85.04773858289388, -84.62535306309194, 324.01717914733086, -95.42812958241134, 235.4452518620175, -21.965291551028244, 42.903516420945195, -138.14427383560826, -21.137169417599914, 219.83599239618346, -71.55078724877811, 78.40679585609462, -69.51885613487629, 67.75120084288592, 84.97577897794004, 59.708004961428315, 27.928615520111112, 42.855668023095774, -139.72697318841284, -107.23384378775363, -123.32427739078611, -74.66671127204881, -53.53638412962588, -131.26269149410658, 52.95120385151647, -120.67575782494941, -145.62438711165137, -106.60260312223969, -127.14512754993034, -72.44687178106724, -74.7351576039002, 67.06387295372984, -3.2186038241350374, 99.33417170717502, -95.99833668008914, 43.05190003430684, -101.16963316470856, -15.687733834269235, -129.37967585824651, 103.12420889399716, -49.04250145793337, 99.17272847165101, -74.41086316051735, 87.64505545849357, 294.8720836699429, -25.767045723299475, 116.14567339925588, -37.65516069555904, 160.51423586914837, -22.75346614316384, 142.8452270109767, -69.09780766604885, 76.85281036897447, -82.9997984684831, 55.109751055570236, -18.431662610770797, 106.4762298883745, -175.94883263092905, -184.59320873512064, -92.64718923736214, -115.29555749086364, 34.24630373589436, -107.33549692986522, -112.8833510151187, -5.100415073271288, -61.671172244365486, -135.8437445290207, -98.28838018639804, -185.60928448790662]}, "sampler_perf": {"mean_env_wait_ms": 58.40287487628795, "mean_raw_obs_processing_ms": 2.488194053540057, "mean_inference_ms": 2.5060884813182933, "mean_action_processing_ms": 0.15079042342120944}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 117600, "timers": {"sample_time_ms": 112814.448, "sample_throughput": 37.229, "load_time_ms": 18.162, "load_throughput": 231252.214, "learn_time_ms": 10572.529, "learn_throughput": 397.256, "update_time_ms": 9.716}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 21.663925170898438, "policy_loss": -0.027451621368527412, "vf_loss": 21.683378219604492, "vf_explained_var": 0.970309853553772, "kl": 0.017773618921637535, "entropy": 1.1008918285369873, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 19.38927459716797, "policy_loss": -0.021566258743405342, "vf_loss": 19.40328025817871, "vf_explained_var": 0.9671679139137268, "kl": 0.016807055100798607, "entropy": 1.1158379316329956, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 14.408641815185547, "policy_loss": -0.029840832576155663, "vf_loss": 14.429220199584961, "vf_explained_var": 0.9771013855934143, "kl": 0.0137203149497509, "entropy": 1.1701184511184692, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 16.0867919921875, "policy_loss": -0.025039764121174812, "vf_loss": 16.102741241455078, "vf_explained_var": 0.9771578311920166, "kl": 0.013464839197695255, "entropy": 1.0944658517837524, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 117600, "num_steps_trained": 117600}, "done": false, "episodes_total": 995, "training_iteration": 28, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-07-57", "timestamp": 1624212477, "time_this_iter_s": 185.51252055168152, "time_total_s": 3062.738737821579, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd4040b80e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd4040b83b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4040b85f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8710>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4040b85f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8710>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4040b85f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8710>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4040b85f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8710>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd4042bd5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3062.738737821579, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 60.80490566037736, "ram_util_percent": 87.57207547169811}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1258.6805191802584, "episode_reward_min": -814.9432251657336, "episode_reward_mean": -83.55581431410961, "episode_len_mean": 119.13, "episodes_this_iter": 36, "policy_reward_min": {"AGENT-3": -228.72167054292626, "AGENT-0": -217.26801917866507, "AGENT-2": -228.52294094048156, "AGENT-1": -185.60928448790662}, "policy_reward_max": {"AGENT-3": 359.234991084874, "AGENT-0": 278.6817090655835, "AGENT-2": 325.89173535985736, "AGENT-1": 294.8720836699429}, "policy_reward_mean": {"AGENT-3": -12.203909030705296, "AGENT-0": -32.975983853150204, "AGENT-2": -24.04661968978782, "AGENT-1": -14.329301740466395}, "custom_metrics": {"mean_ego_speed_mean": 43.340015, "mean_ego_speed_min": 28.349999999999998, "mean_ego_speed_max": 50.82925, "distance_travelled_mean": 109.14076500000002, "distance_travelled_min": 41.84675, "distance_travelled_max": 124.84575}, "hist_stats": {"episode_reward": [-67.65957517700211, 348.15863707197946, 94.98878102191003, 622.6057058511999, -170.9130262381648, -269.0463270453569, -200.66837790066901, 284.8486508652262, -33.72009613688066, -13.657463138191453, -155.66991834129985, 340.1049560164957, 323.20513188427503, -195.74889985057717, 258.1830222257978, 366.19271591241073, 429.23011492455316, -93.15407818898441, -360.691387763253, 313.42238429137626, -412.0609561561898, 154.6249719369007, -403.48568964670756, 663.9141544111748, -697.4504204642178, -580.9550087619335, -284.13812580348315, -290.44626026226314, 33.69652747419864, -447.9277767515648, -459.2855281183153, -444.12534000044775, -727.7945802545381, -500.0398457727293, -380.6390937224337, -814.9432251657336, -316.46976800374046, 530.8670115565144, -341.4206588476263, 144.985959725712, -313.22317192603805, 392.51601238458255, 1258.6805191802584, -155.42675407914558, 444.4036796126826, -154.300005483288, 625.978935337624, 21.827899446561375, 557.2536702451742, -157.27198684752082, 304.7870630421955, -186.75124823747686, 338.88341280577407, 30.013123971621077, 447.33641914573656, -730.2248526467679, -749.5110238893512, -420.2333366921182, -448.7273160453251, -64.48270781465266, -588.1838366358149, -345.96307071245417, -276.4849263977471, -355.93762710874336, -520.086313536163, -391.43467145014415, -570.9516034757969, -151.54728535606094, 728.564634269874, 570.371518969787, -374.2724775160862, -205.07671509439186, -332.2695399004404, 930.285960729219, -518.1891210126814, -74.79547681768835, -317.12197573757385, 67.96794152778939, -25.27287759039665, 518.4443220358785, 132.60904373229675, 315.4576801542385, -246.91717746469644, 301.2025658778567, -205.10068246266403, 530.1394525422247, -407.0724554649369, 551.3807488909626, -74.5125900800874, -526.3442949793316, -266.96980996280416, 73.09934577045766, -699.9152739907406, -389.21911371081416, -348.0074275828574, -634.335611387919, -742.1608580921045, -476.5305837231364, 104.71678986517449, -403.59366770039225], "episode_lengths": [103, 111, 134, 120, 103, 115, 114, 118, 124, 101, 121, 115, 118, 119, 117, 129, 118, 113, 103, 125, 111, 114, 106, 127, 110, 110, 138, 113, 215, 117, 118, 116, 115, 114, 116, 61, 89, 142, 118, 138, 108, 127, 155, 113, 118, 116, 118, 118, 124, 121, 121, 52, 122, 104, 124, 107, 117, 114, 118, 128, 126, 105, 132, 122, 117, 121, 116, 142, 137, 126, 114, 151, 116, 146, 117, 74, 116, 138, 116, 125, 125, 110, 114, 127, 120, 125, 113, 122, 128, 111, 136, 131, 115, 124, 118, 118, 115, 118, 131, 121], "policy_AGENT-3_reward": [-15.176469745208946, 103.06865718867627, -30.404633885117114, 162.64376192739087, -40.55234032994937, -79.6871859193413, -15.550717293798224, 115.88574314228974, -42.83627890312405, -6.812867069267428, -9.996446729546324, 112.828601761085, 105.49846850578592, -31.48237883751626, 90.86880588180172, 93.38682478414087, 150.77697981081766, -12.669392757529362, -91.73777404710964, 111.28096918800397, -116.72868867620443, 73.73205082439377, -115.66655130279958, 180.12935478085802, -176.56536758768968, -124.78453566575695, -115.41817605816864, -6.373836879925263, -76.79389998137643, -103.44564828522567, -106.97187648644405, -102.11125479015828, -165.52802129542658, -106.96370452759216, -87.92889791103936, -228.72167054292626, -29.02188672904893, 169.1666395046298, -48.46578900351632, -4.820096760153454, -79.24319086625611, 110.0340964829206, 359.234991084874, -27.720432127009033, 149.503723944626, -15.316133692026623, 167.00447936219808, -23.313256672894784, 136.97137004391885, -8.977312400580892, 114.16032113709052, -10.299910412926284, 131.05867392305538, -18.996410311645327, 144.08326098229213, -165.44033095597104, -190.43419681643635, -96.09573237400848, -88.42983798791383, -45.68612811168161, -163.29430922720383, -37.94920647740991, -109.88265178795973, -93.45610641159786, -104.0571808766092, -104.48144284167267, -192.34942331812155, -75.88727346422809, 182.5623817423641, 153.0786912330205, -57.035753860978545, 58.348550612635016, -47.25110753344964, 233.40601710308985, -120.41797097484782, 14.960744268575766, -68.65790037264708, 62.83821415448865, -10.556307337039133, 162.26751450709222, -9.304449343881686, 116.38599845340502, -45.72825881810296, 113.51146599231437, -31.2514700470839, 148.96327244972633, -81.18989549217147, 148.39639914974478, -7.010784454889923, -110.18724964407662, -111.51515564383156, -40.54109671645429, -175.80645198607775, -104.04279344486496, -50.70489056027349, -131.92249025908106, -188.18186449311995, -132.6224178430206, -32.55120681092208, -95.42155622590744], "policy_AGENT-0_reward": [-19.251150128531254, 98.31650906319261, 53.39936977189665, 153.62214823826437, -45.54377994141632, -122.20293406900262, -108.05902323381741, 25.885665481984425, 3.597720170182704, 24.013136108339324, -91.07623787640173, 77.09731919658105, 42.1114371561828, -67.2826610616198, 8.825361291082238, 73.71870255930548, 62.24800296530459, -53.53913509487347, -64.39662318131393, 42.80080496794615, -90.82626688285399, 27.665934162162916, -62.34759473498262, 154.63353911879767, -175.35370829999528, -168.02403808151414, -47.94161263657506, -47.698839776568754, 73.23362351046649, -143.5950881666502, -145.69231936202783, -144.3551546313455, -217.26801917866507, -150.46363421292259, -125.89347792820956, -178.86179620704954, -129.06816260996703, 89.38038423045454, -144.60573704503105, 55.400836120854166, -83.73226274195588, 84.86675386349545, 278.6817090655835, -74.88420967790317, 68.06508525648472, -85.96579693959781, 161.23284177726475, 12.523473428947959, 140.01869608806248, -70.25300498713852, 37.35559142354037, -83.04505794612874, 55.55920365216272, 52.10557401675905, 98.45886553897826, -175.84738572787515, -184.71865844939768, -138.7644396644248, -129.24659587955915, -7.362366761305815, -154.29140327044558, -112.93501302789666, -51.59102212107776, -107.66872651694402, -143.9096697456478, -92.49199683722519, -96.21526205162704, -21.21837458278377, 166.34455570286124, 138.15555477939293, -153.42620782164855, -167.35130565357125, -141.0200522001386, 219.90035122026208, -161.4656240523258, -52.16672158785468, -112.12178260367864, -31.752040956663173, -2.2690833730837454, 88.7947102417551, 97.41342347492048, 110.19876019748756, -102.60015739963508, 47.26194911628826, -73.00256193555023, 120.75008754686228, -109.24966114236923, 136.0446598670456, -32.39165897640185, -82.54986560681027, 2.505152280380336, 77.17939146609784, -176.85833031569283, -121.32357828219327, -91.7427860585571, -196.3083201414169, -183.03963171546968, -165.40379761397247, 84.81772221685918, -128.25158294220762], "policy_AGENT-2_reward": [-19.810035424532927, 69.92683870913616, -30.39623931813816, 150.77999057203635, -46.11036038414183, -33.78622370785744, -62.292668979963565, 68.26114231198473, -42.895087069222676, -54.715522496447576, -46.29068484260364, 73.21461240089104, 84.75340243733956, -31.41482961605068, 55.49734809752225, 118.00038416165987, 106.10932989173585, -13.750925009852173, -140.18512254413378, 71.30171748839547, -91.38983714020372, 24.250913192308126, -163.06203564834667, 159.79616436048153, -175.91554406115233, -168.77394760910803, -115.4818866934588, -118.40359030142014, -76.73659240179381, -102.08493606297063, -107.45575609886491, -98.57901916930709, -172.8092167136569, -121.5724569588682, -84.28082410301515, -228.52294094048156, -29.000042806477957, 169.19577892743294, -99.3066313411459, -4.767508106639788, -75.83685515730924, 109.9701065796732, 325.89173535985736, -27.0550665509338, 110.68919701231533, -15.362914156104496, 137.22737832901208, 55.37114883367199, 137.41837710221535, -8.943861793752653, 76.41834011259004, -10.406481409938744, 97.15578417498526, 15.335622877278162, 98.31806273609135, -212.98830333199248, -189.7649598883968, -92.72597541632274, -115.75532468698856, -45.680516677559645, -163.2626272083002, -82.19550019202879, -109.91083741543865, -93.14162193583593, -136.2757183848858, -96.17285158484833, -96.77763361814127, -75.94550602564873, 182.5718987432813, 136.75801420459294, -107.04488568484406, 58.33100343810593, -96.40463662685599, 243.71589160378446, -118.53378889175923, 14.90085346142181, -68.48234164734679, 62.962583278274465, -10.612367586644194, 133.38090465500753, -9.337975790182007, 68.11049451355478, -45.54378857635086, 89.62896766652523, -28.774286630731087, 125.79460802099884, -132.58748698308295, 129.61432343371914, -7.046273754087265, -167.02039813918665, -111.57357473855978, -40.58554015125249, -177.42231426373476, -83.75393826821617, -103.14648794146986, -153.36060958702583, -188.2760434672896, -59.92248836091745, -32.59746412365652, -95.29517546918566], "policy_AGENT-1_reward": [-13.421919878728923, 76.84663211097444, 102.39028445326878, 155.55980511350847, -38.706545582657384, -33.36998334915562, -14.765968393089937, 74.81609992896756, 48.41354966528329, 23.857790319184247, -8.306548892748014, 76.96442265793853, 90.84182378496696, -65.56903033539028, 102.99150695539112, 81.08680440730464, 110.09580225669451, -13.194625326729392, -64.3718679906957, 88.03889264703048, -113.1161634569278, 28.976073758036183, -62.40950796057851, 169.35509615103808, -169.61580051538078, -119.37248740555455, -5.296450415280781, -117.96999330434917, 113.99339634690246, -98.80210423671855, -99.16557617097831, -99.07991140963695, -172.18932306679014, -121.04005007334646, -82.5358937801701, -178.83681747527615, -129.37967585824651, 103.12420889399716, -49.04250145793337, 99.17272847165101, -74.41086316051735, 87.64505545849357, 294.8720836699429, -25.767045723299475, 116.14567339925588, -37.65516069555904, 160.51423586914837, -22.75346614316384, 142.8452270109767, -69.09780766604885, 76.85281036897447, -82.9997984684831, 55.109751055570236, -18.431662610770797, 106.4762298883745, -175.94883263092905, -184.59320873512064, -92.64718923736214, -115.29555749086364, 34.24630373589436, -107.33549692986522, -112.8833510151187, -5.100415073271288, -61.671172244365486, -135.8437445290207, -98.28838018639804, -185.60928448790662, 21.503868716599627, 197.08579808136722, 142.37925875278052, -56.76563014861523, -154.40496349156146, -47.59374353999636, 233.26370080208218, -117.77173709374867, -52.49035295983126, -67.85995111390062, -26.080814948310714, -1.8351192936295817, 134.00119263202336, 53.83804539144005, 20.762426989791003, -53.04497267060762, 50.80018310272871, -72.07236384929887, 134.63148452463724, -84.0454118473131, 137.325366440453, -28.063872894708215, -166.5867815892585, -46.38623186079348, 77.04659117206663, -169.8281774252358, -80.09880371553999, -102.41326302255716, -152.74419140039504, -182.6633184162253, -118.58187990522549, 85.04773858289388, -84.62535306309194]}, "sampler_perf": {"mean_env_wait_ms": 60.13350759554993, "mean_raw_obs_processing_ms": 2.552611731172681, "mean_inference_ms": 2.5615824915480503, "mean_action_processing_ms": 0.15467363917882057}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 121800, "timers": {"sample_time_ms": 121317.143, "sample_throughput": 34.62, "load_time_ms": 19.99, "load_throughput": 210105.396, "learn_time_ms": 11252.215, "learn_throughput": 373.26, "update_time_ms": 10.18}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 17.658004760742188, "policy_loss": -0.03202975168824196, "vf_loss": 17.681781768798828, "vf_explained_var": 0.9755234122276306, "kl": 0.01834314689040184, "entropy": 1.100927710533142, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 17.42217254638672, "policy_loss": -0.021769650280475616, "vf_loss": 17.435747146606445, "vf_explained_var": 0.9684153199195862, "kl": 0.01821056194603443, "entropy": 1.087285041809082, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 8.837308883666992, "policy_loss": -0.03811262920498848, "vf_loss": 8.864421844482422, "vf_explained_var": 0.9838677048683167, "kl": 0.016296138986945152, "entropy": 1.1396310329437256, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 9.889792442321777, "policy_loss": -0.02517307549715042, "vf_loss": 9.906193733215332, "vf_explained_var": 0.9829830527305603, "kl": 0.012994195334613323, "entropy": 1.0332125425338745, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 121800, "num_steps_trained": 121800}, "done": false, "episodes_total": 1031, "training_iteration": 29, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-11-08", "timestamp": 1624212668, "time_this_iter_s": 190.80158972740173, "time_total_s": 3253.5403275489807, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40428cef0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40419fe60>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40419f320>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40420e9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420e8c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420e830>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40419f320>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40420e9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420e8c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420e830>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40419f320>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40420e9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420e8c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420e830>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40419f320>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40420e9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420e8c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420e830>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd4040b8b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3253.5403275489807, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 59.819047619047616, "ram_util_percent": 87.64029304029305}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 930.285960729219, "episode_reward_min": -814.9432251657336, "episode_reward_mean": -133.26242440941198, "episode_len_mean": 116.91, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-3": -228.72167054292626, "AGENT-0": -236.9669143050308, "AGENT-2": -228.52294094048156, "AGENT-1": -182.6633184162253}, "policy_reward_max": {"AGENT-3": 233.40601710308985, "AGENT-0": 219.90035122026208, "AGENT-2": 243.71589160378446, "AGENT-1": 233.26370080208218}, "policy_reward_mean": {"AGENT-3": -28.104255724731612, "AGENT-0": -43.76032511902684, "AGENT-2": -38.171770659949146, "AGENT-1": -23.22607290570441}, "custom_metrics": {"mean_ego_speed_mean": 43.88256749999999, "mean_ego_speed_min": 28.349999999999998, "mean_ego_speed_max": 50.82925, "distance_travelled_mean": 108.35434000000001, "distance_travelled_min": 69.33425000000001, "distance_travelled_max": 124.84575}, "hist_stats": {"episode_reward": [-101.48097959233112, 377.29487154434645, -54.9914778749019, 219.91516565177346, -436.47497165528836, -134.3268043569409, -347.8145330109868, -25.11701225055255, -167.7794084960644, -38.8733134008727, 30.632238401802468, 151.49846988437912, -357.54795954451004, -217.37121542051918, 92.49435368386415, -448.0138504472593, 150.7170072594424, -36.63434298198008, -499.0804692733491, -404.30803875987255, -74.51808499926052, -77.96625268212176, 453.6708896426916, -416.34987253147517, 237.16329397346058, -351.8411405485131, -657.5897579007191, -369.3079375131615, -706.6483307690164, -423.91710957526476, -359.50430649479614, -229.26708486407102, -226.5392002135249, -395.8349842953683, -211.44860666920994, -328.3816816617662, -338.89960979109503, 930.285960729219, -518.1891210126814, -74.79547681768835, -317.12197573757385, 67.96794152778939, -25.27287759039665, 518.4443220358785, 132.60904373229675, 315.4576801542385, -246.91717746469644, 301.2025658778567, -205.10068246266403, 530.1394525422247, -407.0724554649369, 551.3807488909626, -74.5125900800874, -526.3442949793316, -266.96980996280416, 73.09934577045766, -699.9152739907406, -389.21911371081416, -348.0074275828574, -634.335611387919, -742.1608580921045, -476.5305837231364, 104.71678986517449, -403.59366770039225, -67.65957517700211, 348.15863707197946, 94.98878102191003, 622.6057058511999, -170.9130262381648, -269.0463270453569, -200.66837790066901, 284.8486508652262, -33.72009613688066, -13.657463138191453, -155.66991834129985, 340.1049560164957, 323.20513188427503, -195.74889985057717, 258.1830222257978, 366.19271591241073, 429.23011492455316, -93.15407818898441, -360.691387763253, 313.42238429137626, -412.0609561561898, 154.6249719369007, -403.48568964670756, 663.9141544111748, -697.4504204642178, -580.9550087619335, -284.13812580348315, -290.44626026226314, 33.69652747419864, -447.9277767515648, -459.2855281183153, -444.12534000044775, -727.7945802545381, -500.0398457727293, -380.6390937224337, -814.9432251657336], "episode_lengths": [102, 105, 123, 113, 114, 124, 111, 103, 118, 121, 121, 118, 104, 119, 113, 107, 113, 107, 117, 112, 102, 114, 112, 104, 113, 114, 126, 110, 118, 107, 120, 130, 103, 113, 108, 119, 137, 146, 117, 74, 116, 138, 116, 125, 125, 110, 114, 127, 120, 125, 113, 122, 128, 111, 136, 131, 115, 124, 118, 118, 115, 118, 131, 121, 103, 111, 134, 120, 103, 115, 114, 118, 124, 101, 121, 115, 118, 119, 117, 129, 118, 113, 103, 125, 111, 114, 106, 127, 110, 110, 138, 113, 215, 117, 118, 116, 115, 114, 116, 61], "policy_AGENT-3_reward": [-25.761282937448172, 103.64755296275368, -32.777261774379134, 81.13986754460737, -102.86932915984255, -29.526845565835664, -50.85489475896958, -21.015654195940527, -44.52817428429433, 9.606775430022351, -46.515093383383274, 79.04893373829152, -52.586887026322906, -59.030570537244394, 25.066736802404595, -110.42370932165163, 85.18352251941855, -12.922376020946508, -194.63725794748387, -137.90613163565033, -26.309791328735084, 0.6762482685018223, 133.42284035661666, -161.00539976305183, 91.37726618304497, -91.26983435803484, -143.03317076292777, -121.532639672328, -165.13259242217697, -127.864793884504, -32.558541262637604, -58.12013317417022, -20.996652694833625, -102.38120185623235, 6.763237238778487, -85.97329760821235, -111.13205407750915, 233.40601710308985, -120.41797097484782, 14.960744268575766, -68.65790037264708, 62.83821415448865, -10.556307337039133, 162.26751450709222, -9.304449343881686, 116.38599845340502, -45.72825881810296, 113.51146599231437, -31.2514700470839, 148.96327244972633, -81.18989549217147, 148.39639914974478, -7.010784454889923, -110.18724964407662, -111.51515564383156, -40.54109671645429, -175.80645198607775, -104.04279344486496, -50.70489056027349, -131.92249025908106, -188.18186449311995, -132.6224178430206, -32.55120681092208, -95.42155622590744, -15.176469745208946, 103.06865718867627, -30.404633885117114, 162.64376192739087, -40.55234032994937, -79.6871859193413, -15.550717293798224, 115.88574314228974, -42.83627890312405, -6.812867069267428, -9.996446729546324, 112.828601761085, 105.49846850578592, -31.48237883751626, 90.86880588180172, 93.38682478414087, 150.77697981081766, -12.669392757529362, -91.73777404710964, 111.28096918800397, -116.72868867620443, 73.73205082439377, -115.66655130279958, 180.12935478085802, -176.56536758768968, -124.78453566575695, -115.41817605816864, -6.373836879925263, -76.79389998137643, -103.44564828522567, -106.97187648644405, -102.11125479015828, -165.52802129542658, -106.96370452759216, -87.92889791103936, -228.72167054292626], "policy_AGENT-0_reward": [-25.58118854564599, 106.21991320012341, -16.414987508229835, 47.09686839390087, -138.4830261955861, -59.57805787528072, -145.89124197451312, 31.697106876306506, -60.49791270930457, -29.451400087995843, 41.49788693021465, -5.00976300008243, -101.5261944729034, -37.94434425684809, -16.407786789555487, -89.98603156083198, -10.350992740720372, -5.454373928064271, -236.9669143050308, -65.79332595959099, 13.461187307664835, -42.71931679244065, 122.47641319834571, -170.67537289988203, 49.36677645078714, -117.93370306245384, -182.39390246595957, -81.90691830683636, -212.17805124049642, -87.97897979283653, -72.33353117478465, -76.32945835559923, -104.6291690005494, -128.74941660092026, -91.2733874107423, -109.44673548566443, -77.82838176010658, 219.90035122026208, -161.4656240523258, -52.16672158785468, -112.12178260367864, -31.752040956663173, -2.2690833730837454, 88.7947102417551, 97.41342347492048, 110.19876019748756, -102.60015739963508, 47.26194911628826, -73.00256193555023, 120.75008754686228, -109.24966114236923, 136.0446598670456, -32.39165897640185, -82.54986560681027, 2.505152280380336, 77.17939146609784, -176.85833031569283, -121.32357828219327, -91.7427860585571, -196.3083201414169, -183.03963171546968, -165.40379761397247, 84.81772221685918, -128.25158294220762, -19.251150128531254, 98.31650906319261, 53.39936977189665, 153.62214823826437, -45.54377994141632, -122.20293406900262, -108.05902323381741, 25.885665481984425, 3.597720170182704, 24.013136108339324, -91.07623787640173, 77.09731919658105, 42.1114371561828, -67.2826610616198, 8.825361291082238, 73.71870255930548, 62.24800296530459, -53.53913509487347, -64.39662318131393, 42.80080496794615, -90.82626688285399, 27.665934162162916, -62.34759473498262, 154.63353911879767, -175.35370829999528, -168.02403808151414, -47.94161263657506, -47.698839776568754, 73.23362351046649, -143.5950881666502, -145.69231936202783, -144.3551546313455, -217.26801917866507, -150.46363421292259, -125.89347792820956, -178.86179620704954], "policy_AGENT-2_reward": [-26.147554360181044, 61.518449831720304, -32.82241758740453, 44.181035947379286, -92.81770077296366, -29.478841875567447, -99.84671985007924, -67.41862430607722, -44.58363111253017, -36.229216404642344, -46.43546186382667, 36.373662164100494, -101.9673691669154, -61.84034890756237, 41.70095314716996, -157.67467181667024, 37.993615528699806, -12.851288883373005, -34.04413590027604, -66.34641965957722, -75.15376403728426, 4.8664944537492785, 96.4751818056275, -42.58607295374348, 46.912525604686586, -70.21911350720549, -166.4298577565679, -61.05116222474084, -165.15259516960336, -88.53280657252672, -127.52253570616352, -58.02803100647249, 3.685540523322267, -81.41862428966225, -35.67722431275216, -66.83305414208523, -111.18712344542116, 243.71589160378446, -118.53378889175923, 14.90085346142181, -68.48234164734679, 62.962583278274465, -10.612367586644194, 133.38090465500753, -9.337975790182007, 68.11049451355478, -45.54378857635086, 89.62896766652523, -28.774286630731087, 125.79460802099884, -132.58748698308295, 129.61432343371914, -7.046273754087265, -167.02039813918665, -111.57357473855978, -40.58554015125249, -177.42231426373476, -83.75393826821617, -103.14648794146986, -153.36060958702583, -188.2760434672896, -59.92248836091745, -32.59746412365652, -95.29517546918566, -19.810035424532927, 69.92683870913616, -30.39623931813816, 150.77999057203635, -46.11036038414183, -33.78622370785744, -62.292668979963565, 68.26114231198473, -42.895087069222676, -54.715522496447576, -46.29068484260364, 73.21461240089104, 84.75340243733956, -31.41482961605068, 55.49734809752225, 118.00038416165987, 106.10932989173585, -13.750925009852173, -140.18512254413378, 71.30171748839547, -91.38983714020372, 24.250913192308126, -163.06203564834667, 159.79616436048153, -175.91554406115233, -168.77394760910803, -115.4818866934588, -118.40359030142014, -76.73659240179381, -102.08493606297063, -107.45575609886491, -98.57901916930709, -172.8092167136569, -121.5724569588682, -84.28082410301515, -228.52294094048156], "policy_AGENT-1_reward": [-23.990953749055837, 105.90895554974946, 27.023188995111447, 47.497393765885704, -102.30491552689585, -15.743059040257112, -51.221676427424846, 31.620159375158707, -18.169690389935035, 17.200527661743024, 82.0849067187979, 41.085636982069644, -101.46750887836838, -58.555951718864186, 42.13445052384547, -89.92943774810581, 37.89086195204445, -5.406304149596274, -33.432161120558355, -134.26216150505377, 13.484283059093965, -40.78967861193224, 101.29645428210175, -42.08302691479771, 49.50672573494239, -72.41848962081906, -165.73282691526316, -104.81721730925639, -164.18509193674026, -119.54052932539754, -127.08969835121056, -36.78946232782888, -104.59891904146437, -83.28574154855369, -91.26123218449416, -66.12859442580401, -38.7520505080579, 233.26370080208218, -117.77173709374867, -52.49035295983126, -67.85995111390062, -26.080814948310714, -1.8351192936295817, 134.00119263202336, 53.83804539144005, 20.762426989791003, -53.04497267060762, 50.80018310272871, -72.07236384929887, 134.63148452463724, -84.0454118473131, 137.325366440453, -28.063872894708215, -166.5867815892585, -46.38623186079348, 77.04659117206663, -169.8281774252358, -80.09880371553999, -102.41326302255716, -152.74419140039504, -182.6633184162253, -118.58187990522549, 85.04773858289388, -84.62535306309194, -13.421919878728923, 76.84663211097444, 102.39028445326878, 155.55980511350847, -38.706545582657384, -33.36998334915562, -14.765968393089937, 74.81609992896756, 48.41354966528329, 23.857790319184247, -8.306548892748014, 76.96442265793853, 90.84182378496696, -65.56903033539028, 102.99150695539112, 81.08680440730464, 110.09580225669451, -13.194625326729392, -64.3718679906957, 88.03889264703048, -113.1161634569278, 28.976073758036183, -62.40950796057851, 169.35509615103808, -169.61580051538078, -119.37248740555455, -5.296450415280781, -117.96999330434917, 113.99339634690246, -98.80210423671855, -99.16557617097831, -99.07991140963695, -172.18932306679014, -121.04005007334646, -82.5358937801701, -178.83681747527615]}, "sampler_perf": {"mean_env_wait_ms": 61.701293567946315, "mean_raw_obs_processing_ms": 2.6075749941304376, "mean_inference_ms": 2.617933874330424, "mean_action_processing_ms": 0.15813823883237585}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 126000, "timers": {"sample_time_ms": 128281.434, "sample_throughput": 32.741, "load_time_ms": 20.166, "load_throughput": 208269.955, "learn_time_ms": 11228.561, "learn_throughput": 374.046, "update_time_ms": 10.176}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 17.671161651611328, "policy_loss": -0.032320085912942886, "vf_loss": 17.6954288482666, "vf_explained_var": 0.9738121032714844, "kl": 0.01789977215230465, "entropy": 1.1242575645446777, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 16.610456466674805, "policy_loss": -0.02668723464012146, "vf_loss": 16.630393981933594, "vf_explained_var": 0.9685232043266296, "kl": 0.014997919090092182, "entropy": 1.0363264083862305, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 16.429075241088867, "policy_loss": -0.030122460797429085, "vf_loss": 16.451488494873047, "vf_explained_var": 0.9676712155342102, "kl": 0.01142387930303812, "entropy": 1.1313354969024658, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 16.503698348999023, "policy_loss": -0.024270877242088318, "vf_loss": 16.518285751342773, "vf_explained_var": 0.973214328289032, "kl": 0.014346235431730747, "entropy": 1.050696849822998, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 126000, "num_steps_trained": 126000}, "done": false, "episodes_total": 1068, "training_iteration": 30, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-13-56", "timestamp": 1624212836, "time_this_iter_s": 167.23329544067383, "time_total_s": 3420.7736229896545, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd4040724d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd4040723b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd404072170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd404072050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd404072830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404072950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd404072170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd404072050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd404072830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404072950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd404072170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd404072050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd404072830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404072950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd404072170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd404072050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd404072830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404072950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd4040725f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3420.7736229896545, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 59.99201680672268, "ram_util_percent": 87.50294117647057}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 663.9141544111748, "episode_reward_min": -814.9432251657336, "episode_reward_mean": -162.4217851388799, "episode_len_mean": 116.24, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-3": -228.72167054292626, "AGENT-0": -236.9669143050308, "AGENT-2": -228.52294094048156, "AGENT-1": -178.83681747527615}, "policy_reward_max": {"AGENT-3": 180.12935478085802, "AGENT-0": 154.63353911879767, "AGENT-2": 159.79616436048153, "AGENT-1": 169.35509615103808}, "policy_reward_mean": {"AGENT-3": -37.72853480294315, "AGENT-0": -50.126586286732845, "AGENT-2": -46.99181672349752, "AGENT-1": -27.574847325706404}, "custom_metrics": {"mean_ego_speed_mean": 44.041912499999995, "mean_ego_speed_min": 28.349999999999998, "mean_ego_speed_max": 50.82925, "distance_travelled_mean": 106.56208749999998, "distance_travelled_min": 71.89075, "distance_travelled_max": 124.84575}, "hist_stats": {"episode_reward": [-216.98387037107503, 465.86838740528344, 60.10722314878581, -53.062011974671094, -292.81950862545, -322.3926017606068, -5.189955061058406, 56.50963880845382, -387.1075115482722, 571.5419258996062, -358.4454433493643, 137.95937416588617, -392.10928899822215, 457.23879898018254, -383.42320411314813, -280.3024772688668, -320.38588537546127, 133.2153956527377, -447.5895240627765, 269.4215596583581, -416.5428522331976, -116.34429406817492, 364.2301210863339, -378.4895340655702, -546.698504055658, -708.1652840631104, -166.38308419099403, -383.71862002737276, -177.19345343254253, -85.23953522940218, -247.67271152307828, -351.90153452475136, -390.27498203378906, -198.44972187672255, 6.416217895310645, -33.72009613688066, -13.657463138191453, -155.66991834129985, 340.1049560164957, 323.20513188427503, -195.74889985057717, 258.1830222257978, 366.19271591241073, 429.23011492455316, -93.15407818898441, -360.691387763253, 313.42238429137626, -412.0609561561898, 154.6249719369007, -403.48568964670756, 663.9141544111748, -697.4504204642178, -580.9550087619335, -284.13812580348315, -290.44626026226314, 33.69652747419864, -447.9277767515648, -459.2855281183153, -444.12534000044775, -727.7945802545381, -500.0398457727293, -380.6390937224337, -814.9432251657336, -101.48097959233112, 377.29487154434645, -54.9914778749019, 219.91516565177346, -436.47497165528836, -134.3268043569409, -347.8145330109868, -25.11701225055255, -167.7794084960644, -38.8733134008727, 30.632238401802468, 151.49846988437912, -357.54795954451004, -217.37121542051918, 92.49435368386415, -448.0138504472593, 150.7170072594424, -36.63434298198008, -499.0804692733491, -404.30803875987255, -74.51808499926052, -77.96625268212176, 453.6708896426916, -416.34987253147517, 237.16329397346058, -351.8411405485131, -657.5897579007191, -369.3079375131615, -706.6483307690164, -423.91710957526476, -359.50430649479614, -229.26708486407102, -226.5392002135249, -395.8349842953683, -211.44860666920994, -328.3816816617662, -338.89960979109503], "episode_lengths": [103, 123, 121, 104, 114, 113, 124, 107, 121, 119, 123, 111, 114, 115, 118, 108, 114, 117, 118, 115, 115, 118, 120, 102, 120, 118, 126, 106, 148, 132, 104, 119, 118, 127, 130, 124, 101, 121, 115, 118, 119, 117, 129, 118, 113, 103, 125, 111, 114, 106, 127, 110, 110, 138, 113, 215, 117, 118, 116, 115, 114, 116, 61, 102, 105, 123, 113, 114, 124, 111, 103, 118, 121, 121, 118, 104, 119, 113, 107, 113, 107, 117, 112, 102, 114, 112, 104, 113, 114, 126, 110, 118, 107, 120, 130, 103, 113, 108, 119, 137], "policy_AGENT-3_reward": [-51.790846707519634, 158.06629632011274, -46.22829957513845, -20.43823222325582, -105.32688926441567, -22.095456125093925, -38.693754856536465, 48.26836164271761, -111.62315515608617, 156.72728514554552, -98.54416101270976, 106.5328803448419, -114.27827286954826, 148.5375226322364, -108.38103637120777, -90.16589394966002, -57.48150682730411, 32.28509728322635, -111.11444732981151, 96.4382146371389, -92.23202570605648, -41.53118575754544, 107.34193577231161, -92.94131256469026, -123.0671428403555, -161.22742446324156, -87.46436796722777, -104.57763926010935, -109.18450203594799, -54.02436106925644, -38.62375419061374, -79.08468013917688, -58.89323236863388, -84.50496939734707, -59.76472087570946, -42.83627890312405, -6.812867069267428, -9.996446729546324, 112.828601761085, 105.49846850578592, -31.48237883751626, 90.86880588180172, 93.38682478414087, 150.77697981081766, -12.669392757529362, -91.73777404710964, 111.28096918800397, -116.72868867620443, 73.73205082439377, -115.66655130279958, 180.12935478085802, -176.56536758768968, -124.78453566575695, -115.41817605816864, -6.373836879925263, -76.79389998137643, -103.44564828522567, -106.97187648644405, -102.11125479015828, -165.52802129542658, -106.96370452759216, -87.92889791103936, -228.72167054292626, -25.761282937448172, 103.64755296275368, -32.777261774379134, 81.13986754460737, -102.86932915984255, -29.526845565835664, -50.85489475896958, -21.015654195940527, -44.52817428429433, 9.606775430022351, -46.515093383383274, 79.04893373829152, -52.586887026322906, -59.030570537244394, 25.066736802404595, -110.42370932165163, 85.18352251941855, -12.922376020946508, -194.63725794748387, -137.90613163565033, -26.309791328735084, 0.6762482685018223, 133.42284035661666, -161.00539976305183, 91.37726618304497, -91.26983435803484, -143.03317076292777, -121.532639672328, -165.13259242217697, -127.864793884504, -32.558541262637604, -58.12013317417022, -20.996652694833625, -102.38120185623235, 6.763237238778487, -85.97329760821235, -111.13205407750915], "policy_AGENT-0_reward": [-57.51302982170899, 76.7891874373573, 52.91397636558393, 17.343488997421396, -28.692817388442542, -139.04494177147168, 15.635354116438322, 3.3907987479018367, -103.0659491598993, 138.42701232951137, -101.83038376942116, -37.90140401066288, -62.21629516343584, 103.90993832419342, -84.55976340289286, -66.54736141294404, -102.90761687752034, -9.679909117887512, -152.00971361463763, 57.51133828116164, -136.64824136506667, -18.36882008906951, 38.97232078007064, -72.62299377318013, -147.6446846035541, -211.0916942096265, -17.415584981100665, -78.66559696016648, 1.221260780814113, -8.660636439995692, -98.13739042758667, -118.22243124587102, -97.87201773027812, -35.832866623727305, 42.947179135739944, 3.597720170182704, 24.013136108339324, -91.07623787640173, 77.09731919658105, 42.1114371561828, -67.2826610616198, 8.825361291082238, 73.71870255930548, 62.24800296530459, -53.53913509487347, -64.39662318131393, 42.80080496794615, -90.82626688285399, 27.665934162162916, -62.34759473498262, 154.63353911879767, -175.35370829999528, -168.02403808151414, -47.94161263657506, -47.698839776568754, 73.23362351046649, -143.5950881666502, -145.69231936202783, -144.3551546313455, -217.26801917866507, -150.46363421292259, -125.89347792820956, -178.86179620704954, -25.58118854564599, 106.21991320012341, -16.414987508229835, 47.09686839390087, -138.4830261955861, -59.57805787528072, -145.89124197451312, 31.697106876306506, -60.49791270930457, -29.451400087995843, 41.49788693021465, -5.00976300008243, -101.5261944729034, -37.94434425684809, -16.407786789555487, -89.98603156083198, -10.350992740720372, -5.454373928064271, -236.9669143050308, -65.79332595959099, 13.461187307664835, -42.71931679244065, 122.47641319834571, -170.67537289988203, 49.36677645078714, -117.93370306245384, -182.39390246595957, -81.90691830683636, -212.17805124049642, -87.97897979283653, -72.33353117478465, -76.32945835559923, -104.6291690005494, -128.74941660092026, -91.2733874107423, -109.44673548566443, -77.82838176010658], "policy_AGENT-2_reward": [-58.07225400368949, 109.29513789048178, -46.16993312531233, -67.39168527923894, -54.036915373566345, -22.149435510773372, -38.6321324570456, 0.26139967277479315, -61.35993836599249, 135.51540565993264, -60.08936912372619, 57.79920080956593, -153.1521788137599, 99.90156342462507, -105.43964563127408, -32.228386955741954, -56.958062972209625, 55.04473241141892, -92.4523652545533, 55.553412997309266, -94.13541662156995, -40.693379514377625, 84.18314373746614, -140.35126499833407, -153.48479801666122, -168.23016108763267, -87.4858499855184, -99.89164684180338, -109.10473300917656, -54.08709312812993, -12.858202367822152, -78.9603572829173, -117.07083009435378, -84.50943177582016, -59.75440932628112, -42.895087069222676, -54.715522496447576, -46.29068484260364, 73.21461240089104, 84.75340243733956, -31.41482961605068, 55.49734809752225, 118.00038416165987, 106.10932989173585, -13.750925009852173, -140.18512254413378, 71.30171748839547, -91.38983714020372, 24.250913192308126, -163.06203564834667, 159.79616436048153, -175.91554406115233, -168.77394760910803, -115.4818866934588, -118.40359030142014, -76.73659240179381, -102.08493606297063, -107.45575609886491, -98.57901916930709, -172.8092167136569, -121.5724569588682, -84.28082410301515, -228.52294094048156, -26.147554360181044, 61.518449831720304, -32.82241758740453, 44.181035947379286, -92.81770077296366, -29.478841875567447, -99.84671985007924, -67.41862430607722, -44.58363111253017, -36.229216404642344, -46.43546186382667, 36.373662164100494, -101.9673691669154, -61.84034890756237, 41.70095314716996, -157.67467181667024, 37.993615528699806, -12.851288883373005, -34.04413590027604, -66.34641965957722, -75.15376403728426, 4.8664944537492785, 96.4751818056275, -42.58607295374348, 46.912525604686586, -70.21911350720549, -166.4298577565679, -61.05116222474084, -165.15259516960336, -88.53280657252672, -127.52253570616352, -58.02803100647249, 3.685540523322267, -81.41862428966225, -35.67722431275216, -66.83305414208523, -111.18712344542116], "policy_AGENT-1_reward": [-49.60773983815664, 121.71776575733115, 99.59147948365262, 17.424416530402286, -104.76288659902556, -139.10276835326763, 56.500578136085295, 4.589078745059695, -111.0584688662942, 140.87222276461648, -97.9815294435073, 11.528697022141564, -62.46254215147809, 104.88977459912768, -85.04275870777357, -91.36083495052091, -103.03869869842721, 55.5654750759794, -92.01299786377407, 59.91859374274836, -93.52716854050446, -15.750908707182436, 133.73272079648578, -72.57396272936555, -122.50187859508739, -167.61600430260884, 25.982718742852747, -100.5837369652933, 39.87452083176788, 31.532555407979896, -98.05336453705574, -75.63406585678632, -116.43890184052333, 6.397545920172128, 82.98816896156131, 48.41354966528329, 23.857790319184247, -8.306548892748014, 76.96442265793853, 90.84182378496696, -65.56903033539028, 102.99150695539112, 81.08680440730464, 110.09580225669451, -13.194625326729392, -64.3718679906957, 88.03889264703048, -113.1161634569278, 28.976073758036183, -62.40950796057851, 169.35509615103808, -169.61580051538078, -119.37248740555455, -5.296450415280781, -117.96999330434917, 113.99339634690246, -98.80210423671855, -99.16557617097831, -99.07991140963695, -172.18932306679014, -121.04005007334646, -82.5358937801701, -178.83681747527615, -23.990953749055837, 105.90895554974946, 27.023188995111447, 47.497393765885704, -102.30491552689585, -15.743059040257112, -51.221676427424846, 31.620159375158707, -18.169690389935035, 17.200527661743024, 82.0849067187979, 41.085636982069644, -101.46750887836838, -58.555951718864186, 42.13445052384547, -89.92943774810581, 37.89086195204445, -5.406304149596274, -33.432161120558355, -134.26216150505377, 13.484283059093965, -40.78967861193224, 101.29645428210175, -42.08302691479771, 49.50672573494239, -72.41848962081906, -165.73282691526316, -104.81721730925639, -164.18509193674026, -119.54052932539754, -127.08969835121056, -36.78946232782888, -104.59891904146437, -83.28574154855369, -91.26123218449416, -66.12859442580401, -38.7520505080579]}, "sampler_perf": {"mean_env_wait_ms": 62.463585153126196, "mean_raw_obs_processing_ms": 2.636796801186155, "mean_inference_ms": 2.6466843985554704, "mean_action_processing_ms": 0.1598420189797916}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 130200, "timers": {"sample_time_ms": 128726.212, "sample_throughput": 32.627, "load_time_ms": 20.009, "load_throughput": 209907.115, "learn_time_ms": 11200.786, "learn_throughput": 374.974, "update_time_ms": 10.334}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 25.47389793395996, "policy_loss": -0.028634389862418175, "vf_loss": 25.49434471130371, "vf_explained_var": 0.9714948534965515, "kl": 0.018199902027845383, "entropy": 1.0933171510696411, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 18.918350219726562, "policy_loss": -0.021779417991638184, "vf_loss": 18.932775497436523, "vf_explained_var": 0.9739872813224792, "kl": 0.016342297196388245, "entropy": 1.0291614532470703, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 17.480539321899414, "policy_loss": -0.026747258380055428, "vf_loss": 17.49867820739746, "vf_explained_var": 0.9727467894554138, "kl": 0.012751676142215729, "entropy": 1.1673120260238647, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 16.153419494628906, "policy_loss": -0.02778059057891369, "vf_loss": 16.172344207763672, "vf_explained_var": 0.9759014248847961, "kl": 0.013115428388118744, "entropy": 1.0336875915527344, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 130200, "num_steps_trained": 130200}, "done": false, "episodes_total": 1103, "training_iteration": 31, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-15-38", "timestamp": 1624212938, "time_this_iter_s": 101.63259935379028, "time_total_s": 3522.406222343445, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd4042bdc20>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd4042bd560>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd050>, action_adapter=<function AgentSpec.<lambda> at 0x7fd404254050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420ef80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420e7a0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd050>, action_adapter=<function AgentSpec.<lambda> at 0x7fd404254050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420ef80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420e7a0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd050>, action_adapter=<function AgentSpec.<lambda> at 0x7fd404254050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420ef80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420e7a0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd050>, action_adapter=<function AgentSpec.<lambda> at 0x7fd404254050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420ef80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420e7a0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd404072b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3522.406222343445, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 55.55793103448276, "ram_util_percent": 87.61793103448278}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 878.3383737505617, "episode_reward_min": -1043.6930512396198, "episode_reward_mean": -153.50810749988267, "episode_len_mean": 117.17, "episodes_this_iter": 36, "policy_reward_min": {"AGENT-3": -242.93717455209895, "AGENT-0": -247.1329750119267, "AGENT-2": -277.1192626254035, "AGENT-1": -276.50363905019066}, "policy_reward_max": {"AGENT-3": 250.20254335956912, "AGENT-0": 213.98690410161714, "AGENT-2": 226.23652747701212, "AGENT-1": 237.17936528343108}, "policy_reward_mean": {"AGENT-3": -34.49368023923665, "AGENT-0": -46.81776467329404, "AGENT-2": -41.11061584363414, "AGENT-1": -31.08604674371783}, "custom_metrics": {"mean_ego_speed_mean": 44.127092499999996, "mean_ego_speed_min": 35.02425, "mean_ego_speed_max": 50.684, "distance_travelled_mean": 106.26270749999998, "distance_travelled_min": 75.52600000000001, "distance_travelled_max": 124.82775000000001}, "hist_stats": {"episode_reward": [-432.61239741935725, -39.943298976293406, -133.47478589936244, 108.21418753403219, -62.88130440199248, 455.9063098366113, -343.34170060327995, 418.05414638247686, -210.82917787220205, -417.8009142434135, -167.250749255633, -15.826592652617808, 445.2604129000877, -386.77978683666163, 562.7227246201178, -81.38309244431449, 80.07890878823949, -357.4061658182956, 878.3383737505617, -121.17082323545587, 397.226998529643, -229.75166895931645, 406.3018867757182, -378.57384187481046, -303.57241679721545, -544.5969288090236, -518.872514190604, -350.5678700886942, 368.32047646066644, -406.2463575156163, -338.2154850902791, 1.141796675792314, -1043.6930512396198, -340.4613393385095, -476.6356495638448, -444.6660019952508, -167.7794084960644, -38.8733134008727, 30.632238401802468, 151.49846988437912, -357.54795954451004, -217.37121542051918, 92.49435368386415, -448.0138504472593, 150.7170072594424, -36.63434298198008, -499.0804692733491, -404.30803875987255, -74.51808499926052, -77.96625268212176, 453.6708896426916, -416.34987253147517, 237.16329397346058, -351.8411405485131, -657.5897579007191, -369.3079375131615, -706.6483307690164, -423.91710957526476, -359.50430649479614, -229.26708486407102, -226.5392002135249, -395.8349842953683, -211.44860666920994, -328.3816816617662, -338.89960979109503, -216.98387037107503, 465.86838740528344, 60.10722314878581, -53.062011974671094, -292.81950862545, -322.3926017606068, -5.189955061058406, 56.50963880845382, -387.1075115482722, 571.5419258996062, -358.4454433493643, 137.95937416588617, -392.10928899822215, 457.23879898018254, -383.42320411314813, -280.3024772688668, -320.38588537546127, 133.2153956527377, -447.5895240627765, 269.4215596583581, -416.5428522331976, -116.34429406817492, 364.2301210863339, -378.4895340655702, -546.698504055658, -708.1652840631104, -166.38308419099403, -383.71862002737276, -177.19345343254253, -85.23953522940218, -247.67271152307828, -351.90153452475136, -390.27498203378906, -198.44972187672255, 6.416217895310645], "episode_lengths": [115, 105, 112, 124, 134, 128, 130, 122, 116, 120, 113, 101, 119, 113, 119, 118, 116, 117, 125, 113, 119, 116, 125, 111, 108, 115, 115, 127, 136, 114, 126, 129, 126, 127, 122, 116, 118, 121, 121, 118, 104, 119, 113, 107, 113, 107, 117, 112, 102, 114, 112, 104, 113, 114, 126, 110, 118, 107, 120, 130, 103, 113, 108, 119, 137, 103, 123, 121, 104, 114, 113, 124, 107, 121, 119, 123, 111, 114, 115, 118, 108, 114, 117, 118, 115, 115, 118, 120, 102, 120, 118, 126, 106, 148, 132, 104, 119, 118, 127, 130], "policy_AGENT-3_reward": [-111.28182038993651, -25.293149614842424, -25.194076475593704, 31.765936681161634, -50.02307948148814, 161.5570905430398, -85.47459743413258, 120.86222137804045, -27.458411790553168, -182.90658164926054, -62.3172362267308, -37.28547383105177, 156.32705255905293, -135.58385405019934, 172.26437456218534, -17.752396389040918, 14.565965181979784, -79.08623242735707, 226.1108652040699, -30.06284613705177, 143.8791493134605, -35.69487934875856, 122.70401282121405, -131.11609805329812, -96.61225300557619, -92.12143862699436, -124.51006501236273, -27.194557781452453, 250.20254335956912, -107.95676845235963, -19.97848204511571, -47.53120023486424, -242.93717455209895, -54.427144355358685, -115.82657909993813, -100.18041945070188, -44.52817428429433, 9.606775430022351, -46.515093383383274, 79.04893373829152, -52.586887026322906, -59.030570537244394, 25.066736802404595, -110.42370932165163, 85.18352251941855, -12.922376020946508, -194.63725794748387, -137.90613163565033, -26.309791328735084, 0.6762482685018223, 133.42284035661666, -161.00539976305183, 91.37726618304497, -91.26983435803484, -143.03317076292777, -121.532639672328, -165.13259242217697, -127.864793884504, -32.558541262637604, -58.12013317417022, -20.996652694833625, -102.38120185623235, 6.763237238778487, -85.97329760821235, -111.13205407750915, -51.790846707519634, 158.06629632011274, -46.22829957513845, -20.43823222325582, -105.32688926441567, -22.095456125093925, -38.693754856536465, 48.26836164271761, -111.62315515608617, 156.72728514554552, -98.54416101270976, 106.5328803448419, -114.27827286954826, 148.5375226322364, -108.38103637120777, -90.16589394966002, -57.48150682730411, 32.28509728322635, -111.11444732981151, 96.4382146371389, -92.23202570605648, -41.53118575754544, 107.34193577231161, -92.94131256469026, -123.0671428403555, -161.22742446324156, -87.46436796722777, -104.57763926010935, -109.18450203594799, -54.02436106925644, -38.62375419061374, -79.08468013917688, -58.89323236863388, -84.50496939734707, -59.76472087570946], "policy_AGENT-0_reward": [-126.87851375552859, 28.955250581764155, -35.13180469622259, 2.592923564903323, -0.45756035254346017, 55.86242290810538, -106.43002488352516, 47.44969094269119, -106.20409785453042, -30.134943962577708, -66.39590813488577, 17.97878684297238, 66.15904933096371, -60.83180254870241, 131.83142870659185, -22.0079297309984, -26.917624670243264, -120.59785338176759, 188.81161578604835, -68.74283323135273, 52.711702036834325, -80.50281861293925, 52.29389837033389, -60.748043014077005, -57.086967599038815, -156.19939928154773, -130.97750479092946, -64.17827724141547, 213.98690410161714, -130.46940988274864, -57.80513704340645, 27.55711965016433, -247.1329750119267, -91.36405820996401, -147.8857275292599, -145.83265579511996, -60.49791270930457, -29.451400087995843, 41.49788693021465, -5.00976300008243, -101.5261944729034, -37.94434425684809, -16.407786789555487, -89.98603156083198, -10.350992740720372, -5.454373928064271, -236.9669143050308, -65.79332595959099, 13.461187307664835, -42.71931679244065, 122.47641319834571, -170.67537289988203, 49.36677645078714, -117.93370306245384, -182.39390246595957, -81.90691830683636, -212.17805124049642, -87.97897979283653, -72.33353117478465, -76.32945835559923, -104.6291690005494, -128.74941660092026, -91.2733874107423, -109.44673548566443, -77.82838176010658, -57.51302982170899, 76.7891874373573, 52.91397636558393, 17.343488997421396, -28.692817388442542, -139.04494177147168, 15.635354116438322, 3.3907987479018367, -103.0659491598993, 138.42701232951137, -101.83038376942116, -37.90140401066288, -62.21629516343584, 103.90993832419342, -84.55976340289286, -66.54736141294404, -102.90761687752034, -9.679909117887512, -152.00971361463763, 57.51133828116164, -136.64824136506667, -18.36882008906951, 38.97232078007064, -72.62299377318013, -147.6446846035541, -211.0916942096265, -17.415584981100665, -78.66559696016648, 1.221260780814113, -8.660636439995692, -98.13739042758667, -118.22243124587102, -97.87201773027812, -35.832866623727305, 42.947179135739944], "policy_AGENT-2_reward": [-83.73332479708313, -72.41265156068161, -58.49345417447871, 27.044519189889286, -50.03465101186018, 138.5490350488501, -66.52713618714633, 121.08349306823217, -61.76205363287735, -30.68754968123313, -20.853406242592357, -14.45260121881358, 108.65099164332267, -61.38741868769377, 126.41365038602437, -17.756938268210963, 45.9988040338351, -79.07609840587199, 226.23652747701212, -11.396837684215297, 99.08485544991038, -33.9541707331008, 93.21867177094137, -61.29574189522151, -69.46990311925086, -156.75654930278088, -132.27539463278274, -129.81739230314514, -48.18179080639796, -83.1456665860121, -130.42804310919908, -47.55887333664543, -277.1192626254035, -97.62212855434875, -106.77115930775548, -99.41951864067524, -44.58363111253017, -36.229216404642344, -46.43546186382667, 36.373662164100494, -101.9673691669154, -61.84034890756237, 41.70095314716996, -157.67467181667024, 37.993615528699806, -12.851288883373005, -34.04413590027604, -66.34641965957722, -75.15376403728426, 4.8664944537492785, 96.4751818056275, -42.58607295374348, 46.912525604686586, -70.21911350720549, -166.4298577565679, -61.05116222474084, -165.15259516960336, -88.53280657252672, -127.52253570616352, -58.02803100647249, 3.685540523322267, -81.41862428966225, -35.67722431275216, -66.83305414208523, -111.18712344542116, -58.07225400368949, 109.29513789048178, -46.16993312531233, -67.39168527923894, -54.036915373566345, -22.149435510773372, -38.6321324570456, 0.26139967277479315, -61.35993836599249, 135.51540565993264, -60.08936912372619, 57.79920080956593, -153.1521788137599, 99.90156342462507, -105.43964563127408, -32.228386955741954, -56.958062972209625, 55.04473241141892, -92.4523652545533, 55.553412997309266, -94.13541662156995, -40.693379514377625, 84.18314373746614, -140.35126499833407, -153.48479801666122, -168.23016108763267, -87.4858499855184, -99.89164684180338, -109.10473300917656, -54.08709312812993, -12.858202367822152, -78.9603572829173, -117.07083009435378, -84.50943177582016, -59.75440932628112], "policy_AGENT-1_reward": [-110.7187384768092, 28.8072516174665, -14.655450553067702, 46.81080809807813, 37.63398644389933, 99.93776133661603, -84.90994209847587, 128.65874099351257, -15.404614594240892, -174.07183895034223, -17.68419865142419, 17.932695554275128, 114.12331936674894, -128.97671155006626, 132.2132709653155, -23.865828056064213, 46.431764242667654, -78.64598160329938, 237.17936528343108, -10.968306182836052, 101.55129172943734, -79.59980026451771, 138.08530381322925, -125.41395891221393, -80.4032930733496, -139.5195415977011, -131.1095497545285, -129.37764276268075, -47.68718019412165, -84.67451259449645, -130.00382289255785, 68.67475059713769, -276.50363905019066, -97.04800821883784, -106.1521836268911, -99.23340810875335, -18.169690389935035, 17.200527661743024, 82.0849067187979, 41.085636982069644, -101.46750887836838, -58.555951718864186, 42.13445052384547, -89.92943774810581, 37.89086195204445, -5.406304149596274, -33.432161120558355, -134.26216150505377, 13.484283059093965, -40.78967861193224, 101.29645428210175, -42.08302691479771, 49.50672573494239, -72.41848962081906, -165.73282691526316, -104.81721730925639, -164.18509193674026, -119.54052932539754, -127.08969835121056, -36.78946232782888, -104.59891904146437, -83.28574154855369, -91.26123218449416, -66.12859442580401, -38.7520505080579, -49.60773983815664, 121.71776575733115, 99.59147948365262, 17.424416530402286, -104.76288659902556, -139.10276835326763, 56.500578136085295, 4.589078745059695, -111.0584688662942, 140.87222276461648, -97.9815294435073, 11.528697022141564, -62.46254215147809, 104.88977459912768, -85.04275870777357, -91.36083495052091, -103.03869869842721, 55.5654750759794, -92.01299786377407, 59.91859374274836, -93.52716854050446, -15.750908707182436, 133.73272079648578, -72.57396272936555, -122.50187859508739, -167.61600430260884, 25.982718742852747, -100.5837369652933, 39.87452083176788, 31.532555407979896, -98.05336453705574, -75.63406585678632, -116.43890184052333, 6.397545920172128, 82.98816896156131]}, "sampler_perf": {"mean_env_wait_ms": 62.58311088506567, "mean_raw_obs_processing_ms": 2.6437475229624563, "mean_inference_ms": 2.652232373393307, "mean_action_processing_ms": 0.1601787633844782}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 134400, "timers": {"sample_time_ms": 128574.69, "sample_throughput": 32.666, "load_time_ms": 19.908, "load_throughput": 210973.001, "learn_time_ms": 11117.764, "learn_throughput": 377.774, "update_time_ms": 10.279}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 20.907268524169922, "policy_loss": -0.03330041468143463, "vf_loss": 20.93217658996582, "vf_explained_var": 0.9759112000465393, "kl": 0.01865231618285179, "entropy": 1.085573673248291, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 15.329571723937988, "policy_loss": -0.032688677310943604, "vf_loss": 15.35589599609375, "vf_explained_var": 0.9750067591667175, "kl": 0.014140864834189415, "entropy": 1.0359082221984863, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 16.210113525390625, "policy_loss": -0.03078131377696991, "vf_loss": 16.230138778686523, "vf_explained_var": 0.9743991494178772, "kl": 0.015933426097035408, "entropy": 1.1426055431365967, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 17.67851448059082, "policy_loss": -0.029829522594809532, "vf_loss": 17.70088768005371, "vf_explained_var": 0.9769864082336426, "kl": 0.011042882688343525, "entropy": 0.9925941824913025, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 134400, "num_steps_trained": 134400}, "done": false, "episodes_total": 1139, "training_iteration": 32, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-17-12", "timestamp": 1624213032, "time_this_iter_s": 94.6025173664093, "time_total_s": 3617.008739709854, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40405c4d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40405c3b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40405c170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40405c050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40405c830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40405c950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40405c170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40405c050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40405c830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40405c950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40405c170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40405c050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40405c830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40405c950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40405c170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40405c050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40405c830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40405c950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd40405c5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3617.008739709854, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 57.035555555555554, "ram_util_percent": 87.52074074074073}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 878.3383737505617, "episode_reward_min": -1043.6930512396198, "episode_reward_mean": -121.45255789688136, "episode_len_mean": 117.87, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-3": -242.93717455209895, "AGENT-0": -247.1329750119267, "AGENT-2": -277.1192626254035, "AGENT-1": -276.50363905019066}, "policy_reward_max": {"AGENT-3": 250.20254335956912, "AGENT-0": 213.98690410161714, "AGENT-2": 226.23652747701212, "AGENT-1": 237.17936528343108}, "policy_reward_mean": {"AGENT-3": -22.320419139029813, "AGENT-0": -40.33672997048434, "AGENT-2": -35.519824584404816, "AGENT-1": -23.275584202962428}, "custom_metrics": {"mean_ego_speed_mean": 44.41359249999999, "mean_ego_speed_min": 35.02425, "mean_ego_speed_max": 51.89075, "distance_travelled_mean": 108.623645, "distance_travelled_min": 76.069, "distance_travelled_max": 124.82775000000001}, "hist_stats": {"episode_reward": [-164.28143550442292, 714.6536281246802, -144.40809487449093, 375.4575447589125, -311.2288830146324, 240.09011385968412, -73.77494700099975, 409.4930866400487, -380.8182255415065, -19.134482922598096, -80.91492117975643, -22.724388885868606, 782.9133907524574, -146.55041760427767, -323.25640048562445, -395.52614880299785, 226.4228613925172, -297.6770080674212, 349.3331767397263, -157.38637010671718, 284.662034951601, 64.6607602387173, 242.11936959237596, -172.86233206670323, -362.87583684806117, -391.8562824559695, -264.9374606674309, -474.7323983728305, -317.9363572644569, -636.8301081820313, -333.0841182531655, -513.104459154649, -640.608015634929, -58.65843623904705, -379.81216578588925, -5.189955061058406, 56.50963880845382, -387.1075115482722, 571.5419258996062, -358.4454433493643, 137.95937416588617, -392.10928899822215, 457.23879898018254, -383.42320411314813, -280.3024772688668, -320.38588537546127, 133.2153956527377, -447.5895240627765, 269.4215596583581, -416.5428522331976, -116.34429406817492, 364.2301210863339, -378.4895340655702, -546.698504055658, -708.1652840631104, -166.38308419099403, -383.71862002737276, -177.19345343254253, -85.23953522940218, -247.67271152307828, -351.90153452475136, -390.27498203378906, -198.44972187672255, 6.416217895310645, -432.61239741935725, -39.943298976293406, -133.47478589936244, 108.21418753403219, -62.88130440199248, 455.9063098366113, -343.34170060327995, 418.05414638247686, -210.82917787220205, -417.8009142434135, -167.250749255633, -15.826592652617808, 445.2604129000877, -386.77978683666163, 562.7227246201178, -81.38309244431449, 80.07890878823949, -357.4061658182956, 878.3383737505617, -121.17082323545587, 397.226998529643, -229.75166895931645, 406.3018867757182, -378.57384187481046, -303.57241679721545, -544.5969288090236, -518.872514190604, -350.5678700886942, 368.32047646066644, -406.2463575156163, -338.2154850902791, 1.141796675792314, -1043.6930512396198, -340.4613393385095, -476.6356495638448, -444.6660019952508], "episode_lengths": [118, 124, 115, 114, 117, 120, 112, 118, 113, 101, 116, 117, 124, 114, 114, 105, 125, 111, 122, 114, 118, 119, 116, 108, 112, 148, 127, 104, 104, 117, 108, 107, 118, 144, 104, 124, 107, 121, 119, 123, 111, 114, 115, 118, 108, 114, 117, 118, 115, 115, 118, 120, 102, 120, 118, 126, 106, 148, 132, 104, 119, 118, 127, 130, 115, 105, 112, 124, 134, 128, 130, 122, 116, 120, 113, 101, 119, 113, 119, 118, 116, 117, 125, 113, 119, 116, 125, 111, 108, 115, 115, 127, 136, 114, 126, 129, 126, 127, 122, 116], "policy_AGENT-3_reward": [-19.449679989946972, 212.08424739159688, -9.15333537593849, 125.32860703080257, -91.08000354531212, 89.05750747915661, 14.740464862016289, 133.07421900800492, -84.90553171550071, -12.932574592906612, 12.199412469638535, -8.359230576127636, 202.8008737146126, -17.22984911647388, -122.6105985005879, -107.16022177217853, 91.97643046757568, -64.13483046246165, 132.02507359191821, -50.924907736459076, 100.0017551015526, 32.76535123819537, 102.66866863369762, -21.50340605984418, -81.20946058617297, -49.22407166520085, 2.1526109862714042, -137.63592144547835, -67.30634518629034, -146.50184060624397, -71.48932802776854, -147.61404443845112, -115.01183795829401, -63.73333902136136, -106.90692363591903, -38.693754856536465, 48.26836164271761, -111.62315515608617, 156.72728514554552, -98.54416101270976, 106.5328803448419, -114.27827286954826, 148.5375226322364, -108.38103637120777, -90.16589394966002, -57.48150682730411, 32.28509728322635, -111.11444732981151, 96.4382146371389, -92.23202570605648, -41.53118575754544, 107.34193577231161, -92.94131256469026, -123.0671428403555, -161.22742446324156, -87.46436796722777, -104.57763926010935, -109.18450203594799, -54.02436106925644, -38.62375419061374, -79.08468013917688, -58.89323236863388, -84.50496939734707, -59.76472087570946, -111.28182038993651, -25.293149614842424, -25.194076475593704, 31.765936681161634, -50.02307948148814, 161.5570905430398, -85.47459743413258, 120.86222137804045, -27.458411790553168, -182.90658164926054, -62.3172362267308, -37.28547383105177, 156.32705255905293, -135.58385405019934, 172.26437456218534, -17.752396389040918, 14.565965181979784, -79.08623242735707, 226.1108652040699, -30.06284613705177, 143.8791493134605, -35.69487934875856, 122.70401282121405, -131.11609805329812, -96.61225300557619, -92.12143862699436, -124.51006501236273, -27.194557781452453, 250.20254335956912, -107.95676845235963, -19.97848204511571, -47.53120023486424, -242.93717455209895, -54.427144355358685, -115.82657909993813, -100.18041945070188], "policy_AGENT-0_reward": [-92.60538520928304, 168.0706375790151, -89.55162653506069, 84.5778631109882, -86.69741227542613, 20.09477229867023, -75.54555586567086, 93.26378484187126, -129.443955915954, 26.990988593222934, -76.37287976557141, 5.151427911804116, 193.4511094499227, -57.30608074511457, -161.7892143591472, -66.84664804367594, 18.356048743188225, -107.92787931656383, 44.15898280397706, -27.884065088632358, 65.12196017927918, -2.9924269199529476, 16.245878366171233, -54.2928737055401, -124.52315261137801, -83.0982321936271, -34.39644064235779, -100.71577128773245, -68.26600973652121, -189.01593853093766, -118.99113237779179, -111.03061078525597, -226.9218588773958, 16.008561974235626, -84.34063123723384, 15.635354116438322, 3.3907987479018367, -103.0659491598993, 138.42701232951137, -101.83038376942116, -37.90140401066288, -62.21629516343584, 103.90993832419342, -84.55976340289286, -66.54736141294404, -102.90761687752034, -9.679909117887512, -152.00971361463763, 57.51133828116164, -136.64824136506667, -18.36882008906951, 38.97232078007064, -72.62299377318013, -147.6446846035541, -211.0916942096265, -17.415584981100665, -78.66559696016648, 1.221260780814113, -8.660636439995692, -98.13739042758667, -118.22243124587102, -97.87201773027812, -35.832866623727305, 42.947179135739944, -126.87851375552859, 28.955250581764155, -35.13180469622259, 2.592923564903323, -0.45756035254346017, 55.86242290810538, -106.43002488352516, 47.44969094269119, -106.20409785453042, -30.134943962577708, -66.39590813488577, 17.97878684297238, 66.15904933096371, -60.83180254870241, 131.83142870659185, -22.0079297309984, -26.917624670243264, -120.59785338176759, 188.81161578604835, -68.74283323135273, 52.711702036834325, -80.50281861293925, 52.29389837033389, -60.748043014077005, -57.086967599038815, -156.19939928154773, -130.97750479092946, -64.17827724141547, 213.98690410161714, -130.46940988274864, -57.80513704340645, 27.55711965016433, -247.1329750119267, -91.36405820996401, -147.8857275292599, -145.83265579511996], "policy_AGENT-2_reward": [-46.8233061064302, 164.07525248902445, -44.45533782206687, 80.5998820012383, -42.9339673923487, 62.23148734808605, -29.077290660112613, 88.2717431886639, -82.12653198212044, -59.93982031040836, -30.228060987397882, -25.93427318184777, 191.25706157660665, -17.15284182672536, -19.645006819619795, -154.55723408249384, 54.78149423043458, -63.193346285704806, 83.95655208839526, -51.51048920546902, 55.35142677329643, 32.73528283062252, 60.22712991752653, -21.559010998175783, -78.35606178857545, -130.00633413559856, -116.61257246060605, -101.26530053382947, -115.01197367019435, -150.95378576907316, -70.92334324207228, -111.58804495481115, -184.22536355151598, -63.7146424626169, -84.8958673054926, -38.6321324570456, 0.26139967277479315, -61.35993836599249, 135.51540565993264, -60.08936912372619, 57.79920080956593, -153.1521788137599, 99.90156342462507, -105.43964563127408, -32.228386955741954, -56.958062972209625, 55.04473241141892, -92.4523652545533, 55.553412997309266, -94.13541662156995, -40.693379514377625, 84.18314373746614, -140.35126499833407, -153.48479801666122, -168.23016108763267, -87.4858499855184, -99.89164684180338, -109.10473300917656, -54.08709312812993, -12.858202367822152, -78.9603572829173, -117.07083009435378, -84.50943177582016, -59.75440932628112, -83.73332479708313, -72.41265156068161, -58.49345417447871, 27.044519189889286, -50.03465101186018, 138.5490350488501, -66.52713618714633, 121.08349306823217, -61.76205363287735, -30.68754968123313, -20.853406242592357, -14.45260121881358, 108.65099164332267, -61.38741868769377, 126.41365038602437, -17.756938268210963, 45.9988040338351, -79.07609840587199, 226.23652747701212, -11.396837684215297, 99.08485544991038, -33.9541707331008, 93.21867177094137, -61.29574189522151, -69.46990311925086, -156.75654930278088, -132.27539463278274, -129.81739230314514, -48.18179080639796, -83.1456665860121, -130.42804310919908, -47.55887333664543, -277.1192626254035, -97.62212855434875, -106.77115930775548, -99.41951864067524], "policy_AGENT-1_reward": [-5.4030641987626815, 170.42349066504318, -1.2477951414249475, 84.95119261588307, -90.51749980154568, 68.7063467337711, 16.107434662767506, 94.8833396015089, -84.34220592793136, 26.74692338749393, 13.486607103574284, 6.417686960302724, 195.40434601131497, -54.86164591596382, -19.21158080626941, -66.9620449046493, 61.308887951319385, -62.42095200269087, 89.19256825543556, -27.066908076156512, 64.18689289747286, 2.1525530898524083, 62.97769267498056, -75.50704130314321, -78.78716186193436, -129.52764446154268, -116.08105855073839, -135.11540510579042, -67.35202867145102, -150.35854327577644, -71.68031460553314, -142.87175897613088, -114.44895524772352, 52.78098327069565, -103.6687436072438, 56.500578136085295, 4.589078745059695, -111.0584688662942, 140.87222276461648, -97.9815294435073, 11.528697022141564, -62.46254215147809, 104.88977459912768, -85.04275870777357, -91.36083495052091, -103.03869869842721, 55.5654750759794, -92.01299786377407, 59.91859374274836, -93.52716854050446, -15.750908707182436, 133.73272079648578, -72.57396272936555, -122.50187859508739, -167.61600430260884, 25.982718742852747, -100.5837369652933, 39.87452083176788, 31.532555407979896, -98.05336453705574, -75.63406585678632, -116.43890184052333, 6.397545920172128, 82.98816896156131, -110.7187384768092, 28.8072516174665, -14.655450553067702, 46.81080809807813, 37.63398644389933, 99.93776133661603, -84.90994209847587, 128.65874099351257, -15.404614594240892, -174.07183895034223, -17.68419865142419, 17.932695554275128, 114.12331936674894, -128.97671155006626, 132.2132709653155, -23.865828056064213, 46.431764242667654, -78.64598160329938, 237.17936528343108, -10.968306182836052, 101.55129172943734, -79.59980026451771, 138.08530381322925, -125.41395891221393, -80.4032930733496, -139.5195415977011, -131.1095497545285, -129.37764276268075, -47.68718019412165, -84.67451259449645, -130.00382289255785, 68.67475059713769, -276.50363905019066, -97.04800821883784, -106.1521836268911, -99.23340810875335]}, "sampler_perf": {"mean_env_wait_ms": 62.29284402205918, "mean_raw_obs_processing_ms": 2.6334478233202008, "mean_inference_ms": 2.6404408967292907, "mean_action_processing_ms": 0.15955821504953507}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 138600, "timers": {"sample_time_ms": 128645.282, "sample_throughput": 32.648, "load_time_ms": 19.892, "load_throughput": 211137.614, "learn_time_ms": 11098.548, "learn_throughput": 378.428, "update_time_ms": 10.358}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 24.213851928710938, "policy_loss": -0.035059113055467606, "vf_loss": 24.241424560546875, "vf_explained_var": 0.9687023758888245, "kl": 0.016645967960357666, "entropy": 1.0854023694992065, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 20.506549835205078, "policy_loss": -0.022266069427132607, "vf_loss": 20.521709442138672, "vf_explained_var": 0.9630088210105896, "kl": 0.015788227319717407, "entropy": 0.9595517516136169, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 12.631625175476074, "policy_loss": -0.03462500870227814, "vf_loss": 12.655962944030762, "vf_explained_var": 0.9802272915840149, "kl": 0.01523919403553009, "entropy": 1.1422125101089478, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 13.353287696838379, "policy_loss": -0.023852501064538956, "vf_loss": 13.366732597351074, "vf_explained_var": 0.9803510904312134, "kl": 0.015418353490531445, "entropy": 0.9913156628608704, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 138600, "num_steps_trained": 138600}, "done": false, "episodes_total": 1174, "training_iteration": 33, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-18-52", "timestamp": 1624213132, "time_this_iter_s": 98.94461250305176, "time_total_s": 3715.953352212906, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40419fb00>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd4040b8a70>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8b90>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40434bdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420e950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420eef0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8b90>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40434bdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420e950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420eef0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8b90>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40434bdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420e950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420eef0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8b90>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40434bdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420e950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420eef0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd40405cb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3715.953352212906, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 56.34718309859154, "ram_util_percent": 87.58239436619719}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 878.3383737505617, "episode_reward_min": -1043.6930512396198, "episode_reward_mean": -93.91055505663495, "episode_len_mean": 117.45, "episodes_this_iter": 36, "policy_reward_min": {"AGENT-3": -242.93717455209895, "AGENT-0": -254.24794154210352, "AGENT-2": -277.1192626254035, "AGENT-1": -276.50363905019066}, "policy_reward_max": {"AGENT-3": 250.20254335956912, "AGENT-0": 213.98690410161714, "AGENT-2": 226.23652747701212, "AGENT-1": 237.17936528343108}, "policy_reward_mean": {"AGENT-3": -11.608965654301523, "AGENT-0": -36.39655532863727, "AGENT-2": -27.497031550036066, "AGENT-1": -18.408002523660095}, "custom_metrics": {"mean_ego_speed_mean": 44.64929000000001, "mean_ego_speed_min": 35.150999999999996, "mean_ego_speed_max": 51.89075, "distance_travelled_mean": 108.40449750000002, "distance_travelled_min": 75.46025, "distance_travelled_max": 124.82425}, "hist_stats": {"episode_reward": [12.284960328899025, 608.7519289156353, -204.38768926960995, 209.70138022850355, -24.87106801570566, 238.50508905608265, -350.216292856982, 592.99633563398, -293.97331735057816, 483.53516962518586, -189.17205448683333, 707.6881427246465, 457.6080421581154, -23.726348397847516, -358.26580349183564, -393.71762597190883, 320.2278945264189, -406.0417656184423, 539.765709728763, -3.380024121830864, -64.61291560781608, -395.82508030719646, 287.98552233581904, -489.50922089125254, -652.1296486094066, 91.66386480348109, -147.10901813434876, -358.75866595098205, -338.85497692466413, -408.14066816861384, -172.36140533571825, -261.29296969374616, 147.68728475364537, -520.4598670014013, -365.2333033204941, -715.3886701516237, 418.05414638247686, -210.82917787220205, -417.8009142434135, -167.250749255633, -15.826592652617808, 445.2604129000877, -386.77978683666163, 562.7227246201178, -81.38309244431449, 80.07890878823949, -357.4061658182956, 878.3383737505617, -121.17082323545587, 397.226998529643, -229.75166895931645, 406.3018867757182, -378.57384187481046, -303.57241679721545, -544.5969288090236, -518.872514190604, -350.5678700886942, 368.32047646066644, -406.2463575156163, -338.2154850902791, 1.141796675792314, -1043.6930512396198, -340.4613393385095, -476.6356495638448, -444.6660019952508, -164.28143550442292, 714.6536281246802, -144.40809487449093, 375.4575447589125, -311.2288830146324, 240.09011385968412, -73.77494700099975, 409.4930866400487, -380.8182255415065, -19.134482922598096, -80.91492117975643, -22.724388885868606, 782.9133907524574, -146.55041760427767, -323.25640048562445, -395.52614880299785, 226.4228613925172, -297.6770080674212, 349.3331767397263, -157.38637010671718, 284.662034951601, 64.6607602387173, 242.11936959237596, -172.86233206670323, -362.87583684806117, -391.8562824559695, -264.9374606674309, -474.7323983728305, -317.9363572644569, -636.8301081820313, -333.0841182531655, -513.104459154649, -640.608015634929, -58.65843623904705, -379.81216578588925], "episode_lengths": [118, 122, 104, 115, 100, 129, 124, 122, 113, 117, 102, 123, 107, 119, 114, 104, 118, 116, 120, 114, 121, 113, 121, 122, 117, 158, 120, 118, 114, 113, 126, 115, 112, 116, 127, 119, 122, 116, 120, 113, 101, 119, 113, 119, 118, 116, 117, 125, 113, 119, 116, 125, 111, 108, 115, 115, 127, 136, 114, 126, 129, 126, 127, 122, 116, 118, 124, 115, 114, 117, 120, 112, 118, 113, 101, 116, 117, 124, 114, 114, 105, 125, 111, 122, 114, 118, 119, 116, 108, 112, 148, 127, 104, 104, 117, 108, 107, 118, 144, 104], "policy_AGENT-3_reward": [20.929537761330607, 180.50523651398248, -64.0083278573184, 92.92591177977995, -9.195588868408604, 95.65771186378034, -89.63879746717737, 156.82831450758897, -38.65488562720906, 147.99284489505655, -54.04618231157721, 171.05451057413705, 140.8184428125146, 15.055004748977087, -30.79370339018759, -110.72136478935099, 111.85299220806971, -133.4266755165729, 154.0808347452226, -10.559404633878994, 14.720571456877252, -113.60236420829399, 110.34861361345179, -200.41692717601268, -145.7725713404436, -47.26300544551978, -79.50709779315834, -80.78702655846708, -52.3313141822271, -92.8478440239931, -73.96706339634302, -56.19665336355555, 114.60184619359872, -123.49262085557343, -51.07905095036343, -123.13450116845624, 120.86222137804045, -27.458411790553168, -182.90658164926054, -62.3172362267308, -37.28547383105177, 156.32705255905293, -135.58385405019934, 172.26437456218534, -17.752396389040918, 14.565965181979784, -79.08623242735707, 226.1108652040699, -30.06284613705177, 143.8791493134605, -35.69487934875856, 122.70401282121405, -131.11609805329812, -96.61225300557619, -92.12143862699436, -124.51006501236273, -27.194557781452453, 250.20254335956912, -107.95676845235963, -19.97848204511571, -47.53120023486424, -242.93717455209895, -54.427144355358685, -115.82657909993813, -100.18041945070188, -19.449679989946972, 212.08424739159688, -9.15333537593849, 125.32860703080257, -91.08000354531212, 89.05750747915661, 14.740464862016289, 133.07421900800492, -84.90553171550071, -12.932574592906612, 12.199412469638535, -8.359230576127636, 202.8008737146126, -17.22984911647388, -122.6105985005879, -107.16022177217853, 91.97643046757568, -64.13483046246165, 132.02507359191821, -50.924907736459076, 100.0017551015526, 32.76535123819537, 102.66866863369762, -21.50340605984418, -81.20946058617297, -49.22407166520085, 2.1526109862714042, -137.63592144547835, -67.30634518629034, -146.50184060624397, -71.48932802776854, -147.61404443845112, -115.01183795829401, -63.73333902136136, -106.90692363591903], "policy_AGENT-0_reward": [-16.75993609340081, 144.19758124021868, -39.35831289879021, 6.866117116736476, -5.2217811817456745, 23.77040674617399, -106.56940568983364, 146.4961852676088, -131.72465655637316, 113.99198175194101, -41.51619840537949, 176.83790401955716, 130.80085992225233, -29.827009273935253, -171.45703140698777, -63.52808178396739, 43.7318168198133, -171.49448238489498, 97.65227095784692, 8.927959909931452, -43.60439010504147, -63.53561101454852, 31.33545538812487, -240.63998497436214, -200.01430681347105, 76.4095278704247, 19.3956339800842, -123.39995550801666, -92.81402537217997, -134.63132124365757, -33.47480194289517, -97.59573958685931, 143.40241082253635, -160.83057513650508, -88.92655782933491, -254.24794154210352, 47.44969094269119, -106.20409785453042, -30.134943962577708, -66.39590813488577, 17.97878684297238, 66.15904933096371, -60.83180254870241, 131.83142870659185, -22.0079297309984, -26.917624670243264, -120.59785338176759, 188.81161578604835, -68.74283323135273, 52.711702036834325, -80.50281861293925, 52.29389837033389, -60.748043014077005, -57.086967599038815, -156.19939928154773, -130.97750479092946, -64.17827724141547, 213.98690410161714, -130.46940988274864, -57.80513704340645, 27.55711965016433, -247.1329750119267, -91.36405820996401, -147.8857275292599, -145.83265579511996, -92.60538520928304, 168.0706375790151, -89.55162653506069, 84.5778631109882, -86.69741227542613, 20.09477229867023, -75.54555586567086, 93.26378484187126, -129.443955915954, 26.990988593222934, -76.37287976557141, 5.151427911804116, 193.4511094499227, -57.30608074511457, -161.7892143591472, -66.84664804367594, 18.356048743188225, -107.92787931656383, 44.15898280397706, -27.884065088632358, 65.12196017927918, -2.9924269199529476, 16.245878366171233, -54.2928737055401, -124.52315261137801, -83.0982321936271, -34.39644064235779, -100.71577128773245, -68.26600973652121, -189.01593853093766, -118.99113237779179, -111.03061078525597, -226.9218588773958, 16.008561974235626, -84.34063123723384], "policy_AGENT-2_reward": [-17.323510947456395, 138.20311197063648, -39.79163802879024, 55.05243647782316, -5.778007205641129, 52.18279682847533, -64.93035805304672, 141.56703577964905, -84.67946405107725, 107.45784803210782, -42.071814613543275, 175.52038668311133, 91.77806795310617, 17.75911944360733, -30.75523550683276, -155.79474995713701, 79.30721249561364, -50.80499853792626, 141.96015968918925, -10.544792926516406, 14.686477677824769, -155.1676819630625, 68.4079458952504, -24.441626083736054, -153.24644340254432, -47.25824752459446, -79.47668964921044, -78.31816887530402, -97.22784440704737, -90.64005710013393, -73.83410195878162, -54.72767202729308, -55.404027900567606, -119.37110517367485, -112.85762093401085, -215.43589706571044, 121.08349306823217, -61.76205363287735, -30.68754968123313, -20.853406242592357, -14.45260121881358, 108.65099164332267, -61.38741868769377, 126.41365038602437, -17.756938268210963, 45.9988040338351, -79.07609840587199, 226.23652747701212, -11.396837684215297, 99.08485544991038, -33.9541707331008, 93.21867177094137, -61.29574189522151, -69.46990311925086, -156.75654930278088, -132.27539463278274, -129.81739230314514, -48.18179080639796, -83.1456665860121, -130.42804310919908, -47.55887333664543, -277.1192626254035, -97.62212855434875, -106.77115930775548, -99.41951864067524, -46.8233061064302, 164.07525248902445, -44.45533782206687, 80.5998820012383, -42.9339673923487, 62.23148734808605, -29.077290660112613, 88.2717431886639, -82.12653198212044, -59.93982031040836, -30.228060987397882, -25.93427318184777, 191.25706157660665, -17.15284182672536, -19.645006819619795, -154.55723408249384, 54.78149423043458, -63.193346285704806, 83.95655208839526, -51.51048920546902, 55.35142677329643, 32.73528283062252, 60.22712991752653, -21.559010998175783, -78.35606178857545, -130.00633413559856, -116.61257246060605, -101.26530053382947, -115.01197367019435, -150.95378576907316, -70.92334324207228, -111.58804495481115, -184.22536355151598, -63.7146424626169, -84.8958673054926], "policy_AGENT-1_reward": [25.438869608425613, 145.84599919079793, -61.22941048471117, 54.856914854164145, -4.675690759910017, 66.89417361765292, -89.07773164692452, 148.10480007913324, -38.914311115918736, 114.09249494607997, -51.53785915633324, 184.275341447841, 94.21067147024196, -26.713463316496586, -125.25983318782745, -63.67342944145351, 85.33587300292234, -50.31560917904816, 146.07244433650465, 8.796213528633068, -50.41557463747658, -63.51942312129134, 77.89350743899189, -24.010682657141803, -153.09632705294774, 109.77558990317065, -7.520864672064218, -76.25351500919426, -96.48179296320903, -90.02144580082896, 8.914561962301498, -52.77290471603834, -54.91294436192189, -116.76556583564866, -112.37007360678501, -122.57033037535385, 128.65874099351257, -15.404614594240892, -174.07183895034223, -17.68419865142419, 17.932695554275128, 114.12331936674894, -128.97671155006626, 132.2132709653155, -23.865828056064213, 46.431764242667654, -78.64598160329938, 237.17936528343108, -10.968306182836052, 101.55129172943734, -79.59980026451771, 138.08530381322925, -125.41395891221393, -80.4032930733496, -139.5195415977011, -131.1095497545285, -129.37764276268075, -47.68718019412165, -84.67451259449645, -130.00382289255785, 68.67475059713769, -276.50363905019066, -97.04800821883784, -106.1521836268911, -99.23340810875335, -5.4030641987626815, 170.42349066504318, -1.2477951414249475, 84.95119261588307, -90.51749980154568, 68.7063467337711, 16.107434662767506, 94.8833396015089, -84.34220592793136, 26.74692338749393, 13.486607103574284, 6.417686960302724, 195.40434601131497, -54.86164591596382, -19.21158080626941, -66.9620449046493, 61.308887951319385, -62.42095200269087, 89.19256825543556, -27.066908076156512, 64.18689289747286, 2.1525530898524083, 62.97769267498056, -75.50704130314321, -78.78716186193436, -129.52764446154268, -116.08105855073839, -135.11540510579042, -67.35202867145102, -150.35854327577644, -71.68031460553314, -142.87175897613088, -114.44895524772352, 52.78098327069565, -103.6687436072438]}, "sampler_perf": {"mean_env_wait_ms": 61.99549643319831, "mean_raw_obs_processing_ms": 2.6228526768516547, "mean_inference_ms": 2.6278752781568784, "mean_action_processing_ms": 0.15893284656099455}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 142800, "timers": {"sample_time_ms": 128480.503, "sample_throughput": 32.69, "load_time_ms": 20.142, "load_throughput": 208516.232, "learn_time_ms": 11092.774, "learn_throughput": 378.625, "update_time_ms": 10.55}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 20.882423400878906, "policy_loss": -0.03057711198925972, "vf_loss": 20.904701232910156, "vf_explained_var": 0.9755285382270813, "kl": 0.018442930653691292, "entropy": 1.0566753149032593, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 20.297210693359375, "policy_loss": -0.02875765971839428, "vf_loss": 20.32037353515625, "vf_explained_var": 0.9686880111694336, "kl": 0.012430037371814251, "entropy": 0.9278634786605835, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 11.509299278259277, "policy_loss": -0.030210955068469048, "vf_loss": 11.528634071350098, "vf_explained_var": 0.9855159521102905, "kl": 0.016113193705677986, "entropy": 1.154009461402893, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 10.892816543579102, "policy_loss": -0.02762678824365139, "vf_loss": 10.912456512451172, "vf_explained_var": 0.9867570996284485, "kl": 0.011831958778202534, "entropy": 0.972457230091095, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 142800, "num_steps_trained": 142800}, "done": false, "episodes_total": 1210, "training_iteration": 34, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-20-26", "timestamp": 1624213226, "time_this_iter_s": 94.05798196792603, "time_total_s": 3810.011334180832, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd3940854d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd3940853b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd394085170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd394085050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd394085830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd394085950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd394085170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd394085050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd394085830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd394085950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd394085170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd394085050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd394085830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd394085950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd394085170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd394085050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd394085830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd394085950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd3940855f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3810.011334180832, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 57.002985074626864, "ram_util_percent": 87.5268656716418}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 782.9133907524574, "episode_reward_min": -715.3886701516237, "episode_reward_mean": -112.12615955963594, "episode_len_mean": 116.37, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-3": -200.41692717601268, "AGENT-0": -254.24794154210352, "AGENT-2": -215.43589706571044, "AGENT-1": -157.98156207190144}, "policy_reward_max": {"AGENT-3": 202.8008737146126, "AGENT-0": 193.4511094499227, "AGENT-2": 191.25706157660665, "AGENT-1": 195.40434601131497}, "policy_reward_mean": {"AGENT-3": -16.80961909562126, "AGENT-0": -44.24539836771266, "AGENT-2": -34.043842848448925, "AGENT-1": -17.027299247853094}, "custom_metrics": {"mean_ego_speed_mean": 44.8376125, "mean_ego_speed_min": 35.150999999999996, "mean_ego_speed_max": 51.89075, "distance_travelled_mean": 109.44305249999998, "distance_travelled_min": 75.46025, "distance_travelled_max": 124.834}, "hist_stats": {"episode_reward": [-156.1023044016825, 366.6138471351128, -301.90952115104466, -233.8550062704134, -323.24693295773807, 489.6575656860307, 67.29465750455051, -27.690783683674262, -255.73479407905376, 510.64736683841477, 52.10446219937065, 461.38164396690087, 502.61936386025803, -168.9799876071697, -247.13306234857941, 227.87294049233648, 197.56239007970626, 323.00859288069285, -261.9960699694285, -135.51427938662118, -318.87193030421605, 377.8416317191066, -359.628032988396, 700.5973897910405, -434.6264922388364, -513.5051730694225, -275.06340941272197, -599.101998773849, -401.76693570034894, -441.5859696325622, -334.1858035467345, -679.90370534895, -279.7519851563223, -583.7063201261564, -555.1734664186356, -593.761284068357, -146.82074376200063, -380.8182255415065, -19.134482922598096, -80.91492117975643, -22.724388885868606, 782.9133907524574, -146.55041760427767, -323.25640048562445, -395.52614880299785, 226.4228613925172, -297.6770080674212, 349.3331767397263, -157.38637010671718, 284.662034951601, 64.6607602387173, 242.11936959237596, -172.86233206670323, -362.87583684806117, -391.8562824559695, -264.9374606674309, -474.7323983728305, -317.9363572644569, -636.8301081820313, -333.0841182531655, -513.104459154649, -640.608015634929, -58.65843623904705, -379.81216578588925, 12.284960328899025, 608.7519289156353, -204.38768926960995, 209.70138022850355, -24.87106801570566, 238.50508905608265, -350.216292856982, 592.99633563398, -293.97331735057816, 483.53516962518586, -189.17205448683333, 707.6881427246465, 457.6080421581154, -23.726348397847516, -358.26580349183564, -393.71762597190883, 320.2278945264189, -406.0417656184423, 539.765709728763, -3.380024121830864, -64.61291560781608, -395.82508030719646, 287.98552233581904, -489.50922089125254, -652.1296486094066, 91.66386480348109, -147.10901813434876, -358.75866595098205, -338.85497692466413, -408.14066816861384, -172.36140533571825, -261.29296969374616, 147.68728475364537, -520.4598670014013, -365.2333033204941, -715.3886701516237], "episode_lengths": [112, 120, 111, 117, 117, 118, 141, 107, 112, 126, 133, 118, 103, 112, 111, 123, 126, 115, 114, 114, 114, 122, 114, 115, 107, 102, 103, 118, 118, 109, 101, 114, 122, 121, 108, 108, 128, 113, 101, 116, 117, 124, 114, 114, 105, 125, 111, 122, 114, 118, 119, 116, 108, 112, 148, 127, 104, 104, 117, 108, 107, 118, 144, 104, 118, 122, 104, 115, 100, 129, 124, 122, 113, 117, 102, 123, 107, 119, 114, 104, 118, 116, 120, 114, 121, 113, 121, 122, 117, 158, 120, 118, 114, 113, 126, 115, 112, 116, 127, 119], "policy_AGENT-3_reward": [-5.152561554872354, 122.89316338270274, -39.02932417879715, -76.48255868338853, -83.3817397934472, 174.32296500918187, -34.6286704731381, -25.399675959701046, -29.841939828047753, 152.38460912886012, 38.34148576217271, 145.11263588740405, 140.08512968638905, -60.269706271828085, -40.43857955775301, 80.4614800798439, 55.90990600780532, 121.89859574385346, -29.399131719539213, 0.24513413031880066, -68.21277403608424, 128.9797792351951, -140.4521176812728, 147.91842834293672, -104.58314466606626, -103.07150600585669, -67.59052889496229, -134.01540175288505, -92.54496930961362, -91.99208941764553, -95.36664688730352, -157.73304311465722, 4.733183613535004, -143.8205425825889, -121.09346847939266, -121.94121478222854, -73.93238579127588, -84.90553171550071, -12.932574592906612, 12.199412469638535, -8.359230576127636, 202.8008737146126, -17.22984911647388, -122.6105985005879, -107.16022177217853, 91.97643046757568, -64.13483046246165, 132.02507359191821, -50.924907736459076, 100.0017551015526, 32.76535123819537, 102.66866863369762, -21.50340605984418, -81.20946058617297, -49.22407166520085, 2.1526109862714042, -137.63592144547835, -67.30634518629034, -146.50184060624397, -71.48932802776854, -147.61404443845112, -115.01183795829401, -63.73333902136136, -106.90692363591903, 20.929537761330607, 180.50523651398248, -64.0083278573184, 92.92591177977995, -9.195588868408604, 95.65771186378034, -89.63879746717737, 156.82831450758897, -38.65488562720906, 147.99284489505655, -54.04618231157721, 171.05451057413705, 140.8184428125146, 15.055004748977087, -30.79370339018759, -110.72136478935099, 111.85299220806971, -133.4266755165729, 154.0808347452226, -10.559404633878994, 14.720571456877252, -113.60236420829399, 110.34861361345179, -200.41692717601268, -145.7725713404436, -47.26300544551978, -79.50709779315834, -80.78702655846708, -52.3313141822271, -92.8478440239931, -73.96706339634302, -56.19665336355555, 114.60184619359872, -123.49262085557343, -51.07905095036343, -123.13450116845624], "policy_AGENT-0_reward": [-97.45820609204742, 52.548545361970326, -135.76967810552068, -118.54394018495533, -100.5748316117211, 90.62069892947801, 49.731157032371776, 33.375566312329646, -121.31606295346728, 58.7446666904182, 13.10097032326835, 107.07166716631286, 135.4401563414412, -36.30352136966772, -83.98362078691991, 4.831085202609692, 31.531430089428795, 36.55231084032554, -78.57388712541925, -48.599008772835155, -112.2177091823774, 62.28024600247149, -179.89912366770997, 186.85167051309014, -90.35995150646696, -153.39440066937829, -70.9066475184245, -184.21586359904347, -132.1243517781631, -152.94655747929193, -79.91472024110726, -206.37804496296621, -33.82700579282165, -127.49978693493988, -160.68611419220932, -174.09427949723647, -19.605854502474685, -129.443955915954, 26.990988593222934, -76.37287976557141, 5.151427911804116, 193.4511094499227, -57.30608074511457, -161.7892143591472, -66.84664804367594, 18.356048743188225, -107.92787931656383, 44.15898280397706, -27.884065088632358, 65.12196017927918, -2.9924269199529476, 16.245878366171233, -54.2928737055401, -124.52315261137801, -83.0982321936271, -34.39644064235779, -100.71577128773245, -68.26600973652121, -189.01593853093766, -118.99113237779179, -111.03061078525597, -226.9218588773958, 16.008561974235626, -84.34063123723384, -16.75993609340081, 144.19758124021868, -39.35831289879021, 6.866117116736476, -5.2217811817456745, 23.77040674617399, -106.56940568983364, 146.4961852676088, -131.72465655637316, 113.99198175194101, -41.51619840537949, 176.83790401955716, 130.80085992225233, -29.827009273935253, -171.45703140698777, -63.52808178396739, 43.7318168198133, -171.49448238489498, 97.65227095784692, 8.927959909931452, -43.60439010504147, -63.53561101454852, 31.33545538812487, -240.63998497436214, -200.01430681347105, 76.4095278704247, 19.3956339800842, -123.39995550801666, -92.81402537217997, -134.63132124365757, -33.47480194289517, -97.59573958685931, 143.40241082253635, -160.83057513650508, -88.92655782933491, -254.24794154210352], "policy_AGENT-2_reward": [-49.609110627303394, 93.62662273218204, -88.74186108930746, -19.63253798477212, -56.47346073417348, 134.2211803086358, -34.751808751771684, -68.7623541817597, -74.78499269989321, 143.68119430192104, -51.115590742676154, 102.00492909995418, 91.94531673939576, -37.04874300485997, -38.599458611468506, 47.06351947331756, 72.4338286771321, 81.26914529554446, -79.14244062106405, -49.15770184109517, -69.48371997357421, 82.06521535883542, -19.85932923780093, 179.10161530997124, -149.31806663423004, -153.95407669342902, -71.46099049402358, -141.27099334275994, -89.78594529137672, -105.21995514647894, -80.48887170542672, -157.81105519942597, -125.54576679409772, -178.73580654376198, -161.34439966734107, -174.65641665525195, -73.95128476794736, -82.12653198212044, -59.93982031040836, -30.228060987397882, -25.93427318184777, 191.25706157660665, -17.15284182672536, -19.645006819619795, -154.55723408249384, 54.78149423043458, -63.193346285704806, 83.95655208839526, -51.51048920546902, 55.35142677329643, 32.73528283062252, 60.22712991752653, -21.559010998175783, -78.35606178857545, -130.00633413559856, -116.61257246060605, -101.26530053382947, -115.01197367019435, -150.95378576907316, -70.92334324207228, -111.58804495481115, -184.22536355151598, -63.7146424626169, -84.8958673054926, -17.323510947456395, 138.20311197063648, -39.79163802879024, 55.05243647782316, -5.778007205641129, 52.18279682847533, -64.93035805304672, 141.56703577964905, -84.67946405107725, 107.45784803210782, -42.071814613543275, 175.52038668311133, 91.77806795310617, 17.75911944360733, -30.75523550683276, -155.79474995713701, 79.30721249561364, -50.80499853792626, 141.96015968918925, -10.544792926516406, 14.686477677824769, -155.1676819630625, 68.4079458952504, -24.441626083736054, -153.24644340254432, -47.25824752459446, -79.47668964921044, -78.31816887530402, -97.22784440704737, -90.64005710013393, -73.83410195878162, -54.72767202729308, -55.404027900567606, -119.37110517367485, -112.85762093401085, -215.43589706571044], "policy_AGENT-1_reward": [-3.8824261274593788, 97.54551565825702, -38.368657777419415, -19.195969417297597, -82.81690081839614, 90.49272143873407, 86.94397969708851, 33.09568014545684, -29.791798597645435, 155.83689671721567, 51.77759685660558, 107.19241181323044, 135.14876109303265, -35.35801696081375, -84.11140339243796, 95.51685573656522, 37.68722530534007, 83.28854100096937, -74.88061050340595, -38.002702903009684, -68.95772711218032, 104.51639112260474, -19.417462401612067, 186.72567562504275, -90.3653294320734, -103.08518970075889, -65.10524250531184, -139.59974007916063, -87.31166932119551, -91.42736758914589, -78.41556471289678, -157.98156207190144, -125.11239618293781, -133.6501840648659, -112.04948407969216, -123.0693731336401, 20.668781299697088, -84.34220592793136, 26.74692338749393, 13.486607103574284, 6.417686960302724, 195.40434601131497, -54.86164591596382, -19.21158080626941, -66.9620449046493, 61.308887951319385, -62.42095200269087, 89.19256825543556, -27.066908076156512, 64.18689289747286, 2.1525530898524083, 62.97769267498056, -75.50704130314321, -78.78716186193436, -129.52764446154268, -116.08105855073839, -135.11540510579042, -67.35202867145102, -150.35854327577644, -71.68031460553314, -142.87175897613088, -114.44895524772352, 52.78098327069565, -103.6687436072438, 25.438869608425613, 145.84599919079793, -61.22941048471117, 54.856914854164145, -4.675690759910017, 66.89417361765292, -89.07773164692452, 148.10480007913324, -38.914311115918736, 114.09249494607997, -51.53785915633324, 184.275341447841, 94.21067147024196, -26.713463316496586, -125.25983318782745, -63.67342944145351, 85.33587300292234, -50.31560917904816, 146.07244433650465, 8.796213528633068, -50.41557463747658, -63.51942312129134, 77.89350743899189, -24.010682657141803, -153.09632705294774, 109.77558990317065, -7.520864672064218, -76.25351500919426, -96.48179296320903, -90.02144580082896, 8.914561962301498, -52.77290471603834, -54.91294436192189, -116.76556583564866, -112.37007360678501, -122.57033037535385]}, "sampler_perf": {"mean_env_wait_ms": 61.725252046272935, "mean_raw_obs_processing_ms": 2.613496020726521, "mean_inference_ms": 2.616425212803943, "mean_action_processing_ms": 0.15833550321972858}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 147000, "timers": {"sample_time_ms": 128906.174, "sample_throughput": 32.582, "load_time_ms": 20.369, "load_throughput": 206200.705, "learn_time_ms": 11143.934, "learn_throughput": 376.887, "update_time_ms": 10.588}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 17.50716781616211, "policy_loss": -0.035726144909858704, "vf_loss": 17.53453826904297, "vf_explained_var": 0.9765434861183167, "kl": 0.01856681890785694, "entropy": 1.0953680276870728, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 16.278959274291992, "policy_loss": -0.02649727649986744, "vf_loss": 16.29850196838379, "vf_explained_var": 0.9712815880775452, "kl": 0.015456230379641056, "entropy": 0.9777668118476868, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 11.744194984436035, "policy_loss": -0.03432004898786545, "vf_loss": 11.767464637756348, "vf_explained_var": 0.9793021082878113, "kl": 0.016371946781873703, "entropy": 1.1765429973602295, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 11.48457145690918, "policy_loss": -0.02633616514503956, "vf_loss": 11.499687194824219, "vf_explained_var": 0.9838380217552185, "kl": 0.01662316732108593, "entropy": 1.0267536640167236, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 147000, "num_steps_trained": 147000}, "done": false, "episodes_total": 1247, "training_iteration": 35, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-22-05", "timestamp": 1624213325, "time_this_iter_s": 98.83917212486267, "time_total_s": 3908.8505063056946, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd404072ef0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd404072c20>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40405c680>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420e710>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420eb00>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40405c680>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420e710>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420eb00>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40405c680>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420e710>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420eb00>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40405c680>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd4d0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420e710>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420eb00>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd394085b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3908.8505063056946, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 56.616312056737584, "ram_util_percent": 87.56312056737589}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 865.1874015500188, "episode_reward_min": -715.3886701516237, "episode_reward_mean": -108.63922589480109, "episode_len_mean": 116.03, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-3": -215.86457859492734, "AGENT-0": -254.24794154210352, "AGENT-2": -215.43589706571044, "AGENT-1": -157.98156207190144}, "policy_reward_max": {"AGENT-3": 244.77259005809776, "AGENT-0": 202.1570525676601, "AGENT-2": 207.54993384899183, "AGENT-1": 210.7078250752694}, "policy_reward_mean": {"AGENT-3": -22.46233443221548, "AGENT-0": -43.89432359968059, "AGENT-2": -31.90141854473846, "AGENT-1": -10.381149318166553}, "custom_metrics": {"mean_ego_speed_mean": 44.5296175, "mean_ego_speed_min": 35.150999999999996, "mean_ego_speed_max": 51.57575, "distance_travelled_mean": 107.07241749999999, "distance_travelled_min": 39.48625, "distance_travelled_max": 124.84525}, "hist_stats": {"episode_reward": [-112.44455891890519, 865.1874015500188, -631.0754465801801, 328.95882777168214, -125.68279567282738, 496.02238882304033, -671.9952693639276, 682.2975151709047, 89.93488850009396, 681.3133586179855, -111.46808836269486, -25.403919828609094, 362.03874053285614, -211.78403147165005, -157.96624117776855, -177.8785601221876, 505.73365574391556, 66.95535569357048, 297.3730691981378, -415.28187345742157, 354.75088305817957, -208.91097686575046, -495.7527836971058, -341.68863319917915, 537.4499229143152, -636.5336510421503, -91.05386031718263, -533.9963126615972, -632.906702947468, -566.85342331723, -341.5474730386979, -571.5259904149362, 12.035634504172002, 62.18847932944017, -337.10050890118197, -166.6822671790798, -576.8616309462225, -189.17205448683333, 707.6881427246465, 457.6080421581154, -23.726348397847516, -358.26580349183564, -393.71762597190883, 320.2278945264189, -406.0417656184423, 539.765709728763, -3.380024121830864, -64.61291560781608, -395.82508030719646, 287.98552233581904, -489.50922089125254, -652.1296486094066, 91.66386480348109, -147.10901813434876, -358.75866595098205, -338.85497692466413, -408.14066816861384, -172.36140533571825, -261.29296969374616, 147.68728475364537, -520.4598670014013, -365.2333033204941, -715.3886701516237, -156.1023044016825, 366.6138471351128, -301.90952115104466, -233.8550062704134, -323.24693295773807, 489.6575656860307, 67.29465750455051, -27.690783683674262, -255.73479407905376, 510.64736683841477, 52.10446219937065, 461.38164396690087, 502.61936386025803, -168.9799876071697, -247.13306234857941, 227.87294049233648, 197.56239007970626, 323.00859288069285, -261.9960699694285, -135.51427938662118, -318.87193030421605, 377.8416317191066, -359.628032988396, 700.5973897910405, -434.6264922388364, -513.5051730694225, -275.06340941272197, -599.101998773849, -401.76693570034894, -441.5859696325622, -334.1858035467345, -679.90370534895, -279.7519851563223, -583.7063201261564, -555.1734664186356, -593.761284068357, -146.82074376200063], "episode_lengths": [102, 130, 115, 118, 121, 117, 116, 132, 152, 122, 115, 103, 118, 113, 118, 112, 121, 118, 111, 105, 119, 44, 120, 48, 123, 119, 146, 106, 109, 109, 110, 121, 117, 130, 116, 153, 111, 102, 123, 107, 119, 114, 104, 118, 116, 120, 114, 121, 113, 121, 122, 117, 158, 120, 118, 114, 113, 126, 115, 112, 116, 127, 119, 112, 120, 111, 117, 117, 118, 141, 107, 112, 126, 133, 118, 103, 112, 111, 123, 126, 115, 114, 114, 114, 122, 114, 115, 107, 102, 103, 118, 118, 109, 101, 114, 122, 121, 108, 108, 128], "policy_AGENT-3_reward": [-25.228918161837118, 244.77259005809776, -209.7065938477575, 141.35801104876302, -93.09162806861741, 134.59843458166034, -215.86457859492734, 187.00515220543963, -44.56522276015843, 185.49440006527345, 4.626242512779474, -14.82713791615754, 122.44390537808313, -29.592694481683107, -77.51807251938189, -29.04300034290147, 118.31829298445307, 32.17708858079878, 87.43488406643878, -118.81288281372605, 110.18109857250464, -18.504916639784792, -198.0688232944191, -110.13438425134379, 165.0464916331383, -122.70069906354526, -78.23520466181871, -132.81676926184983, -108.56350333810761, -140.18635947296525, -102.96857724162115, -144.13654904917288, -47.329941324299135, -29.475618824509624, -84.38168248586415, -120.06682655811895, -109.36966977113752, -54.04618231157721, 171.05451057413705, 140.8184428125146, 15.055004748977087, -30.79370339018759, -110.72136478935099, 111.85299220806971, -133.4266755165729, 154.0808347452226, -10.559404633878994, 14.720571456877252, -113.60236420829399, 110.34861361345179, -200.41692717601268, -145.7725713404436, -47.26300544551978, -79.50709779315834, -80.78702655846708, -52.3313141822271, -92.8478440239931, -73.96706339634302, -56.19665336355555, 114.60184619359872, -123.49262085557343, -51.07905095036343, -123.13450116845624, -5.152561554872354, 122.89316338270274, -39.02932417879715, -76.48255868338853, -83.3817397934472, 174.32296500918187, -34.6286704731381, -25.399675959701046, -29.841939828047753, 152.38460912886012, 38.34148576217271, 145.11263588740405, 140.08512968638905, -60.269706271828085, -40.43857955775301, 80.4614800798439, 55.90990600780532, 121.89859574385346, -29.399131719539213, 0.24513413031880066, -68.21277403608424, 128.9797792351951, -140.4521176812728, 147.91842834293672, -104.58314466606626, -103.07150600585669, -67.59052889496229, -134.01540175288505, -92.54496930961362, -91.99208941764553, -95.36664688730352, -157.73304311465722, 4.733183613535004, -143.8205425825889, -121.09346847939266, -121.94121478222854, -73.93238579127588], "policy_AGENT-0_reward": [-32.13788585607908, 202.1570525676601, -247.93618172191884, 14.897439433802404, 9.558372102280948, 89.98050726892997, -254.0772244058938, 136.428130328902, 72.67006407212067, 167.7384566388054, -84.2375004535302, 25.398803415164053, 82.16870607051138, -76.33749753464664, -117.91422790572216, -65.68894778923425, 101.71119088036271, -5.5866092028064145, 69.39904920305688, -65.47371166522305, 83.55008954244337, -86.05969286761817, -235.5158619189817, -60.73219924581978, 93.36241672506009, -217.58812071772672, 14.288887124183638, -136.14521961067663, -207.89496947785784, -144.6006913831347, -55.13153815595228, -138.36780081870032, 30.0405897347865, 39.71762555514998, -120.95481757909334, 53.045498491122316, -203.60736845656876, -41.51619840537949, 176.83790401955716, 130.80085992225233, -29.827009273935253, -171.45703140698777, -63.52808178396739, 43.7318168198133, -171.49448238489498, 97.65227095784692, 8.927959909931452, -43.60439010504147, -63.53561101454852, 31.33545538812487, -240.63998497436214, -200.01430681347105, 76.4095278704247, 19.3956339800842, -123.39995550801666, -92.81402537217997, -134.63132124365757, -33.47480194289517, -97.59573958685931, 143.40241082253635, -160.83057513650508, -88.92655782933491, -254.24794154210352, -97.45820609204742, 52.548545361970326, -135.76967810552068, -118.54394018495533, -100.5748316117211, 90.62069892947801, 49.731157032371776, 33.375566312329646, -121.31606295346728, 58.7446666904182, 13.10097032326835, 107.07166716631286, 135.4401563414412, -36.30352136966772, -83.98362078691991, 4.831085202609692, 31.531430089428795, 36.55231084032554, -78.57388712541925, -48.599008772835155, -112.2177091823774, 62.28024600247149, -179.89912366770997, 186.85167051309014, -90.35995150646696, -153.39440066937829, -70.9066475184245, -184.21586359904347, -132.1243517781631, -152.94655747929193, -79.91472024110726, -206.37804496296621, -33.82700579282165, -127.49978693493988, -160.68611419220932, -174.09427949723647, -19.605854502474685], "policy_AGENT-2_reward": [-32.69221717557282, 207.54993384899183, -87.00027357237789, 108.9617400816802, 50.37756544951378, 132.3401041774514, -101.28520605706768, 175.38641647009473, -44.53432205260213, 160.25345207158446, -37.563323435057754, -61.4298613459099, 74.58156156310142, -29.3838610257226, 18.513499066735804, -17.19390435633624, 143.0367714503559, 42.84323119059403, 46.961171827157166, -165.39330854876349, 77.59732320023616, -18.33803732202393, -31.323069590577, -109.81651429356921, 137.5824885292462, -174.1084297024879, -78.27456501285256, -136.78804158220674, -208.44785644072493, -145.1574518622924, -105.84289654834687, -144.7806630988304, -47.324335155940574, -29.49477087964891, -53.50357736146386, -120.11817782806875, -155.07887164203845, -42.071814613543275, 175.52038668311133, 91.77806795310617, 17.75911944360733, -30.75523550683276, -155.79474995713701, 79.30721249561364, -50.80499853792626, 141.96015968918925, -10.544792926516406, 14.686477677824769, -155.1676819630625, 68.4079458952504, -24.441626083736054, -153.24644340254432, -47.25824752459446, -79.47668964921044, -78.31816887530402, -97.22784440704737, -90.64005710013393, -73.83410195878162, -54.72767202729308, -55.404027900567606, -119.37110517367485, -112.85762093401085, -215.43589706571044, -49.609110627303394, 93.62662273218204, -88.74186108930746, -19.63253798477212, -56.47346073417348, 134.2211803086358, -34.751808751771684, -68.7623541817597, -74.78499269989321, 143.68119430192104, -51.115590742676154, 102.00492909995418, 91.94531673939576, -37.04874300485997, -38.599458611468506, 47.06351947331756, 72.4338286771321, 81.26914529554446, -79.14244062106405, -49.15770184109517, -69.48371997357421, 82.06521535883542, -19.85932923780093, 179.10161530997124, -149.31806663423004, -153.95407669342902, -71.46099049402358, -141.27099334275994, -89.78594529137672, -105.21995514647894, -80.48887170542672, -157.81105519942597, -125.54576679409772, -178.73580654376198, -161.34439966734107, -174.65641665525195, -73.95128476794736], "policy_AGENT-1_reward": [-22.385537725416274, 210.7078250752694, -86.432397438126, 63.74163720743648, -92.52710515600486, 139.10334279499867, -100.76826030603931, 183.47781616646876, 106.36436924073384, 167.8270498423217, 5.706493013113655, 25.45427601829432, 82.84456752116057, -76.4699784295978, 18.95256018059989, -65.95270763371562, 142.6674004287437, -2.478354875015912, 93.57796410148501, -65.60197042970924, 83.42237174299515, -86.00833003632353, -30.84502889312818, -61.00553540844646, 141.45852602687143, -122.13640155838985, 51.16702223330491, -128.24628220686424, -108.00037369077717, -136.9089205988374, -77.60446109277751, -144.2409774482329, 76.64932124962522, 81.44124347844883, -78.26043147476096, 20.457238715985657, -108.80572107647771, -51.53785915633324, 184.275341447841, 94.21067147024196, -26.713463316496586, -125.25983318782745, -63.67342944145351, 85.33587300292234, -50.31560917904816, 146.07244433650465, 8.796213528633068, -50.41557463747658, -63.51942312129134, 77.89350743899189, -24.010682657141803, -153.09632705294774, 109.77558990317065, -7.520864672064218, -76.25351500919426, -96.48179296320903, -90.02144580082896, 8.914561962301498, -52.77290471603834, -54.91294436192189, -116.76556583564866, -112.37007360678501, -122.57033037535385, -3.8824261274593788, 97.54551565825702, -38.368657777419415, -19.195969417297597, -82.81690081839614, 90.49272143873407, 86.94397969708851, 33.09568014545684, -29.791798597645435, 155.83689671721567, 51.77759685660558, 107.19241181323044, 135.14876109303265, -35.35801696081375, -84.11140339243796, 95.51685573656522, 37.68722530534007, 83.28854100096937, -74.88061050340595, -38.002702903009684, -68.95772711218032, 104.51639112260474, -19.417462401612067, 186.72567562504275, -90.3653294320734, -103.08518970075889, -65.10524250531184, -139.59974007916063, -87.31166932119551, -91.42736758914589, -78.41556471289678, -157.98156207190144, -125.11239618293781, -133.6501840648659, -112.04948407969216, -123.0693731336401, 20.668781299697088]}, "sampler_perf": {"mean_env_wait_ms": 61.452778258402084, "mean_raw_obs_processing_ms": 2.605285785289999, "mean_inference_ms": 2.605297195544767, "mean_action_processing_ms": 0.1577811064709962}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 151200, "timers": {"sample_time_ms": 121133.351, "sample_throughput": 34.673, "load_time_ms": 19.032, "load_throughput": 220681.494, "learn_time_ms": 10424.355, "learn_throughput": 402.903, "update_time_ms": 9.803}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 24.369953155517578, "policy_loss": -0.030507361516356468, "vf_loss": 24.392961502075195, "vf_explained_var": 0.9758655428886414, "kl": 0.01666296273469925, "entropy": 1.0536249876022339, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 22.0331974029541, "policy_loss": -0.027942614629864693, "vf_loss": 22.053260803222656, "vf_explained_var": 0.9706956744194031, "kl": 0.017516078427433968, "entropy": 0.9386093020439148, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 16.9171142578125, "policy_loss": -0.03373517468571663, "vf_loss": 16.941967010498047, "vf_explained_var": 0.9796014428138733, "kl": 0.01315871812403202, "entropy": 1.1468682289123535, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 16.912508010864258, "policy_loss": -0.029666032642126083, "vf_loss": 16.933258056640625, "vf_explained_var": 0.981168270111084, "kl": 0.013206268660724163, "entropy": 1.0304185152053833, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 151200, "num_steps_trained": 151200}, "done": false, "episodes_total": 1284, "training_iteration": 36, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-23-41", "timestamp": 1624213421, "time_this_iter_s": 96.0460901260376, "time_total_s": 4004.896596431732, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd39406a4d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd39406a3b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd39406a170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd39406a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd39406a830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd39406a950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd39406a170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd39406a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd39406a830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd39406a950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd39406a170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd39406a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd39406a830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd39406a950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd39406a170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd39406a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd39406a830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd39406a950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd39406a5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4004.896596431732, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 55.71376811594203, "ram_util_percent": 87.51014492753625}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 865.1874015500188, "episode_reward_min": -679.90370534895, "episode_reward_mean": -88.65597482634018, "episode_len_mean": 117.07, "episodes_this_iter": 34, "policy_reward_min": {"AGENT-3": -215.86457859492734, "AGENT-0": -254.0772244058938, "AGENT-2": -208.44785644072493, "AGENT-1": -217.13406603691902}, "policy_reward_max": {"AGENT-3": 244.77259005809776, "AGENT-0": 211.5916279914266, "AGENT-2": 207.54993384899183, "AGENT-1": 222.87899745711863}, "policy_reward_mean": {"AGENT-3": -19.954036195891142, "AGENT-0": -34.40521564730673, "AGENT-2": -26.58989508100093, "AGENT-1": -7.706827902141353}, "custom_metrics": {"mean_ego_speed_mean": 44.477865, "mean_ego_speed_min": 36.22, "mean_ego_speed_max": 51.33275, "distance_travelled_mean": 108.48705249999999, "distance_travelled_min": 39.48625, "distance_travelled_max": 124.84525}, "hist_stats": {"episode_reward": [-96.76467834072754, 335.6143149973858, -252.7608843958115, 752.344928758043, -42.123089464464734, 495.42670801084824, -626.3114196666143, 705.6321941952556, -228.22262945960742, 750.0766563979603, -312.90883162441907, 29.734058166179196, -267.43231050741775, 80.1904675397229, -28.455770789816846, 113.33200697642408, -303.4628843485177, 141.28969792180854, -82.08104853609942, 275.3672627809204, 411.5423830836357, 295.2798936559906, 18.97629149231536, 55.443875771550395, -370.9240524532467, -425.7829745605469, -225.98580040947624, -673.277112354036, -416.156727774167, -167.95538332169966, -587.3962029822396, -347.8283874844188, -459.0834662025336, -377.60402752002005, -255.73479407905376, 510.64736683841477, 52.10446219937065, 461.38164396690087, 502.61936386025803, -168.9799876071697, -247.13306234857941, 227.87294049233648, 197.56239007970626, 323.00859288069285, -261.9960699694285, -135.51427938662118, -318.87193030421605, 377.8416317191066, -359.628032988396, 700.5973897910405, -434.6264922388364, -513.5051730694225, -275.06340941272197, -599.101998773849, -401.76693570034894, -441.5859696325622, -334.1858035467345, -679.90370534895, -279.7519851563223, -583.7063201261564, -555.1734664186356, -593.761284068357, -146.82074376200063, -112.44455891890519, 865.1874015500188, -631.0754465801801, 328.95882777168214, -125.68279567282738, 496.02238882304033, -671.9952693639276, 682.2975151709047, 89.93488850009396, 681.3133586179855, -111.46808836269486, -25.403919828609094, 362.03874053285614, -211.78403147165005, -157.96624117776855, -177.8785601221876, 505.73365574391556, 66.95535569357048, 297.3730691981378, -415.28187345742157, 354.75088305817957, -208.91097686575046, -495.7527836971058, -341.68863319917915, 537.4499229143152, -636.5336510421503, -91.05386031718263, -533.9963126615972, -632.906702947468, -566.85342331723, -341.5474730386979, -571.5259904149362, 12.035634504172002, 62.18847932944017, -337.10050890118197, -166.6822671790798, -576.8616309462225], "episode_lengths": [114, 118, 113, 127, 101, 123, 113, 130, 129, 132, 121, 109, 100, 102, 113, 123, 117, 127, 119, 124, 152, 130, 125, 171, 100, 116, 140, 110, 116, 127, 131, 121, 109, 113, 112, 126, 133, 118, 103, 112, 111, 123, 126, 115, 114, 114, 114, 122, 114, 115, 107, 102, 103, 118, 118, 109, 101, 114, 122, 121, 108, 108, 128, 102, 130, 115, 118, 121, 117, 116, 132, 152, 122, 115, 103, 118, 113, 118, 112, 121, 118, 111, 105, 119, 44, 120, 48, 123, 119, 146, 106, 109, 109, 110, 121, 117, 130, 116, 153, 111], "policy_AGENT-3_reward": [-13.104584924132846, 115.99010467209658, -28.34089425259013, 214.27607904680673, -15.342195184485899, 151.81832588792227, -186.99164635178062, 172.06147385028208, -97.16322551603776, 188.21415243788257, -88.76206941179626, -2.960372033796366, -84.85668020558676, 4.863478064648688, -19.048227056542054, 22.01343227246187, -12.640875465383873, 28.900463200023136, -21.69438958579499, 98.08555374887814, -11.517871723375336, 90.19408547708264, -30.317212430282687, -73.65522250851684, -80.56828808236239, -100.23054811381772, 13.392539425313162, -121.17938976178584, -75.52655571559072, -67.59699642449142, -148.61743413969378, -82.0507906839443, -114.7800150034425, -86.30533687831888, -29.841939828047753, 152.38460912886012, 38.34148576217271, 145.11263588740405, 140.08512968638905, -60.269706271828085, -40.43857955775301, 80.4614800798439, 55.90990600780532, 121.89859574385346, -29.399131719539213, 0.24513413031880066, -68.21277403608424, 128.9797792351951, -140.4521176812728, 147.91842834293672, -104.58314466606626, -103.07150600585669, -67.59052889496229, -134.01540175288505, -92.54496930961362, -91.99208941764553, -95.36664688730352, -157.73304311465722, 4.733183613535004, -143.8205425825889, -121.09346847939266, -121.94121478222854, -73.93238579127588, -25.228918161837118, 244.77259005809776, -209.7065938477575, 141.35801104876302, -93.09162806861741, 134.59843458166034, -215.86457859492734, 187.00515220543963, -44.56522276015843, 185.49440006527345, 4.626242512779474, -14.82713791615754, 122.44390537808313, -29.592694481683107, -77.51807251938189, -29.04300034290147, 118.31829298445307, 32.17708858079878, 87.43488406643878, -118.81288281372605, 110.18109857250464, -18.504916639784792, -198.0688232944191, -110.13438425134379, 165.0464916331383, -122.70069906354526, -78.23520466181871, -132.81676926184983, -108.56350333810761, -140.18635947296525, -102.96857724162115, -144.13654904917288, -47.329941324299135, -29.475618824509624, -84.38168248586415, -120.06682655811895, -109.36966977113752], "policy_AGENT-0_reward": [-56.406583065578715, 43.5337419575187, -121.25483268878394, 179.7162300906228, -10.156709358188156, 86.00921515330725, -230.85780165533748, 180.3553711589517, -36.40378931859584, 182.5235666104393, -89.69687434845531, 39.22172036989234, -60.34082102486679, 24.369885860935568, 4.632940652199142, -12.092014473676755, -161.9132073890025, 20.866948177670622, -18.501020136799315, 15.991429645812474, 211.5916279914266, 26.47096127405097, 37.76443885892522, 119.12638868446481, -80.28872027168518, -72.15346975042925, -18.4398283639083, -167.11020753180827, -115.63189657180975, -11.011956629157886, -124.52171414697375, -116.81729781056947, -102.4369816046159, -126.34280810025228, -121.31606295346728, 58.7446666904182, 13.10097032326835, 107.07166716631286, 135.4401563414412, -36.30352136966772, -83.98362078691991, 4.831085202609692, 31.531430089428795, 36.55231084032554, -78.57388712541925, -48.599008772835155, -112.2177091823774, 62.28024600247149, -179.89912366770997, 186.85167051309014, -90.35995150646696, -153.39440066937829, -70.9066475184245, -184.21586359904347, -132.1243517781631, -152.94655747929193, -79.91472024110726, -206.37804496296621, -33.82700579282165, -127.49978693493988, -160.68611419220932, -174.09427949723647, -19.605854502474685, -32.13788585607908, 202.1570525676601, -247.93618172191884, 14.897439433802404, 9.558372102280948, 89.98050726892997, -254.0772244058938, 136.428130328902, 72.67006407212067, 167.7384566388054, -84.2375004535302, 25.398803415164053, 82.16870607051138, -76.33749753464664, -117.91422790572216, -65.68894778923425, 101.71119088036271, -5.5866092028064145, 69.39904920305688, -65.47371166522305, 83.55008954244337, -86.05969286761817, -235.5158619189817, -60.73219924581978, 93.36241672506009, -217.58812071772672, 14.288887124183638, -136.14521961067663, -207.89496947785784, -144.6006913831347, -55.13153815595228, -138.36780081870032, 30.0405897347865, 39.71762555514998, -120.95481757909334, 53.045498491122316, -203.60736845656876], "policy_AGENT-2_reward": [-13.96603128399099, 84.90980254273967, -75.54238624220629, 175.9400325697566, -10.71884967269641, 123.5730135218959, -104.46853304333155, 171.887179044877, 1.9413691048563528, 188.34535959630944, -46.251956941421824, -45.80099179621379, -61.589430882328216, 26.527511594605805, -19.09789697100414, 51.46661352286308, -12.53783677101101, 62.060011316009785, -21.44752243806858, 56.895041803842055, -11.41037064153458, 65.1903794781492, -30.32532299087527, -73.46412614013893, -80.85133487812898, -126.9819847918718, -110.6886040382384, -167.85344902352287, -112.71467413803751, -46.73752994442864, -167.55489511447854, -75.10026759560007, -127.65271688842829, -82.9099915927893, -74.78499269989321, 143.68119430192104, -51.115590742676154, 102.00492909995418, 91.94531673939576, -37.04874300485997, -38.599458611468506, 47.06351947331756, 72.4338286771321, 81.26914529554446, -79.14244062106405, -49.15770184109517, -69.48371997357421, 82.06521535883542, -19.85932923780093, 179.10161530997124, -149.31806663423004, -153.95407669342902, -71.46099049402358, -141.27099334275994, -89.78594529137672, -105.21995514647894, -80.48887170542672, -157.81105519942597, -125.54576679409772, -178.73580654376198, -161.34439966734107, -174.65641665525195, -73.95128476794736, -32.69221717557282, 207.54993384899183, -87.00027357237789, 108.9617400816802, 50.37756544951378, 132.3401041774514, -101.28520605706768, 175.38641647009473, -44.53432205260213, 160.25345207158446, -37.563323435057754, -61.4298613459099, 74.58156156310142, -29.3838610257226, 18.513499066735804, -17.19390435633624, 143.0367714503559, 42.84323119059403, 46.961171827157166, -165.39330854876349, 77.59732320023616, -18.33803732202393, -31.323069590577, -109.81651429356921, 137.5824885292462, -174.1084297024879, -78.27456501285256, -136.78804158220674, -208.44785644072493, -145.1574518622924, -105.84289654834687, -144.7806630988304, -47.324335155940574, -29.49477087964891, -53.50357736146386, -120.11817782806875, -155.07887164203845], "policy_AGENT-1_reward": [-13.287479067024913, 91.18066582503076, -27.622771212231044, 182.4125870508566, -5.905335249094362, 134.02615344772278, -103.99343861616472, 181.32817014114536, -96.59698372983027, 190.99357775332862, -88.19793092274546, 39.27370162629704, -60.64537839463574, 24.429592019532937, 5.057412585530217, 51.943975654775876, -116.37096472312035, 29.46227522810517, -20.438116375436433, 104.39523758238784, 222.87899745711863, 113.42446742670757, 41.85438805454805, 83.43683573574138, -129.21570922107048, -126.41697190442788, -110.24990743264266, -217.13406603691902, -112.28360134872877, -42.608900323621555, -146.70215958109313, -73.86003139430541, -114.21375270604683, -82.04589094865982, -29.791798597645435, 155.83689671721567, 51.77759685660558, 107.19241181323044, 135.14876109303265, -35.35801696081375, -84.11140339243796, 95.51685573656522, 37.68722530534007, 83.28854100096937, -74.88061050340595, -38.002702903009684, -68.95772711218032, 104.51639112260474, -19.417462401612067, 186.72567562504275, -90.3653294320734, -103.08518970075889, -65.10524250531184, -139.59974007916063, -87.31166932119551, -91.42736758914589, -78.41556471289678, -157.98156207190144, -125.11239618293781, -133.6501840648659, -112.04948407969216, -123.0693731336401, 20.668781299697088, -22.385537725416274, 210.7078250752694, -86.432397438126, 63.74163720743648, -92.52710515600486, 139.10334279499867, -100.76826030603931, 183.47781616646876, 106.36436924073384, 167.8270498423217, 5.706493013113655, 25.45427601829432, 82.84456752116057, -76.4699784295978, 18.95256018059989, -65.95270763371562, 142.6674004287437, -2.478354875015912, 93.57796410148501, -65.60197042970924, 83.42237174299515, -86.00833003632353, -30.84502889312818, -61.00553540844646, 141.45852602687143, -122.13640155838985, 51.16702223330491, -128.24628220686424, -108.00037369077717, -136.9089205988374, -77.60446109277751, -144.2409774482329, 76.64932124962522, 81.44124347844883, -78.26043147476096, 20.457238715985657, -108.80572107647771]}, "sampler_perf": {"mean_env_wait_ms": 61.21825424952063, "mean_raw_obs_processing_ms": 2.5974658111963658, "mean_inference_ms": 2.5966356647544857, "mean_action_processing_ms": 0.1573015136438025}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 155400, "timers": {"sample_time_ms": 112650.567, "sample_throughput": 37.283, "load_time_ms": 19.025, "load_throughput": 220758.652, "learn_time_ms": 10083.771, "learn_throughput": 416.511, "update_time_ms": 9.715}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 22.190893173217773, "policy_loss": -0.026641326025128365, "vf_loss": 22.20755386352539, "vf_explained_var": 0.9758445620536804, "kl": 0.022186724469065666, "entropy": 1.057454228401184, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 16.00425910949707, "policy_loss": -0.02558666467666626, "vf_loss": 16.023422241210938, "vf_explained_var": 0.9757538437843323, "kl": 0.014275247231125832, "entropy": 0.9448737502098083, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 15.37073040008545, "policy_loss": -0.0332375206053257, "vf_loss": 15.394575119018555, "vf_explained_var": 0.9796276688575745, "kl": 0.013913231901824474, "entropy": 1.1400028467178345, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 13.887282371520996, "policy_loss": -0.023876363411545753, "vf_loss": 13.901287078857422, "vf_explained_var": 0.9835368990898132, "kl": 0.014621814712882042, "entropy": 0.9948375225067139, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 155400, "num_steps_trained": 155400}, "done": false, "episodes_total": 1318, "training_iteration": 37, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-25-22", "timestamp": 1624213522, "time_this_iter_s": 100.2272732257843, "time_total_s": 4105.1238696575165, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40405cef0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd394085560>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40428ce60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420ef80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420e9e0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40428ce60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420ef80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420e9e0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40428ce60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420ef80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420e9e0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40428ce60>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8c20>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420ef80>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420e9e0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd39406ab90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4105.1238696575165, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 55.62237762237762, "ram_util_percent": 87.1146853146853}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 752.344928758043, "episode_reward_min": -673.277112354036, "episode_reward_mean": -98.61449968020341, "episode_len_mean": 116.57, "episodes_this_iter": 37, "policy_reward_min": {"AGENT-3": -198.0688232944191, "AGENT-0": -235.5158619189817, "AGENT-2": -208.44785644072493, "AGENT-1": -217.13406603691902}, "policy_reward_max": {"AGENT-3": 214.27607904680673, "AGENT-0": 211.5916279914266, "AGENT-2": 188.34535959630944, "AGENT-1": 222.87899745711863}, "policy_reward_mean": {"AGENT-3": -22.215272678111948, "AGENT-0": -34.64021020867924, "AGENT-2": -27.38340945954388, "AGENT-1": -14.375607333868372}, "custom_metrics": {"mean_ego_speed_mean": 44.054339999999996, "mean_ego_speed_min": 36.22, "mean_ego_speed_max": 51.72075, "distance_travelled_mean": 104.8954525, "distance_travelled_min": 38.22925, "distance_travelled_max": 124.84525}, "hist_stats": {"episode_reward": [-631.9413320640971, 490.2950921267062, -135.57038098337657, 541.0883047364116, -114.8093881357835, 569.1229632150823, -114.12779152888164, 345.1576321897646, -571.2716389112796, 375.7394171019784, -24.97206989261175, -13.562166501094616, -379.591094540578, 600.32603561053, -96.21120706250743, 180.345222986509, -172.70112796935206, 56.503285742751345, -109.77529449604195, 18.357079837774148, -169.5718422405639, -367.7525823550596, -151.64774979483963, 466.5537013101614, -474.29747897373386, -132.13298971567934, -478.42837639462743, -156.98580934795402, -417.55263860052963, -597.2946043661378, -544.325827797472, -491.72717102142633, -486.05236813219574, -368.7394148258272, -309.87701318856875, -444.452504158899, -85.87695657560607, 89.93488850009396, 681.3133586179855, -111.46808836269486, -25.403919828609094, 362.03874053285614, -211.78403147165005, -157.96624117776855, -177.8785601221876, 505.73365574391556, 66.95535569357048, 297.3730691981378, -415.28187345742157, 354.75088305817957, -208.91097686575046, -495.7527836971058, -341.68863319917915, 537.4499229143152, -636.5336510421503, -91.05386031718263, -533.9963126615972, -632.906702947468, -566.85342331723, -341.5474730386979, -571.5259904149362, 12.035634504172002, 62.18847932944017, -337.10050890118197, -166.6822671790798, -576.8616309462225, -96.76467834072754, 335.6143149973858, -252.7608843958115, 752.344928758043, -42.123089464464734, 495.42670801084824, -626.3114196666143, 705.6321941952556, -228.22262945960742, 750.0766563979603, -312.90883162441907, 29.734058166179196, -267.43231050741775, 80.1904675397229, -28.455770789816846, 113.33200697642408, -303.4628843485177, 141.28969792180854, -82.08104853609942, 275.3672627809204, 411.5423830836357, 295.2798936559906, 18.97629149231536, 55.443875771550395, -370.9240524532467, -425.7829745605469, -225.98580040947624, -673.277112354036, -416.156727774167, -167.95538332169966, -587.3962029822396, -347.8283874844188, -459.0834662025336, -377.60402752002005], "episode_lengths": [114, 132, 149, 149, 103, 118, 117, 140, 111, 159, 101, 114, 100, 127, 117, 113, 112, 111, 111, 133, 40, 117, 114, 120, 130, 114, 114, 103, 116, 104, 110, 106, 57, 110, 102, 109, 135, 152, 122, 115, 103, 118, 113, 118, 112, 121, 118, 111, 105, 119, 44, 120, 48, 123, 119, 146, 106, 109, 109, 110, 121, 117, 130, 116, 153, 111, 114, 118, 113, 127, 101, 123, 113, 130, 129, 132, 121, 109, 100, 102, 113, 123, 117, 127, 119, 124, 152, 130, 125, 171, 100, 116, 140, 110, 116, 127, 131, 121, 109, 113], "policy_AGENT-3_reward": [-185.58954405296964, 151.21126717235276, -79.39843520710446, 155.8124798331963, -30.111260840089464, 170.60399363089738, -30.683749324969522, 114.04367081746327, -152.25233918010343, 123.12051022339006, -6.347402426632341, -11.55571224163039, -113.88721967895434, 183.20603676148835, -13.541042697767878, 70.3342296776805, -23.349868549089734, -9.874464923389823, -19.53229835386476, -35.98992638964758, -11.47515979376469, -138.5175198038486, -18.084584773035033, 107.74160165527078, -91.53223138092879, 59.59167908021605, -105.08041144870658, -0.04645511801230806, -113.05053078822107, -111.37028187011673, -97.95197465845112, -129.89396703288196, -121.5246330164303, -95.50119035065613, -73.12103643547036, -111.34332101586828, 72.43109033870427, -44.56522276015843, 185.49440006527345, 4.626242512779474, -14.82713791615754, 122.44390537808313, -29.592694481683107, -77.51807251938189, -29.04300034290147, 118.31829298445307, 32.17708858079878, 87.43488406643878, -118.81288281372605, 110.18109857250464, -18.504916639784792, -198.0688232944191, -110.13438425134379, 165.0464916331383, -122.70069906354526, -78.23520466181871, -132.81676926184983, -108.56350333810761, -140.18635947296525, -102.96857724162115, -144.13654904917288, -47.329941324299135, -29.475618824509624, -84.38168248586415, -120.06682655811895, -109.36966977113752, -13.104584924132846, 115.99010467209658, -28.34089425259013, 214.27607904680673, -15.342195184485899, 151.81832588792227, -186.99164635178062, 172.06147385028208, -97.16322551603776, 188.21415243788257, -88.76206941179626, -2.960372033796366, -84.85668020558676, 4.863478064648688, -19.048227056542054, 22.01343227246187, -12.640875465383873, 28.900463200023136, -21.69438958579499, 98.08555374887814, -11.517871723375336, 90.19408547708264, -30.317212430282687, -73.65522250851684, -80.56828808236239, -100.23054811381772, 13.392539425313162, -121.17938976178584, -75.52655571559072, -67.59699642449142, -148.61743413969378, -82.0507906839443, -114.7800150034425, -86.30533687831888], "policy_AGENT-0_reward": [-229.43342144914828, 93.5668496140309, -6.337899009467947, 114.45051064483681, -30.16897260449693, 135.46537775279654, -48.7540120393738, 59.9749121783613, -195.7332660545098, 67.21095246411946, -8.48298452450476, -51.628585509197414, -76.24177681829299, 111.71609866445112, -33.86424300706645, -9.493349154206491, -52.751108940151326, 17.729201164301344, -35.34635439897829, -0.050459427938609025, -73.31971895758204, -176.75734652834723, -82.47282154405232, 88.99987260352479, -128.66732480867566, 19.814298629716646, -154.33005247827134, -91.03531728306615, -132.7132131064836, -162.46488583688105, -148.8395105000654, -117.13227647418942, -121.50502517531335, -88.79265524577139, -95.6307374235404, -111.1259555608741, 39.07364436118677, 72.67006407212067, 167.7384566388054, -84.2375004535302, 25.398803415164053, 82.16870607051138, -76.33749753464664, -117.91422790572216, -65.68894778923425, 101.71119088036271, -5.5866092028064145, 69.39904920305688, -65.47371166522305, 83.55008954244337, -86.05969286761817, -235.5158619189817, -60.73219924581978, 93.36241672506009, -217.58812071772672, 14.288887124183638, -136.14521961067663, -207.89496947785784, -144.6006913831347, -55.13153815595228, -138.36780081870032, 30.0405897347865, 39.71762555514998, -120.95481757909334, 53.045498491122316, -203.60736845656876, -56.406583065578715, 43.5337419575187, -121.25483268878394, 179.7162300906228, -10.156709358188156, 86.00921515330725, -230.85780165533748, 180.3553711589517, -36.40378931859584, 182.5235666104393, -89.69687434845531, 39.22172036989234, -60.34082102486679, 24.369885860935568, 4.632940652199142, -12.092014473676755, -161.9132073890025, 20.866948177670622, -18.501020136799315, 15.991429645812474, 211.5916279914266, 26.47096127405097, 37.76443885892522, 119.12638868446481, -80.28872027168518, -72.15346975042925, -18.4398283639083, -167.11020753180827, -115.63189657180975, -11.011956629157886, -124.52171414697375, -116.81729781056947, -102.4369816046159, -126.34280810025228], "policy_AGENT-2_reward": [-108.67449063832879, 108.3714911152824, 29.000632636901067, 117.66517937500447, -30.730555508187315, 127.51491404059126, -4.807340003918561, 71.90945323028691, -111.95801189390903, 84.59592066177012, -9.040552551337399, 24.593675902713876, -113.2826870280156, 147.4711653326697, -13.382190769473786, 37.43062735772314, -23.222972089613357, 24.100233783979412, -19.454788063905678, 26.933139066921512, -11.471238825766928, -26.491243427866713, -18.13772495934228, 133.36356171693112, -127.356124072526, -105.98428692185061, -109.82894619335285, 25.014244892419352, -85.40398432656933, -163.02685555364428, -149.3968734323481, -117.68856082544703, -122.05707226271707, -89.51007196439016, -96.19785339523492, -110.81043917884583, -98.9335912700966, -44.53432205260213, 160.25345207158446, -37.563323435057754, -61.4298613459099, 74.58156156310142, -29.3838610257226, 18.513499066735804, -17.19390435633624, 143.0367714503559, 42.84323119059403, 46.961171827157166, -165.39330854876349, 77.59732320023616, -18.33803732202393, -31.323069590577, -109.81651429356921, 137.5824885292462, -174.1084297024879, -78.27456501285256, -136.78804158220674, -208.44785644072493, -145.1574518622924, -105.84289654834687, -144.7806630988304, -47.324335155940574, -29.49477087964891, -53.50357736146386, -120.11817782806875, -155.07887164203845, -13.96603128399099, 84.90980254273967, -75.54238624220629, 175.9400325697566, -10.71884967269641, 123.5730135218959, -104.46853304333155, 171.887179044877, 1.9413691048563528, 188.34535959630944, -46.251956941421824, -45.80099179621379, -61.589430882328216, 26.527511594605805, -19.09789697100414, 51.46661352286308, -12.53783677101101, 62.060011316009785, -21.44752243806858, 56.895041803842055, -11.41037064153458, 65.1903794781492, -30.32532299087527, -73.46412614013893, -80.85133487812898, -126.9819847918718, -110.6886040382384, -167.85344902352287, -112.71467413803751, -46.73752994442864, -167.55489511447854, -75.10026759560007, -127.65271688842829, -82.9099915927893], "policy_AGENT-1_reward": [-108.24387592365017, 137.14548422504006, -78.83467940370528, 153.16013488337398, -23.79859918300957, 135.53867779079658, -29.882690160619983, 99.22959596365362, -111.32802178275696, 100.81203375269885, -1.101130390137408, 25.02845534701931, -76.17941101531525, 157.93273485192023, -35.42373058819929, 82.07371510531172, -73.3771783904977, 24.548315717860447, -35.44185367929326, 27.464326588438723, -73.30572466345023, -25.986472594996993, -32.952618518409956, 136.44866533443462, -126.74179871160318, -105.55468050376146, -109.18896627429689, -90.91828183929482, -86.38491037925579, -160.43258110549564, -148.13746920660708, -127.01236668890793, -120.96563767773503, -94.93549726500969, -44.92738593432347, -111.17278840331113, -98.44810000540042, 106.36436924073384, 167.8270498423217, 5.706493013113655, 25.45427601829432, 82.84456752116057, -76.4699784295978, 18.95256018059989, -65.95270763371562, 142.6674004287437, -2.478354875015912, 93.57796410148501, -65.60197042970924, 83.42237174299515, -86.00833003632353, -30.84502889312818, -61.00553540844646, 141.45852602687143, -122.13640155838985, 51.16702223330491, -128.24628220686424, -108.00037369077717, -136.9089205988374, -77.60446109277751, -144.2409774482329, 76.64932124962522, 81.44124347844883, -78.26043147476096, 20.457238715985657, -108.80572107647771, -13.287479067024913, 91.18066582503076, -27.622771212231044, 182.4125870508566, -5.905335249094362, 134.02615344772278, -103.99343861616472, 181.32817014114536, -96.59698372983027, 190.99357775332862, -88.19793092274546, 39.27370162629704, -60.64537839463574, 24.429592019532937, 5.057412585530217, 51.943975654775876, -116.37096472312035, 29.46227522810517, -20.438116375436433, 104.39523758238784, 222.87899745711863, 113.42446742670757, 41.85438805454805, 83.43683573574138, -129.21570922107048, -126.41697190442788, -110.24990743264266, -217.13406603691902, -112.28360134872877, -42.608900323621555, -146.70215958109313, -73.86003139430541, -114.21375270604683, -82.04589094865982]}, "sampler_perf": {"mean_env_wait_ms": 60.977741406486075, "mean_raw_obs_processing_ms": 2.5899650913711936, "mean_inference_ms": 2.5864775074157462, "mean_action_processing_ms": 0.15685392646629265}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 159600, "timers": {"sample_time_ms": 104584.796, "sample_throughput": 40.159, "load_time_ms": 17.56, "load_throughput": 239175.987, "learn_time_ms": 9426.596, "learn_throughput": 445.548, "update_time_ms": 8.747}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 23.711048126220703, "policy_loss": -0.027641072869300842, "vf_loss": 23.73025131225586, "vf_explained_var": 0.9717327952384949, "kl": 0.012502619065344334, "entropy": 1.1383652687072754, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 22.765989303588867, "policy_loss": -0.027836956083774567, "vf_loss": 22.787925720214844, "vf_explained_var": 0.9670504331588745, "kl": 0.013099259696900845, "entropy": 0.9372438788414001, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 20.296245574951172, "policy_loss": -0.03506476804614067, "vf_loss": 20.322038650512695, "vf_explained_var": 0.9740793704986572, "kl": 0.013742989860475063, "entropy": 1.1402493715286255, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 25.003253936767578, "policy_loss": -0.026054713875055313, "vf_loss": 25.020885467529297, "vf_explained_var": 0.9738086462020874, "kl": 0.012481016106903553, "entropy": 0.9769041538238525, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 159600, "num_steps_trained": 159600}, "done": false, "episodes_total": 1355, "training_iteration": 38, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-27-00", "timestamp": 1624213620, "time_this_iter_s": 98.24148106575012, "time_total_s": 4203.365350723267, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd3847da4d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd3847da3b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd3847da170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd3847da050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd3847da830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd3847da950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd3847da170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd3847da050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd3847da830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd3847da950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd3847da170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd3847da050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd3847da830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd3847da950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd3847da170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd3847da050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd3847da830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd3847da950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd3847da5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4203.365350723267, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 56.309999999999995, "ram_util_percent": 87.13285714285716}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 903.5612690121474, "episode_reward_min": -673.277112354036, "episode_reward_mean": -98.25272503960873, "episode_len_mean": 118.2, "episodes_this_iter": 34, "policy_reward_min": {"AGENT-3": -225.87225045962066, "AGENT-0": -262.276991270041, "AGENT-1": -217.13406603691902, "AGENT-2": -200.02452380143225}, "policy_reward_max": {"AGENT-3": 226.8968146368183, "AGENT-0": 225.48488015954155, "AGENT-1": 257.8015200680026, "AGENT-2": 229.2333457980755}, "policy_reward_mean": {"AGENT-3": -22.179688202365593, "AGENT-0": -35.507227423719065, "AGENT-1": -17.0953332587769, "AGENT-2": -23.47047615474718}, "custom_metrics": {"mean_ego_speed_mean": 43.70393, "mean_ego_speed_min": 32.67925, "mean_ego_speed_max": 51.72075, "distance_travelled_mean": 104.58035000000001, "distance_travelled_min": 38.22925, "distance_travelled_max": 124.84424999999999}, "hist_stats": {"episode_reward": [656.5457418015651, -586.6219394086845, 539.4335999035774, -662.2146665907806, 665.7380879178779, -163.0447466146031, 210.19037874641376, 46.41169636479024, 739.5873834735652, -224.41179241692106, 361.6768528670379, -211.38551192104487, 903.5612690121474, -539.2966432245889, -223.17162690285727, 97.2607356888806, -318.5823328375305, -180.32052575202715, -356.56193357502383, -405.9033841325004, -217.96632341041504, 508.5288255790155, 231.98554476508838, 422.8851958850222, -353.0782867683546, -416.76458943271797, -252.099852381556, -404.3163567031536, -590.1723290879486, -526.671416165201, -318.7605542317746, -277.1979604196247, -607.9293053545404, -446.2681199146832, 495.42670801084824, -626.3114196666143, 705.6321941952556, -228.22262945960742, 750.0766563979603, -312.90883162441907, 29.734058166179196, -267.43231050741775, 80.1904675397229, -28.455770789816846, 113.33200697642408, -303.4628843485177, 141.28969792180854, -82.08104853609942, 275.3672627809204, 411.5423830836357, 295.2798936559906, 18.97629149231536, 55.443875771550395, -370.9240524532467, -425.7829745605469, -225.98580040947624, -673.277112354036, -416.156727774167, -167.95538332169966, -587.3962029822396, -347.8283874844188, -459.0834662025336, -377.60402752002005, -631.9413320640971, 490.2950921267062, -135.57038098337657, 541.0883047364116, -114.8093881357835, 569.1229632150823, -114.12779152888164, 345.1576321897646, -571.2716389112796, 375.7394171019784, -24.97206989261175, -13.562166501094616, -379.591094540578, 600.32603561053, -96.21120706250743, 180.345222986509, -172.70112796935206, 56.503285742751345, -109.77529449604195, 18.357079837774148, -169.5718422405639, -367.7525823550596, -151.64774979483963, 466.5537013101614, -474.29747897373386, -132.13298971567934, -478.42837639462743, -156.98580934795402, -417.55263860052963, -597.2946043661378, -544.325827797472, -491.72717102142633, -486.05236813219574, -368.7394148258272, -309.87701318856875, -444.452504158899, -85.87695657560607], "episode_lengths": [122, 113, 120, 120, 122, 118, 73, 97, 126, 138, 126, 120, 131, 102, 112, 117, 118, 116, 115, 114, 53, 149, 126, 227, 118, 118, 113, 124, 119, 107, 120, 105, 122, 124, 123, 113, 130, 129, 132, 121, 109, 100, 102, 113, 123, 117, 127, 119, 124, 152, 130, 125, 171, 100, 116, 140, 110, 116, 127, 131, 121, 109, 113, 114, 132, 149, 149, 103, 118, 117, 140, 111, 159, 101, 114, 100, 127, 117, 113, 112, 111, 111, 133, 40, 117, 114, 120, 130, 114, 114, 103, 116, 104, 110, 106, 57, 110, 102, 109, 135], "policy_AGENT-3_reward": [148.55545696007857, -216.51106127336655, 160.6737889697016, -225.87225045962066, 189.56659433116386, -18.1932623286026, 29.03784736791504, -44.43142974387718, 209.55436696664938, -84.1857801282511, 96.14328944167335, -57.72791028641584, 226.8968146368183, -141.30628247996782, -46.258390874130576, 30.947850782998273, -51.276250787944505, -73.24761066267203, -100.06693535085496, -111.23128608545927, -17.081942737812305, 149.58321968905642, 70.00802576005655, -30.168384721908016, -80.50060517180263, -92.5443167444534, -73.05180871367467, -66.06778701098496, -103.913342394701, -131.53532354126975, -72.38993372006175, -20.384771001795546, -118.86318250298682, -92.69658153026433, 151.81832588792227, -186.99164635178062, 172.06147385028208, -97.16322551603776, 188.21415243788257, -88.76206941179626, -2.960372033796366, -84.85668020558676, 4.863478064648688, -19.048227056542054, 22.01343227246187, -12.640875465383873, 28.900463200023136, -21.69438958579499, 98.08555374887814, -11.517871723375336, 90.19408547708264, -30.317212430282687, -73.65522250851684, -80.56828808236239, -100.23054811381772, 13.392539425313162, -121.17938976178584, -75.52655571559072, -67.59699642449142, -148.61743413969378, -82.0507906839443, -114.7800150034425, -86.30533687831888, -185.58954405296964, 151.21126717235276, -79.39843520710446, 155.8124798331963, -30.111260840089464, 170.60399363089738, -30.683749324969522, 114.04367081746327, -152.25233918010343, 123.12051022339006, -6.347402426632341, -11.55571224163039, -113.88721967895434, 183.20603676148835, -13.541042697767878, 70.3342296776805, -23.349868549089734, -9.874464923389823, -19.53229835386476, -35.98992638964758, -11.47515979376469, -138.5175198038486, -18.084584773035033, 107.74160165527078, -91.53223138092879, 59.59167908021605, -105.08041144870658, -0.04645511801230806, -113.05053078822107, -111.37028187011673, -97.95197465845112, -129.89396703288196, -121.5246330164303, -95.50119035065613, -73.12103643547036, -111.34332101586828, 72.43109033870427], "policy_AGENT-0_reward": [143.1815977613901, -185.31074048817877, 126.33847497048333, -262.276991270041, 161.35329191555374, -92.63630803828191, 76.10830888114752, 53.69121536805307, 175.8912583345616, -47.34556529047937, 60.46918060201595, -101.76043153397748, 208.41529057716463, -84.04597889840008, -54.85006898923133, -4.830157889278709, -131.51488513728938, -110.09166060840121, -78.24171630441835, -153.50991773220403, -91.98112447857852, 83.090399987215, 38.19112613267449, 225.48488015954155, -119.69581334186506, -138.58548319497666, -41.76385710746166, -105.01571588519843, -214.32925781574926, -133.4154205056504, -110.71631379659388, -96.9194562640652, -170.74520243621367, -62.64822958218419, 86.00921515330725, -230.85780165533748, 180.3553711589517, -36.40378931859584, 182.5235666104393, -89.69687434845531, 39.22172036989234, -60.34082102486679, 24.369885860935568, 4.632940652199142, -12.092014473676755, -161.9132073890025, 20.866948177670622, -18.501020136799315, 15.991429645812474, 211.5916279914266, 26.47096127405097, 37.76443885892522, 119.12638868446481, -80.28872027168518, -72.15346975042925, -18.4398283639083, -167.11020753180827, -115.63189657180975, -11.011956629157886, -124.52171414697375, -116.81729781056947, -102.4369816046159, -126.34280810025228, -229.43342144914828, 93.5668496140309, -6.337899009467947, 114.45051064483681, -30.16897260449693, 135.46537775279654, -48.7540120393738, 59.9749121783613, -195.7332660545098, 67.21095246411946, -8.48298452450476, -51.628585509197414, -76.24177681829299, 111.71609866445112, -33.86424300706645, -9.493349154206491, -52.751108940151326, 17.729201164301344, -35.34635439897829, -0.050459427938609025, -73.31971895758204, -176.75734652834723, -82.47282154405232, 88.99987260352479, -128.66732480867566, 19.814298629716646, -154.33005247827134, -91.03531728306615, -132.7132131064836, -162.46488583688105, -148.8395105000654, -117.13227647418942, -121.50502517531335, -88.79265524577139, -95.6307374235404, -111.1259555608741, 39.07364436118677], "policy_AGENT-1_reward": [189.30791706705332, -92.08163678214021, 129.62361300275649, -86.76968382611854, 161.71221791289395, -5.886742593937164, 76.03088901047614, 81.54213218271435, 179.70890892765445, -83.61981644974523, 104.54074792808689, -25.735294385583718, 239.0158180000889, -156.6471556134187, -75.98613047738692, 35.790223691874615, -84.67307642846909, 1.8075562663441715, -78.28976854722534, -110.48169969184205, -91.93929054593082, 162.22007411903726, 42.602361628907026, 257.8015200680026, -75.1398163547752, -92.59598737400395, -67.9559922230798, -116.2984709284747, -103.34914898121426, -127.75089598930583, -66.02464060545314, -96.85229904699464, -118.29639661390743, -145.10003254956982, 134.02615344772278, -103.99343861616472, 181.32817014114536, -96.59698372983027, 190.99357775332862, -88.19793092274546, 39.27370162629704, -60.64537839463574, 24.429592019532937, 5.057412585530217, 51.943975654775876, -116.37096472312035, 29.46227522810517, -20.438116375436433, 104.39523758238784, 222.87899745711863, 113.42446742670757, 41.85438805454805, 83.43683573574138, -129.21570922107048, -126.41697190442788, -110.24990743264266, -217.13406603691902, -112.28360134872877, -42.608900323621555, -146.70215958109313, -73.86003139430541, -114.21375270604683, -82.04589094865982, -108.24387592365017, 137.14548422504006, -78.83467940370528, 153.16013488337398, -23.79859918300957, 135.53867779079658, -29.882690160619983, 99.22959596365362, -111.32802178275696, 100.81203375269885, -1.101130390137408, 25.02845534701931, -76.17941101531525, 157.93273485192023, -35.42373058819929, 82.07371510531172, -73.3771783904977, 24.548315717860447, -35.44185367929326, 27.464326588438723, -73.30572466345023, -25.986472594996993, -32.952618518409956, 136.44866533443462, -126.74179871160318, -105.55468050376146, -109.18896627429689, -90.91828183929482, -86.38491037925579, -160.43258110549564, -148.13746920660708, -127.01236668890793, -120.96563767773503, -94.93549726500969, -44.92738593432347, -111.17278840331113, -98.44810000540042], "policy_AGENT-2_reward": [175.50077001304265, -92.71850086499884, 122.79772296063621, -87.29574103500039, 153.10598375826578, -46.328433653781545, 29.01333348687492, -44.39022144210004, 174.43284924469873, -9.26063054844527, 100.52363489526195, -26.16187571506783, 229.2333457980755, -157.29722623280233, -46.07703656210843, 35.3528191032863, -51.11812048382744, 1.2111892527017787, -99.96351337252514, -30.6804806229946, -16.9639656480934, 113.6351317837071, 81.18403124345025, -30.23281962061389, -77.74205189991157, -93.03880211928437, -69.32819433734, -116.93438287849558, -168.58057989628364, -133.96977612897507, -69.62966610966585, -63.041434106769216, -200.02452380143225, -145.82327625266495, 123.5730135218959, -104.46853304333155, 171.887179044877, 1.9413691048563528, 188.34535959630944, -46.251956941421824, -45.80099179621379, -61.589430882328216, 26.527511594605805, -19.09789697100414, 51.46661352286308, -12.53783677101101, 62.060011316009785, -21.44752243806858, 56.895041803842055, -11.41037064153458, 65.1903794781492, -30.32532299087527, -73.46412614013893, -80.85133487812898, -126.9819847918718, -110.6886040382384, -167.85344902352287, -112.71467413803751, -46.73752994442864, -167.55489511447854, -75.10026759560007, -127.65271688842829, -82.9099915927893, -108.67449063832879, 108.3714911152824, 29.000632636901067, 117.66517937500447, -30.730555508187315, 127.51491404059126, -4.807340003918561, 71.90945323028691, -111.95801189390903, 84.59592066177012, -9.040552551337399, 24.593675902713876, -113.2826870280156, 147.4711653326697, -13.382190769473786, 37.43062735772314, -23.222972089613357, 24.100233783979412, -19.454788063905678, 26.933139066921512, -11.471238825766928, -26.491243427866713, -18.13772495934228, 133.36356171693112, -127.356124072526, -105.98428692185061, -109.82894619335285, 25.014244892419352, -85.40398432656933, -163.02685555364428, -149.3968734323481, -117.68856082544703, -122.05707226271707, -89.51007196439016, -96.19785339523492, -110.81043917884583, -98.9335912700966]}, "sampler_perf": {"mean_env_wait_ms": 60.737426918146866, "mean_raw_obs_processing_ms": 2.5812604308693063, "mean_inference_ms": 2.5772639143962395, "mean_action_processing_ms": 0.1563578383740929}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 163800, "timers": {"sample_time_ms": 95384.724, "sample_throughput": 44.032, "load_time_ms": 15.825, "load_throughput": 265405.486, "learn_time_ms": 8637.924, "learn_throughput": 486.228, "update_time_ms": 8.304}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 19.278226852416992, "policy_loss": -0.026528147980570793, "vf_loss": 19.293962478637695, "vf_explained_var": 0.9802370071411133, "kl": 0.015990614891052246, "entropy": 1.094177007675171, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 18.5401554107666, "policy_loss": -0.024367300793528557, "vf_loss": 18.557483673095703, "vf_explained_var": 0.9778878092765808, "kl": 0.015642767772078514, "entropy": 0.9115519523620605, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 20.37342643737793, "policy_loss": -0.035103801637887955, "vf_loss": 20.398969650268555, "vf_explained_var": 0.9764244556427002, "kl": 0.014161467552185059, "entropy": 1.1448490619659424, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 19.25776481628418, "policy_loss": -0.0277178343385458, "vf_loss": 19.276655197143555, "vf_explained_var": 0.9792673587799072, "kl": 0.013078196905553341, "entropy": 0.9769566059112549, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 163800, "num_steps_trained": 163800}, "done": false, "episodes_total": 1389, "training_iteration": 39, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-28-31", "timestamp": 1624213711, "time_this_iter_s": 90.878897190094, "time_total_s": 4294.244247913361, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd39406a680>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd3940859e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd394085a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd050>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420e830>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd394085a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd050>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420e830>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd394085a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd050>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420e830>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd394085a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4042bdef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4042bd050>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420e830>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd3847dab90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4294.244247913361, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 57.875572519083974, "ram_util_percent": 87.4358778625954}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 903.5612690121474, "episode_reward_min": -662.2146665907806, "episode_reward_mean": -51.5111111718794, "episode_len_mean": 123.36, "episodes_this_iter": 31, "policy_reward_min": {"AGENT-3": -225.87225045962066, "AGENT-0": -262.276991270041, "AGENT-2": -200.02452380143225, "AGENT-1": -207.13993192803846}, "policy_reward_max": {"AGENT-3": 226.8968146368183, "AGENT-0": 225.48488015954155, "AGENT-2": 229.2333457980755, "AGENT-1": 257.8015200680026}, "policy_reward_mean": {"AGENT-3": -12.202857277231374, "AGENT-0": -22.955847941076883, "AGENT-2": -16.431224418885048, "AGENT-1": 0.0788184653139058}, "custom_metrics": {"mean_ego_speed_mean": 42.924817499999996, "mean_ego_speed_min": 27.61175, "mean_ego_speed_max": 52.0, "distance_travelled_mean": 102.79289, "distance_travelled_min": 38.22925, "distance_travelled_max": 124.84424999999999}, "hist_stats": {"episode_reward": [218.8254248998766, 796.6119250292522, 94.11306521005746, 30.044590143090694, -31.22082516078458, 707.602588895507, 171.92562472712962, 492.1417676148471, 152.14944118812872, 421.59145279266494, 520.1655568922768, -328.44371769541493, 504.1535832604292, -413.52843317786096, 572.9544433840817, -305.02197356474716, -173.57739013035695, -470.61964499861926, -231.48346144121496, -158.21160802014805, 337.543644780183, -304.8741324674517, 309.3023815663084, -586.1308851776424, -631.1306002962348, 253.26729256168545, 193.02667685122333, 317.0572780740319, -541.6815030045169, 281.34230791927496, -193.9572578217813, -135.57038098337657, 541.0883047364116, -114.8093881357835, 569.1229632150823, -114.12779152888164, 345.1576321897646, -571.2716389112796, 375.7394171019784, -24.97206989261175, -13.562166501094616, -379.591094540578, 600.32603561053, -96.21120706250743, 180.345222986509, -172.70112796935206, 56.503285742751345, -109.77529449604195, 18.357079837774148, -169.5718422405639, -367.7525823550596, -151.64774979483963, 466.5537013101614, -474.29747897373386, -132.13298971567934, -478.42837639462743, -156.98580934795402, -417.55263860052963, -597.2946043661378, -544.325827797472, -491.72717102142633, -486.05236813219574, -368.7394148258272, -309.87701318856875, -444.452504158899, -85.87695657560607, 656.5457418015651, -586.6219394086845, 539.4335999035774, -662.2146665907806, 665.7380879178779, -163.0447466146031, 210.19037874641376, 46.41169636479024, 739.5873834735652, -224.41179241692106, 361.6768528670379, -211.38551192104487, 903.5612690121474, -539.2966432245889, -223.17162690285727, 97.2607356888806, -318.5823328375305, -180.32052575202715, -356.56193357502383, -405.9033841325004, -217.96632341041504, 508.5288255790155, 231.98554476508838, 422.8851958850222, -353.0782867683546, -416.76458943271797, -252.099852381556, -404.3163567031536, -590.1723290879486, -526.671416165201, -318.7605542317746, -277.1979604196247, -607.9293053545404, -446.2681199146832], "episode_lengths": [218, 126, 116, 215, 101, 134, 217, 123, 126, 106, 120, 110, 104, 124, 121, 125, 120, 128, 114, 121, 116, 97, 218, 119, 118, 143, 204, 181, 109, 200, 131, 149, 149, 103, 118, 117, 140, 111, 159, 101, 114, 100, 127, 117, 113, 112, 111, 111, 133, 40, 117, 114, 120, 130, 114, 114, 103, 116, 104, 110, 106, 57, 110, 102, 109, 135, 122, 113, 120, 120, 122, 118, 73, 97, 126, 138, 126, 120, 131, 102, 112, 117, 118, 116, 115, 114, 53, 149, 126, 227, 118, 118, 113, 124, 119, 107, 120, 105, 122, 124], "policy_AGENT-3_reward": [-41.7526078879905, 205.69724896947417, 53.6047536058212, -25.608149807988855, -9.169769942200167, 212.96801263409782, -43.48495966259114, 102.33325769195275, 24.811855900032267, 113.09710300883982, 117.04572057084337, -88.99483212411694, 140.11819435442467, -13.28787980999821, 156.5305403129733, -25.667051054884777, -61.90760812793448, -52.44987126689723, -91.85537712436778, -22.435853154421345, 93.99879353162343, -99.65071498587723, -50.282795565674895, -140.9121116320312, -116.7613570777065, 211.81467789469534, -57.509369362581275, -45.99521330666387, -123.38779280520625, -41.145182514359036, -53.37648835632835, -79.39843520710446, 155.8124798331963, -30.111260840089464, 170.60399363089738, -30.683749324969522, 114.04367081746327, -152.25233918010343, 123.12051022339006, -6.347402426632341, -11.55571224163039, -113.88721967895434, 183.20603676148835, -13.541042697767878, 70.3342296776805, -23.349868549089734, -9.874464923389823, -19.53229835386476, -35.98992638964758, -11.47515979376469, -138.5175198038486, -18.084584773035033, 107.74160165527078, -91.53223138092879, 59.59167908021605, -105.08041144870658, -0.04645511801230806, -113.05053078822107, -111.37028187011673, -97.95197465845112, -129.89396703288196, -121.5246330164303, -95.50119035065613, -73.12103643547036, -111.34332101586828, 72.43109033870427, 148.55545696007857, -216.51106127336655, 160.6737889697016, -225.87225045962066, 189.56659433116386, -18.1932623286026, 29.03784736791504, -44.43142974387718, 209.55436696664938, -84.1857801282511, 96.14328944167335, -57.72791028641584, 226.8968146368183, -141.30628247996782, -46.258390874130576, 30.947850782998273, -51.276250787944505, -73.24761066267203, -100.06693535085496, -111.23128608545927, -17.081942737812305, 149.58321968905642, 70.00802576005655, -30.168384721908016, -80.50060517180263, -92.5443167444534, -73.05180871367467, -66.06778701098496, -103.913342394701, -131.53532354126975, -72.38993372006175, -20.384771001795546, -118.86318250298682, -92.69658153026433], "policy_AGENT-0_reward": [133.92914496491434, 173.45276254078257, 16.328686914579578, 22.782122475553088, -46.156891000307134, 60.93201079186358, 119.23242466578677, 105.68391394600238, 24.119981004042614, 120.82147446892579, 106.60328195923115, -63.778469348082666, 136.07782513548793, -179.7025992327313, 94.66894149460705, -112.5333639568813, -90.9455861686412, -203.55811513193825, -131.78686902922794, -56.734422665981626, 51.339765817483716, -63.5588610487757, 188.15309870279546, -135.33903199566248, -218.49062722792326, 177.4555596752981, 137.59474003558992, 190.65486017302595, -134.67766120247958, 167.42030641117046, -66.35294142927535, -6.337899009467947, 114.45051064483681, -30.16897260449693, 135.46537775279654, -48.7540120393738, 59.9749121783613, -195.7332660545098, 67.21095246411946, -8.48298452450476, -51.628585509197414, -76.24177681829299, 111.71609866445112, -33.86424300706645, -9.493349154206491, -52.751108940151326, 17.729201164301344, -35.34635439897829, -0.050459427938609025, -73.31971895758204, -176.75734652834723, -82.47282154405232, 88.99987260352479, -128.66732480867566, 19.814298629716646, -154.33005247827134, -91.03531728306615, -132.7132131064836, -162.46488583688105, -148.8395105000654, -117.13227647418942, -121.50502517531335, -88.79265524577139, -95.6307374235404, -111.1259555608741, 39.07364436118677, 143.1815977613901, -185.31074048817877, 126.33847497048333, -262.276991270041, 161.35329191555374, -92.63630803828191, 76.10830888114752, 53.69121536805307, 175.8912583345616, -47.34556529047937, 60.46918060201595, -101.76043153397748, 208.41529057716463, -84.04597889840008, -54.85006898923133, -4.830157889278709, -131.51488513728938, -110.09166060840121, -78.24171630441835, -153.50991773220403, -91.98112447857852, 83.090399987215, 38.19112613267449, 225.48488015954155, -119.69581334186506, -138.58548319497666, -41.76385710746166, -105.01571588519843, -214.32925781574926, -133.4154205056504, -110.71631379659388, -96.9194562640652, -170.74520243621367, -62.64822958218419], "policy_AGENT-2_reward": [-41.768448392939824, 202.06043748482438, -36.38432725786174, -25.422594726013674, 22.484576584480738, 209.99221612771757, -43.39356362983787, 134.0475355758632, 68.09611973568923, 67.16860560109768, 148.08396254446455, -88.2345091301676, 92.09703280697443, -13.398022207092916, 136.29890864058103, -25.721111595635218, -10.578173704224369, -52.41544419498042, -4.184854738281409, -22.381298071323073, 94.82947121154895, -77.9036041597917, -50.21020147256762, -159.34949758463878, -179.6842461295457, -68.2784029636357, -57.556619379049806, -45.868076069464486, -160.7924303014318, -41.07541202342128, -44.48881215621392, 29.000632636901067, 117.66517937500447, -30.730555508187315, 127.51491404059126, -4.807340003918561, 71.90945323028691, -111.95801189390903, 84.59592066177012, -9.040552551337399, 24.593675902713876, -113.2826870280156, 147.4711653326697, -13.382190769473786, 37.43062735772314, -23.222972089613357, 24.100233783979412, -19.454788063905678, 26.933139066921512, -11.471238825766928, -26.491243427866713, -18.13772495934228, 133.36356171693112, -127.356124072526, -105.98428692185061, -109.82894619335285, 25.014244892419352, -85.40398432656933, -163.02685555364428, -149.3968734323481, -117.68856082544703, -122.05707226271707, -89.51007196439016, -96.19785339523492, -110.81043917884583, -98.9335912700966, 175.50077001304265, -92.71850086499884, 122.79772296063621, -87.29574103500039, 153.10598375826578, -46.328433653781545, 29.01333348687492, -44.39022144210004, 174.43284924469873, -9.26063054844527, 100.52363489526195, -26.16187571506783, 229.2333457980755, -157.29722623280233, -46.07703656210843, 35.3528191032863, -51.11812048382744, 1.2111892527017787, -99.96351337252514, -30.6804806229946, -16.9639656480934, 113.6351317837071, 81.18403124345025, -30.23281962061389, -77.74205189991157, -93.03880211928437, -69.32819433734, -116.93438287849558, -168.58057989628364, -133.96977612897507, -69.62966610966585, -63.041434106769216, -200.02452380143225, -145.82327625266495], "policy_AGENT-1_reward": [168.41733621589296, 215.40147603417108, 60.563951947518404, 58.29321220154003, 1.6212591972423034, 223.71034934182777, 139.57172335377197, 150.07706040102906, 35.121484548364705, 120.50426971380145, 148.43259181773752, -87.43590709304745, 135.86053096354263, -207.13993192803846, 185.4560529359204, -141.100446957346, -10.14602212955684, -162.19621440480338, -3.6563605493376627, -56.660034128421906, 97.37561421952691, -63.7609522730073, 221.64227990175564, -150.53024396530918, -116.19436986105933, -67.72454204467239, 170.4979255572646, 218.26570727713448, -122.82361869539915, 196.14259604588483, -29.739015879963937, -78.83467940370528, 153.16013488337398, -23.79859918300957, 135.53867779079658, -29.882690160619983, 99.22959596365362, -111.32802178275696, 100.81203375269885, -1.101130390137408, 25.02845534701931, -76.17941101531525, 157.93273485192023, -35.42373058819929, 82.07371510531172, -73.3771783904977, 24.548315717860447, -35.44185367929326, 27.464326588438723, -73.30572466345023, -25.986472594996993, -32.952618518409956, 136.44866533443462, -126.74179871160318, -105.55468050376146, -109.18896627429689, -90.91828183929482, -86.38491037925579, -160.43258110549564, -148.13746920660708, -127.01236668890793, -120.96563767773503, -94.93549726500969, -44.92738593432347, -111.17278840331113, -98.44810000540042, 189.30791706705332, -92.08163678214021, 129.62361300275649, -86.76968382611854, 161.71221791289395, -5.886742593937164, 76.03088901047614, 81.54213218271435, 179.70890892765445, -83.61981644974523, 104.54074792808689, -25.735294385583718, 239.0158180000889, -156.6471556134187, -75.98613047738692, 35.790223691874615, -84.67307642846909, 1.8075562663441715, -78.28976854722534, -110.48169969184205, -91.93929054593082, 162.22007411903726, 42.602361628907026, 257.8015200680026, -75.1398163547752, -92.59598737400395, -67.9559922230798, -116.2984709284747, -103.34914898121426, -127.75089598930583, -66.02464060545314, -96.85229904699464, -118.29639661390743, -145.10003254956982]}, "sampler_perf": {"mean_env_wait_ms": 60.475578642903116, "mean_raw_obs_processing_ms": 2.5731746166689784, "mean_inference_ms": 2.567277338857772, "mean_action_processing_ms": 0.1558086850856126}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 168000, "timers": {"sample_time_ms": 87158.72, "sample_throughput": 48.188, "load_time_ms": 15.605, "load_throughput": 269146.618, "learn_time_ms": 8556.268, "learn_throughput": 490.868, "update_time_ms": 8.27}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 19.55843734741211, "policy_loss": -0.027017943561077118, "vf_loss": 19.574949264526367, "vf_explained_var": 0.980302095413208, "kl": 0.015565766952931881, "entropy": 1.0583316087722778, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 15.096776008605957, "policy_loss": -0.020826205611228943, "vf_loss": 15.108901977539062, "vf_explained_var": 0.9840474128723145, "kl": 0.019331807270646095, "entropy": 0.9314233660697937, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 20.39385223388672, "policy_loss": -0.044359467923641205, "vf_loss": 20.42975616455078, "vf_explained_var": 0.9766255617141724, "kl": 0.012528586201369762, "entropy": 1.1431366205215454, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 24.078657150268555, "policy_loss": -0.035632092505693436, "vf_loss": 24.106897354125977, "vf_explained_var": 0.9756969213485718, "kl": 0.010947118513286114, "entropy": 1.001456379890442, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 168000, "num_steps_trained": 168000}, "done": false, "episodes_total": 1420, "training_iteration": 40, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-29-56", "timestamp": 1624213796, "time_this_iter_s": 84.15685677528381, "time_total_s": 4378.401104688644, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd3847384d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd3847383b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd384738170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd384738050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd384738830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd384738950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd384738170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd384738050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd384738830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd384738950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd384738170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd384738050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd384738830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd384738950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd384738170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd384738050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd384738830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd384738950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd3847385f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4378.401104688644, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 54.644999999999996, "ram_util_percent": 87.24500000000003}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 937.5732584780567, "episode_reward_min": -662.2146665907806, "episode_reward_mean": -17.603068476016997, "episode_len_mean": 128.4, "episodes_this_iter": 33, "policy_reward_min": {"AGENT-3": -225.87225045962066, "AGENT-0": -262.276991270041, "AGENT-2": -200.02452380143225, "AGENT-1": -207.13993192803846}, "policy_reward_max": {"AGENT-3": 231.24332044597375, "AGENT-0": 230.83018401525388, "AGENT-2": 248.40472685470883, "AGENT-1": 257.8015200680026}, "policy_reward_mean": {"AGENT-3": -9.378419264420113, "AGENT-0": -8.310158725537466, "AGENT-2": -10.89916345379716, "AGENT-1": 10.98467296773777}, "custom_metrics": {"mean_ego_speed_mean": 42.6926225, "mean_ego_speed_min": 27.48975, "mean_ego_speed_max": 52.0, "distance_travelled_mean": 101.143615, "distance_travelled_min": 40.544, "distance_travelled_max": 124.81600000000002}, "hist_stats": {"episode_reward": [234.17285109730986, 722.0263885674633, -334.6523681376005, 693.498126594914, -490.73285359378394, 937.5732584780567, -137.25583275122852, 861.3818017644094, -269.22210050446444, 915.4329956007334, -560.3580427095573, 354.37435560942316, -203.14363780146925, -427.78185877064055, -188.93582303865097, 292.6668576950676, -114.44901643378697, -269.53379676383963, -243.24425735198415, -169.0995425519218, 337.58722025177883, -150.57436884465235, -405.78521671089175, -579.7399566764162, -345.4881027275384, 247.72937655813158, -258.71230007382377, 94.17484801333849, -201.52650436658672, 160.64206737187544, -318.8228980105044, -168.70564112450026, -348.4761431175797, -444.452504158899, -85.87695657560607, 656.5457418015651, -586.6219394086845, 539.4335999035774, -662.2146665907806, 665.7380879178779, -163.0447466146031, 210.19037874641376, 46.41169636479024, 739.5873834735652, -224.41179241692106, 361.6768528670379, -211.38551192104487, 903.5612690121474, -539.2966432245889, -223.17162690285727, 97.2607356888806, -318.5823328375305, -180.32052575202715, -356.56193357502383, -405.9033841325004, -217.96632341041504, 508.5288255790155, 231.98554476508838, 422.8851958850222, -353.0782867683546, -416.76458943271797, -252.099852381556, -404.3163567031536, -590.1723290879486, -526.671416165201, -318.7605542317746, -277.1979604196247, -607.9293053545404, -446.2681199146832, 218.8254248998766, 796.6119250292522, 94.11306521005746, 30.044590143090694, -31.22082516078458, 707.602588895507, 171.92562472712962, 492.1417676148471, 152.14944118812872, 421.59145279266494, 520.1655568922768, -328.44371769541493, 504.1535832604292, -413.52843317786096, 572.9544433840817, -305.02197356474716, -173.57739013035695, -470.61964499861926, -231.48346144121496, -158.21160802014805, 337.543644780183, -304.8741324674517, 309.3023815663084, -586.1308851776424, -631.1306002962348, 253.26729256168545, 193.02667685122333, 317.0572780740319, -541.6815030045169, 281.34230791927496, -193.9572578217813], "episode_lengths": [178, 129, 120, 122, 102, 140, 147, 131, 125, 125, 110, 117, 117, 120, 123, 129, 105, 120, 134, 40, 160, 115, 114, 135, 120, 243, 157, 112, 117, 188, 116, 130, 105, 109, 135, 122, 113, 120, 120, 122, 118, 73, 97, 126, 138, 126, 120, 131, 102, 112, 117, 118, 116, 115, 114, 53, 149, 126, 227, 118, 118, 113, 124, 119, 107, 120, 105, 122, 124, 218, 126, 116, 215, 101, 134, 217, 123, 126, 106, 120, 110, 104, 124, 121, 125, 120, 128, 114, 121, 116, 97, 218, 119, 118, 143, 204, 181, 109, 200, 131], "policy_AGENT-3_reward": [-47.53210395823314, 209.90778115505074, -96.50255355809487, 194.25813302440116, -128.10608549550327, 226.04968440076894, -91.70579025419565, 231.24332044597375, -110.21563025405952, 219.3054541996959, -199.79640349144293, 113.51541290570869, -38.52480293596674, -32.44897425692949, -25.212534821439515, 111.31596427969392, 19.443050316987815, -34.51812639222742, -63.03453733322326, -14.915010974226456, 30.94745771071774, -36.37634443934391, -189.1133801799986, -97.10183393043229, -80.04140575309766, -39.04373488183022, 11.629472789627266, -41.864287059118844, -56.19378545171718, -56.6611773116828, -71.23709772114906, -101.60696230145187, -82.63886179630022, -111.34332101586828, 72.43109033870427, 148.55545696007857, -216.51106127336655, 160.6737889697016, -225.87225045962066, 189.56659433116386, -18.1932623286026, 29.03784736791504, -44.43142974387718, 209.55436696664938, -84.1857801282511, 96.14328944167335, -57.72791028641584, 226.8968146368183, -141.30628247996782, -46.258390874130576, 30.947850782998273, -51.276250787944505, -73.24761066267203, -100.06693535085496, -111.23128608545927, -17.081942737812305, 149.58321968905642, 70.00802576005655, -30.168384721908016, -80.50060517180263, -92.5443167444534, -73.05180871367467, -66.06778701098496, -103.913342394701, -131.53532354126975, -72.38993372006175, -20.384771001795546, -118.86318250298682, -92.69658153026433, -41.7526078879905, 205.69724896947417, 53.6047536058212, -25.608149807988855, -9.169769942200167, 212.96801263409782, -43.48495966259114, 102.33325769195275, 24.811855900032267, 113.09710300883982, 117.04572057084337, -88.99483212411694, 140.11819435442467, -13.28787980999821, 156.5305403129733, -25.667051054884777, -61.90760812793448, -52.44987126689723, -91.85537712436778, -22.435853154421345, 93.99879353162343, -99.65071498587723, -50.282795565674895, -140.9121116320312, -116.7613570777065, 211.81467789469534, -57.509369362581275, -45.99521330666387, -123.38779280520625, -41.145182514359036, -53.37648835632835], "policy_AGENT-0_reward": [181.9674512860054, 165.55362107692446, -92.11921642997007, 168.0338395156622, -94.17356013912261, 228.2151123210937, 6.802425321237237, 206.5344460272394, -44.418899700860806, 230.83018401525388, -170.72912548326528, 81.66169522325136, -87.48288510006311, -202.6352891330733, -92.3962717323889, 45.812056841334844, -30.225402160249914, -124.6604896836564, -88.4618665815192, -69.60239561813489, 122.36488253461964, -38.86606774729697, -158.35029867537486, -132.89974007501294, -115.5730051856872, 146.29733991272187, -18.12448194198491, 80.86610951500701, -80.08398717256826, 121.88875706183649, -112.36949393844591, -3.5567587228803106, -72.68243662500613, -111.1259555608741, 39.07364436118677, 143.1815977613901, -185.31074048817877, 126.33847497048333, -262.276991270041, 161.35329191555374, -92.63630803828191, 76.10830888114752, 53.69121536805307, 175.8912583345616, -47.34556529047937, 60.46918060201595, -101.76043153397748, 208.41529057716463, -84.04597889840008, -54.85006898923133, -4.830157889278709, -131.51488513728938, -110.09166060840121, -78.24171630441835, -153.50991773220403, -91.98112447857852, 83.090399987215, 38.19112613267449, 225.48488015954155, -119.69581334186506, -138.58548319497666, -41.76385710746166, -105.01571588519843, -214.32925781574926, -133.4154205056504, -110.71631379659388, -96.9194562640652, -170.74520243621367, -62.64822958218419, 133.92914496491434, 173.45276254078257, 16.328686914579578, 22.782122475553088, -46.156891000307134, 60.93201079186358, 119.23242466578677, 105.68391394600238, 24.119981004042614, 120.82147446892579, 106.60328195923115, -63.778469348082666, 136.07782513548793, -179.7025992327313, 94.66894149460705, -112.5333639568813, -90.9455861686412, -203.55811513193825, -131.78686902922794, -56.734422665981626, 51.339765817483716, -63.5588610487757, 188.15309870279546, -135.33903199566248, -218.49062722792326, 177.4555596752981, 137.59474003558992, 190.65486017302595, -134.67766120247958, 167.42030641117046, -66.35294142927535], "policy_AGENT-2_reward": [-47.53051215234639, 175.02758349524242, -50.09119852647387, 161.53023791898028, -174.34139791134837, 248.40472685470883, 38.7885665003857, 213.18766267776297, -4.937573217364719, 227.2716618913897, -95.13895525502804, 76.97315677115007, -38.442320646133005, -32.39054619801793, -25.254682508799505, 84.10361667075809, -73.28442193713502, -34.52744848937385, -29.27640062438181, -14.862664381263048, 152.7680811477966, -36.43415496292397, -29.378154840147026, -175.1242734841305, -75.70630906853518, -39.08469492550777, -126.32588731679752, -41.832724278608396, -32.33718351030926, -56.566981371207156, -68.99313807839142, -101.58038864663882, -120.24437116002804, -110.81043917884583, -98.9335912700966, 175.50077001304265, -92.71850086499884, 122.79772296063621, -87.29574103500039, 153.10598375826578, -46.328433653781545, 29.01333348687492, -44.39022144210004, 174.43284924469873, -9.26063054844527, 100.52363489526195, -26.16187571506783, 229.2333457980755, -157.29722623280233, -46.07703656210843, 35.3528191032863, -51.11812048382744, 1.2111892527017787, -99.96351337252514, -30.6804806229946, -16.9639656480934, 113.6351317837071, 81.18403124345025, -30.23281962061389, -77.74205189991157, -93.03880211928437, -69.32819433734, -116.93438287849558, -168.58057989628364, -133.96977612897507, -69.62966610966585, -63.041434106769216, -200.02452380143225, -145.82327625266495, -41.768448392939824, 202.06043748482438, -36.38432725786174, -25.422594726013674, 22.484576584480738, 209.99221612771757, -43.39356362983787, 134.0475355758632, 68.09611973568923, 67.16860560109768, 148.08396254446455, -88.2345091301676, 92.09703280697443, -13.398022207092916, 136.29890864058103, -25.721111595635218, -10.578173704224369, -52.41544419498042, -4.184854738281409, -22.381298071323073, 94.82947121154895, -77.9036041597917, -50.21020147256762, -159.34949758463878, -179.6842461295457, -68.2784029636357, -57.556619379049806, -45.868076069464486, -160.7924303014318, -41.07541202342128, -44.48881215621392], "policy_AGENT-1_reward": [147.26801592188392, 171.53740284024585, -95.93939962306146, 169.67591613587027, -94.11181004780985, 234.9037349014854, -91.14103431865595, 210.41637261343345, -109.64999733217934, 238.0256954943942, -94.69355847982081, 82.22409070931313, -38.69362911930647, -160.30704918261978, -46.07233397602293, 51.43521990328098, -30.382242653389877, -75.82773219858218, -62.471452812859916, -69.7194715782974, 31.506798858644878, -38.89780169508742, -28.94338301537105, -174.61410918684004, -74.1673827202185, 179.56046645274736, -125.89140360466851, 97.00574983605874, -32.91154823199191, 151.9814689929289, -66.22316827251815, 38.038468546470874, -72.91047353624516, -111.17278840331113, -98.44810000540042, 189.30791706705332, -92.08163678214021, 129.62361300275649, -86.76968382611854, 161.71221791289395, -5.886742593937164, 76.03088901047614, 81.54213218271435, 179.70890892765445, -83.61981644974523, 104.54074792808689, -25.735294385583718, 239.0158180000889, -156.6471556134187, -75.98613047738692, 35.790223691874615, -84.67307642846909, 1.8075562663441715, -78.28976854722534, -110.48169969184205, -91.93929054593082, 162.22007411903726, 42.602361628907026, 257.8015200680026, -75.1398163547752, -92.59598737400395, -67.9559922230798, -116.2984709284747, -103.34914898121426, -127.75089598930583, -66.02464060545314, -96.85229904699464, -118.29639661390743, -145.10003254956982, 168.41733621589296, 215.40147603417108, 60.563951947518404, 58.29321220154003, 1.6212591972423034, 223.71034934182777, 139.57172335377197, 150.07706040102906, 35.121484548364705, 120.50426971380145, 148.43259181773752, -87.43590709304745, 135.86053096354263, -207.13993192803846, 185.4560529359204, -141.100446957346, -10.14602212955684, -162.19621440480338, -3.6563605493376627, -56.660034128421906, 97.37561421952691, -63.7609522730073, 221.64227990175564, -150.53024396530918, -116.19436986105933, -67.72454204467239, 170.4979255572646, 218.26570727713448, -122.82361869539915, 196.14259604588483, -29.739015879963937]}, "sampler_perf": {"mean_env_wait_ms": 60.121152151693614, "mean_raw_obs_processing_ms": 2.560991665354212, "mean_inference_ms": 2.5553468398363015, "mean_action_processing_ms": 0.1551241608226708}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 172200, "timers": {"sample_time_ms": 85437.526, "sample_throughput": 49.159, "load_time_ms": 15.424, "load_throughput": 272301.41, "learn_time_ms": 8473.264, "learn_throughput": 495.677, "update_time_ms": 8.178}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 25.394628524780273, "policy_loss": -0.02451007440686226, "vf_loss": 25.4090633392334, "vf_explained_var": 0.9783586859703064, "kl": 0.01492514368146658, "entropy": 1.0157978534698486, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 21.115825653076172, "policy_loss": -0.02521470934152603, "vf_loss": 21.13503646850586, "vf_explained_var": 0.9787014126777649, "kl": 0.013343525119125843, "entropy": 0.9190171360969543, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 18.660728454589844, "policy_loss": -0.02825768291950226, "vf_loss": 18.677614212036133, "vf_explained_var": 0.9809623956680298, "kl": 0.016850240528583527, "entropy": 1.118995189666748, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 21.88469123840332, "policy_loss": -0.031181761994957924, "vf_loss": 21.907445907592773, "vf_explained_var": 0.9809961318969727, "kl": 0.012483140453696251, "entropy": 1.0161423683166504, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 172200, "num_steps_trained": 172200}, "done": false, "episodes_total": 1453, "training_iteration": 41, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-31-19", "timestamp": 1624213879, "time_this_iter_s": 83.58531045913696, "time_total_s": 4461.986415147781, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40405cc20>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd39406ad40>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd39406aa70>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8b90>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4040b89e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420ef80>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd39406aa70>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8b90>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4040b89e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420ef80>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd39406aa70>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8b90>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4040b89e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420ef80>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd39406aa70>, action_adapter=<function AgentSpec.<lambda> at 0x7fd4040b8b90>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd4040b89e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fd40420ef80>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd384738b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4461.986415147781, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 55.54033613445378, "ram_util_percent": 87.03025210084033}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1100.8325441011893, "episode_reward_min": -631.1306002962348, "episode_reward_mean": -9.759999597472115, "episode_len_mean": 131.78, "episodes_this_iter": 32, "policy_reward_min": {"AGENT-3": -199.79640349144293, "AGENT-0": -218.49062722792326, "AGENT-1": -207.13993192803846, "AGENT-2": -202.33682014572787}, "policy_reward_max": {"AGENT-3": 231.36794812659878, "AGENT-0": 279.7283416149292, "AGENT-1": 291.14860449496734, "AGENT-2": 312.46704560664386}, "policy_reward_mean": {"AGENT-3": -9.312868657528986, "AGENT-0": -4.2829341317683705, "AGENT-1": 14.0675530924599, "AGENT-2": -10.231749900634611}, "custom_metrics": {"mean_ego_speed_mean": 42.370145, "mean_ego_speed_min": 27.48975, "mean_ego_speed_max": 52.0, "distance_travelled_mean": 100.2105575, "distance_travelled_min": 40.544, "distance_travelled_max": 124.81799999999998}, "hist_stats": {"episode_reward": [558.8428769926949, -112.8538506494935, 676.1095502123413, 58.27823974759652, 558.9319214120579, -331.9681908141603, 1100.8325441011893, -173.15424458787493, 670.52622225703, -108.62103134532222, 549.4340027413158, -75.65708163596294, -167.88960541870406, -421.6165320050506, -152.20756249523015, 467.78660839798863, -260.215761658154, 313.9710992715251, -161.81595249366842, -111.93739797296595, -208.48849612713036, -393.892271308668, -535.3840995394243, -231.284146826087, -480.4017206546115, -407.7559995343535, -482.54533923238876, -367.53518388148586, 348.6338432402296, -116.50746319379081, -375.2371224062344, -621.179372794152, -318.7605542317746, -277.1979604196247, -607.9293053545404, -446.2681199146832, 218.8254248998766, 796.6119250292522, 94.11306521005746, 30.044590143090694, -31.22082516078458, 707.602588895507, 171.92562472712962, 492.1417676148471, 152.14944118812872, 421.59145279266494, 520.1655568922768, -328.44371769541493, 504.1535832604292, -413.52843317786096, 572.9544433840817, -305.02197356474716, -173.57739013035695, -470.61964499861926, -231.48346144121496, -158.21160802014805, 337.543644780183, -304.8741324674517, 309.3023815663084, -586.1308851776424, -631.1306002962348, 253.26729256168545, 193.02667685122333, 317.0572780740319, -541.6815030045169, 281.34230791927496, -193.9572578217813, 234.17285109730986, 722.0263885674633, -334.6523681376005, 693.498126594914, -490.73285359378394, 937.5732584780567, -137.25583275122852, 861.3818017644094, -269.22210050446444, 915.4329956007334, -560.3580427095573, 354.37435560942316, -203.14363780146925, -427.78185877064055, -188.93582303865097, 292.6668576950676, -114.44901643378697, -269.53379676383963, -243.24425735198415, -169.0995425519218, 337.58722025177883, -150.57436884465235, -405.78521671089175, -579.7399566764162, -345.4881027275384, 247.72937655813158, -258.71230007382377, 94.17484801333849, -201.52650436658672, 160.64206737187544, -318.8228980105044, -168.70564112450026, -348.4761431175797], "episode_lengths": [121, 114, 125, 184, 129, 121, 150, 149, 129, 145, 162, 127, 116, 125, 112, 112, 116, 116, 122, 115, 118, 111, 115, 157, 116, 168, 106, 116, 194, 146, 124, 95, 120, 105, 122, 124, 218, 126, 116, 215, 101, 134, 217, 123, 126, 106, 120, 110, 104, 124, 121, 125, 120, 128, 114, 121, 116, 97, 218, 119, 118, 143, 204, 181, 109, 200, 131, 178, 129, 120, 122, 102, 140, 147, 131, 125, 125, 110, 117, 117, 120, 123, 129, 105, 120, 134, 40, 160, 115, 114, 135, 120, 243, 157, 112, 117, 188, 116, 130, 105], "policy_AGENT-3_reward": [175.59407510256057, -4.3921835605226045, 175.88758219269252, -58.38182847746421, 173.351731730831, -93.21524329385366, 231.36794812659878, -100.0813054987913, 198.4617250510327, -79.29670747160455, -10.784705568886544, -21.261939002380263, -20.551887795741596, -164.981661634718, -30.09110841097059, 124.9932608285622, -16.409384200086215, 107.05087610595743, -18.447659276149537, -5.879606394846974, -26.924256311875073, -179.2024872545516, -122.64456055389067, -94.60586874325183, -100.03674949020673, -149.76912076267993, -135.6856450814709, -83.38189864234361, -38.26234278835355, 52.75275061459927, -62.91598154031256, -108.81769457759128, -72.38993372006175, -20.384771001795546, -118.86318250298682, -92.69658153026433, -41.7526078879905, 205.69724896947417, 53.6047536058212, -25.608149807988855, -9.169769942200167, 212.96801263409782, -43.48495966259114, 102.33325769195275, 24.811855900032267, 113.09710300883982, 117.04572057084337, -88.99483212411694, 140.11819435442467, -13.28787980999821, 156.5305403129733, -25.667051054884777, -61.90760812793448, -52.44987126689723, -91.85537712436778, -22.435853154421345, 93.99879353162343, -99.65071498587723, -50.282795565674895, -140.9121116320312, -116.7613570777065, 211.81467789469534, -57.509369362581275, -45.99521330666387, -123.38779280520625, -41.145182514359036, -53.37648835632835, -47.53210395823314, 209.90778115505074, -96.50255355809487, 194.25813302440116, -128.10608549550327, 226.04968440076894, -91.70579025419565, 231.24332044597375, -110.21563025405952, 219.3054541996959, -199.79640349144293, 113.51541290570869, -38.52480293596674, -32.44897425692949, -25.212534821439515, 111.31596427969392, 19.443050316987815, -34.51812639222742, -63.03453733322326, -14.915010974226456, 30.94745771071774, -36.37634443934391, -189.1133801799986, -97.10183393043229, -80.04140575309766, -39.04373488183022, 11.629472789627266, -41.864287059118844, -56.19378545171718, -56.6611773116828, -71.23709772114906, -101.60696230145187, -82.63886179630022], "policy_AGENT-0_reward": [101.04166676162592, -82.33868187866864, 166.43239460617656, 73.54287733484176, 104.17742692364087, -93.74841985058515, 272.4415132463094, -2.379675713730826, 131.85252987431397, 7.590194989322917, 279.7283416149292, -52.68649374847513, -87.18604037317836, -200.60537780365092, -35.443439376035116, 143.5556992450605, -134.09048566576922, 37.179038472107266, -63.24353951766895, -74.15973376775423, -101.70619621852407, -148.60173299075657, -167.7423409925864, -37.638404928883915, -71.47752897843007, -97.69570819092579, -109.1941568533956, -123.23211413830691, 197.9860275598092, 22.719033364289807, -121.6200445018456, -201.77255014589417, -110.71631379659388, -96.9194562640652, -170.74520243621367, -62.64822958218419, 133.92914496491434, 173.45276254078257, 16.328686914579578, 22.782122475553088, -46.156891000307134, 60.93201079186358, 119.23242466578677, 105.68391394600238, 24.119981004042614, 120.82147446892579, 106.60328195923115, -63.778469348082666, 136.07782513548793, -179.7025992327313, 94.66894149460705, -112.5333639568813, -90.9455861686412, -203.55811513193825, -131.78686902922794, -56.734422665981626, 51.339765817483716, -63.5588610487757, 188.15309870279546, -135.33903199566248, -218.49062722792326, 177.4555596752981, 137.59474003558992, 190.65486017302595, -134.67766120247958, 167.42030641117046, -66.35294142927535, 181.9674512860054, 165.55362107692446, -92.11921642997007, 168.0338395156622, -94.17356013912261, 228.2151123210937, 6.802425321237237, 206.5344460272394, -44.418899700860806, 230.83018401525388, -170.72912548326528, 81.66169522325136, -87.48288510006311, -202.6352891330733, -92.3962717323889, 45.812056841334844, -30.225402160249914, -124.6604896836564, -88.4618665815192, -69.60239561813489, 122.36488253461964, -38.86606774729697, -158.35029867537486, -132.89974007501294, -115.5730051856872, 146.29733991272187, -18.12448194198491, 80.86610951500701, -80.08398717256826, 121.88875706183649, -112.36949393844591, -3.5567587228803106, -72.68243662500613], "policy_AGENT-1_reward": [148.188765857855, 8.768921688232641, 168.77884211866686, 101.39565938853714, 149.82120051012748, -92.64935571089637, 284.556037121638, -99.51570479224966, 179.47440207041484, -78.73165365493526, 291.14860449496734, 19.60433060017605, -39.577622327691635, -27.76914076286403, -56.580325959858, 101.02241951187793, -93.39129519399583, 85.90889707937758, -61.63964420383472, -26.1816835105152, -52.88586073739024, -32.79792380055717, -122.13311851925968, -4.375839926801514, -154.07631772477737, -63.99854657128072, -127.92210236556116, -80.15027956490144, 227.12893469186994, -95.6421983490843, -62.355596855607565, -108.25230792493855, -66.02464060545314, -96.85229904699464, -118.29639661390743, -145.10003254956982, 168.41733621589296, 215.40147603417108, 60.563951947518404, 58.29321220154003, 1.6212591972423034, 223.71034934182777, 139.57172335377197, 150.07706040102906, 35.121484548364705, 120.50426971380145, 148.43259181773752, -87.43590709304745, 135.86053096354263, -207.13993192803846, 185.4560529359204, -141.100446957346, -10.14602212955684, -162.19621440480338, -3.6563605493376627, -56.660034128421906, 97.37561421952691, -63.7609522730073, 221.64227990175564, -150.53024396530918, -116.19436986105933, -67.72454204467239, 170.4979255572646, 218.26570727713448, -122.82361869539915, 196.14259604588483, -29.739015879963937, 147.26801592188392, 171.53740284024585, -95.93939962306146, 169.67591613587027, -94.11181004780985, 234.9037349014854, -91.14103431865595, 210.41637261343345, -109.64999733217934, 238.0256954943942, -94.69355847982081, 82.22409070931313, -38.69362911930647, -160.30704918261978, -46.07233397602293, 51.43521990328098, -30.382242653389877, -75.82773219858218, -62.471452812859916, -69.7194715782974, 31.506798858644878, -38.89780169508742, -28.94338301537105, -174.61410918684004, -74.1673827202185, 179.56046645274736, -125.89140360466851, 97.00574983605874, -32.91154823199191, 151.9814689929289, -66.22316827251815, 38.038468546470874, -72.91047353624516], "policy_AGENT-2_reward": [134.01836927065352, -34.89190689853475, 165.01073129480483, -58.27846849831812, 131.58156224745863, -52.35517195882492, 312.46704560664386, 28.822441416897032, 160.7375652612691, 41.8171347918946, -10.658237799694142, -21.312979485283602, -20.574054922092596, -28.26035180381784, -30.092688748366438, 98.21522881248816, -16.32459659830299, 83.83228761408282, -18.485109496015266, -5.71637429984937, -26.972182859340954, -33.2901272628028, -122.86407947368743, -94.66403322714983, -154.8111244611972, -96.29262400946709, -109.74343493196119, -80.77089153593359, -38.21877622309621, -96.33704882359532, -128.34549950846878, -202.33682014572787, -69.62966610966585, -63.041434106769216, -200.02452380143225, -145.82327625266495, -41.768448392939824, 202.06043748482438, -36.38432725786174, -25.422594726013674, 22.484576584480738, 209.99221612771757, -43.39356362983787, 134.0475355758632, 68.09611973568923, 67.16860560109768, 148.08396254446455, -88.2345091301676, 92.09703280697443, -13.398022207092916, 136.29890864058103, -25.721111595635218, -10.578173704224369, -52.41544419498042, -4.184854738281409, -22.381298071323073, 94.82947121154895, -77.9036041597917, -50.21020147256762, -159.34949758463878, -179.6842461295457, -68.2784029636357, -57.556619379049806, -45.868076069464486, -160.7924303014318, -41.07541202342128, -44.48881215621392, -47.53051215234639, 175.02758349524242, -50.09119852647387, 161.53023791898028, -174.34139791134837, 248.40472685470883, 38.7885665003857, 213.18766267776297, -4.937573217364719, 227.2716618913897, -95.13895525502804, 76.97315677115007, -38.442320646133005, -32.39054619801793, -25.254682508799505, 84.10361667075809, -73.28442193713502, -34.52744848937385, -29.27640062438181, -14.862664381263048, 152.7680811477966, -36.43415496292397, -29.378154840147026, -175.1242734841305, -75.70630906853518, -39.08469492550777, -126.32588731679752, -41.832724278608396, -32.33718351030926, -56.566981371207156, -68.99313807839142, -101.58038864663882, -120.24437116002804]}, "sampler_perf": {"mean_env_wait_ms": 59.75410312967795, "mean_raw_obs_processing_ms": 2.548841925561728, "mean_inference_ms": 2.542667372854999, "mean_action_processing_ms": 0.15446404753427664}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 176400, "timers": {"sample_time_ms": 84533.587, "sample_throughput": 49.684, "load_time_ms": 15.507, "load_throughput": 270842.394, "learn_time_ms": 8420.849, "learn_throughput": 498.762, "update_time_ms": 8.316}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 23.453176498413086, "policy_loss": -0.02481939271092415, "vf_loss": 23.468666076660156, "vf_explained_var": 0.9791551232337952, "kl": 0.01381848007440567, "entropy": 1.0191738605499268, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 20.248735427856445, "policy_loss": -0.026216695085167885, "vf_loss": 20.267000198364258, "vf_explained_var": 0.9779049754142761, "kl": 0.017671458423137665, "entropy": 0.8867799639701843, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 18.914609909057617, "policy_loss": -0.03279969468712807, "vf_loss": 18.933391571044922, "vf_explained_var": 0.980739176273346, "kl": 0.020771462470293045, "entropy": 1.1530531644821167, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 21.37344741821289, "policy_loss": -0.030971234664320946, "vf_loss": 21.397274017333984, "vf_explained_var": 0.9818553328514099, "kl": 0.01058154832571745, "entropy": 0.99012690782547, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 176400, "num_steps_trained": 176400}, "done": false, "episodes_total": 1485, "training_iteration": 42, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-32-45", "timestamp": 1624213965, "time_this_iter_s": 85.03908181190491, "time_total_s": 4547.025496959686, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd3847234d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd3847233b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd384723170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd384723050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd384723830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd384723950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd384723170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd384723050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd384723830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd384723950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd384723170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd384723050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd384723830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd384723950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd384723170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd384723050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd384723830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd384723950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd3847235f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4547.025496959686, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 55.795901639344265, "ram_util_percent": 86.99590163934427}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1180.4378738051587, "episode_reward_min": -844.0279314101973, "episode_reward_mean": -9.08829713498763, "episode_len_mean": 130.32, "episodes_this_iter": 32, "policy_reward_min": {"AGENT-3": -199.79640349144293, "AGENT-0": -246.66266931500934, "AGENT-1": -204.32025649007855, "AGENT-2": -207.92071799964833}, "policy_reward_max": {"AGENT-3": 326.63958063513684, "AGENT-0": 294.04536686160554, "AGENT-1": 322.1115137920228, "AGENT-2": 312.46704560664386}, "policy_reward_mean": {"AGENT-3": -13.218665050281608, "AGENT-0": -2.435808900038991, "AGENT-1": 14.954336973457439, "AGENT-2": -8.388160158124421}, "custom_metrics": {"mean_ego_speed_mean": 42.602, "mean_ego_speed_min": 27.48975, "mean_ego_speed_max": 51.940250000000006, "distance_travelled_mean": 102.4012125, "distance_travelled_min": 40.544, "distance_travelled_max": 124.81799999999998}, "hist_stats": {"episode_reward": [1125.1962834048215, 1180.4378738051587, -181.046607201006, 780.198020994022, -493.7615832249872, 869.1465999564608, -38.51695386222075, 766.7973406600413, -122.85144622093023, 390.3834846208939, -157.1556653830808, 402.0685760246323, -129.01320857198658, -372.20207221548253, -328.1120807464341, 830.4484040497987, 439.8761147148083, -154.01613644463887, 562.6556975331903, -398.5050083409245, -69.82692280632735, -760.7127079781086, -433.2226236481088, -352.1627227059171, -679.4671781575476, -535.3770714256353, 164.3148388585182, -304.72115951875503, -434.77205272329616, 527.0444654693625, -844.0279314101973, -373.8481954379993, -541.6815030045169, 281.34230791927496, -193.9572578217813, 234.17285109730986, 722.0263885674633, -334.6523681376005, 693.498126594914, -490.73285359378394, 937.5732584780567, -137.25583275122852, 861.3818017644094, -269.22210050446444, 915.4329956007334, -560.3580427095573, 354.37435560942316, -203.14363780146925, -427.78185877064055, -188.93582303865097, 292.6668576950676, -114.44901643378697, -269.53379676383963, -243.24425735198415, -169.0995425519218, 337.58722025177883, -150.57436884465235, -405.78521671089175, -579.7399566764162, -345.4881027275384, 247.72937655813158, -258.71230007382377, 94.17484801333849, -201.52650436658672, 160.64206737187544, -318.8228980105044, -168.70564112450026, -348.4761431175797, 558.8428769926949, -112.8538506494935, 676.1095502123413, 58.27823974759652, 558.9319214120579, -331.9681908141603, 1100.8325441011893, -173.15424458787493, 670.52622225703, -108.62103134532222, 549.4340027413158, -75.65708163596294, -167.88960541870406, -421.6165320050506, -152.20756249523015, 467.78660839798863, -260.215761658154, 313.9710992715251, -161.81595249366842, -111.93739797296595, -208.48849612713036, -393.892271308668, -535.3840995394243, -231.284146826087, -480.4017206546115, -407.7559995343535, -482.54533923238876, -367.53518388148586, 348.6338432402296, -116.50746319379081, -375.2371224062344, -621.179372794152], "episode_lengths": [100, 141, 137, 183, 117, 136, 99, 129, 101, 128, 117, 140, 111, 143, 111, 122, 158, 115, 200, 111, 109, 118, 88, 117, 131, 109, 195, 116, 118, 243, 130, 117, 109, 200, 131, 178, 129, 120, 122, 102, 140, 147, 131, 125, 125, 110, 117, 117, 120, 123, 129, 105, 120, 134, 40, 160, 115, 114, 135, 120, 243, 157, 112, 117, 188, 116, 130, 105, 121, 114, 125, 184, 129, 121, 150, 149, 129, 145, 162, 127, 116, 125, 112, 112, 116, 116, 122, 115, 118, 111, 115, 157, 116, 168, 106, 116, 194, 146, 124, 95], "policy_AGENT-3_reward": [291.3097772232769, 326.63958063513684, -101.84395240680152, 190.0572429382435, -138.16769403677765, 209.4387207849266, -20.545081735712472, 209.83346333804062, -37.65161294463759, 76.08089376806366, -15.058241251012719, 97.22335450819374, -15.904953790505736, -31.20139959616426, -103.49635451682626, 189.16407450340716, -10.560939554937994, -13.019785751526982, -12.448954086751783, -178.3580116453865, -26.514773260632175, -183.89229545515838, -96.69858814388024, -76.71106767314244, -120.73469039053597, -95.75337974793692, -51.94489032013747, -68.6558500424529, -110.19268350655722, -43.813303853154494, -185.1242876054609, -102.07378783271727, -123.38779280520625, -41.145182514359036, -53.37648835632835, -47.53210395823314, 209.90778115505074, -96.50255355809487, 194.25813302440116, -128.10608549550327, 226.04968440076894, -91.70579025419565, 231.24332044597375, -110.21563025405952, 219.3054541996959, -199.79640349144293, 113.51541290570869, -38.52480293596674, -32.44897425692949, -25.212534821439515, 111.31596427969392, 19.443050316987815, -34.51812639222742, -63.03453733322326, -14.915010974226456, 30.94745771071774, -36.37634443934391, -189.1133801799986, -97.10183393043229, -80.04140575309766, -39.04373488183022, 11.629472789627266, -41.864287059118844, -56.19378545171718, -56.6611773116828, -71.23709772114906, -101.60696230145187, -82.63886179630022, 175.59407510256057, -4.3921835605226045, 175.88758219269252, -58.38182847746421, 173.351731730831, -93.21524329385366, 231.36794812659878, -100.0813054987913, 198.4617250510327, -79.29670747160455, -10.784705568886544, -21.261939002380263, -20.551887795741596, -164.981661634718, -30.09110841097059, 124.9932608285622, -16.409384200086215, 107.05087610595743, -18.447659276149537, -5.879606394846974, -26.924256311875073, -179.2024872545516, -122.64456055389067, -94.60586874325183, -100.03674949020673, -149.76912076267993, -135.6856450814709, -83.38189864234361, -38.26234278835355, 52.75275061459927, -62.91598154031256, -108.81769457759128], "policy_AGENT-0_reward": [294.04536686160554, 274.51538032745356, -6.348948990386511, 188.05456450868758, -174.93095228896254, 213.0132703385544, -6.278359620316175, 158.23055524695928, -29.141696098855718, 81.36580495603603, -91.57759828541626, 96.8720100446198, -38.29477793916616, -168.54656807066175, -72.98469078388028, 212.38213172419808, 206.1555987199404, -52.05459718425112, 289.5395087080688, -152.65838972565933, -4.025440000019412, -176.4391890649978, -72.90875085217259, -122.99800904415235, -237.04236685923192, -152.0502084462724, 121.2305313212857, -107.99831502564967, -93.26720223632292, 292.5339317895949, -246.66266931500934, -120.80084566192158, -134.67766120247958, 167.42030641117046, -66.35294142927535, 181.9674512860054, 165.55362107692446, -92.11921642997007, 168.0338395156622, -94.17356013912261, 228.2151123210937, 6.802425321237237, 206.5344460272394, -44.418899700860806, 230.83018401525388, -170.72912548326528, 81.66169522325136, -87.48288510006311, -202.6352891330733, -92.3962717323889, 45.812056841334844, -30.225402160249914, -124.6604896836564, -88.4618665815192, -69.60239561813489, 122.36488253461964, -38.86606774729697, -158.35029867537486, -132.89974007501294, -115.5730051856872, 146.29733991272187, -18.12448194198491, 80.86610951500701, -80.08398717256826, 121.88875706183649, -112.36949393844591, -3.5567587228803106, -72.68243662500613, 101.04166676162592, -82.33868187866864, 166.43239460617656, 73.54287733484176, 104.17742692364087, -93.74841985058515, 272.4415132463094, -2.379675713730826, 131.85252987431397, 7.590194989322917, 279.7283416149292, -52.68649374847513, -87.18604037317836, -200.60537780365092, -35.443439376035116, 143.5556992450605, -134.09048566576922, 37.179038472107266, -63.24353951766895, -74.15973376775423, -101.70619621852407, -148.60173299075657, -167.7423409925864, -37.638404928883915, -71.47752897843007, -97.69570819092579, -109.1941568533956, -123.23211413830691, 197.9860275598092, 22.719033364289807, -121.6200445018456, -201.77255014589417], "policy_AGENT-1_reward": [293.72853825158444, 282.87200984886346, -101.27799915625235, 218.80099814753717, -89.93782509706753, 222.40840557595422, -4.831188527438154, 205.30329771242853, -26.359982823691915, 124.23391289063862, -5.574977658971721, 111.65899232473521, -58.91152496114506, -141.1987099899072, -75.59803933206054, 217.224193623873, 254.88748189684608, -75.9196464332341, 298.06287303306215, -33.48955440839743, -19.426946394809963, -197.76114993610733, -131.4694729234262, -77.14239868673006, -120.16904319430057, -134.97202926493415, 147.01562170417705, -63.57527140619573, -114.37204226108616, 322.1115137920228, -204.32025649007855, -75.32696027861766, -122.82361869539915, 196.14259604588483, -29.739015879963937, 147.26801592188392, 171.53740284024585, -95.93939962306146, 169.67591613587027, -94.11181004780985, 234.9037349014854, -91.14103431865595, 210.41637261343345, -109.64999733217934, 238.0256954943942, -94.69355847982081, 82.22409070931313, -38.69362911930647, -160.30704918261978, -46.07233397602293, 51.43521990328098, -30.382242653389877, -75.82773219858218, -62.471452812859916, -69.7194715782974, 31.506798858644878, -38.89780169508742, -28.94338301537105, -174.61410918684004, -74.1673827202185, 179.56046645274736, -125.89140360466851, 97.00574983605874, -32.91154823199191, 151.9814689929289, -66.22316827251815, 38.038468546470874, -72.91047353624516, 148.188765857855, 8.768921688232641, 168.77884211866686, 101.39565938853714, 149.82120051012748, -92.64935571089637, 284.556037121638, -99.51570479224966, 179.47440207041484, -78.73165365493526, 291.14860449496734, 19.60433060017605, -39.577622327691635, -27.76914076286403, -56.580325959858, 101.02241951187793, -93.39129519399583, 85.90889707937758, -61.63964420383472, -26.1816835105152, -52.88586073739024, -32.79792380055717, -122.13311851925968, -4.375839926801514, -154.07631772477737, -63.99854657128072, -127.92210236556116, -80.15027956490144, 227.12893469186994, -95.6421983490843, -62.355596855607565, -108.25230792493855], "policy_AGENT-2_reward": [246.11260106835368, 296.4109029937057, 28.424293352434237, 183.28521539955443, -90.72511180217936, 224.286203257025, -6.86232397875399, 193.4300243626138, -29.698154353744886, 108.70287300615573, -44.94484818768007, 96.31421914708392, -15.901951881169651, -31.255394558749472, -76.0329961136672, 211.67800419832096, -10.606026347039911, -13.022107075626806, -12.497730121188603, -33.999052561480966, -19.85976315086572, -202.620073521845, -132.14581172862955, -75.31124730189207, -201.52107771347917, -152.60145396649182, -51.98642384680712, -64.49172304445736, -116.94012471932997, -43.787676259100905, -207.92071799964833, -75.64660166474283, -160.7924303014318, -41.07541202342128, -44.48881215621392, -47.53051215234639, 175.02758349524242, -50.09119852647387, 161.53023791898028, -174.34139791134837, 248.40472685470883, 38.7885665003857, 213.18766267776297, -4.937573217364719, 227.2716618913897, -95.13895525502804, 76.97315677115007, -38.442320646133005, -32.39054619801793, -25.254682508799505, 84.10361667075809, -73.28442193713502, -34.52744848937385, -29.27640062438181, -14.862664381263048, 152.7680811477966, -36.43415496292397, -29.378154840147026, -175.1242734841305, -75.70630906853518, -39.08469492550777, -126.32588731679752, -41.832724278608396, -32.33718351030926, -56.566981371207156, -68.99313807839142, -101.58038864663882, -120.24437116002804, 134.01836927065352, -34.89190689853475, 165.01073129480483, -58.27846849831812, 131.58156224745863, -52.35517195882492, 312.46704560664386, 28.822441416897032, 160.7375652612691, 41.8171347918946, -10.658237799694142, -21.312979485283602, -20.574054922092596, -28.26035180381784, -30.092688748366438, 98.21522881248816, -16.32459659830299, 83.83228761408282, -18.485109496015266, -5.71637429984937, -26.972182859340954, -33.2901272628028, -122.86407947368743, -94.66403322714983, -154.8111244611972, -96.29262400946709, -109.74343493196119, -80.77089153593359, -38.21877622309621, -96.33704882359532, -128.34549950846878, -202.33682014572787]}, "sampler_perf": {"mean_env_wait_ms": 59.39783876337706, "mean_raw_obs_processing_ms": 2.535400773860726, "mean_inference_ms": 2.5312867028059127, "mean_action_processing_ms": 0.15382543294999076}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 180600, "timers": {"sample_time_ms": 83741.183, "sample_throughput": 50.155, "load_time_ms": 15.485, "load_throughput": 271230.63, "learn_time_ms": 8321.238, "learn_throughput": 504.733, "update_time_ms": 8.509}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 21.70067024230957, "policy_loss": -0.02988520637154579, "vf_loss": 21.721595764160156, "vf_explained_var": 0.9834420680999756, "kl": 0.013277963735163212, "entropy": 0.9870145320892334, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 19.92628288269043, "policy_loss": -0.024006908759474754, "vf_loss": 19.94189453125, "vf_explained_var": 0.9796542525291443, "kl": 0.01865675114095211, "entropy": 0.8905131220817566, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 1.0125000476837158, "cur_lr": 0.0010000000474974513, "total_loss": 18.806331634521484, "policy_loss": -0.034805528819561005, "vf_loss": 18.829402923583984, "vf_explained_var": 0.9833205938339233, "kl": 0.011590691283345222, "entropy": 1.1777080297470093, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 16.848461151123047, "policy_loss": -0.03228180482983589, "vf_loss": 16.870590209960938, "vf_explained_var": 0.9869333505630493, "kl": 0.01504428032785654, "entropy": 0.9740551114082336, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 180600, "num_steps_trained": 180600}, "done": false, "episodes_total": 1517, "training_iteration": 43, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-34-15", "timestamp": 1624214055, "time_this_iter_s": 90.02120399475098, "time_total_s": 4637.046700954437, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd4040729e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd404072d40>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd3847dac20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd3847daa70>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd3847dad40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd39406a680>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd3847dac20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd3847daa70>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd3847dad40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd39406a680>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd3847dac20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd3847daa70>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd3847dad40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd39406a680>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd3847dac20>, action_adapter=<function AgentSpec.<lambda> at 0x7fd3847daa70>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd3847dad40>, info_adapter=<function AgentSpec.<lambda> at 0x7fd39406a680>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd384723b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4637.046700954437, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 54.68062015503876, "ram_util_percent": 87.20542635658914}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1227.5360093232985, "episode_reward_min": -844.0279314101973, "episode_reward_mean": -34.665936161314555, "episode_len_mean": 127.12, "episodes_this_iter": 36, "policy_reward_min": {"AGENT-3": -204.3764180563085, "AGENT-0": -246.66266931500934, "AGENT-1": -204.32025649007855, "AGENT-2": -207.92071799964833}, "policy_reward_max": {"AGENT-3": 326.63958063513684, "AGENT-0": 297.2158755087758, "AGENT-1": 322.1115137920228, "AGENT-2": 330.0155520057784}, "policy_reward_mean": {"AGENT-3": -17.997809402686922, "AGENT-0": -17.67227221963152, "AGENT-1": 9.757658847462942, "AGENT-2": -8.75351338645897}, "custom_metrics": {"mean_ego_speed_mean": 42.8979425, "mean_ego_speed_min": 29.35825, "mean_ego_speed_max": 52.1245, "distance_travelled_mean": 104.03482749999999, "distance_travelled_min": 64.82775000000001, "distance_travelled_max": 124.828}, "hist_stats": {"episode_reward": [660.5604539523308, -250.0956087773271, -65.45976206041334, -646.7539355449845, 60.98343347136497, -610.3718178475582, 799.536753956467, 22.67301212771932, 1227.5360093232985, -578.2545398979763, 835.441022742066, -583.0785830495952, 784.7183943469504, -212.92645231754, -412.53856974480885, -274.28975835459454, 524.1435886614996, -431.4978928015504, 521.6625530740913, -229.41774168548983, 521.636018735775, -344.4526409242237, -187.19390239409276, -362.2695481502569, -288.432100572697, -553.5926261780817, -121.92364831971902, -364.78382447422564, 228.7332807691404, -422.9083687141645, -447.8350917721054, -562.026753879441, -559.2772847314727, -417.2448976074703, -83.2440061701914, -524.7956351893584, 558.8428769926949, -112.8538506494935, 676.1095502123413, 58.27823974759652, 558.9319214120579, -331.9681908141603, 1100.8325441011893, -173.15424458787493, 670.52622225703, -108.62103134532222, 549.4340027413158, -75.65708163596294, -167.88960541870406, -421.6165320050506, -152.20756249523015, 467.78660839798863, -260.215761658154, 313.9710992715251, -161.81595249366842, -111.93739797296595, -208.48849612713036, -393.892271308668, -535.3840995394243, -231.284146826087, -480.4017206546115, -407.7559995343535, -482.54533923238876, -367.53518388148586, 348.6338432402296, -116.50746319379081, -375.2371224062344, -621.179372794152, 1125.1962834048215, 1180.4378738051587, -181.046607201006, 780.198020994022, -493.7615832249872, 869.1465999564608, -38.51695386222075, 766.7973406600413, -122.85144622093023, 390.3834846208939, -157.1556653830808, 402.0685760246323, -129.01320857198658, -372.20207221548253, -328.1120807464341, 830.4484040497987, 439.8761147148083, -154.01613644463887, 562.6556975331903, -398.5050083409245, -69.82692280632735, -760.7127079781086, -433.2226236481088, -352.1627227059171, -679.4671781575476, -535.3770714256353, 164.3148388585182, -304.72115951875503, -434.77205272329616, 527.0444654693625, -844.0279314101973, -373.8481954379993], "episode_lengths": [120, 150, 116, 129, 97, 114, 124, 104, 137, 113, 142, 114, 158, 112, 113, 114, 119, 121, 152, 112, 127, 120, 115, 114, 125, 112, 105, 114, 218, 103, 105, 107, 112, 116, 111, 101, 121, 114, 125, 184, 129, 121, 150, 149, 129, 145, 162, 127, 116, 125, 112, 112, 116, 116, 122, 115, 118, 111, 115, 157, 116, 168, 106, 116, 194, 146, 124, 95, 100, 141, 137, 183, 117, 136, 99, 129, 101, 128, 117, 140, 111, 143, 111, 122, 158, 115, 200, 111, 109, 118, 88, 117, 131, 109, 195, 116, 118, 243, 130, 117], "policy_AGENT-3_reward": [189.7243517844552, -75.74360531225331, -43.940501582431644, -204.3764180563085, -10.49182836935293, -191.9605697800037, 207.77752464571762, 3.615978835783508, 295.548717086812, -182.23856351933978, 230.2468656089239, -171.79677206715326, 178.14054299923293, -33.64103576212662, -149.62696742019494, -31.548847061491255, 107.0769241401394, -112.34386483834982, 155.8402248200887, -65.08258835914683, 164.8945101333485, -45.53643776300477, -71.34318986172823, -90.03954150274369, -67.11467665422157, -139.97931477188462, -53.186301048768634, -68.9150490580444, -44.272252808907965, -111.27777559692618, -118.20189975624774, -141.5927386457544, -116.83185011098513, -78.15890938597028, -48.13559955381588, -128.08813364681006, 175.59407510256057, -4.3921835605226045, 175.88758219269252, -58.38182847746421, 173.351731730831, -93.21524329385366, 231.36794812659878, -100.0813054987913, 198.4617250510327, -79.29670747160455, -10.784705568886544, -21.261939002380263, -20.551887795741596, -164.981661634718, -30.09110841097059, 124.9932608285622, -16.409384200086215, 107.05087610595743, -18.447659276149537, -5.879606394846974, -26.924256311875073, -179.2024872545516, -122.64456055389067, -94.60586874325183, -100.03674949020673, -149.76912076267993, -135.6856450814709, -83.38189864234361, -38.26234278835355, 52.75275061459927, -62.91598154031256, -108.81769457759128, 291.3097772232769, 326.63958063513684, -101.84395240680152, 190.0572429382435, -138.16769403677765, 209.4387207849266, -20.545081735712472, 209.83346333804062, -37.65161294463759, 76.08089376806366, -15.058241251012719, 97.22335450819374, -15.904953790505736, -31.20139959616426, -103.49635451682626, 189.16407450340716, -10.560939554937994, -13.019785751526982, -12.448954086751783, -178.3580116453865, -26.514773260632175, -183.89229545515838, -96.69858814388024, -76.71106767314244, -120.73469039053597, -95.75337974793692, -51.94489032013747, -68.6558500424529, -110.19268350655722, -43.813303853154494, -185.1242876054609, -102.07378783271727], "policy_AGENT-0_reward": [156.81209675575866, -66.8030083212902, -12.193415244845333, -237.95035770530365, 27.98356050740401, -229.94645717226385, 196.8383406258371, -32.29288732343531, 297.2158755087758, -221.72774108350927, 183.89331035107259, -209.76302652095313, 238.00153185130895, -61.46078624970359, -188.74551880236174, -93.36264911898209, 110.69469917094011, -149.250837325874, 105.97079720486894, -111.29453019820076, 96.92347188817831, -148.93435630993417, -114.50090832681735, -129.11706979188796, -94.48192363292787, -122.57646710562398, -31.186320404862304, -136.10323081585753, 145.76029980030367, -100.98165370328971, -63.27961823050309, -142.28113642782722, -151.88509112935486, -152.40334497436874, -22.621756961469355, -134.79027015721303, 101.04166676162592, -82.33868187866864, 166.43239460617656, 73.54287733484176, 104.17742692364087, -93.74841985058515, 272.4415132463094, -2.379675713730826, 131.85252987431397, 7.590194989322917, 279.7283416149292, -52.68649374847513, -87.18604037317836, -200.60537780365092, -35.443439376035116, 143.5556992450605, -134.09048566576922, 37.179038472107266, -63.24353951766895, -74.15973376775423, -101.70619621852407, -148.60173299075657, -167.7423409925864, -37.638404928883915, -71.47752897843007, -97.69570819092579, -109.1941568533956, -123.23211413830691, 197.9860275598092, 22.719033364289807, -121.6200445018456, -201.77255014589417, 294.04536686160554, 274.51538032745356, -6.348948990386511, 188.05456450868758, -174.93095228896254, 213.0132703385544, -6.278359620316175, 158.23055524695928, -29.141696098855718, 81.36580495603603, -91.57759828541626, 96.8720100446198, -38.29477793916616, -168.54656807066175, -72.98469078388028, 212.38213172419808, 206.1555987199404, -52.05459718425112, 289.5395087080688, -152.65838972565933, -4.025440000019412, -176.4391890649978, -72.90875085217259, -122.99800904415235, -237.04236685923192, -152.0502084462724, 121.2305313212857, -107.99831502564967, -93.26720223632292, 292.5339317895949, -246.66266931500934, -120.80084566192158], "policy_AGENT-1_reward": [159.19732172145245, -75.17939845135211, -4.401227548204645, -101.92110202520215, 27.973526442122616, -94.01740211650801, 199.9731729882302, 14.342301025104042, 304.75586472193345, -86.77096494332804, 225.88830212369132, -100.44237872786242, 201.549462116042, -84.3589389122405, -36.69939814201652, -117.80850034525363, 153.52574534459364, -84.7393362915235, 144.8361457558858, -26.302506200627892, 140.74554206320533, -104.39099817218278, -0.41987711675154316, -71.33839682511162, -66.55072834237042, -144.85244118483556, -30.30626051121511, -68.3492056683114, 171.5683902131767, -109.12140191146462, -117.63775617393141, -135.31031175770894, -116.26968753666249, -77.59019530613723, -19.078415751788075, -126.5763760605637, 148.188765857855, 8.768921688232641, 168.77884211866686, 101.39565938853714, 149.82120051012748, -92.64935571089637, 284.556037121638, -99.51570479224966, 179.47440207041484, -78.73165365493526, 291.14860449496734, 19.60433060017605, -39.577622327691635, -27.76914076286403, -56.580325959858, 101.02241951187793, -93.39129519399583, 85.90889707937758, -61.63964420383472, -26.1816835105152, -52.88586073739024, -32.79792380055717, -122.13311851925968, -4.375839926801514, -154.07631772477737, -63.99854657128072, -127.92210236556116, -80.15027956490144, 227.12893469186994, -95.6421983490843, -62.355596855607565, -108.25230792493855, 293.72853825158444, 282.87200984886346, -101.27799915625235, 218.80099814753717, -89.93782509706753, 222.40840557595422, -4.831188527438154, 205.30329771242853, -26.359982823691915, 124.23391289063862, -5.574977658971721, 111.65899232473521, -58.91152496114506, -141.1987099899072, -75.59803933206054, 217.224193623873, 254.88748189684608, -75.9196464332341, 298.06287303306215, -33.48955440839743, -19.426946394809963, -197.76114993610733, -131.4694729234262, -77.14239868673006, -120.16904319430057, -134.97202926493415, 147.01562170417705, -63.57527140619573, -114.37204226108616, 322.1115137920228, -204.32025649007855, -75.32696027861766], "policy_AGENT-2_reward": [154.82668369066417, -32.369596692431585, -4.924617684931718, -102.50605775817041, 15.51817489119134, -94.44738877878225, 194.94771569668188, 37.007619590267126, 330.0155520057784, -87.51727035179957, 195.41254465837812, -101.07640573362674, 167.02685738036698, -33.4656913934693, -37.466685380235624, -31.56976182886763, 152.84622000582692, -85.16385434580273, 115.01538529324836, -26.738116927514273, 119.07249465104337, -45.59084867910172, -0.9299270887958428, -71.77454003051348, -60.28477194317709, -146.1844031157374, -7.244766354873271, -91.41633893201212, -44.32315643543169, -101.52753750248364, -148.7158176114229, -142.8425670481504, -174.29065595446997, -109.09244794099403, 6.591766096881887, -135.34085532477116, 134.01836927065352, -34.89190689853475, 165.01073129480483, -58.27846849831812, 131.58156224745863, -52.35517195882492, 312.46704560664386, 28.822441416897032, 160.7375652612691, 41.8171347918946, -10.658237799694142, -21.312979485283602, -20.574054922092596, -28.26035180381784, -30.092688748366438, 98.21522881248816, -16.32459659830299, 83.83228761408282, -18.485109496015266, -5.71637429984937, -26.972182859340954, -33.2901272628028, -122.86407947368743, -94.66403322714983, -154.8111244611972, -96.29262400946709, -109.74343493196119, -80.77089153593359, -38.21877622309621, -96.33704882359532, -128.34549950846878, -202.33682014572787, 246.11260106835368, 296.4109029937057, 28.424293352434237, 183.28521539955443, -90.72511180217936, 224.286203257025, -6.86232397875399, 193.4300243626138, -29.698154353744886, 108.70287300615573, -44.94484818768007, 96.31421914708392, -15.901951881169651, -31.255394558749472, -76.0329961136672, 211.67800419832096, -10.606026347039911, -13.022107075626806, -12.497730121188603, -33.999052561480966, -19.85976315086572, -202.620073521845, -132.14581172862955, -75.31124730189207, -201.52107771347917, -152.60145396649182, -51.98642384680712, -64.49172304445736, -116.94012471932997, -43.787676259100905, -207.92071799964833, -75.64660166474283]}, "sampler_perf": {"mean_env_wait_ms": 59.06621874943511, "mean_raw_obs_processing_ms": 2.524527021857724, "mean_inference_ms": 2.519990255302335, "mean_action_processing_ms": 0.15317979816900779}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 184800, "timers": {"sample_time_ms": 83114.219, "sample_throughput": 50.533, "load_time_ms": 15.254, "load_throughput": 275331.218, "learn_time_ms": 8298.627, "learn_throughput": 506.108, "update_time_ms": 8.336}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 23.190692901611328, "policy_loss": -0.026397177949547768, "vf_loss": 23.206684112548828, "vf_explained_var": 0.977640688419342, "kl": 0.01541974302381277, "entropy": 1.062791109085083, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 19.539026260375977, "policy_loss": -0.026043780148029327, "vf_loss": 19.55835723876953, "vf_explained_var": 0.9790753722190857, "kl": 0.014919540844857693, "entropy": 0.8974462151527405, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 1.0125000476837158, "cur_lr": 0.0010000000474974513, "total_loss": 19.52215576171875, "policy_loss": -0.029886115342378616, "vf_loss": 19.539474487304688, "vf_explained_var": 0.9777699708938599, "kl": 0.012412960641086102, "entropy": 1.153716802597046, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 16.26940155029297, "policy_loss": -0.02962413802742958, "vf_loss": 16.28742218017578, "vf_explained_var": 0.9845301508903503, "kl": 0.01719372533261776, "entropy": 1.020245909690857, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 184800, "num_steps_trained": 184800}, "done": false, "episodes_total": 1553, "training_iteration": 44, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-35-43", "timestamp": 1624214143, "time_this_iter_s": 87.55788207054138, "time_total_s": 4724.604583024979, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd3846dc4d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd3846dc3b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd3846dc170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd3846dc050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd3846dc830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd3846dc950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd3846dc170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd3846dc050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd3846dc830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd3846dc950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd3846dc170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd3846dc050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd3846dc830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd3846dc950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd3846dc170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd3846dc050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd3846dc830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd3846dc950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd3846dc5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4724.604583024979, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 56.30160000000001, "ram_util_percent": 87.20000000000006}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1227.5360093232985, "episode_reward_min": -844.0279314101973, "episode_reward_mean": -28.38580083611633, "episode_len_mean": 125.93, "episodes_this_iter": 32, "policy_reward_min": {"AGENT-3": -204.3764180563085, "AGENT-0": -246.66266931500934, "AGENT-1": -204.32025649007855, "AGENT-2": -235.2394128680614}, "policy_reward_max": {"AGENT-3": 326.63958063513684, "AGENT-0": 297.2158755087758, "AGENT-1": 322.1115137920228, "AGENT-2": 330.0155520057784}, "policy_reward_mean": {"AGENT-3": -12.983279158120956, "AGENT-0": -17.451671459126093, "AGENT-1": 9.096224723202793, "AGENT-2": -7.047074942072016}, "custom_metrics": {"mean_ego_speed_mean": 43.1993125, "mean_ego_speed_min": 29.35825, "mean_ego_speed_max": 52.186499999999995, "distance_travelled_mean": 104.06497749999997, "distance_travelled_min": 53.86925, "distance_travelled_max": 124.828}, "hist_stats": {"episode_reward": [114.08897983860737, -90.24240609524018, 468.04911907201466, -226.57976858223816, 680.8093101999067, -148.15092563779757, 453.83426177386576, -60.66964944746994, 376.97674061017443, 895.8836502504956, -351.27565484154565, 659.3751407865471, -210.60282177434698, 657.9750598813317, -325.31015693211214, 469.6662612134287, -206.99560402873266, 325.3971981328075, -438.2684420991008, 841.8599247856655, -134.9431789045948, -213.31527324525945, -337.7689565825897, -293.855251869135, -465.8598626912164, -650.0759396028516, 112.8908212308758, -682.9385242160292, -611.8708471541214, -318.9812003656698, -25.65905795987678, -630.2309314269143, 1125.1962834048215, 1180.4378738051587, -181.046607201006, 780.198020994022, -493.7615832249872, 869.1465999564608, -38.51695386222075, 766.7973406600413, -122.85144622093023, 390.3834846208939, -157.1556653830808, 402.0685760246323, -129.01320857198658, -372.20207221548253, -328.1120807464341, 830.4484040497987, 439.8761147148083, -154.01613644463887, 562.6556975331903, -398.5050083409245, -69.82692280632735, -760.7127079781086, -433.2226236481088, -352.1627227059171, -679.4671781575476, -535.3770714256353, 164.3148388585182, -304.72115951875503, -434.77205272329616, 527.0444654693625, -844.0279314101973, -373.8481954379993, 660.5604539523308, -250.0956087773271, -65.45976206041334, -646.7539355449845, 60.98343347136497, -610.3718178475582, 799.536753956467, 22.67301212771932, 1227.5360093232985, -578.2545398979763, 835.441022742066, -583.0785830495952, 784.7183943469504, -212.92645231754, -412.53856974480885, -274.28975835459454, 524.1435886614996, -431.4978928015504, 521.6625530740913, -229.41774168548983, 521.636018735775, -344.4526409242237, -187.19390239409276, -362.2695481502569, -288.432100572697, -553.5926261780817, -121.92364831971902, -364.78382447422564, 228.7332807691404, -422.9083687141645, -447.8350917721054, -562.026753879441, -559.2772847314727, -417.2448976074703, -83.2440061701914, -524.7956351893584], "episode_lengths": [97, 159, 133, 133, 121, 196, 128, 100, 245, 126, 116, 127, 108, 122, 115, 125, 110, 117, 119, 126, 108, 115, 102, 115, 112, 116, 149, 107, 110, 122, 137, 121, 100, 141, 137, 183, 117, 136, 99, 129, 101, 128, 117, 140, 111, 143, 111, 122, 158, 115, 200, 111, 109, 118, 88, 117, 131, 109, 195, 116, 118, 243, 130, 117, 120, 150, 116, 129, 97, 114, 124, 104, 137, 113, 142, 114, 158, 112, 113, 114, 119, 121, 152, 112, 127, 120, 115, 114, 125, 112, 105, 114, 218, 103, 105, 107, 112, 116, 111, 101], "policy_AGENT-3_reward": [7.426275760138978, -88.98281343954781, 159.86167571596005, -88.32145964317331, 182.75121270498383, -82.61812479486699, 145.32131137556144, 0.8159381851367717, -30.105124762814196, 227.53690723557375, -105.98760809465446, 191.31503388813758, -102.24543659385051, 176.58394777272807, -22.051027975301785, 115.95349179477694, -24.75576554574396, 122.75239246862236, -157.89551757162548, 193.84367996093104, -20.442008960902758, -51.03643948336253, -90.64998177244755, -64.39964343336999, -121.43485823130827, -127.47991270787789, 117.69495657106984, -106.79404020548066, -153.86709725571038, -29.754566521652464, -54.70784830364795, -103.43640025939422, 291.3097772232769, 326.63958063513684, -101.84395240680152, 190.0572429382435, -138.16769403677765, 209.4387207849266, -20.545081735712472, 209.83346333804062, -37.65161294463759, 76.08089376806366, -15.058241251012719, 97.22335450819374, -15.904953790505736, -31.20139959616426, -103.49635451682626, 189.16407450340716, -10.560939554937994, -13.019785751526982, -12.448954086751783, -178.3580116453865, -26.514773260632175, -183.89229545515838, -96.69858814388024, -76.71106767314244, -120.73469039053597, -95.75337974793692, -51.94489032013747, -68.6558500424529, -110.19268350655722, -43.813303853154494, -185.1242876054609, -102.07378783271727, 189.7243517844552, -75.74360531225331, -43.940501582431644, -204.3764180563085, -10.49182836935293, -191.9605697800037, 207.77752464571762, 3.615978835783508, 295.548717086812, -182.23856351933978, 230.2468656089239, -171.79677206715326, 178.14054299923293, -33.64103576212662, -149.62696742019494, -31.548847061491255, 107.0769241401394, -112.34386483834982, 155.8402248200887, -65.08258835914683, 164.8945101333485, -45.53643776300477, -71.34318986172823, -90.03954150274369, -67.11467665422157, -139.97931477188462, -53.186301048768634, -68.9150490580444, -44.272252808907965, -111.27777559692618, -118.20189975624774, -141.5927386457544, -116.83185011098513, -78.15890938597028, -48.13559955381588, -128.08813364681006], "policy_AGENT-0_reward": [38.75382449190289, 27.152925625174973, 37.5481636710172, -43.39438778654817, 168.12456871168968, 22.73957331882066, 81.37935920747742, -36.873678546763074, 206.11538377317515, 220.32552274998324, -145.56703296762055, 158.94480906767868, -74.14386996954156, 161.3285764713598, -161.99173447405408, 98.80406407897748, -66.72946715250599, 40.66671306332635, -200.3654284714671, 189.16766742349614, -36.41346749066739, -78.16458152822288, -88.46555046288336, -106.93864691862267, -99.12643034327951, -219.02688942458616, 86.21731358424138, -234.67227021003194, -115.58564990743521, -67.91506793796347, 24.050151244137233, -232.2003084823611, 294.04536686160554, 274.51538032745356, -6.348948990386511, 188.05456450868758, -174.93095228896254, 213.0132703385544, -6.278359620316175, 158.23055524695928, -29.141696098855718, 81.36580495603603, -91.57759828541626, 96.8720100446198, -38.29477793916616, -168.54656807066175, -72.98469078388028, 212.38213172419808, 206.1555987199404, -52.05459718425112, 289.5395087080688, -152.65838972565933, -4.025440000019412, -176.4391890649978, -72.90875085217259, -122.99800904415235, -237.04236685923192, -152.0502084462724, 121.2305313212857, -107.99831502564967, -93.26720223632292, 292.5339317895949, -246.66266931500934, -120.80084566192158, 156.81209675575866, -66.8030083212902, -12.193415244845333, -237.95035770530365, 27.98356050740401, -229.94645717226385, 196.8383406258371, -32.29288732343531, 297.2158755087758, -221.72774108350927, 183.89331035107259, -209.76302652095313, 238.00153185130895, -61.46078624970359, -188.74551880236174, -93.36264911898209, 110.69469917094011, -149.250837325874, 105.97079720486894, -111.29453019820076, 96.92347188817831, -148.93435630993417, -114.50090832681735, -129.11706979188796, -94.48192363292787, -122.57646710562398, -31.186320404862304, -136.10323081585753, 145.76029980030367, -100.98165370328971, -63.27961823050309, -142.28113642782722, -151.88509112935486, -152.40334497436874, -22.621756961469355, -134.79027015721303], "policy_AGENT-1_reward": [38.73567599267969, -88.42118267746127, 158.51398241026058, -87.7576711436171, 168.51683571927478, -82.05603456843298, 124.56416137608376, 12.817992701770217, 231.07485175299237, 228.26606784758334, -49.64209073069268, 159.0374861245343, -16.886605179123606, 163.23938272731144, -119.36996700686733, 116.52688884143492, -90.69498991925063, 81.21302451279078, -39.70555166422077, 237.09290718110864, -57.59206033046392, -35.77172487488921, -69.74668680784772, -61.2380978904748, -122.0101421553772, -126.91691974968668, -45.3027694136594, -106.23280093245504, -147.7702470610499, -110.27034049996723, 59.68706203471301, -102.87335236627479, 293.72853825158444, 282.87200984886346, -101.27799915625235, 218.80099814753717, -89.93782509706753, 222.40840557595422, -4.831188527438154, 205.30329771242853, -26.359982823691915, 124.23391289063862, -5.574977658971721, 111.65899232473521, -58.91152496114506, -141.1987099899072, -75.59803933206054, 217.224193623873, 254.88748189684608, -75.9196464332341, 298.06287303306215, -33.48955440839743, -19.426946394809963, -197.76114993610733, -131.4694729234262, -77.14239868673006, -120.16904319430057, -134.97202926493415, 147.01562170417705, -63.57527140619573, -114.37204226108616, 322.1115137920228, -204.32025649007855, -75.32696027861766, 159.19732172145245, -75.17939845135211, -4.401227548204645, -101.92110202520215, 27.973526442122616, -94.01740211650801, 199.9731729882302, 14.342301025104042, 304.75586472193345, -86.77096494332804, 225.88830212369132, -100.44237872786242, 201.549462116042, -84.3589389122405, -36.69939814201652, -117.80850034525363, 153.52574534459364, -84.7393362915235, 144.8361457558858, -26.302506200627892, 140.74554206320533, -104.39099817218278, -0.41987711675154316, -71.33839682511162, -66.55072834237042, -144.85244118483556, -30.30626051121511, -68.3492056683114, 171.5683902131767, -109.12140191146462, -117.63775617393141, -135.31031175770894, -116.26968753666249, -77.59019530613723, -19.078415751788075, -126.5763760605637], "policy_AGENT-2_reward": [29.17320359388597, 60.008664396593645, 112.12529727477667, -7.10625000889943, 161.41669306395755, -6.2163395933184304, 102.5694298147433, -37.429901787613815, -30.10837015317922, 219.755152417354, -50.078923048578034, 150.07781170619714, -17.32691003183135, 156.8231529099321, -21.89742747588867, 138.38181649823923, -24.81538141123207, 80.76506808806813, -40.301944391787295, 221.75567022012908, -20.49564212256074, -48.342527358784416, -88.90673753941103, -61.27886362666797, -123.28843196125094, -176.65221772070086, -45.718679510775985, -235.2394128680614, -194.647852929926, -111.04122540608653, -54.68842293507898, -191.72087031888398, 246.11260106835368, 296.4109029937057, 28.424293352434237, 183.28521539955443, -90.72511180217936, 224.286203257025, -6.86232397875399, 193.4300243626138, -29.698154353744886, 108.70287300615573, -44.94484818768007, 96.31421914708392, -15.901951881169651, -31.255394558749472, -76.0329961136672, 211.67800419832096, -10.606026347039911, -13.022107075626806, -12.497730121188603, -33.999052561480966, -19.85976315086572, -202.620073521845, -132.14581172862955, -75.31124730189207, -201.52107771347917, -152.60145396649182, -51.98642384680712, -64.49172304445736, -116.94012471932997, -43.787676259100905, -207.92071799964833, -75.64660166474283, 154.82668369066417, -32.369596692431585, -4.924617684931718, -102.50605775817041, 15.51817489119134, -94.44738877878225, 194.94771569668188, 37.007619590267126, 330.0155520057784, -87.51727035179957, 195.41254465837812, -101.07640573362674, 167.02685738036698, -33.4656913934693, -37.466685380235624, -31.56976182886763, 152.84622000582692, -85.16385434580273, 115.01538529324836, -26.738116927514273, 119.07249465104337, -45.59084867910172, -0.9299270887958428, -71.77454003051348, -60.28477194317709, -146.1844031157374, -7.244766354873271, -91.41633893201212, -44.32315643543169, -101.52753750248364, -148.7158176114229, -142.8425670481504, -174.29065595446997, -109.09244794099403, 6.591766096881887, -135.34085532477116]}, "sampler_perf": {"mean_env_wait_ms": 58.79431184226576, "mean_raw_obs_processing_ms": 2.5151225775291453, "mean_inference_ms": 2.5101536363186785, "mean_action_processing_ms": 0.1526774033424533}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 189000, "timers": {"sample_time_ms": 81814.781, "sample_throughput": 51.335, "load_time_ms": 15.088, "load_throughput": 278371.571, "learn_time_ms": 8156.256, "learn_throughput": 514.942, "update_time_ms": 8.245}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 22.73116111755371, "policy_loss": -0.0232501570135355, "vf_loss": 22.743459701538086, "vf_explained_var": 0.9817725419998169, "kl": 0.016224706545472145, "entropy": 1.0243505239486694, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 18.24681282043457, "policy_loss": -0.026080813258886337, "vf_loss": 18.264657974243164, "vf_explained_var": 0.9813982844352722, "kl": 0.01830178312957287, "entropy": 0.8138056993484497, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 1.0125000476837158, "cur_lr": 0.0010000000474974513, "total_loss": 19.29352378845215, "policy_loss": -0.0339539609849453, "vf_loss": 19.3158016204834, "vf_explained_var": 0.9816544055938721, "kl": 0.011532683856785297, "entropy": 1.151792049407959, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 15.553529739379883, "policy_loss": -0.03153242543339729, "vf_loss": 15.575355529785156, "vf_explained_var": 0.9869726896286011, "kl": 0.014378052204847336, "entropy": 0.9827370643615723, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 189000, "num_steps_trained": 189000}, "done": false, "episodes_total": 1585, "training_iteration": 45, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-37-07", "timestamp": 1624214227, "time_this_iter_s": 84.42082905769348, "time_total_s": 4809.025412082672, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd40420ef80>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd40420eb00>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd39406a680>, action_adapter=<function AgentSpec.<lambda> at 0x7fd39406aef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd384738a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fd384738d40>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd39406a680>, action_adapter=<function AgentSpec.<lambda> at 0x7fd39406aef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd384738a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fd384738d40>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd39406a680>, action_adapter=<function AgentSpec.<lambda> at 0x7fd39406aef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd384738a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fd384738d40>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd39406a680>, action_adapter=<function AgentSpec.<lambda> at 0x7fd39406aef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd384738a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fd384738d40>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd3846dcb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4809.025412082672, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 55.31157024793388, "ram_util_percent": 87.36446280991733}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1227.5360093232985, "episode_reward_min": -786.1131787811731, "episode_reward_mean": -81.10252099553671, "episode_len_mean": 124.08, "episodes_this_iter": 34, "policy_reward_min": {"AGENT-3": -255.94855627984234, "AGENT-0": -295.5708804505271, "AGENT-2": -235.2394128680614, "AGENT-1": -179.2475552864227}, "policy_reward_max": {"AGENT-3": 295.548717086812, "AGENT-0": 297.2158755087758, "AGENT-2": 330.0155520057784, "AGENT-1": 304.75586472193345}, "policy_reward_mean": {"AGENT-3": -20.497342783480086, "AGENT-0": -36.50719257428135, "AGENT-2": -15.722108489647693, "AGENT-1": -8.375877148127554}, "custom_metrics": {"mean_ego_speed_mean": 43.602225000000004, "mean_ego_speed_min": 30.49625, "mean_ego_speed_max": 52.21375, "distance_travelled_mean": 102.64922250000001, "distance_travelled_min": 53.86925, "distance_travelled_max": 124.828}, "hist_stats": {"episode_reward": [64.18536488927083, 691.6365545501556, 29.828795404964758, 402.53422018131727, -91.12929960113102, 647.1432237082522, -176.37774196661584, 596.4507471569674, -733.4113012836539, 596.6697174873976, -201.20233956104454, 109.05098341859151, -343.7657116080221, -90.72996028683353, -355.10102609859297, -37.16779835870098, -227.41760657987564, -480.0391185642249, -301.7821065056533, 391.48288349420375, -341.8520995444566, 344.8403443802696, -352.5348543770788, -418.25105588781133, -128.76121296290543, -50.99295559494677, 0.2062620286359902, -505.65655832631455, -709.8026636869275, -653.8511541807028, -229.84803464129965, -17.9795568273118, -626.2205601736591, -786.1131787811731, -65.45976206041334, -646.7539355449845, 60.98343347136497, -610.3718178475582, 799.536753956467, 22.67301212771932, 1227.5360093232985, -578.2545398979763, 835.441022742066, -583.0785830495952, 784.7183943469504, -212.92645231754, -412.53856974480885, -274.28975835459454, 524.1435886614996, -431.4978928015504, 521.6625530740913, -229.41774168548983, 521.636018735775, -344.4526409242237, -187.19390239409276, -362.2695481502569, -288.432100572697, -553.5926261780817, -121.92364831971902, -364.78382447422564, 228.7332807691404, -422.9083687141645, -447.8350917721054, -562.026753879441, -559.2772847314727, -417.2448976074703, -83.2440061701914, -524.7956351893584, 114.08897983860737, -90.24240609524018, 468.04911907201466, -226.57976858223816, 680.8093101999067, -148.15092563779757, 453.83426177386576, -60.66964944746994, 376.97674061017443, 895.8836502504956, -351.27565484154565, 659.3751407865471, -210.60282177434698, 657.9750598813317, -325.31015693211214, 469.6662612134287, -206.99560402873266, 325.3971981328075, -438.2684420991008, 841.8599247856655, -134.9431789045948, -213.31527324525945, -337.7689565825897, -293.855251869135, -465.8598626912164, -650.0759396028516, 112.8908212308758, -682.9385242160292, -611.8708471541214, -318.9812003656698, -25.65905795987678, -630.2309314269143], "episode_lengths": [143, 121, 117, 126, 99, 123, 143, 139, 123, 126, 115, 108, 117, 117, 116, 117, 120, 125, 112, 123, 117, 130, 116, 111, 135, 179, 134, 107, 124, 112, 133, 209, 117, 121, 116, 129, 97, 114, 124, 104, 137, 113, 142, 114, 158, 112, 113, 114, 119, 121, 152, 112, 127, 120, 115, 114, 125, 112, 105, 114, 218, 103, 105, 107, 112, 116, 111, 101, 97, 159, 133, 133, 121, 196, 128, 100, 245, 126, 116, 127, 108, 122, 115, 125, 110, 117, 119, 126, 108, 115, 102, 115, 112, 116, 149, 107, 110, 122, 137, 121], "policy_AGENT-3_reward": [-49.75936010646599, 151.19942550893612, -9.084072525051493, 104.13872259035408, -19.38193415953412, 174.96918431563003, -91.61878180494486, 121.71615533714487, -255.94855627984234, 158.97228682070616, -91.95473674749022, 52.25620228752539, -36.829635827845834, -42.08920871192537, -48.316849797025284, 15.52421534609634, -40.72483437281551, -194.41124731474932, -30.80272893656179, 86.37584313610965, -118.48045514513086, 94.85533825865745, -55.233314554484, -118.74779053266097, 58.617172909125756, 57.75281288377419, 85.74789924924517, -126.35935424749849, -105.16355918510402, -155.68644551050664, -91.28391021624337, -83.76562630853829, -104.59291889930753, -179.9350249728085, -43.940501582431644, -204.3764180563085, -10.49182836935293, -191.9605697800037, 207.77752464571762, 3.615978835783508, 295.548717086812, -182.23856351933978, 230.2468656089239, -171.79677206715326, 178.14054299923293, -33.64103576212662, -149.62696742019494, -31.548847061491255, 107.0769241401394, -112.34386483834982, 155.8402248200887, -65.08258835914683, 164.8945101333485, -45.53643776300477, -71.34318986172823, -90.03954150274369, -67.11467665422157, -139.97931477188462, -53.186301048768634, -68.9150490580444, -44.272252808907965, -111.27777559692618, -118.20189975624774, -141.5927386457544, -116.83185011098513, -78.15890938597028, -48.13559955381588, -128.08813364681006, 7.426275760138978, -88.98281343954781, 159.86167571596005, -88.32145964317331, 182.75121270498383, -82.61812479486699, 145.32131137556144, 0.8159381851367717, -30.105124762814196, 227.53690723557375, -105.98760809465446, 191.31503388813758, -102.24543659385051, 176.58394777272807, -22.051027975301785, 115.95349179477694, -24.75576554574396, 122.75239246862236, -157.89551757162548, 193.84367996093104, -20.442008960902758, -51.03643948336253, -90.64998177244755, -64.39964343336999, -121.43485823130827, -127.47991270787789, 117.69495657106984, -106.79404020548066, -153.86709725571038, -29.754566521652464, -54.70784830364795, -103.43640025939422], "policy_AGENT-0_reward": [65.05780857050289, 151.0042617515562, -10.728741692632923, 100.1558882471884, -47.22596414374728, 158.38000546970235, -14.094501591860443, 140.3922409688298, -295.5708804505271, 169.5570446761825, 3.247475515563732, 37.51856968163779, -157.4233713075213, -84.1264581488418, -151.3279768833919, -57.456515604689905, -70.11201148593057, -230.16979657218627, -124.68134520823435, 85.84633346928703, -157.1959335109052, 72.14343694350924, -143.43616002520145, -85.62298826663937, 25.014828686060916, 29.773864914284445, 118.68978220995493, -128.94736609603837, -270.06367551674873, -147.20183680062883, -92.24371895218562, 61.22592473216638, -230.26118758775408, -234.73098001812016, -12.193415244845333, -237.95035770530365, 27.98356050740401, -229.94645717226385, 196.8383406258371, -32.29288732343531, 297.2158755087758, -221.72774108350927, 183.89331035107259, -209.76302652095313, 238.00153185130895, -61.46078624970359, -188.74551880236174, -93.36264911898209, 110.69469917094011, -149.250837325874, 105.97079720486894, -111.29453019820076, 96.92347188817831, -148.93435630993417, -114.50090832681735, -129.11706979188796, -94.48192363292787, -122.57646710562398, -31.186320404862304, -136.10323081585753, 145.76029980030367, -100.98165370328971, -63.27961823050309, -142.28113642782722, -151.88509112935486, -152.40334497436874, -22.621756961469355, -134.79027015721303, 38.75382449190289, 27.152925625174973, 37.5481636710172, -43.39438778654817, 168.12456871168968, 22.73957331882066, 81.37935920747742, -36.873678546763074, 206.11538377317515, 220.32552274998324, -145.56703296762055, 158.94480906767868, -74.14386996954156, 161.3285764713598, -161.99173447405408, 98.80406407897748, -66.72946715250599, 40.66671306332635, -200.3654284714671, 189.16766742349614, -36.41346749066739, -78.16458152822288, -88.46555046288336, -106.93864691862267, -99.12643034327951, -219.02688942458616, 86.21731358424138, -234.67227021003194, -115.58564990743521, -67.91506793796347, 24.050151244137233, -232.2003084823611], "policy_AGENT-2_reward": [-49.69211816508781, 189.98807384505076, 37.09348678488773, 74.20526335263074, -12.71063915652313, 154.7520300518595, 20.390810318402334, 153.65935007004518, -91.29741411600799, 122.80812805571279, -21.107536547611925, 8.801245122819012, -36.79866390745954, 17.522724398179534, -48.13155662644441, 15.45966521485051, -40.71495826781351, -27.980143236322263, -30.85758292665249, 127.74709040561974, -33.327262641918104, 64.93828441821447, -55.25687808966453, -102.8296971075057, -106.51150834225068, -69.63977228899053, -102.42117410860293, -125.75133165232832, -229.98411524370536, -197.61726881513306, -8.295722443931233, -83.68159951217109, -187.33991321098387, -192.19961850382222, -4.924617684931718, -102.50605775817041, 15.51817489119134, -94.44738877878225, 194.94771569668188, 37.007619590267126, 330.0155520057784, -87.51727035179957, 195.41254465837812, -101.07640573362674, 167.02685738036698, -33.4656913934693, -37.466685380235624, -31.56976182886763, 152.84622000582692, -85.16385434580273, 115.01538529324836, -26.738116927514273, 119.07249465104337, -45.59084867910172, -0.9299270887958428, -71.77454003051348, -60.28477194317709, -146.1844031157374, -7.244766354873271, -91.41633893201212, -44.32315643543169, -101.52753750248364, -148.7158176114229, -142.8425670481504, -174.29065595446997, -109.09244794099403, 6.591766096881887, -135.34085532477116, 29.17320359388597, 60.008664396593645, 112.12529727477667, -7.10625000889943, 161.41669306395755, -6.2163395933184304, 102.5694298147433, -37.429901787613815, -30.10837015317922, 219.755152417354, -50.078923048578034, 150.07781170619714, -17.32691003183135, 156.8231529099321, -21.89742747588867, 138.38181649823923, -24.81538141123207, 80.76506808806813, -40.301944391787295, 221.75567022012908, -20.49564212256074, -48.342527358784416, -88.90673753941103, -61.27886362666797, -123.28843196125094, -176.65221772070086, -45.718679510775985, -235.2394128680614, -194.647852929926, -111.04122540608653, -54.68842293507898, -191.72087031888398], "policy_AGENT-1_reward": [98.57903459032184, 199.44479344461155, 12.548122837761438, 124.03434599114438, -11.810762141326794, 159.04200387106084, -91.05526888821333, 180.68300078094708, -90.59445043727732, 145.3322579347963, -91.38754178150594, 10.474966326609193, -112.71404056519498, 17.962982175754142, -107.32464279173143, -10.695163314957934, -75.86580245331595, -27.477931440966938, -115.4404494342048, 91.51361648318712, -32.84844824650233, 112.90328475988835, -98.60850170772841, -111.05057998100546, -105.88170621584183, -68.8798611040148, -101.81024532196125, -124.59850633044876, -104.59131374136948, -153.34560305443404, -38.02468302893934, 88.24174426123116, -104.02654047561336, -179.2475552864227, -4.401227548204645, -101.92110202520215, 27.973526442122616, -94.01740211650801, 199.9731729882302, 14.342301025104042, 304.75586472193345, -86.77096494332804, 225.88830212369132, -100.44237872786242, 201.549462116042, -84.3589389122405, -36.69939814201652, -117.80850034525363, 153.52574534459364, -84.7393362915235, 144.8361457558858, -26.302506200627892, 140.74554206320533, -104.39099817218278, -0.41987711675154316, -71.33839682511162, -66.55072834237042, -144.85244118483556, -30.30626051121511, -68.3492056683114, 171.5683902131767, -109.12140191146462, -117.63775617393141, -135.31031175770894, -116.26968753666249, -77.59019530613723, -19.078415751788075, -126.5763760605637, 38.73567599267969, -88.42118267746127, 158.51398241026058, -87.7576711436171, 168.51683571927478, -82.05603456843298, 124.56416137608376, 12.817992701770217, 231.07485175299237, 228.26606784758334, -49.64209073069268, 159.0374861245343, -16.886605179123606, 163.23938272731144, -119.36996700686733, 116.52688884143492, -90.69498991925063, 81.21302451279078, -39.70555166422077, 237.09290718110864, -57.59206033046392, -35.77172487488921, -69.74668680784772, -61.2380978904748, -122.0101421553772, -126.91691974968668, -45.3027694136594, -106.23280093245504, -147.7702470610499, -110.27034049996723, 59.68706203471301, -102.87335236627479]}, "sampler_perf": {"mean_env_wait_ms": 58.525939731598974, "mean_raw_obs_processing_ms": 2.5071760769148383, "mean_inference_ms": 2.4999993700175525, "mean_action_processing_ms": 0.1521608141697394}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 193200, "timers": {"sample_time_ms": 80807.824, "sample_throughput": 51.975, "load_time_ms": 15.188, "load_throughput": 276533.625, "learn_time_ms": 8107.161, "learn_throughput": 518.06, "update_time_ms": 8.749}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 29.44353485107422, "policy_loss": -0.024052903056144714, "vf_loss": 29.457223892211914, "vf_explained_var": 0.9755103588104248, "kl": 0.015351371839642525, "entropy": 1.0792770385742188, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 20.027799606323242, "policy_loss": -0.028846226632595062, "vf_loss": 20.049068450927734, "vf_explained_var": 0.9754812717437744, "kl": 0.0168323777616024, "entropy": 0.8204190731048584, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 1.0125000476837158, "cur_lr": 0.0010000000474974513, "total_loss": 21.09790802001953, "policy_loss": -0.04097334295511246, "vf_loss": 21.125898361206055, "vf_explained_var": 0.9773138165473938, "kl": 0.012823622673749924, "entropy": 1.1379098892211914, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 23.757997512817383, "policy_loss": -0.030120262876152992, "vf_loss": 23.779233932495117, "vf_explained_var": 0.9798504114151001, "kl": 0.013158515095710754, "entropy": 0.9980573654174805, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 193200, "num_steps_trained": 193200}, "done": false, "episodes_total": 1619, "training_iteration": 46, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-38-33", "timestamp": 1624214313, "time_this_iter_s": 85.49528002738953, "time_total_s": 4894.520692110062, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd3846f74d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd3846f73b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd3846f7170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd3846f7050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd3846f7830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd3846f7950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd3846f7170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd3846f7050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd3846f7830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd3846f7950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd3846f7170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd3846f7050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd3846f7830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd3846f7950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd3846f7170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd3846f7050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd3846f7830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd3846f7950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd3846f75f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4894.520692110062, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 55.5155737704918, "ram_util_percent": 87.38196721311478}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1285.6284695077889, "episode_reward_min": -786.1131787811731, "episode_reward_mean": -53.54962588249075, "episode_len_mean": 127.11, "episodes_this_iter": 32, "policy_reward_min": {"AGENT-3": -255.94855627984234, "AGENT-0": -295.5708804505271, "AGENT-1": -179.2475552864227, "AGENT-2": -235.2394128680614}, "policy_reward_max": {"AGENT-3": 227.53690723557375, "AGENT-0": 667.9718625685636, "AGENT-1": 698.0163492849946, "AGENT-2": 221.75567022012908}, "policy_reward_mean": {"AGENT-3": -11.642983352046818, "AGENT-0": -19.969985096822366, "AGENT-1": -6.183441324096996, "AGENT-2": -15.753216109524631}, "custom_metrics": {"mean_ego_speed_mean": 43.5738, "mean_ego_speed_min": 33.11, "mean_ego_speed_max": 52.322250000000004, "distance_travelled_mean": 102.17577750000001, "distance_travelled_min": 53.86925, "distance_travelled_max": 124.79875}, "hist_stats": {"episode_reward": [46.27997300370402, -140.00880204053072, 90.69578680049977, 20.405028366588045, 492.09867966775806, -189.08417256919648, 103.26800103860523, 1285.6284695077889, 876.549485475516, 122.37742854704796, 393.2359224919318, -289.3399648663307, 719.6751748016162, -411.79120269332145, 439.4381558335663, -582.9447693260596, 343.2814593353451, -170.81076840068323, -236.9802180385968, -322.00201072719557, 151.41934428533222, -583.2734981112668, -477.7546026120251, -226.926448838165, -231.10048291148988, -214.14965542577505, -450.61472815580066, -361.08634518085483, -663.9302771059824, -191.4302407041627, 300.0713855972624, -35.37226955462083, -83.2440061701914, -524.7956351893584, 114.08897983860737, -90.24240609524018, 468.04911907201466, -226.57976858223816, 680.8093101999067, -148.15092563779757, 453.83426177386576, -60.66964944746994, 376.97674061017443, 895.8836502504956, -351.27565484154565, 659.3751407865471, -210.60282177434698, 657.9750598813317, -325.31015693211214, 469.6662612134287, -206.99560402873266, 325.3971981328075, -438.2684420991008, 841.8599247856655, -134.9431789045948, -213.31527324525945, -337.7689565825897, -293.855251869135, -465.8598626912164, -650.0759396028516, 112.8908212308758, -682.9385242160292, -611.8708471541214, -318.9812003656698, -25.65905795987678, -630.2309314269143, 64.18536488927083, 691.6365545501556, 29.828795404964758, 402.53422018131727, -91.12929960113102, 647.1432237082522, -176.37774196661584, 596.4507471569674, -733.4113012836539, 596.6697174873976, -201.20233956104454, 109.05098341859151, -343.7657116080221, -90.72996028683353, -355.10102609859297, -37.16779835870098, -227.41760657987564, -480.0391185642249, -301.7821065056533, 391.48288349420375, -341.8520995444566, 344.8403443802696, -352.5348543770788, -418.25105588781133, -128.76121296290543, -50.99295559494677, 0.2062620286359902, -505.65655832631455, -709.8026636869275, -653.8511541807028, -229.84803464129965, -17.9795568273118, -626.2205601736591, -786.1131787811731], "episode_lengths": [128, 148, 106, 99, 139, 123, 98, 360, 125, 113, 129, 115, 130, 120, 165, 122, 121, 103, 113, 112, 106, 118, 106, 120, 165, 122, 103, 96, 121, 122, 189, 150, 111, 101, 97, 159, 133, 133, 121, 196, 128, 100, 245, 126, 116, 127, 108, 122, 115, 125, 110, 117, 119, 126, 108, 115, 102, 115, 112, 116, 149, 107, 110, 122, 137, 121, 143, 121, 117, 126, 99, 123, 143, 139, 123, 126, 115, 108, 117, 117, 116, 117, 120, 125, 112, 123, 117, 130, 116, 111, 135, 179, 134, 107, 124, 112, 133, 209, 117, 121], "policy_AGENT-3_reward": [8.827042737235407, -87.43530070964906, 14.390620511821618, -1.080611693533862, 146.22091498255242, -81.13235770072419, 8.531752884435734, -40.188590666163634, 211.70576744638552, -39.912774455565454, 101.86482057130193, -110.62112898064638, 187.26222266743076, -55.59479047133947, 135.44724566798587, -160.2075754863095, 120.38314323719669, -13.18299771413477, -23.692618705098262, -51.912568898087216, 65.83906583529199, -102.931741904861, -138.38822168579958, -56.45734364514884, -3.4479744343430374, -56.4944935133756, -133.52247052435953, -61.63724691262835, -148.29565712595706, -51.37290323911388, 202.34272206861084, 99.77338748887624, -48.13559955381588, -128.08813364681006, 7.426275760138978, -88.98281343954781, 159.86167571596005, -88.32145964317331, 182.75121270498383, -82.61812479486699, 145.32131137556144, 0.8159381851367717, -30.105124762814196, 227.53690723557375, -105.98760809465446, 191.31503388813758, -102.24543659385051, 176.58394777272807, -22.051027975301785, 115.95349179477694, -24.75576554574396, 122.75239246862236, -157.89551757162548, 193.84367996093104, -20.442008960902758, -51.03643948336253, -90.64998177244755, -64.39964343336999, -121.43485823130827, -127.47991270787789, 117.69495657106984, -106.79404020548066, -153.86709725571038, -29.754566521652464, -54.70784830364795, -103.43640025939422, -49.75936010646599, 151.19942550893612, -9.084072525051493, 104.13872259035408, -19.38193415953412, 174.96918431563003, -91.61878180494486, 121.71615533714487, -255.94855627984234, 158.97228682070616, -91.95473674749022, 52.25620228752539, -36.829635827845834, -42.08920871192537, -48.316849797025284, 15.52421534609634, -40.72483437281551, -194.41124731474932, -30.80272893656179, 86.37584313610965, -118.48045514513086, 94.85533825865745, -55.233314554484, -118.74779053266097, 58.617172909125756, 57.75281288377419, 85.74789924924517, -126.35935424749849, -105.16355918510402, -155.68644551050664, -91.28391021624337, -83.76562630853829, -104.59291889930753, -179.9350249728085], "policy_AGENT-0_reward": [-24.339028141223274, 0.09018320178003592, 51.541685252590355, 6.180075626321543, 88.90194078941573, -0.09486421185779292, 32.902655187683415, 667.9718625685636, 222.05948395810682, 114.55597399647235, 86.35217866800073, -81.19799362613429, 151.4436852457475, -172.08509545827349, 81.89819640224744, -216.71931432278714, 47.4844230703668, -82.73074793857477, -82.81629332117586, -96.04340347079713, 40.12823191169276, -210.30318594160116, -103.61566875831627, -86.75059624369462, -26.397151740879263, -81.9482514212865, -92.80675736223144, -76.76542799832063, -203.36424169284868, -77.08817606823962, 179.0209903260871, 65.81793856906685, -22.621756961469355, -134.79027015721303, 38.75382449190289, 27.152925625174973, 37.5481636710172, -43.39438778654817, 168.12456871168968, 22.73957331882066, 81.37935920747742, -36.873678546763074, 206.11538377317515, 220.32552274998324, -145.56703296762055, 158.94480906767868, -74.14386996954156, 161.3285764713598, -161.99173447405408, 98.80406407897748, -66.72946715250599, 40.66671306332635, -200.3654284714671, 189.16766742349614, -36.41346749066739, -78.16458152822288, -88.46555046288336, -106.93864691862267, -99.12643034327951, -219.02688942458616, 86.21731358424138, -234.67227021003194, -115.58564990743521, -67.91506793796347, 24.050151244137233, -232.2003084823611, 65.05780857050289, 151.0042617515562, -10.728741692632923, 100.1558882471884, -47.22596414374728, 158.38000546970235, -14.094501591860443, 140.3922409688298, -295.5708804505271, 169.5570446761825, 3.247475515563732, 37.51856968163779, -157.4233713075213, -84.1264581488418, -151.3279768833919, -57.456515604689905, -70.11201148593057, -230.16979657218627, -124.68134520823435, 85.84633346928703, -157.1959335109052, 72.14343694350924, -143.43616002520145, -85.62298826663937, 25.014828686060916, 29.773864914284445, 118.68978220995493, -128.94736609603837, -270.06367551674873, -147.20183680062883, -92.24371895218562, 61.22592473216638, -230.26118758775408, -234.73098001812016], "policy_AGENT-1_reward": [31.11813059585262, -86.8701493735594, 51.46985952266675, 9.6861886203933, 129.46733489401817, -80.5704181433037, 32.717451120143785, 698.0163492849946, 223.93360941781881, 87.66970887184407, 124.66319089574775, -48.43447747431068, 198.99904138264404, -128.57186729403278, 111.35474441399447, -174.73999056345832, 88.08808095735716, -61.66309501539018, -106.8604338609639, -122.06988499623014, 22.882818252979106, -102.36742083988784, -131.58041239945618, -40.00056032463447, -100.3236883507313, -35.47445134953552, -131.05458578966474, -110.95068124845494, -155.09888680369596, -28.010995286403826, -40.43019543362561, -100.19129424552469, -19.078415751788075, -126.5763760605637, 38.73567599267969, -88.42118267746127, 158.51398241026058, -87.7576711436171, 168.51683571927478, -82.05603456843298, 124.56416137608376, 12.817992701770217, 231.07485175299237, 228.26606784758334, -49.64209073069268, 159.0374861245343, -16.886605179123606, 163.23938272731144, -119.36996700686733, 116.52688884143492, -90.69498991925063, 81.21302451279078, -39.70555166422077, 237.09290718110864, -57.59206033046392, -35.77172487488921, -69.74668680784772, -61.2380978904748, -122.0101421553772, -126.91691974968668, -45.3027694136594, -106.23280093245504, -147.7702470610499, -110.27034049996723, 59.68706203471301, -102.87335236627479, 98.57903459032184, 199.44479344461155, 12.548122837761438, 124.03434599114438, -11.810762141326794, 159.04200387106084, -91.05526888821333, 180.68300078094708, -90.59445043727732, 145.3322579347963, -91.38754178150594, 10.474966326609193, -112.71404056519498, 17.962982175754142, -107.32464279173143, -10.695163314957934, -75.86580245331595, -27.477931440966938, -115.4404494342048, 91.51361648318712, -32.84844824650233, 112.90328475988835, -98.60850170772841, -111.05057998100546, -105.88170621584183, -68.8798611040148, -101.81024532196125, -124.59850633044876, -104.59131374136948, -153.34560305443404, -38.02468302893934, 88.24174426123116, -104.02654047561336, -179.2475552864227], "policy_AGENT-2_reward": [30.673827811839573, 34.20646484089745, -26.706378486578874, 5.619375813407261, 127.50848900177215, -27.286532513310963, 29.116141846342263, -40.17115167960832, 218.85062465320453, -39.935479865703044, 80.35573235688133, -49.086364785239, 181.97022550579425, -55.53944946967567, 110.73796934933856, -31.27788895350476, 87.32581207042463, -13.233927732583512, -23.61087215135875, -51.97615336208096, 22.569228285368304, -167.6711494249167, -104.17029976845325, -43.71794862468706, -100.93166838553664, -40.23245914157766, -93.23091447954478, -111.73298902145065, -157.17149148347977, -34.95816611040529, -40.862131363810214, -100.77230136703938, 6.591766096881887, -135.34085532477116, 29.17320359388597, 60.008664396593645, 112.12529727477667, -7.10625000889943, 161.41669306395755, -6.2163395933184304, 102.5694298147433, -37.429901787613815, -30.10837015317922, 219.755152417354, -50.078923048578034, 150.07781170619714, -17.32691003183135, 156.8231529099321, -21.89742747588867, 138.38181649823923, -24.81538141123207, 80.76506808806813, -40.301944391787295, 221.75567022012908, -20.49564212256074, -48.342527358784416, -88.90673753941103, -61.27886362666797, -123.28843196125094, -176.65221772070086, -45.718679510775985, -235.2394128680614, -194.647852929926, -111.04122540608653, -54.68842293507898, -191.72087031888398, -49.69211816508781, 189.98807384505076, 37.09348678488773, 74.20526335263074, -12.71063915652313, 154.7520300518595, 20.390810318402334, 153.65935007004518, -91.29741411600799, 122.80812805571279, -21.107536547611925, 8.801245122819012, -36.79866390745954, 17.522724398179534, -48.13155662644441, 15.45966521485051, -40.71495826781351, -27.980143236322263, -30.85758292665249, 127.74709040561974, -33.327262641918104, 64.93828441821447, -55.25687808966453, -102.8296971075057, -106.51150834225068, -69.63977228899053, -102.42117410860293, -125.75133165232832, -229.98411524370536, -197.61726881513306, -8.295722443931233, -83.68159951217109, -187.33991321098387, -192.19961850382222]}, "sampler_perf": {"mean_env_wait_ms": 58.24076208916449, "mean_raw_obs_processing_ms": 2.496390159194681, "mean_inference_ms": 2.4905037210895613, "mean_action_processing_ms": 0.15164189474879416}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 197400, "timers": {"sample_time_ms": 79341.367, "sample_throughput": 52.936, "load_time_ms": 14.684, "load_throughput": 286033.78, "learn_time_ms": 7819.273, "learn_throughput": 537.134, "update_time_ms": 8.23}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 25.720800399780273, "policy_loss": -0.02901080809533596, "vf_loss": 25.74113655090332, "vf_explained_var": 0.9798686504364014, "kl": 0.012847752310335636, "entropy": 1.052868127822876, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 16.438072204589844, "policy_loss": -0.017275379970669746, "vf_loss": 16.446794509887695, "vf_explained_var": 0.9840801954269409, "kl": 0.019014567136764526, "entropy": 0.7666727304458618, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 1.0125000476837158, "cur_lr": 0.0010000000474974513, "total_loss": 21.58448028564453, "policy_loss": -0.025925949215888977, "vf_loss": 21.595319747924805, "vf_explained_var": 0.9764763116836548, "kl": 0.014901366084814072, "entropy": 1.152916431427002, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 25.091350555419922, "policy_loss": -0.029095187783241272, "vf_loss": 25.11250114440918, "vf_explained_var": 0.9785957336425781, "kl": 0.01177884079515934, "entropy": 0.9391778707504272, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 197400, "num_steps_trained": 197400}, "done": false, "episodes_total": 1651, "training_iteration": 47, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-39-56", "timestamp": 1624214396, "time_this_iter_s": 82.66441750526428, "time_total_s": 4977.185109615326, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd384723b90>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd4042bdef0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40420e710>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40420e9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420e950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404072d40>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40420e710>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40420e9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420e950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404072d40>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40420e710>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40420e9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420e950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404072d40>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd40420e710>, action_adapter=<function AgentSpec.<lambda> at 0x7fd40420e9e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd40420e950>, info_adapter=<function AgentSpec.<lambda> at 0x7fd404072d40>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd3846f7b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4977.185109615326, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 55.36271186440678, "ram_util_percent": 87.55169491525426}, "trial_id": "38b86_00000", "experiment_tag": "0"}
{"episode_reward_max": 1287.4073812561205, "episode_reward_min": -786.1131787811731, "episode_reward_mean": -11.432494714118041, "episode_len_mean": 130.22, "episodes_this_iter": 32, "policy_reward_min": {"AGENT-3": -255.94855627984234, "AGENT-0": -295.5708804505271, "AGENT-1": -179.2475552864227, "AGENT-2": -229.98411524370536}, "policy_reward_max": {"AGENT-3": 239.77904854138714, "AGENT-0": 667.9718625685636, "AGENT-1": 698.0163492849946, "AGENT-2": 231.14880271676108}, "policy_reward_mean": {"AGENT-3": -0.3877010659631972, "AGENT-0": -5.498331481626715, "AGENT-1": 6.668254780900929, "AGENT-2": -12.214716947429032}, "custom_metrics": {"mean_ego_speed_mean": 43.10086999999999, "mean_ego_speed_min": 23.030250000000002, "mean_ego_speed_max": 52.447500000000005, "distance_travelled_mean": 102.23343499999999, "distance_travelled_min": 57.74875, "distance_travelled_max": 124.80600000000001}, "hist_stats": {"episode_reward": [930.4696227249468, -197.67878227656823, 306.0131308367641, 526.818499365131, 319.18305607978795, 0.6422025831107092, 613.7371880604001, -220.11079941636876, 214.27764625429595, 710.5281215650041, -143.70758354458616, 223.59822647526872, -416.30668709079936, 431.0029391515816, -293.2422646771892, 365.9868685652099, -347.2860905239992, 677.3125070192466, -352.8867775336625, 531.8036045463916, -277.29655585223134, 717.4683751966485, -75.62850977317333, 1287.4073812561205, -192.24512999099062, 295.2500100700729, -53.26168881505818, -540.3433936361348, -152.28412807577226, -431.5082209888717, -659.8091938031812, 94.87190543199833, -25.65905795987678, -630.2309314269143, 64.18536488927083, 691.6365545501556, 29.828795404964758, 402.53422018131727, -91.12929960113102, 647.1432237082522, -176.37774196661584, 596.4507471569674, -733.4113012836539, 596.6697174873976, -201.20233956104454, 109.05098341859151, -343.7657116080221, -90.72996028683353, -355.10102609859297, -37.16779835870098, -227.41760657987564, -480.0391185642249, -301.7821065056533, 391.48288349420375, -341.8520995444566, 344.8403443802696, -352.5348543770788, -418.25105588781133, -128.76121296290543, -50.99295559494677, 0.2062620286359902, -505.65655832631455, -709.8026636869275, -653.8511541807028, -229.84803464129965, -17.9795568273118, -626.2205601736591, -786.1131787811731, 46.27997300370402, -140.00880204053072, 90.69578680049977, 20.405028366588045, 492.09867966775806, -189.08417256919648, 103.26800103860523, 1285.6284695077889, 876.549485475516, 122.37742854704796, 393.2359224919318, -289.3399648663307, 719.6751748016162, -411.79120269332145, 439.4381558335663, -582.9447693260596, 343.2814593353451, -170.81076840068323, -236.9802180385968, -322.00201072719557, 151.41934428533222, -583.2734981112668, -477.7546026120251, -226.926448838165, -231.10048291148988, -214.14965542577505, -450.61472815580066, -361.08634518085483, -663.9302771059824, -191.4302407041627, 300.0713855972624, -35.37226955462083], "episode_lengths": [126, 98, 126, 278, 124, 110, 119, 180, 124, 129, 107, 116, 117, 119, 115, 118, 114, 125, 111, 123, 88, 124, 108, 399, 122, 153, 127, 119, 146, 114, 111, 112, 137, 121, 143, 121, 117, 126, 99, 123, 143, 139, 123, 126, 115, 108, 117, 117, 116, 117, 120, 125, 112, 123, 117, 130, 116, 111, 135, 179, 134, 107, 124, 112, 133, 209, 117, 121, 128, 148, 106, 99, 139, 123, 98, 360, 125, 113, 129, 115, 130, 120, 165, 122, 121, 103, 113, 112, 106, 118, 106, 120, 165, 122, 103, 96, 121, 122, 189, 150], "policy_AGENT-3_reward": [239.77904854138714, -61.876945146519795, 103.0560362453322, -40.374819700941245, 118.33866268623036, 2.595646488126725, 161.24392557249502, -104.61813932507621, 100.33444844742228, 171.93114428113148, -15.59062214210386, 78.5953330380585, -52.61218987132684, 111.96121335781078, -25.0229393860867, 113.1267444575796, -105.62020540673086, 183.71877784045842, -143.49909133856568, 174.24763328261412, -75.43685470103118, 183.5301126368996, -9.472965685663013, -36.37490561741323, -56.45116889011571, 212.7459137393305, 89.32960254686014, -103.29695685886897, 48.999661036205765, -112.79549790290179, -116.35714411309915, 88.20643373616728, -54.70784830364795, -103.43640025939422, -49.75936010646599, 151.19942550893612, -9.084072525051493, 104.13872259035408, -19.38193415953412, 174.96918431563003, -91.61878180494486, 121.71615533714487, -255.94855627984234, 158.97228682070616, -91.95473674749022, 52.25620228752539, -36.829635827845834, -42.08920871192537, -48.316849797025284, 15.52421534609634, -40.72483437281551, -194.41124731474932, -30.80272893656179, 86.37584313610965, -118.48045514513086, 94.85533825865745, -55.233314554484, -118.74779053266097, 58.617172909125756, 57.75281288377419, 85.74789924924517, -126.35935424749849, -105.16355918510402, -155.68644551050664, -91.28391021624337, -83.76562630853829, -104.59291889930753, -179.9350249728085, 8.827042737235407, -87.43530070964906, 14.390620511821618, -1.080611693533862, 146.22091498255242, -81.13235770072419, 8.531752884435734, -40.188590666163634, 211.70576744638552, -39.912774455565454, 101.86482057130193, -110.62112898064638, 187.26222266743076, -55.59479047133947, 135.44724566798587, -160.2075754863095, 120.38314323719669, -13.18299771413477, -23.692618705098262, -51.912568898087216, 65.83906583529199, -102.931741904861, -138.38822168579958, -56.45734364514884, -3.4479744343430374, -56.4944935133756, -133.52247052435953, -61.63724691262835, -148.29565712595706, -51.37290323911388, 202.34272206861084, 99.77338748887624], "policy_AGENT-0_reward": [228.3861110676513, -37.63963976533828, 21.124030113744233, 285.84827566473194, 37.80761289096644, -28.779726523897875, 153.98500833430515, -15.759829366042723, 11.083970301641571, 181.1933631821435, -45.65414516697514, 2.810497948157021, -176.52139394154503, 113.28019755798893, -143.62300996351965, 40.25563041117789, -148.31261921812984, 135.70425376489052, -113.52553865062764, 56.17506724555332, -113.68902002153266, 180.7577913402425, -17.78200816531393, 666.9693543562338, -78.33214270230556, 178.83392191254165, 52.66930954902469, -143.47393236441627, 16.898699776648876, -152.8300468513351, -213.50223398242343, 117.28983731277017, 24.050151244137233, -232.2003084823611, 65.05780857050289, 151.0042617515562, -10.728741692632923, 100.1558882471884, -47.22596414374728, 158.38000546970235, -14.094501591860443, 140.3922409688298, -295.5708804505271, 169.5570446761825, 3.247475515563732, 37.51856968163779, -157.4233713075213, -84.1264581488418, -151.3279768833919, -57.456515604689905, -70.11201148593057, -230.16979657218627, -124.68134520823435, 85.84633346928703, -157.1959335109052, 72.14343694350924, -143.43616002520145, -85.62298826663937, 25.014828686060916, 29.773864914284445, 118.68978220995493, -128.94736609603837, -270.06367551674873, -147.20183680062883, -92.24371895218562, 61.22592473216638, -230.26118758775408, -234.73098001812016, -24.339028141223274, 0.09018320178003592, 51.541685252590355, 6.180075626321543, 88.90194078941573, -0.09486421185779292, 32.902655187683415, 667.9718625685636, 222.05948395810682, 114.55597399647235, 86.35217866800073, -81.19799362613429, 151.4436852457475, -172.08509545827349, 81.89819640224744, -216.71931432278714, 47.4844230703668, -82.73074793857477, -82.81629332117586, -96.04340347079713, 40.12823191169276, -210.30318594160116, -103.61566875831627, -86.75059624369462, -26.397151740879263, -81.9482514212865, -92.80675736223144, -76.76542799832063, -203.36424169284868, -77.08817606823962, 179.0209903260871, 65.81793856906685], "policy_AGENT-1_reward": [231.155660399148, -60.08531551333593, 114.46167260107133, 321.7669588760738, 82.91563659200645, 15.12168024496967, 154.34194454788607, -104.05268070750189, 51.64772418181393, 181.55027113246743, -66.81773240946085, 92.07301220777862, -134.52432792274462, 118.64675649254644, -99.82608014800861, 129.48870734155108, -46.46025565305856, 184.29366961979528, -47.63690243639483, 154.5866731870664, -43.86385867528344, 181.10705206787932, -38.91954352794958, 693.1726513883364, -25.591265878078424, -47.89448469850376, -97.41499446474022, -102.73186100887166, -108.75237922140502, -109.30494614193996, -115.79126845157602, -54.93398075180889, 59.68706203471301, -102.87335236627479, 98.57903459032184, 199.44479344461155, 12.548122837761438, 124.03434599114438, -11.810762141326794, 159.04200387106084, -91.05526888821333, 180.68300078094708, -90.59445043727732, 145.3322579347963, -91.38754178150594, 10.474966326609193, -112.71404056519498, 17.962982175754142, -107.32464279173143, -10.695163314957934, -75.86580245331595, -27.477931440966938, -115.4404494342048, 91.51361648318712, -32.84844824650233, 112.90328475988835, -98.60850170772841, -111.05057998100546, -105.88170621584183, -68.8798611040148, -101.81024532196125, -124.59850633044876, -104.59131374136948, -153.34560305443404, -38.02468302893934, 88.24174426123116, -104.02654047561336, -179.2475552864227, 31.11813059585262, -86.8701493735594, 51.46985952266675, 9.6861886203933, 129.46733489401817, -80.5704181433037, 32.717451120143785, 698.0163492849946, 223.93360941781881, 87.66970887184407, 124.66319089574775, -48.43447747431068, 198.99904138264404, -128.57186729403278, 111.35474441399447, -174.73999056345832, 88.08808095735716, -61.66309501539018, -106.8604338609639, -122.06988499623014, 22.882818252979106, -102.36742083988784, -131.58041239945618, -40.00056032463447, -100.3236883507313, -35.47445134953552, -131.05458578966474, -110.95068124845494, -155.09888680369596, -28.010995286403826, -40.43019543362561, -100.19129424552469], "policy_AGENT-2_reward": [231.14880271676108, -38.076881851374196, 67.37139187661619, -40.42191547473239, 80.12114391058509, 11.70460237391227, 144.16630960571462, 4.3198499822521725, 51.2115033234182, 175.85334296926138, -15.645083826046367, 50.11938328127456, -52.64877535518268, 87.1147717432356, -24.770235179574083, 83.11578635490179, -46.89301024607981, 173.59580579410272, -48.22524510807427, 146.79423083115833, -44.30682245438405, 172.07341915162775, -9.453992394246779, -36.359718871037586, -31.870552520490953, -48.4353408832957, -97.84560644620261, -190.8406434039785, -109.43010966722201, -56.577730092694594, -214.158547256082, -55.690384865130234, -54.68842293507898, -191.72087031888398, -49.69211816508781, 189.98807384505076, 37.09348678488773, 74.20526335263074, -12.71063915652313, 154.7520300518595, 20.390810318402334, 153.65935007004518, -91.29741411600799, 122.80812805571279, -21.107536547611925, 8.801245122819012, -36.79866390745954, 17.522724398179534, -48.13155662644441, 15.45966521485051, -40.71495826781351, -27.980143236322263, -30.85758292665249, 127.74709040561974, -33.327262641918104, 64.93828441821447, -55.25687808966453, -102.8296971075057, -106.51150834225068, -69.63977228899053, -102.42117410860293, -125.75133165232832, -229.98411524370536, -197.61726881513306, -8.295722443931233, -83.68159951217109, -187.33991321098387, -192.19961850382222, 30.673827811839573, 34.20646484089745, -26.706378486578874, 5.619375813407261, 127.50848900177215, -27.286532513310963, 29.116141846342263, -40.17115167960832, 218.85062465320453, -39.935479865703044, 80.35573235688133, -49.086364785239, 181.97022550579425, -55.53944946967567, 110.73796934933856, -31.27788895350476, 87.32581207042463, -13.233927732583512, -23.61087215135875, -51.97615336208096, 22.569228285368304, -167.6711494249167, -104.17029976845325, -43.71794862468706, -100.93166838553664, -40.23245914157766, -93.23091447954478, -111.73298902145065, -157.17149148347977, -34.95816611040529, -40.862131363810214, -100.77230136703938]}, "sampler_perf": {"mean_env_wait_ms": 57.979775903085866, "mean_raw_obs_processing_ms": 2.4874633655445266, "mean_inference_ms": 2.4820849630169057, "mean_action_processing_ms": 0.15110863116892465}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 201600, "timers": {"sample_time_ms": 78133.943, "sample_throughput": 53.754, "load_time_ms": 14.359, "load_throughput": 292500.017, "learn_time_ms": 7765.311, "learn_throughput": 540.867, "update_time_ms": 8.273}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 28.458921432495117, "policy_loss": -0.027128996327519417, "vf_loss": 28.47547721862793, "vf_explained_var": 0.9802256226539612, "kl": 0.015663471072912216, "entropy": 1.0232198238372803, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0010000000474974513, "total_loss": 15.60764217376709, "policy_loss": -0.01599067635834217, "vf_loss": 15.61672306060791, "vf_explained_var": 0.9862069487571716, "kl": 0.015352443791925907, "entropy": 0.7547757625579834, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 1.0125000476837158, "cur_lr": 0.0010000000474974513, "total_loss": 14.485296249389648, "policy_loss": -0.045954059809446335, "vf_loss": 14.518440246582031, "vf_explained_var": 0.9881506562232971, "kl": 0.012651770375669003, "entropy": 1.1278029680252075, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.675000011920929, "cur_lr": 0.0010000000474974513, "total_loss": 21.11985969543457, "policy_loss": -0.026835190132260323, "vf_loss": 21.136274337768555, "vf_explained_var": 0.9840340614318848, "kl": 0.015436920337378979, "entropy": 0.9459711909294128, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 201600, "num_steps_trained": 201600}, "done": true, "episodes_total": 1683, "training_iteration": 48, "experiment_id": "e0519414b7d14365a6956081b3d78a58", "date": "2021-06-20_18-41-22", "timestamp": 1624214482, "time_this_iter_s": 85.62584710121155, "time_total_s": 5062.8109567165375, "pid": 8721, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fd3846484d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fd3846483b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fd40c300200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd384648170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd384648050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd384648830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd384648950>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd384648170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd384648050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd384648830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd384648950>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd384648170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd384648050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd384648830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd384648950>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fd384648170>, action_adapter=<function AgentSpec.<lambda> at 0x7fd384648050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fd384648830>, info_adapter=<function AgentSpec.<lambda> at 0x7fd384648950>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.001, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fd3846485f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 5062.8109567165375, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 54.236585365853664, "ram_util_percent": 87.49186991869918}, "trial_id": "38b86_00000", "experiment_tag": "0"}
