{"episode_reward_max": 1015.799071930424, "episode_reward_min": -816.3618673454021, "episode_reward_mean": -62.884960415405075, "episode_len_mean": 109.27777777777777, "episodes_this_iter": 36, "policy_reward_min": {"AGENT-2": -201.90204442896308, "AGENT-1": -201.36114796311432, "AGENT-0": -228.5555509974123, "AGENT-3": -184.54312395591228}, "policy_reward_max": {"AGENT-2": 246.78559176524354, "AGENT-1": 251.98718190978605, "AGENT-0": 262.3745361872803, "AGENT-3": 265.41615397017375}, "policy_reward_mean": {"AGENT-2": -13.01513756913989, "AGENT-1": -15.679069637036061, "AGENT-0": -21.87698769319979, "AGENT-3": -12.313765516029324}, "custom_metrics": {"mean_ego_speed_mean": 42.25870138888889, "mean_ego_speed_min": 38.26625, "mean_ego_speed_max": 44.472500000000004, "distance_travelled_mean": 100.24284722222222, "distance_travelled_min": 26.33325, "distance_travelled_max": 124.84175}, "hist_stats": {"episode_reward": [65.29630471494004, -638.2918403647711, 964.1736412467417, -422.2202995308179, 399.62637562091237, -242.52161134807596, 158.8112806728866, -21.44720756444757, 1015.799071930424, -301.1794427073701, 351.92657122070597, -513.596030798226, 405.54076326989895, -816.3618673454021, -180.92567662490848, -452.4242728207436, 658.8491181127195, -383.6905138951887, 297.6384650849175, -553.1155128186318, 356.7341058508834, -388.50750159922194, 653.7301961896806, -510.03898143456024, 77.65558061578321, -404.3140135665606, -45.298282565042, -625.2628560733194, -75.3766285075058, -67.89126856705639, 45.82399123482232, -304.49076060134183, 214.3611301290069, -324.50898957697, -386.41378306584295, -271.947829472901], "episode_lengths": [129, 109, 137, 121, 115, 28, 113, 139, 129, 43, 119, 108, 119, 116, 100, 82, 121, 117, 122, 119, 121, 107, 120, 122, 122, 45, 123, 129, 101, 119, 109, 118, 116, 119, 63, 114], "policy_AGENT-2_reward": [18.06281506820183, -57.567196277968115, 222.450382917493, -105.17183532382585, 72.9119074458075, -33.476360930661365, 47.50207756109105, -75.80414566274328, 246.78559176524354, -47.1276165080488, 81.85386961358252, -189.1596904252391, 87.66008807640225, -201.90204442896308, -26.67719978966122, -91.71918177080485, 162.36914589512884, -99.81413342317627, 48.60706092444693, -137.03999992241992, 57.084196344377474, -95.04555213609609, 160.8388240046705, -139.04469435092938, 25.855932304558056, -125.46322374776237, 17.25514844035031, -139.81057810558025, 9.819021115203324, -8.622754858268985, 102.27468225201787, -65.66768744558613, 51.26395947195728, -68.82121846504943, -121.30900218694026, -51.89553992984362], "policy_AGENT-1_reward": [17.785342919160726, -198.53860652193168, 251.98718190978605, -81.72096370175939, 73.69191045387623, -87.79850327164519, 28.856379820311624, 86.03921426684047, 251.8502740674972, -103.51594080073932, 94.02153408591279, -89.6136450933293, 93.53437064538089, -201.36114796311432, -63.86400783653282, -134.51840423946373, 166.90069447018635, -91.57881337591611, 88.90823607954673, -115.37901345296382, 110.61381443328001, -121.62248729740452, 166.44910354106952, -115.79721169495298, 35.8876287782349, -76.69308996397615, -23.504388928280076, -147.14738565019394, -47.39966564964165, -24.48815609422388, -66.27840760814509, -65.10639612446863, 51.439317621504564, -70.48042950455918, -71.88421730480509, -84.12062794783935], "policy_AGENT-0_reward": [11.367516217220796, -198.43513528353742, 262.3745361872803, -130.19811687038015, 138.0837080348032, -87.85976102222796, 28.828737681900325, 44.32156410773982, 251.74705212750933, -103.44228116197345, 94.15578277145798, -89.66539698582555, 93.74600022695249, -228.5555509974123, -63.75126980417609, -134.46931883484007, 166.53493715738304, -92.25207617490737, 111.79614110523792, -161.43029613865664, 132.1245349552661, -121.59961547342577, 165.41369728788956, -116.19374544545295, -13.332549734369124, -76.73992621656996, -32.661009825512224, -192.5046958811455, -47.45689110720856, -26.20340120402563, -66.35694928909899, -108.56623262045848, 74.94149260154077, -115.50551491459683, -71.798373278481, -84.02914915309194], "policy_AGENT-3_reward": [18.08063051035677, -183.7509022813337, 227.3615402321828, -105.12938363485219, 114.93884968642521, -33.38698612354131, 53.62408560958369, -76.00384027628455, 265.41615397017375, -47.09360423660839, 81.89538474975278, -145.15729829383218, 130.60030432116343, -184.54312395591228, -26.633199194538378, -91.71736797563484, 163.04434059002097, -100.04549092118886, 48.32702697568545, -139.26620330459122, 56.911560117959745, -50.239846692295735, 161.0285713560509, -139.00332994322517, 29.244569267359264, -125.41777363825213, -6.388032251599981, -145.80019643639977, 9.660907134141082, -8.576956410537894, 76.18466588004844, -65.1504444108284, 36.71636043400443, -69.70182669276468, -121.4221902956165, -51.90251244212628]}, "sampler_perf": {"mean_env_wait_ms": 64.76128353778728, "mean_raw_obs_processing_ms": 2.4797509688296375, "mean_inference_ms": 3.723160811557447, "mean_action_processing_ms": 0.1561761384574169}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 4200, "timers": {"sample_time_ms": 109402.72, "sample_throughput": 38.39, "load_time_ms": 1180.957, "load_throughput": 3556.439, "learn_time_ms": 16089.978, "learn_throughput": 261.032, "update_time_ms": 11.262}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 17.907194137573242, "policy_loss": -0.02763679064810276, "vf_loss": 17.932830810546875, "vf_explained_var": 0.42990949749946594, "kl": 0.010002286173403263, "entropy": 1.376325011253357, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 13.348381042480469, "policy_loss": -0.023617595434188843, "vf_loss": 13.370159149169922, "vf_explained_var": 0.4945504069328308, "kl": 0.00919905211776495, "entropy": 1.377241611480713, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 13.10890007019043, "policy_loss": -0.024847351014614105, "vf_loss": 13.131993293762207, "vf_explained_var": 0.5487946271896362, "kl": 0.008779441006481647, "entropy": 1.3776493072509766, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 12.38674259185791, "policy_loss": -0.024822352454066277, "vf_loss": 12.409581184387207, "vf_explained_var": 0.5931132435798645, "kl": 0.009925478138029575, "entropy": 1.3762787580490112, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 4200, "num_steps_trained": 4200}, "done": false, "episodes_total": 36, "training_iteration": 1, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-16-25", "timestamp": 1624216585, "time_this_iter_s": 129.33047080039978, "time_total_s": 129.33047080039978, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c8688200>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c8688b90>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647050>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647050>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647050>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647050>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8688830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 129.33047080039978, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 56.483783783783785, "ram_util_percent": 91.01189189189192}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1015.799071930424, "episode_reward_min": -816.3618673454021, "episode_reward_mean": -68.88863668540054, "episode_len_mean": 112.37837837837837, "episodes_this_iter": 38, "policy_reward_min": {"AGENT-2": -203.4822459207574, "AGENT-1": -201.36114796311432, "AGENT-0": -228.5555509974123, "AGENT-3": -198.453736946062}, "policy_reward_max": {"AGENT-2": 246.78559176524354, "AGENT-1": 251.98718190978605, "AGENT-0": 262.3745361872803, "AGENT-3": 265.41615397017375}, "policy_reward_mean": {"AGENT-2": -15.325283752466639, "AGENT-1": -18.3656290550151, "AGENT-0": -20.09189607310235, "AGENT-3": -15.105827804816457}, "custom_metrics": {"mean_ego_speed_mean": 42.1284695945946, "mean_ego_speed_min": 36.297, "mean_ego_speed_max": 45.161, "distance_travelled_mean": 98.91632432432432, "distance_travelled_min": 26.33325, "distance_travelled_max": 124.86574999999999}, "hist_stats": {"episode_reward": [-54.64444712941415, -576.8642843567546, -240.96544710199703, -253.60783470438764, -163.46819038614342, -321.25194819779216, 485.8553406355966, 13.37084750253917, 916.760394675902, -566.7199599502098, 800.796889910043, -328.36152955124857, -54.39820698972759, 593.8871165505708, 27.038963132534924, 621.656636778791, -559.5003326314603, -232.03712813996043, -531.664583613302, 274.27723558356723, -482.4179118380883, 678.9158980549264, -326.1531164367693, 272.04285061323407, -560.1303305715373, 22.17631801544189, -401.48721575240666, -182.60385591611572, -480.72505463180846, -39.84102626145331, -125.260877891177, -200.26729227050754, -478.7386273097693, 46.0218795818199, 476.49417384154367, -212.0116933240511, -264.9128934357052, -425.16129624978066, 65.29630471494004, -638.2918403647711, 964.1736412467417, -422.2202995308179, 399.62637562091237, -242.52161134807596, 158.8112806728866, -21.44720756444757, 1015.799071930424, -301.1794427073701, 351.92657122070597, -513.596030798226, 405.54076326989895, -816.3618673454021, -180.92567662490848, -452.4242728207436, 658.8491181127195, -383.6905138951887, 297.6384650849175, -553.1155128186318, 356.7341058508834, -388.50750159922194, 653.7301961896806, -510.03898143456024, 77.65558061578321, -404.3140135665606, -45.298282565042, -625.2628560733194, -75.3766285075058, -67.89126856705639, 45.82399123482232, -304.49076060134183, 214.3611301290069, -324.50898957697, -386.41378306584295, -271.947829472901], "episode_lengths": [111, 113, 107, 116, 128, 119, 105, 123, 142, 109, 105, 121, 89, 125, 122, 119, 125, 119, 114, 102, 78, 124, 105, 124, 124, 125, 121, 109, 120, 110, 120, 122, 107, 126, 115, 104, 93, 141, 129, 109, 137, 121, 115, 28, 113, 139, 129, 43, 119, 108, 119, 116, 100, 82, 121, 117, 122, 119, 121, 107, 120, 122, 122, 45, 123, 129, 101, 119, 109, 118, 116, 119, 63, 114], "policy_AGENT-2_reward": [-41.33308169723229, -203.4822459207574, -36.782840524696965, -57.25951267092492, 28.778825953577257, -43.99242829136338, 84.49376593674023, -31.61604260066823, 237.6334458248122, -160.9297640671679, 212.7723308674833, -101.35722526754212, 9.253007251534797, 162.03231540893793, -41.53020243682498, 146.95023865488838, -126.47606608772264, -97.37995032524519, -79.38864177434763, 69.98056979822024, -135.7171268756774, 170.10233173644718, -59.170683798955615, 40.05022206646179, -138.37828216104458, 28.077458409021126, -88.79756597715283, -44.82391992429426, -92.93716411273077, -8.92892220317189, -9.846640982326843, -11.835044783561587, -118.7469280095404, -8.7353132130578, 31.74761673257542, -69.08137069993663, -66.20312911142548, -12.668080316825154, 18.06281506820183, -57.567196277968115, 222.450382917493, -105.17183532382585, 72.9119074458075, -33.476360930661365, 47.50207756109105, -75.80414566274328, 246.78559176524354, -47.1276165080488, 81.85386961358252, -189.1596904252391, 87.66008807640225, -201.90204442896308, -26.67719978966122, -91.71918177080485, 162.36914589512884, -99.81413342317627, 48.60706092444693, -137.03999992241992, 57.084196344377474, -95.04555213609609, 160.8388240046705, -139.04469435092938, 25.855932304558056, -125.46322374776237, 17.25514844035031, -139.81057810558025, 9.819021115203324, -8.622754858268985, 102.27468225201787, -65.66768744558613, 51.26395947195728, -68.82121846504943, -121.30900218694026, -51.89553992984362], "policy_AGENT-1_reward": [28.230890548514594, -106.65838054092293, -83.78623793838608, -67.18464065704978, -103.15038547527205, -113.19065919692045, 134.09973799715806, 38.20235520892846, 227.76146884222348, -122.75739687730831, 188.02546139766162, -39.710659085261156, -36.47222823758946, 163.62382480479513, 78.26527394229232, 153.63049183731474, -122.26071693758368, -32.018382735427735, -174.98138175447463, 67.13576941800466, -105.4707344394782, 192.23459731565845, -104.54464952327726, 117.98008511246519, -118.66739990203443, -15.567028788519277, -88.84440403682065, -69.19346356468893, -145.40735805077594, -11.450167673022996, -52.775185374598124, -64.06767866970974, -120.65425088607319, -8.300206627599906, 32.33577700501266, -61.42689950007856, -66.3161803660825, -181.27909972889245, 17.785342919160726, -198.53860652193168, 251.98718190978605, -81.72096370175939, 73.69191045387623, -87.79850327164519, 28.856379820311624, 86.03921426684047, 251.8502740674972, -103.51594080073932, 94.02153408591279, -89.6136450933293, 93.53437064538089, -201.36114796311432, -63.86400783653282, -134.51840423946373, 166.90069447018635, -91.57881337591611, 88.90823607954673, -115.37901345296382, 110.61381443328001, -121.62248729740452, 166.44910354106952, -115.79721169495298, 35.8876287782349, -76.69308996397615, -23.504388928280076, -147.14738565019394, -47.39966564964165, -24.48815609422388, -66.27840760814509, -65.10639612446863, 51.439317621504564, -70.48042950455918, -71.88421730480509, -84.12062794783935], "policy_AGENT-0_reward": [28.12175952288647, -106.5120027287548, -83.62279668001167, -56.703584183144294, 29.232846325943886, -43.44239264916753, 134.09074732845752, 38.33920432475687, 223.00182567049762, -122.72536563011548, 187.97818492238994, -85.89108023894306, -36.448903632362246, 117.86658968708224, 31.843438220495408, 175.72478725730917, -169.80063092086985, -69.76455638146803, -78.84082313841782, 67.11796443919287, -105.52553062173223, 148.20397555537863, -104.57400639792847, 73.94187196702391, -164.57445390780723, -16.322890580214498, -134.63977409101852, -69.23484469601756, -92.39005061059856, -11.511358790575237, -53.25966352278081, -112.52638783965192, -120.69662004883025, 11.104940279117194, 219.26939146545203, -61.361623299106505, -66.2358037653751, -218.46113506547368, 11.367516217220796, -198.43513528353742, 262.3745361872803, -130.19811687038015, 138.0837080348032, -87.85976102222796, 28.828737681900325, 44.32156410773982, 251.74705212750933, -103.44228116197345, 94.15578277145798, -89.66539698582555, 93.74600022695249, -228.5555509974123, -63.75126980417609, -134.46931883484007, 166.53493715738304, -92.25207617490737, 111.79614110523792, -161.43029613865664, 132.1245349552661, -121.59961547342577, 165.41369728788956, -116.19374544545295, -13.332549734369124, -76.73992621656996, -32.661009825512224, -192.5046958811455, -47.45689110720856, -26.20340120402563, -66.35694928909899, -108.56623262045848, 74.94149260154077, -115.50551491459683, -71.798373278481, -84.02914915309194], "policy_AGENT-3_reward": [-69.66401550358285, -160.2116551663197, -36.773571958902316, -72.4600971932685, -118.3294771903925, -120.62646806034078, 133.17108937324093, -31.554669430477944, 228.3636543383688, -160.30743337561825, 212.02091272250806, -101.40256495950217, 9.269917628689214, 150.36438664975543, -41.53954659342778, 145.35111902927883, -140.96291868528505, -32.87423869781955, -198.453736946062, 70.04293192814936, -135.70451990120037, 168.37499344744236, -57.863776716608456, 40.070671467283134, -138.51019460065046, 25.988778975154503, -89.20547164741505, 0.64837226888503, -149.990481857703, -7.950577594683062, -9.379388011471177, -11.838180977584361, -118.6408283653254, 51.95245914336032, 193.1413886385034, -20.141799824929393, -66.15778019282212, -12.75298113858929, 18.08063051035677, -183.7509022813337, 227.3615402321828, -105.12938363485219, 114.93884968642521, -33.38698612354131, 53.62408560958369, -76.00384027628455, 265.41615397017375, -47.09360423660839, 81.89538474975278, -145.15729829383218, 130.60030432116343, -184.54312395591228, -26.633199194538378, -91.71736797563484, 163.04434059002097, -100.04549092118886, 48.32702697568545, -139.26620330459122, 56.911560117959745, -50.239846692295735, 161.0285713560509, -139.00332994322517, 29.244569267359264, -125.41777363825213, -6.388032251599981, -145.80019643639977, 9.660907134141082, -8.576956410537894, 76.18466588004844, -65.1504444108284, 36.71636043400443, -69.70182669276468, -121.4221902956165, -51.90251244212628]}, "sampler_perf": {"mean_env_wait_ms": 62.762314699995, "mean_raw_obs_processing_ms": 2.544440969284115, "mean_inference_ms": 3.4115026166200977, "mean_action_processing_ms": 0.15499721897731084}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 8400, "timers": {"sample_time_ms": 103148.987, "sample_throughput": 40.718, "load_time_ms": 601.241, "load_throughput": 6985.557, "learn_time_ms": 12686.285, "learn_throughput": 331.066, "update_time_ms": 10.065}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 16.447542190551758, "policy_loss": -0.029232487082481384, "vf_loss": 16.47473907470703, "vf_explained_var": 0.5727371573448181, "kl": 0.010176661424338818, "entropy": 1.368991732597351, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 12.023580551147461, "policy_loss": -0.02722647413611412, "vf_loss": 12.048747062683105, "vf_explained_var": 0.6856629848480225, "kl": 0.010288852266967297, "entropy": 1.366172194480896, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 16.829801559448242, "policy_loss": -0.02868906781077385, "vf_loss": 16.856653213500977, "vf_explained_var": 0.598638653755188, "kl": 0.009197528474032879, "entropy": 1.3662774562835693, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 13.028084754943848, "policy_loss": -0.028082266449928284, "vf_loss": 13.053925514221191, "vf_explained_var": 0.6790499687194824, "kl": 0.011206984519958496, "entropy": 1.3666585683822632, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 8400, "num_steps_trained": 8400}, "done": false, "episodes_total": 74, "training_iteration": 2, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-18-12", "timestamp": 1624216692, "time_this_iter_s": 106.23191666603088, "time_total_s": 235.56238746643066, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c86887a0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c8688170>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc22bab4dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc22bab4f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc22826a680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647cb0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc22bab4dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc22bab4f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc22826a680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647cb0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc22bab4dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc22bab4f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc22826a680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647cb0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc22bab4dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc22bab4f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc22826a680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647cb0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8647320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 235.56238746643066, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 56.89868421052632, "ram_util_percent": 92.90065789473682}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1015.799071930424, "episode_reward_min": -944.2724544497477, "episode_reward_mean": -106.36085032351923, "episode_len_mean": 114.36, "episodes_this_iter": 34, "policy_reward_min": {"AGENT-0": -239.33544303539543, "AGENT-3": -246.64656105785298, "AGENT-2": -247.06228484796912, "AGENT-1": -232.0185897076594}, "policy_reward_max": {"AGENT-0": 251.74705212750933, "AGENT-3": 265.41615397017375, "AGENT-2": 246.78559176524354, "AGENT-1": 251.8502740674972}, "policy_reward_mean": {"AGENT-0": -29.412619108884456, "AGENT-3": -25.442158613067033, "AGENT-2": -25.675277105006504, "AGENT-1": -25.830795496561244}, "custom_metrics": {"mean_ego_speed_mean": 42.111042499999996, "mean_ego_speed_min": 36.297, "mean_ego_speed_max": 46.08125, "distance_travelled_mean": 102.90134, "distance_travelled_min": 39.8885, "distance_travelled_max": 124.8765}, "hist_stats": {"episode_reward": [-374.22217875051444, 304.83855189713114, -899.1254535208673, 785.0171102467192, -563.8800738281402, 208.67796788036605, -340.18431925894924, 192.70097912960674, -410.4072420985282, 65.78377395063339, -663.363638449787, 286.1055191193537, -944.2724544497477, 746.1144580909696, -437.11190121416587, 543.0425217807807, -607.1591721268923, 258.5079065160693, -450.43814379052594, 591.1102530731944, -594.3779668166396, 132.85849582730737, -642.654019819687, -277.50220201887674, -388.23930607800014, -254.30573388813613, -373.5839675875567, -51.528130141459364, -282.85258915696375, -210.31853965167102, -417.36923869910805, -128.32436700366202, -268.6268910651097, 190.19071771794205, 1015.799071930424, -301.1794427073701, 351.92657122070597, -513.596030798226, 405.54076326989895, -816.3618673454021, -180.92567662490848, -452.4242728207436, 658.8491181127195, -383.6905138951887, 297.6384650849175, -553.1155128186318, 356.7341058508834, -388.50750159922194, 653.7301961896806, -510.03898143456024, 77.65558061578321, -404.3140135665606, -45.298282565042, -625.2628560733194, -75.3766285075058, -67.89126856705639, 45.82399123482232, -304.49076060134183, 214.3611301290069, -324.50898957697, -386.41378306584295, -271.947829472901, -54.64444712941415, -576.8642843567546, -240.96544710199703, -253.60783470438764, -163.46819038614342, -321.25194819779216, 485.8553406355966, 13.37084750253917, 916.760394675902, -566.7199599502098, 800.796889910043, -328.36152955124857, -54.39820698972759, 593.8871165505708, 27.038963132534924, 621.656636778791, -559.5003326314603, -232.03712813996043, -531.664583613302, 274.27723558356723, -482.4179118380883, 678.9158980549264, -326.1531164367693, 272.04285061323407, -560.1303305715373, 22.17631801544189, -401.48721575240666, -182.60385591611572, -480.72505463180846, -39.84102626145331, -125.260877891177, -200.26729227050754, -478.7386273097693, 46.0218795818199, 476.49417384154367, -212.0116933240511, -264.9128934357052, -425.16129624978066], "episode_lengths": [120, 106, 105, 133, 119, 123, 147, 127, 123, 114, 108, 117, 132, 127, 120, 122, 136, 121, 125, 129, 120, 123, 132, 127, 53, 124, 101, 123, 111, 82, 129, 94, 117, 121, 129, 43, 119, 108, 119, 116, 100, 82, 121, 117, 122, 119, 121, 107, 120, 122, 122, 45, 123, 129, 101, 119, 109, 118, 116, 119, 63, 114, 111, 113, 107, 116, 128, 119, 105, 123, 142, 109, 105, 121, 89, 125, 122, 119, 125, 119, 114, 102, 78, 124, 105, 124, 124, 125, 121, 109, 120, 110, 120, 122, 107, 126, 115, 104, 93, 141], "policy_AGENT-0_reward": [-88.66599849415587, 98.44300595716321, -202.7014950319118, 191.80295650440732, -168.99567799150196, 53.099207633061724, -98.08575985651902, 57.96047129246378, -100.60281611096015, 33.38292145387403, -150.77395933460082, 125.84070616016436, -239.33544303539543, 221.2271727629774, -69.75846162584813, 104.37753214403696, -113.27296350394407, 73.68082049703492, -90.70949864636285, 121.9689669893243, -143.62698811459063, 71.54583070555202, -200.38887648173835, -146.48796651709137, -68.44460193463453, -113.0616681823026, -112.04975959804972, -34.77102887446828, -95.44312161696942, -76.12544122867087, -89.8150236006466, -51.139305779801624, -99.57189626192121, 14.519607295952909, 251.74705212750933, -103.44228116197345, 94.15578277145798, -89.66539698582555, 93.74600022695249, -228.5555509974123, -63.75126980417609, -134.46931883484007, 166.53493715738304, -92.25207617490737, 111.79614110523792, -161.43029613865664, 132.1245349552661, -121.59961547342577, 165.41369728788956, -116.19374544545295, -13.332549734369124, -76.73992621656996, -32.661009825512224, -192.5046958811455, -47.45689110720856, -26.20340120402563, -66.35694928909899, -108.56623262045848, 74.94149260154077, -115.50551491459683, -71.798373278481, -84.02914915309194, 28.12175952288647, -106.5120027287548, -83.62279668001167, -56.703584183144294, 29.232846325943886, -43.44239264916753, 134.09074732845752, 38.33920432475687, 223.00182567049762, -122.72536563011548, 187.97818492238994, -85.89108023894306, -36.448903632362246, 117.86658968708224, 31.843438220495408, 175.72478725730917, -169.80063092086985, -69.76455638146803, -78.84082313841782, 67.11796443919287, -105.52553062173223, 148.20397555537863, -104.57400639792847, 73.94187196702391, -164.57445390780723, -16.322890580214498, -134.63977409101852, -69.23484469601756, -92.39005061059856, -11.511358790575237, -53.25966352278081, -112.52638783965192, -120.69662004883025, 11.104940279117194, 219.26939146545203, -61.361623299106505, -66.2358037653751, -218.46113506547368], "policy_AGENT-3_reward": [-98.82494057699819, 54.00387122104491, -246.64656105785298, 194.1501895809493, -124.58608577643123, 28.191559272598887, -93.0299599213143, 38.23164395370367, -104.86251194498521, 2.0717941267770597, -179.6202173327609, 28.95544637906118, -234.1780570351844, 164.25023912940003, -153.75543646367558, 144.3961819921399, -175.26120025796263, 55.39601468661658, -134.91563224222728, 150.75184794834428, -152.67896548436016, -6.07143162355257, -141.94419107907228, -13.322084651514093, -125.8282582937901, -14.37351192873177, -85.77278167621088, 9.587037084486173, -46.09885311461539, -28.94591510487718, -108.70386795234587, -13.089548739387926, -54.405210811511694, 56.2787876664919, 265.41615397017375, -47.09360423660839, 81.89538474975278, -145.15729829383218, 130.60030432116343, -184.54312395591228, -26.633199194538378, -91.71736797563484, 163.04434059002097, -100.04549092118886, 48.32702697568545, -139.26620330459122, 56.911560117959745, -50.239846692295735, 161.0285713560509, -139.00332994322517, 29.244569267359264, -125.41777363825213, -6.388032251599981, -145.80019643639977, 9.660907134141082, -8.576956410537894, 76.18466588004844, -65.1504444108284, 36.71636043400443, -69.70182669276468, -121.4221902956165, -51.90251244212628, -69.66401550358285, -160.2116551663197, -36.773571958902316, -72.4600971932685, -118.3294771903925, -120.62646806034078, 133.17108937324093, -31.554669430477944, 228.3636543383688, -160.30743337561825, 212.02091272250806, -101.40256495950217, 9.269917628689214, 150.36438664975543, -41.53954659342778, 145.35111902927883, -140.96291868528505, -32.87423869781955, -198.453736946062, 70.04293192814936, -135.70451990120037, 168.37499344744236, -57.863776716608456, 40.070671467283134, -138.51019460065046, 25.988778975154503, -89.20547164741505, 0.64837226888503, -149.990481857703, -7.950577594683062, -9.379388011471177, -11.838180977584361, -118.6408283653254, 51.95245914336032, 193.1413886385034, -20.141799824929393, -66.15778019282212, -12.75298113858929], "policy_AGENT-2_reward": [-97.99830901848313, 53.95460683905992, -247.06228484796912, 200.23601537382743, -146.79994148670448, 28.390808696298855, -90.7923268379333, 38.173457329369974, -106.71070251816732, -2.810001172471381, -182.18541926212768, 28.918986340009006, -238.74036467150788, 163.1950179075957, -70.20285705928644, 141.63766658771712, -178.59730009046046, 55.369629107734895, -134.7792462991054, 150.85326298178043, -154.52495759253233, -5.881970852132049, -147.38050120949424, -13.271740378218656, -125.54222962751459, -14.374407403983371, -63.76163921470014, 6.4329191172820535, -45.92225424499116, -28.949413104604226, -101.30141641486485, -12.87533043529584, -57.66031550387455, 56.41349094502249, 246.78559176524354, -47.1276165080488, 81.85386961358252, -189.1596904252391, 87.66008807640225, -201.90204442896308, -26.67719978966122, -91.71918177080485, 162.36914589512884, -99.81413342317627, 48.60706092444693, -137.03999992241992, 57.084196344377474, -95.04555213609609, 160.8388240046705, -139.04469435092938, 25.855932304558056, -125.46322374776237, 17.25514844035031, -139.81057810558025, 9.819021115203324, -8.622754858268985, 102.27468225201787, -65.66768744558613, 51.26395947195728, -68.82121846504943, -121.30900218694026, -51.89553992984362, -41.33308169723229, -203.4822459207574, -36.782840524696965, -57.25951267092492, 28.778825953577257, -43.99242829136338, 84.49376593674023, -31.61604260066823, 237.6334458248122, -160.9297640671679, 212.7723308674833, -101.35722526754212, 9.253007251534797, 162.03231540893793, -41.53020243682498, 146.95023865488838, -126.47606608772264, -97.37995032524519, -79.38864177434763, 69.98056979822024, -135.7171268756774, 170.10233173644718, -59.170683798955615, 40.05022206646179, -138.37828216104458, 28.077458409021126, -88.79756597715283, -44.82391992429426, -92.93716411273077, -8.92892220317189, -9.846640982326843, -11.835044783561587, -118.7469280095404, -8.7353132130578, 31.74761673257542, -69.08137069993663, -66.20312911142548, -12.668080316825154], "policy_AGENT-1_reward": [-88.73293066087709, 98.43706787986301, -202.71511258313333, 198.82794878753523, -123.49836857350272, 98.99639227840666, -58.276272643182814, 58.33540655406911, -98.23121152441541, 33.1390595424539, -150.7840425202977, 102.39038024011892, -232.0185897076594, 197.44202829099632, -143.39514606535576, 152.63114105688663, -140.02770827452406, 74.06144222468318, -90.03376660283007, 167.5361751537455, -143.54705562515764, 73.2660675974399, -152.94045104938238, -104.4204104720527, -68.42421622206106, -112.49614637311828, -111.99978709859593, -32.77705746875935, -95.38836018038769, -76.29777021351873, -117.54893073125028, -51.22018204917665, -56.98946848780221, 62.97883181047472, 251.8502740674972, -103.51594080073932, 94.02153408591279, -89.6136450933293, 93.53437064538089, -201.36114796311432, -63.86400783653282, -134.51840423946373, 166.90069447018635, -91.57881337591611, 88.90823607954673, -115.37901345296382, 110.61381443328001, -121.62248729740452, 166.44910354106952, -115.79721169495298, 35.8876287782349, -76.69308996397615, -23.504388928280076, -147.14738565019394, -47.39966564964165, -24.48815609422388, -66.27840760814509, -65.10639612446863, 51.439317621504564, -70.48042950455918, -71.88421730480509, -84.12062794783935, 28.230890548514594, -106.65838054092293, -83.78623793838608, -67.18464065704978, -103.15038547527205, -113.19065919692045, 134.09973799715806, 38.20235520892846, 227.76146884222348, -122.75739687730831, 188.02546139766162, -39.710659085261156, -36.47222823758946, 163.62382480479513, 78.26527394229232, 153.63049183731474, -122.26071693758368, -32.018382735427735, -174.98138175447463, 67.13576941800466, -105.4707344394782, 192.23459731565845, -104.54464952327726, 117.98008511246519, -118.66739990203443, -15.567028788519277, -88.84440403682065, -69.19346356468893, -145.40735805077594, -11.450167673022996, -52.775185374598124, -64.06767866970974, -120.65425088607319, -8.300206627599906, 32.33577700501266, -61.42689950007856, -66.3161803660825, -181.27909972889245]}, "sampler_perf": {"mean_env_wait_ms": 62.977909933387565, "mean_raw_obs_processing_ms": 2.56678757499877, "mean_inference_ms": 3.2489515127226296, "mean_action_processing_ms": 0.15642439618151888}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 12600, "timers": {"sample_time_ms": 104358.777, "sample_throughput": 40.246, "load_time_ms": 407.54, "load_throughput": 10305.745, "learn_time_ms": 11431.04, "learn_throughput": 367.421, "update_time_ms": 9.185}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 9.538262367248535, "policy_loss": -0.029228975996375084, "vf_loss": 9.565145492553711, "vf_explained_var": 0.8080478310585022, "kl": 0.011732338927686214, "entropy": 1.3548554182052612, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 7.987617015838623, "policy_loss": -0.03109356388449669, "vf_loss": 8.016212463378906, "vf_explained_var": 0.8194116950035095, "kl": 0.012493562884628773, "entropy": 1.3534544706344604, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 9.822543144226074, "policy_loss": -0.03375694900751114, "vf_loss": 9.85386848449707, "vf_explained_var": 0.804377555847168, "kl": 0.012157842516899109, "entropy": 1.3559473752975464, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 10.405719757080078, "policy_loss": -0.032785337418317795, "vf_loss": 10.43593978881836, "vf_explained_var": 0.7914634346961975, "kl": 0.012826391495764256, "entropy": 1.3560434579849243, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 12600, "num_steps_trained": 12600}, "done": false, "episodes_total": 108, "training_iteration": 3, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-20-08", "timestamp": 1624216808, "time_this_iter_s": 115.7470874786377, "time_total_s": 351.30947494506836, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c8647830>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c8647950>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647b00>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647290>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c86470e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647200>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647b00>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647290>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c86470e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647200>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647b00>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647290>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c86470e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647200>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647b00>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647290>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c86470e0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647200>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8647ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 351.30947494506836, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 58.20240963855423, "ram_util_percent": 93.75301204819279}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 942.0642110799479, "episode_reward_min": -1064.5875209293397, "episode_reward_mean": -110.55100021736337, "episode_len_mean": 117.14, "episodes_this_iter": 36, "policy_reward_min": {"AGENT-2": -270.7716630661817, "AGENT-1": -274.07550643819894, "AGENT-0": -265.8269363869747, "AGENT-3": -277.3409336490828}, "policy_reward_max": {"AGENT-2": 246.7924091109162, "AGENT-1": 246.81649433378706, "AGENT-0": 225.34244527959643, "AGENT-3": 248.73601137795058}, "policy_reward_mean": {"AGENT-2": -27.295664257359693, "AGENT-1": -27.24251905574251, "AGENT-0": -33.133368757406885, "AGENT-3": -22.87944814685425}, "custom_metrics": {"mean_ego_speed_mean": 41.57046000000001, "mean_ego_speed_min": 33.92775, "mean_ego_speed_max": 46.08125, "distance_travelled_mean": 105.32244749999998, "distance_travelled_min": 30.182499999999997, "distance_travelled_max": 124.892}, "hist_stats": {"episode_reward": [-76.85405010577132, -204.85954183123275, 942.0642110799479, -282.0045992430843, 415.05831699247864, -443.7951017408958, -1.1867127040906738, -335.499243865382, 794.5164374166325, -474.7309400129646, 884.1811844682996, -573.4227771362537, -743.3574091919342, 256.6564834159633, -66.62894620499002, 470.23741325436305, -872.6331109666122, -125.83454485108453, -328.3873860311076, 331.36578335473376, -609.9660273303241, 571.4967714919547, -649.9858021917837, 217.83853987119852, -1064.5875209293397, 220.0321054373736, -128.2047585777368, 378.05079674417254, -693.4742289324055, 273.3256153994687, -710.2544550675742, -170.77234534084047, -326.70477945259086, -258.45501042690705, -681.4586832596201, 10.35814494322068, 916.760394675902, -566.7199599502098, 800.796889910043, -328.36152955124857, -54.39820698972759, 593.8871165505708, 27.038963132534924, 621.656636778791, -559.5003326314603, -232.03712813996043, -531.664583613302, 274.27723558356723, -482.4179118380883, 678.9158980549264, -326.1531164367693, 272.04285061323407, -560.1303305715373, 22.17631801544189, -401.48721575240666, -182.60385591611572, -480.72505463180846, -39.84102626145331, -125.260877891177, -200.26729227050754, -478.7386273097693, 46.0218795818199, 476.49417384154367, -212.0116933240511, -264.9128934357052, -425.16129624978066, -374.22217875051444, 304.83855189713114, -899.1254535208673, 785.0171102467192, -563.8800738281402, 208.67796788036605, -340.18431925894924, 192.70097912960674, -410.4072420985282, 65.78377395063339, -663.363638449787, 286.1055191193537, -944.2724544497477, 746.1144580909696, -437.11190121416587, 543.0425217807807, -607.1591721268923, 258.5079065160693, -450.43814379052594, 591.1102530731944, -594.3779668166396, 132.85849582730737, -642.654019819687, -277.50220201887674, -388.23930607800014, -254.30573388813613, -373.5839675875567, -51.528130141459364, -282.85258915696375, -210.31853965167102, -417.36923869910805, -128.32436700366202, -268.6268910651097, 190.19071771794205], "episode_lengths": [113, 128, 128, 119, 92, 121, 85, 119, 138, 127, 125, 110, 122, 121, 122, 133, 113, 104, 120, 108, 120, 123, 120, 115, 140, 118, 108, 135, 133, 126, 139, 30, 124, 106, 142, 116, 142, 109, 105, 121, 89, 125, 122, 119, 125, 119, 114, 102, 78, 124, 105, 124, 124, 125, 121, 109, 120, 110, 120, 122, 107, 126, 115, 104, 93, 141, 120, 106, 105, 133, 119, 123, 147, 127, 123, 114, 108, 117, 132, 127, 120, 122, 136, 121, 125, 129, 120, 123, 132, 127, 53, 124, 101, 123, 111, 82, 129, 94, 117, 121], "policy_AGENT-2_reward": [-88.58898487643754, -90.35742142849918, 246.7924091109162, -101.19472975811001, 80.44827316870013, -100.61882599472453, 17.005341230515015, -106.3020541157522, 198.61136564959136, -104.12069562977616, 216.212698309863, -207.47881991941284, -198.22467032079228, 44.76686074095509, -32.739997714888055, 106.66119854050439, -167.4607386538555, -5.490324936708937, -96.56391756307814, 151.72088831672627, -155.68717783137575, 128.32005808822632, -168.15396696339033, 58.7695051722072, -270.7716630661817, 39.28492143980851, -0.9529192774466478, 121.73642505897622, -166.95341040755173, 55.605807394676425, -111.61077561654153, -15.524613726995224, -84.88243558220549, -77.28786121930445, -161.42658514057283, 25.771965184858995, 237.6334458248122, -160.9297640671679, 212.7723308674833, -101.35722526754212, 9.253007251534797, 162.03231540893793, -41.53020243682498, 146.95023865488838, -126.47606608772264, -97.37995032524519, -79.38864177434763, 69.98056979822024, -135.7171268756774, 170.10233173644718, -59.170683798955615, 40.05022206646179, -138.37828216104458, 28.077458409021126, -88.79756597715283, -44.82391992429426, -92.93716411273077, -8.92892220317189, -9.846640982326843, -11.835044783561587, -118.7469280095404, -8.7353132130578, 31.74761673257542, -69.08137069993663, -66.20312911142548, -12.668080316825154, -97.99830901848313, 53.95460683905992, -247.06228484796912, 200.23601537382743, -146.79994148670448, 28.390808696298855, -90.7923268379333, 38.173457329369974, -106.71070251816732, -2.810001172471381, -182.18541926212768, 28.918986340009006, -238.74036467150788, 163.1950179075957, -70.20285705928644, 141.63766658771712, -178.59730009046046, 55.369629107734895, -134.7792462991054, 150.85326298178043, -154.52495759253233, -5.881970852132049, -147.38050120949424, -13.271740378218656, -125.54222962751459, -14.374407403983371, -63.76163921470014, 6.4329191172820535, -45.92225424499116, -28.949413104604226, -101.30141641486485, -12.87533043529584, -57.66031550387455, 56.41349094502249], "policy_AGENT-1_reward": [25.90705018270804, -89.68759837607921, 246.81649433378706, -100.55955781716563, 127.11340896475342, -95.7064984033994, -17.629976031636208, -61.242574618211115, 200.52114888278766, -150.2335050295357, 226.30082757616566, -103.55894538348312, -174.6528192846004, 106.14448354233082, 23.570234391515672, 107.33553753280155, -255.92725876305823, -57.534143101914395, -43.78349836657428, 25.759192605087474, -148.86540095249958, 157.55778289211946, -156.26483824204044, 26.7333110162402, -274.07550643819894, 68.30966199845777, -63.16017996376609, 98.95924527940623, -171.25674397903506, 79.58405200094263, -221.19052791309144, -69.82394017577948, -75.71815837318465, -75.08219133188196, -163.45440609501253, -20.562301338968837, 227.76146884222348, -122.75739687730831, 188.02546139766162, -39.710659085261156, -36.47222823758946, 163.62382480479513, 78.26527394229232, 153.63049183731474, -122.26071693758368, -32.018382735427735, -174.98138175447463, 67.13576941800466, -105.4707344394782, 192.23459731565845, -104.54464952327726, 117.98008511246519, -118.66739990203443, -15.567028788519277, -88.84440403682065, -69.19346356468893, -145.40735805077594, -11.450167673022996, -52.775185374598124, -64.06767866970974, -120.65425088607319, -8.300206627599906, 32.33577700501266, -61.42689950007856, -66.3161803660825, -181.27909972889245, -88.73293066087709, 98.43706787986301, -202.71511258313333, 198.82794878753523, -123.49836857350272, 98.99639227840666, -58.276272643182814, 58.33540655406911, -98.23121152441541, 33.1390595424539, -150.7840425202977, 102.39038024011892, -232.0185897076594, 197.44202829099632, -143.39514606535576, 152.63114105688663, -140.02770827452406, 74.06144222468318, -90.03376660283007, 167.5361751537455, -143.54705562515764, 73.2660675974399, -152.94045104938238, -104.4204104720527, -68.42421622206106, -112.49614637311828, -111.99978709859593, -32.77705746875935, -95.38836018038769, -76.29777021351873, -117.54893073125028, -51.22018204917665, -56.98946848780221, 62.97883181047472], "policy_AGENT-0_reward": [26.040329723781614, -31.92253839143441, 199.71929625729427, -61.13185960526987, 127.21597206123245, -144.5411358875215, -17.61209581827482, -61.652218584646945, 194.19081221139365, -116.1762382490646, 225.34244527959643, -103.68615675866161, -173.07908547436708, 60.92461256818652, -24.817943356780813, 142.93639886017334, -255.69723415940862, -57.36503718264319, -91.18141161150785, 25.824024701442767, -148.73505205734995, 156.76308139999495, -157.29215739478772, 26.912728935223093, -242.39941777587586, 69.13746366469317, -63.00533615483718, 57.67782589655576, -214.6749699727629, 79.1940876358028, -265.8269363869747, -69.92809784623165, -84.29774253747146, -74.89451188896327, -200.10260332601354, -20.485088373789225, 223.00182567049762, -122.72536563011548, 187.97818492238994, -85.89108023894306, -36.448903632362246, 117.86658968708224, 31.843438220495408, 175.72478725730917, -169.80063092086985, -69.76455638146803, -78.84082313841782, 67.11796443919287, -105.52553062173223, 148.20397555537863, -104.57400639792847, 73.94187196702391, -164.57445390780723, -16.322890580214498, -134.63977409101852, -69.23484469601756, -92.39005061059856, -11.511358790575237, -53.25966352278081, -112.52638783965192, -120.69662004883025, 11.104940279117194, 219.26939146545203, -61.361623299106505, -66.2358037653751, -218.46113506547368, -88.66599849415587, 98.44300595716321, -202.7014950319118, 191.80295650440732, -168.99567799150196, 53.099207633061724, -98.08575985651902, 57.96047129246378, -100.60281611096015, 33.38292145387403, -150.77395933460082, 125.84070616016436, -239.33544303539543, 221.2271727629774, -69.75846162584813, 104.37753214403696, -113.27296350394407, 73.68082049703492, -90.70949864636285, 121.9689669893243, -143.62698811459063, 71.54583070555202, -200.38887648173835, -146.48796651709137, -68.44460193463453, -113.0616681823026, -112.04975959804972, -34.77102887446828, -95.44312161696942, -76.12544122867087, -89.8150236006466, -51.139305779801624, -99.57189626192121, 14.519607295952909], "policy_AGENT-3_reward": [-40.21244513582345, 7.108016364780388, 248.73601137795058, -19.1184520625386, 80.28066279779236, -102.92864145525026, 17.050017915305297, -106.30239654677155, 201.1931106728601, -104.20050110458857, 216.32521330267562, -158.6988550746961, -197.40083411217418, 44.820526564490976, -32.64123952483668, 113.30427832088372, -193.54787939028984, -5.445039629818005, -96.85855848994744, 128.06167773147746, -156.6783964890986, 128.85584911161436, -168.27483959156652, 105.42299474752805, -277.3409336490828, 43.30005833441413, -1.0863231816868586, 99.67730050923461, -140.58910457305595, 58.941668368046685, -111.62621515096609, -15.49569359183412, -81.80644295972921, -31.190445986757346, -156.47508869802078, 25.633569471119714, 228.3636543383688, -160.30743337561825, 212.02091272250806, -101.40256495950217, 9.269917628689214, 150.36438664975543, -41.53954659342778, 145.35111902927883, -140.96291868528505, -32.87423869781955, -198.453736946062, 70.04293192814936, -135.70451990120037, 168.37499344744236, -57.863776716608456, 40.070671467283134, -138.51019460065046, 25.988778975154503, -89.20547164741505, 0.64837226888503, -149.990481857703, -7.950577594683062, -9.379388011471177, -11.838180977584361, -118.6408283653254, 51.95245914336032, 193.1413886385034, -20.141799824929393, -66.15778019282212, -12.75298113858929, -98.82494057699819, 54.00387122104491, -246.64656105785298, 194.1501895809493, -124.58608577643123, 28.191559272598887, -93.0299599213143, 38.23164395370367, -104.86251194498521, 2.0717941267770597, -179.6202173327609, 28.95544637906118, -234.1780570351844, 164.25023912940003, -153.75543646367558, 144.3961819921399, -175.26120025796263, 55.39601468661658, -134.91563224222728, 150.75184794834428, -152.67896548436016, -6.07143162355257, -141.94419107907228, -13.322084651514093, -125.8282582937901, -14.37351192873177, -85.77278167621088, 9.587037084486173, -46.09885311461539, -28.94591510487718, -108.70386795234587, -13.089548739387926, -54.405210811511694, 56.2787876664919]}, "sampler_perf": {"mean_env_wait_ms": 61.757959026612006, "mean_raw_obs_processing_ms": 2.569884432594456, "mean_inference_ms": 2.9760601028895803, "mean_action_processing_ms": 0.1559450972168749}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 16800, "timers": {"sample_time_ms": 101412.755, "sample_throughput": 41.415, "load_time_ms": 310.805, "load_throughput": 13513.308, "learn_time_ms": 10934.142, "learn_throughput": 384.118, "update_time_ms": 8.672}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 10.672894477844238, "policy_loss": -0.03711314499378204, "vf_loss": 10.70695972442627, "vf_explained_var": 0.8238860964775085, "kl": 0.015239180997014046, "entropy": 1.346129298210144, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 9.21135425567627, "policy_loss": -0.0356510728597641, "vf_loss": 9.24422836303711, "vf_explained_var": 0.8481833338737488, "kl": 0.013880295678973198, "entropy": 1.3426605463027954, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 10.05384349822998, "policy_loss": -0.03716856613755226, "vf_loss": 10.087882041931152, "vf_explained_var": 0.841671884059906, "kl": 0.015649622306227684, "entropy": 1.345168948173523, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 8.628239631652832, "policy_loss": -0.036698538810014725, "vf_loss": 8.661839485168457, "vf_explained_var": 0.8740394711494446, "kl": 0.0154923927038908, "entropy": 1.3454926013946533, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 16800, "num_steps_trained": 16800}, "done": false, "episodes_total": 144, "training_iteration": 4, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-21-51", "timestamp": 1624216911, "time_this_iter_s": 102.06798100471497, "time_total_s": 453.3774559497833, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c85947a0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c8594440>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8594a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85948c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8594d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85943b0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8594a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85948c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8594d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85943b0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8594a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85948c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8594d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85943b0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8594a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85948c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8594d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85943b0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c86888c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 453.3774559497833, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 58.79931506849316, "ram_util_percent": 94.30958904109588}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1253.9055673148864, "episode_reward_min": -1064.5875209293397, "episode_reward_mean": -85.54878762283313, "episode_len_mean": 117.53, "episodes_this_iter": 36, "policy_reward_min": {"AGENT-2": -270.7716630661817, "AGENT-1": -274.07550643819894, "AGENT-0": -265.8269363869747, "AGENT-3": -277.3409336490828}, "policy_reward_max": {"AGENT-2": 290.8858479930638, "AGENT-1": 347.671143654877, "AGENT-0": 303.00040361477124, "AGENT-3": 312.3481720521745}, "policy_reward_mean": {"AGENT-2": -22.868144527708285, "AGENT-1": -21.771042159368054, "AGENT-0": -23.998158576891694, "AGENT-3": -16.911442358865056}, "custom_metrics": {"mean_ego_speed_mean": 41.4925075, "mean_ego_speed_min": 33.7035, "mean_ego_speed_max": 46.08125, "distance_travelled_mean": 106.02897750000002, "distance_travelled_min": 30.182499999999997, "distance_travelled_max": 124.892}, "hist_stats": {"episode_reward": [485.8952664298921, -77.82296420661274, 619.4516053840572, -719.766547996807, 831.3643837221108, 50.053591645405604, 1253.9055673148864, -468.9693341397009, 370.1379188640323, -401.46346924392395, 728.916655538108, -511.4908207679229, -698.1877941676333, 611.0415811892672, -595.0891743911426, 281.21542611572977, -606.3515662910931, -90.19513113026915, -508.1992283141637, 876.7321808550373, -403.5367418766876, 209.11120125749738, -557.3656726443443, 117.84933120315509, -278.01745428183335, 64.35902455363836, -9.167061051141996, -11.134629730576954, -132.34545678381141, 162.40210439490536, -355.7541195643116, 64.78038849287576, -110.87043508409029, 367.77680486364767, -286.8780035009317, -33.18481930623272, -340.18431925894924, 192.70097912960674, -410.4072420985282, 65.78377395063339, -663.363638449787, 286.1055191193537, -944.2724544497477, 746.1144580909696, -437.11190121416587, 543.0425217807807, -607.1591721268923, 258.5079065160693, -450.43814379052594, 591.1102530731944, -594.3779668166396, 132.85849582730737, -642.654019819687, -277.50220201887674, -388.23930607800014, -254.30573388813613, -373.5839675875567, -51.528130141459364, -282.85258915696375, -210.31853965167102, -417.36923869910805, -128.32436700366202, -268.6268910651097, 190.19071771794205, -76.85405010577132, -204.85954183123275, 942.0642110799479, -282.0045992430843, 415.05831699247864, -443.7951017408958, -1.1867127040906738, -335.499243865382, 794.5164374166325, -474.7309400129646, 884.1811844682996, -573.4227771362537, -743.3574091919342, 256.6564834159633, -66.62894620499002, 470.23741325436305, -872.6331109666122, -125.83454485108453, -328.3873860311076, 331.36578335473376, -609.9660273303241, 571.4967714919547, -649.9858021917837, 217.83853987119852, -1064.5875209293397, 220.0321054373736, -128.2047585777368, 378.05079674417254, -693.4742289324055, 273.3256153994687, -710.2544550675742, -170.77234534084047, -326.70477945259086, -258.45501042690705, -681.4586832596201, 10.35814494322068], "episode_lengths": [104, 130, 128, 107, 119, 131, 141, 120, 119, 100, 129, 118, 96, 118, 122, 110, 120, 84, 123, 132, 87, 126, 123, 118, 126, 122, 115, 123, 132, 120, 80, 124, 106, 128, 115, 109, 147, 127, 123, 114, 108, 117, 132, 127, 120, 122, 136, 121, 125, 129, 120, 123, 132, 127, 53, 124, 101, 123, 111, 82, 129, 94, 117, 121, 113, 128, 128, 119, 92, 121, 85, 119, 138, 127, 125, 110, 122, 121, 122, 133, 113, 104, 120, 108, 120, 123, 120, 115, 140, 118, 108, 135, 133, 126, 139, 30, 124, 106, 142, 116], "policy_AGENT-2_reward": [100.02830926241887, -105.25192538099012, 153.9037620148885, -213.45811952993586, 195.3084149173244, -60.5414928806756, 290.8858479930638, -123.25154240194122, 85.20734813617426, -71.60538922898192, 165.08350824488724, -137.9691557866821, -149.32416119272554, 147.2416144778368, -154.32983346895392, 76.68343087927653, -153.73492226590326, -1.5119296373396907, -97.93148254946992, 216.86728410525058, -77.97274505210837, 39.800952573001766, -151.47391895216748, -14.874988138428826, -10.472400182284217, -36.33093947746029, -20.40668100107404, 17.8332679123078, -12.676993269870888, 46.24438893508629, -113.62430637673735, 22.493471005719314, 4.2515711048564615, 90.14968563361319, -75.63208434246519, -0.467462936508408, -90.7923268379333, 38.173457329369974, -106.71070251816732, -2.810001172471381, -182.18541926212768, 28.918986340009006, -238.74036467150788, 163.1950179075957, -70.20285705928644, 141.63766658771712, -178.59730009046046, 55.369629107734895, -134.7792462991054, 150.85326298178043, -154.52495759253233, -5.881970852132049, -147.38050120949424, -13.271740378218656, -125.54222962751459, -14.374407403983371, -63.76163921470014, 6.4329191172820535, -45.92225424499116, -28.949413104604226, -101.30141641486485, -12.87533043529584, -57.66031550387455, 56.41349094502249, -88.58898487643754, -90.35742142849918, 246.7924091109162, -101.19472975811001, 80.44827316870013, -100.61882599472453, 17.005341230515015, -106.3020541157522, 198.61136564959136, -104.12069562977616, 216.212698309863, -207.47881991941284, -198.22467032079228, 44.76686074095509, -32.739997714888055, 106.66119854050439, -167.4607386538555, -5.490324936708937, -96.56391756307814, 151.72088831672627, -155.68717783137575, 128.32005808822632, -168.15396696339033, 58.7695051722072, -270.7716630661817, 39.28492143980851, -0.9529192774466478, 121.73642505897622, -166.95341040755173, 55.605807394676425, -111.61077561654153, -15.524613726995224, -84.88243558220549, -77.28786121930445, -161.42658514057283, 25.771965184858995], "policy_AGENT-1_reward": [142.99965350523797, -104.81041471849778, 158.3673426220939, -167.73046087157715, 195.7366263256017, 105.99262452851244, 347.671143654877, -111.20830376704765, 99.74598409891757, -109.57961026741854, 200.02819215880734, -117.45317310621923, -199.83253579730166, 149.51947924662176, -136.37507545344195, 41.43356361537851, -147.28759185113225, -43.57399657570794, -152.2569591947466, 223.6348661818833, -123.83392898140792, 87.28965829875112, -126.15060466612253, 62.67505049079921, -104.79206015244306, -35.839000297183645, 5.1726395116654444, -1.8459414390508924, -77.32033724345337, 57.17854351831933, -64.22247701409513, 33.25794900351991, -60.16306195303631, 84.14395125868356, -76.1942792316635, -27.087491756255055, -58.276272643182814, 58.33540655406911, -98.23121152441541, 33.1390595424539, -150.7840425202977, 102.39038024011892, -232.0185897076594, 197.44202829099632, -143.39514606535576, 152.63114105688663, -140.02770827452406, 74.06144222468318, -90.03376660283007, 167.5361751537455, -143.54705562515764, 73.2660675974399, -152.94045104938238, -104.4204104720527, -68.42421622206106, -112.49614637311828, -111.99978709859593, -32.77705746875935, -95.38836018038769, -76.29777021351873, -117.54893073125028, -51.22018204917665, -56.98946848780221, 62.97883181047472, 25.90705018270804, -89.68759837607921, 246.81649433378706, -100.55955781716563, 127.11340896475342, -95.7064984033994, -17.629976031636208, -61.242574618211115, 200.52114888278766, -150.2335050295357, 226.30082757616566, -103.55894538348312, -174.6528192846004, 106.14448354233082, 23.570234391515672, 107.33553753280155, -255.92725876305823, -57.534143101914395, -43.78349836657428, 25.759192605087474, -148.86540095249958, 157.55778289211946, -156.26483824204044, 26.7333110162402, -274.07550643819894, 68.30966199845777, -63.16017996376609, 98.95924527940623, -171.25674397903506, 79.58405200094263, -221.19052791309144, -69.82394017577948, -75.71815837318465, -75.08219133188196, -163.45440609501253, -20.562301338968837], "policy_AGENT-0_reward": [142.96763465920023, 47.16289277901095, 153.06552576223984, -167.78622836619425, 233.39979248602, 65.10240563517847, 303.00040361477124, -112.195133675113, 99.92279911863727, -109.5864527421837, 198.67358531419495, -118.11326527434913, -199.61586789854334, 171.04307702613116, -136.24610113375812, 41.48576052342788, -148.9578651478316, -43.60558661116715, -97.35981694435628, 219.45206696060674, -123.6770314798098, 42.20253745256381, -128.189105102054, 85.14069365928466, -152.18908164912725, 48.365041010631266, 26.415945404488497, -44.69169105981088, -29.555726723671025, 7.622383597354414, -64.01198445163945, -16.273269723517856, -59.91233957365071, 107.45590472773492, -55.60101944704785, -27.14039981441697, -98.08575985651902, 57.96047129246378, -100.60281611096015, 33.38292145387403, -150.77395933460082, 125.84070616016436, -239.33544303539543, 221.2271727629774, -69.75846162584813, 104.37753214403696, -113.27296350394407, 73.68082049703492, -90.70949864636285, 121.9689669893243, -143.62698811459063, 71.54583070555202, -200.38887648173835, -146.48796651709137, -68.44460193463453, -113.0616681823026, -112.04975959804972, -34.77102887446828, -95.44312161696942, -76.12544122867087, -89.8150236006466, -51.139305779801624, -99.57189626192121, 14.519607295952909, 26.040329723781614, -31.92253839143441, 199.71929625729427, -61.13185960526987, 127.21597206123245, -144.5411358875215, -17.61209581827482, -61.652218584646945, 194.19081221139365, -116.1762382490646, 225.34244527959643, -103.68615675866161, -173.07908547436708, 60.92461256818652, -24.817943356780813, 142.93639886017334, -255.69723415940862, -57.36503718264319, -91.18141161150785, 25.824024701442767, -148.73505205734995, 156.76308139999495, -157.29215739478772, 26.912728935223093, -242.39941777587586, 69.13746366469317, -63.00533615483718, 57.67782589655576, -214.6749699727629, 79.1940876358028, -265.8269363869747, -69.92809784623165, -84.29774253747146, -74.89451188896327, -200.10260332601354, -20.485088373789225], "policy_AGENT-3_reward": [99.89966900303494, 85.0764831138641, 154.11497498483502, -170.7917392290999, 206.91954999316474, -60.49994563760985, 312.3481720521745, -122.31435429559932, 85.26178751030335, -110.69201700533988, 165.13136982021916, -137.95522660067272, -149.41522927906212, 143.2374104386769, -168.138164334989, 121.61267109764708, -156.37118702622595, -1.503618306054399, -160.65096962559025, 216.77796360729712, -78.0530363633614, 39.81805293318079, -151.55204392400032, -15.091424808499973, -10.563912297979044, 88.16392331765101, -20.348964966221917, 17.569734855977043, -12.792399546816132, 51.356788344145414, -113.89535172183969, 25.302238207154403, 4.953395337740331, 86.02726324361595, -79.45062047975516, 21.510535200947775, -93.0299599213143, 38.23164395370367, -104.86251194498521, 2.0717941267770597, -179.6202173327609, 28.95544637906118, -234.1780570351844, 164.25023912940003, -153.75543646367558, 144.3961819921399, -175.26120025796263, 55.39601468661658, -134.91563224222728, 150.75184794834428, -152.67896548436016, -6.07143162355257, -141.94419107907228, -13.322084651514093, -125.8282582937901, -14.37351192873177, -85.77278167621088, 9.587037084486173, -46.09885311461539, -28.94591510487718, -108.70386795234587, -13.089548739387926, -54.405210811511694, 56.2787876664919, -40.21244513582345, 7.108016364780388, 248.73601137795058, -19.1184520625386, 80.28066279779236, -102.92864145525026, 17.050017915305297, -106.30239654677155, 201.1931106728601, -104.20050110458857, 216.32521330267562, -158.6988550746961, -197.40083411217418, 44.820526564490976, -32.64123952483668, 113.30427832088372, -193.54787939028984, -5.445039629818005, -96.85855848994744, 128.06167773147746, -156.6783964890986, 128.85584911161436, -168.27483959156652, 105.42299474752805, -277.3409336490828, 43.30005833441413, -1.0863231816868586, 99.67730050923461, -140.58910457305595, 58.941668368046685, -111.62621515096609, -15.49569359183412, -81.80644295972921, -31.190445986757346, -156.47508869802078, 25.633569471119714]}, "sampler_perf": {"mean_env_wait_ms": 61.15446293780943, "mean_raw_obs_processing_ms": 2.5217051317842087, "mean_inference_ms": 2.840663506617952, "mean_action_processing_ms": 0.15501164721531563}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 21000, "timers": {"sample_time_ms": 99686.723, "sample_throughput": 42.132, "load_time_ms": 251.696, "load_throughput": 16686.777, "learn_time_ms": 10634.686, "learn_throughput": 394.934, "update_time_ms": 8.274}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 12.445777893066406, "policy_loss": -0.03634987026453018, "vf_loss": 12.479198455810547, "vf_explained_var": 0.8459374904632568, "kl": 0.014655009843409061, "entropy": 1.3302290439605713, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 11.716436386108398, "policy_loss": -0.0343879759311676, "vf_loss": 11.747998237609863, "vf_explained_var": 0.854189395904541, "kl": 0.014124342240393162, "entropy": 1.3336760997772217, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 12.944536209106445, "policy_loss": -0.035442888736724854, "vf_loss": 12.977265357971191, "vf_explained_var": 0.845603346824646, "kl": 0.013577253557741642, "entropy": 1.3408489227294922, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 11.748144149780273, "policy_loss": -0.0333651565015316, "vf_loss": 11.77849292755127, "vf_explained_var": 0.8560663461685181, "kl": 0.015080108307301998, "entropy": 1.3306132555007935, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 21000, "num_steps_trained": 21000}, "done": false, "episodes_total": 180, "training_iteration": 5, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-23-33", "timestamp": 1624217013, "time_this_iter_s": 102.26012659072876, "time_total_s": 555.6375825405121, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c8688dd0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c8688200>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688320>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c86d5e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc23a5fd5f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8594320>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688320>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c86d5e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc23a5fd5f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8594320>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688320>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c86d5e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc23a5fd5f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8594320>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688320>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c86d5e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc23a5fd5f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8594320>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8594cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 555.6375825405121, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 56.64109589041096, "ram_util_percent": 94.73150684931508}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1253.9055673148864, "episode_reward_min": -1064.5875209293397, "episode_reward_mean": -68.01607327167753, "episode_len_mean": 119.13, "episodes_this_iter": 36, "policy_reward_min": {"AGENT-2": -270.7716630661817, "AGENT-1": -274.07550643819894, "AGENT-0": -265.8269363869747, "AGENT-3": -277.3409336490828}, "policy_reward_max": {"AGENT-2": 290.8858479930638, "AGENT-1": 347.671143654877, "AGENT-0": 303.00040361477124, "AGENT-3": 312.3481720521745}, "policy_reward_mean": {"AGENT-2": -16.914542064171904, "AGENT-1": -19.23606431935318, "AGENT-0": -17.334136696234605, "AGENT-3": -14.531330191917807}, "custom_metrics": {"mean_ego_speed_mean": 41.34718999999999, "mean_ego_speed_min": 33.7035, "mean_ego_speed_max": 44.76774999999999, "distance_travelled_mean": 105.04714250000002, "distance_travelled_min": 30.182499999999997, "distance_travelled_max": 124.86825}, "hist_stats": {"episode_reward": [32.832895192951035, -522.5946606491977, 744.5268459508391, -257.3471328991707, 700.1464372647715, -472.0732561579864, 750.5184864409459, -408.41694495516344, 345.86498512966347, -579.5439980864384, 1105.348888230076, -93.2567310747848, -611.297736851983, 685.73841465482, -287.50446983596026, 849.9623877456859, -679.2921509702763, -223.47580551447135, -721.6214668018391, -51.560114757679294, -678.3151578098714, 116.9469728923859, -633.1166850050507, -215.03699535966408, -276.67334188880903, -249.460998429367, -165.4356808042864, -812.1718941965177, 230.46410876383794, -462.7722418266258, -100.08425700365417, 387.2376754349802, -73.57796508244249, -36.16934797281162, 193.27088398285878, -502.0704321618467, 794.5164374166325, -474.7309400129646, 884.1811844682996, -573.4227771362537, -743.3574091919342, 256.6564834159633, -66.62894620499002, 470.23741325436305, -872.6331109666122, -125.83454485108453, -328.3873860311076, 331.36578335473376, -609.9660273303241, 571.4967714919547, -649.9858021917837, 217.83853987119852, -1064.5875209293397, 220.0321054373736, -128.2047585777368, 378.05079674417254, -693.4742289324055, 273.3256153994687, -710.2544550675742, -170.77234534084047, -326.70477945259086, -258.45501042690705, -681.4586832596201, 10.35814494322068, 485.8952664298921, -77.82296420661274, 619.4516053840572, -719.766547996807, 831.3643837221108, 50.053591645405604, 1253.9055673148864, -468.9693341397009, 370.1379188640323, -401.46346924392395, 728.916655538108, -511.4908207679229, -698.1877941676333, 611.0415811892672, -595.0891743911426, 281.21542611572977, -606.3515662910931, -90.19513113026915, -508.1992283141637, 876.7321808550373, -403.5367418766876, 209.11120125749738, -557.3656726443443, 117.84933120315509, -278.01745428183335, 64.35902455363836, -9.167061051141996, -11.134629730576954, -132.34545678381141, 162.40210439490536, -355.7541195643116, 64.78038849287576, -110.87043508409029, 367.77680486364767, -286.8780035009317, -33.18481930623272], "episode_lengths": [122, 38, 131, 120, 129, 114, 128, 126, 126, 127, 131, 126, 134, 130, 110, 135, 118, 126, 132, 122, 111, 124, 109, 125, 108, 119, 106, 143, 127, 141, 120, 131, 115, 111, 124, 131, 138, 127, 125, 110, 122, 121, 122, 133, 113, 104, 120, 108, 120, 123, 120, 115, 140, 118, 108, 135, 133, 126, 139, 30, 124, 106, 142, 116, 104, 130, 128, 107, 119, 131, 141, 120, 119, 100, 129, 118, 96, 118, 122, 110, 120, 84, 123, 132, 87, 126, 123, 118, 126, 122, 115, 123, 132, 120, 80, 124, 106, 128, 115, 109], "policy_AGENT-2_reward": [-15.675154449279901, -158.0641082747047, 185.9285199907614, -117.44379244130668, 176.8766680025518, -48.262976815062615, 185.89632739527315, -58.2891743315751, 47.65949223871445, -154.13431617930175, 274.13359285782036, -77.63603912198603, -142.17469680126734, 159.8232608759416, -27.594684977158963, 183.89358870330602, -173.33971726147632, -35.49847946764381, -180.5914418654805, -36.243722899605835, -151.20749223288541, -7.372588078798259, -163.68063899304678, 34.57187182109254, -95.24867178738646, -47.31986091829666, -59.77713485856195, -162.7993966028563, 59.42296780288657, -10.365609071770145, -39.023839139255784, 8.304108472093908, -42.687322277441204, 5.303055029457057, 64.67435114506648, -64.7826553753255, 198.61136564959136, -104.12069562977616, 216.212698309863, -207.47881991941284, -198.22467032079228, 44.76686074095509, -32.739997714888055, 106.66119854050439, -167.4607386538555, -5.490324936708937, -96.56391756307814, 151.72088831672627, -155.68717783137575, 128.32005808822632, -168.15396696339033, 58.7695051722072, -270.7716630661817, 39.28492143980851, -0.9529192774466478, 121.73642505897622, -166.95341040755173, 55.605807394676425, -111.61077561654153, -15.524613726995224, -84.88243558220549, -77.28786121930445, -161.42658514057283, 25.771965184858995, 100.02830926241887, -105.25192538099012, 153.9037620148885, -213.45811952993586, 195.3084149173244, -60.5414928806756, 290.8858479930638, -123.25154240194122, 85.20734813617426, -71.60538922898192, 165.08350824488724, -137.9691557866821, -149.32416119272554, 147.2416144778368, -154.32983346895392, 76.68343087927653, -153.73492226590326, -1.5119296373396907, -97.93148254946992, 216.86728410525058, -77.97274505210837, 39.800952573001766, -151.47391895216748, -14.874988138428826, -10.472400182284217, -36.33093947746029, -20.40668100107404, 17.8332679123078, -12.676993269870888, 46.24438893508629, -113.62430637673735, 22.493471005719314, 4.2515711048564615, 90.14968563361319, -75.63208434246519, -0.467462936508408], "policy_AGENT-1_reward": [32.8089359671335, -103.27410432259015, 193.64423945763153, -117.02725553762788, 178.94599015774122, -174.54297360079028, 192.45480996924346, -139.9480224718395, 146.58196993356947, -120.35949908759191, 301.19389957658126, 52.493363226053205, -131.41498151331206, 172.48494407589368, -116.30428719785283, 224.63758264988343, -144.59676651128362, -65.48103766135739, -176.31817726530073, 11.069307505716404, -187.9531242186286, 65.83996050608138, -174.76337263117563, -127.33592108291481, -71.23553609870639, -89.94261954188309, -45.62602571258377, -223.4792888511185, 60.880598619797965, -201.3202273992389, -38.57562002635263, 172.07573285268893, -17.377486580540932, -22.625697873287145, 21.181497556017323, -163.3183154704716, 200.52114888278766, -150.2335050295357, 226.30082757616566, -103.55894538348312, -174.6528192846004, 106.14448354233082, 23.570234391515672, 107.33553753280155, -255.92725876305823, -57.534143101914395, -43.78349836657428, 25.759192605087474, -148.86540095249958, 157.55778289211946, -156.26483824204044, 26.7333110162402, -274.07550643819894, 68.30966199845777, -63.16017996376609, 98.95924527940623, -171.25674397903506, 79.58405200094263, -221.19052791309144, -69.82394017577948, -75.71815837318465, -75.08219133188196, -163.45440609501253, -20.562301338968837, 142.99965350523797, -104.81041471849778, 158.3673426220939, -167.73046087157715, 195.7366263256017, 105.99262452851244, 347.671143654877, -111.20830376704765, 99.74598409891757, -109.57961026741854, 200.02819215880734, -117.45317310621923, -199.83253579730166, 149.51947924662176, -136.37507545344195, 41.43356361537851, -147.28759185113225, -43.57399657570794, -152.2569591947466, 223.6348661818833, -123.83392898140792, 87.28965829875112, -126.15060466612253, 62.67505049079921, -104.79206015244306, -35.839000297183645, 5.1726395116654444, -1.8459414390508924, -77.32033724345337, 57.17854351831933, -64.22247701409513, 33.25794900351991, -60.16306195303631, 84.14395125868356, -76.1942792316635, -27.087491756255055], "policy_AGENT-0_reward": [31.43494980563869, -103.2128101280085, 186.10259138833885, 2.7047966827599232, 170.45406906366054, -47.720716356840974, 187.80312866214587, -57.73566503608182, 103.93429317900566, -164.31078801351563, 255.94443980611422, 9.544055123999208, -174.41332494235706, 197.53682672458484, -116.13278895536756, 248.902930397042, -190.05717533633856, -87.01309239292908, -184.17609841004727, 9.71896101414737, -187.96051736939796, 65.91479883982815, -174.7407783209895, 35.12294131473544, -17.94019778783117, -64.8236885829429, -45.530407860547555, -262.9730228255763, 86.2810879919241, -240.78002867050228, -30.847795300726286, 198.49766454374344, -17.429320327857635, -22.34179005416246, 42.91644859650896, -209.11658964442233, 194.19081221139365, -116.1762382490646, 225.34244527959643, -103.68615675866161, -173.07908547436708, 60.92461256818652, -24.817943356780813, 142.93639886017334, -255.69723415940862, -57.36503718264319, -91.18141161150785, 25.824024701442767, -148.73505205734995, 156.76308139999495, -157.29215739478772, 26.912728935223093, -242.39941777587586, 69.13746366469317, -63.00533615483718, 57.67782589655576, -214.6749699727629, 79.1940876358028, -265.8269363869747, -69.92809784623165, -84.29774253747146, -74.89451188896327, -200.10260332601354, -20.485088373789225, 142.96763465920023, 47.16289277901095, 153.06552576223984, -167.78622836619425, 233.39979248602, 65.10240563517847, 303.00040361477124, -112.195133675113, 99.92279911863727, -109.5864527421837, 198.67358531419495, -118.11326527434913, -199.61586789854334, 171.04307702613116, -136.24610113375812, 41.48576052342788, -148.9578651478316, -43.60558661116715, -97.35981694435628, 219.45206696060674, -123.6770314798098, 42.20253745256381, -128.189105102054, 85.14069365928466, -152.18908164912725, 48.365041010631266, 26.415945404488497, -44.69169105981088, -29.555726723671025, 7.622383597354414, -64.01198445163945, -16.273269723517856, -59.91233957365071, 107.45590472773492, -55.60101944704785, -27.14039981441697], "policy_AGENT-3_reward": [-15.735836130541223, -158.0436379238943, 178.85149511410762, -25.580881602996296, 173.8697100408179, -201.54658938529275, 184.3642204142833, -152.44408311566642, 47.68922977837374, -140.7393948060292, 274.07695598956076, -77.65811030285111, -163.29473359504746, 155.8933829783997, -27.47270870558078, 192.52828599545495, -171.29849186117787, -35.48319599254091, -180.5357492610106, -36.10466037793714, -151.19402398895863, -7.435198374725324, -119.93189505983847, -157.3958874125772, -92.24893621488499, -47.37482938624428, -14.502112372593103, -162.92018591696623, 23.879454349229384, -10.3063766851143, 8.362997462680479, 8.36016956645362, 3.916164103397367, 3.4950849251809633, 64.4985866852659, -64.85287167162697, 201.1931106728601, -104.20050110458857, 216.32521330267562, -158.6988550746961, -197.40083411217418, 44.820526564490976, -32.64123952483668, 113.30427832088372, -193.54787939028984, -5.445039629818005, -96.85855848994744, 128.06167773147746, -156.6783964890986, 128.85584911161436, -168.27483959156652, 105.42299474752805, -277.3409336490828, 43.30005833441413, -1.0863231816868586, 99.67730050923461, -140.58910457305595, 58.941668368046685, -111.62621515096609, -15.49569359183412, -81.80644295972921, -31.190445986757346, -156.47508869802078, 25.633569471119714, 99.89966900303494, 85.0764831138641, 154.11497498483502, -170.7917392290999, 206.91954999316474, -60.49994563760985, 312.3481720521745, -122.31435429559932, 85.26178751030335, -110.69201700533988, 165.13136982021916, -137.95522660067272, -149.41522927906212, 143.2374104386769, -168.138164334989, 121.61267109764708, -156.37118702622595, -1.503618306054399, -160.65096962559025, 216.77796360729712, -78.0530363633614, 39.81805293318079, -151.55204392400032, -15.091424808499973, -10.563912297979044, 88.16392331765101, -20.348964966221917, 17.569734855977043, -12.792399546816132, 51.356788344145414, -113.89535172183969, 25.302238207154403, 4.953395337740331, 86.02726324361595, -79.45062047975516, 21.510535200947775]}, "sampler_perf": {"mean_env_wait_ms": 59.946792241267424, "mean_raw_obs_processing_ms": 2.4851905919532316, "mean_inference_ms": 2.7346198765141936, "mean_action_processing_ms": 0.15288262311797535}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 25200, "timers": {"sample_time_ms": 97512.74, "sample_throughput": 43.071, "load_time_ms": 212.083, "load_throughput": 19803.521, "learn_time_ms": 10318.813, "learn_throughput": 407.024, "update_time_ms": 8.007}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 9.296127319335938, "policy_loss": -0.034482087939977646, "vf_loss": 9.3275728225708, "vf_explained_var": 0.911939799785614, "kl": 0.015187392942607403, "entropy": 1.3164197206497192, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 7.475009918212891, "policy_loss": -0.04293418303132057, "vf_loss": 7.514667987823486, "vf_explained_var": 0.9186748266220093, "kl": 0.01637747511267662, "entropy": 1.3225501775741577, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 13.514930725097656, "policy_loss": -0.03877696394920349, "vf_loss": 13.55046558380127, "vf_explained_var": 0.8712520599365234, "kl": 0.016207057982683182, "entropy": 1.329004168510437, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 12.4985933303833, "policy_loss": -0.03764377534389496, "vf_loss": 12.532938003540039, "vf_explained_var": 0.8966441750526428, "kl": 0.016491351649165154, "entropy": 1.315617322921753, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 25200, "num_steps_trained": 25200}, "done": false, "episodes_total": 216, "training_iteration": 6, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-25-09", "timestamp": 1624217109, "time_this_iter_s": 95.50013971328735, "time_total_s": 651.1377222537994, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c85d30e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c85d3200>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3440>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d37a0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3440>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d37a0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3440>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d37a0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3440>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d37a0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8647710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 651.1377222537994, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 58.33722627737226, "ram_util_percent": 94.71167883211679}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1253.9055673148864, "episode_reward_min": -812.1718941965177, "episode_reward_mean": -48.07947594031817, "episode_len_mean": 118.74, "episodes_this_iter": 34, "policy_reward_min": {"AGENT-2": -194.3521380261137, "AGENT-1": -223.4792888511185, "AGENT-0": -262.9730228255763, "AGENT-3": -201.54658938529275}, "policy_reward_max": {"AGENT-2": 290.8858479930638, "AGENT-1": 347.671143654877, "AGENT-0": 303.00040361477124, "AGENT-3": 312.3481720521745}, "policy_reward_mean": {"AGENT-2": -15.167846933148063, "AGENT-1": -13.895603076459787, "AGENT-0": -8.408559922683382, "AGENT-3": -10.607466008026895}, "custom_metrics": {"mean_ego_speed_mean": 41.640922499999995, "mean_ego_speed_min": 32.964749999999995, "mean_ego_speed_max": 44.76774999999999, "distance_travelled_mean": 100.46594499999999, "distance_travelled_min": 27.659999999999997, "distance_travelled_max": 124.86825}, "hist_stats": {"episode_reward": [763.0774081553841, -515.6811785594278, 298.1455237650182, -414.8113624640638, 581.0792307462644, 12.378825266025736, -139.96928576383627, -73.44110429005, -189.4456850734867, 98.28241303230784, -43.98030384178924, 89.71168326356046, 651.4967347598631, 117.02481098886417, 224.74473587990084, -745.1763768548893, -249.74356468145155, -179.55382958019578, -261.8659768663308, -579.1778921395152, -221.7601597820964, -169.81841923085514, 28.72794399438235, 237.62947102266796, 333.53775907339315, -223.58108332576666, -106.2473602435601, -19.268244784362615, -146.67633104157957, -245.3248892753391, -250.40362076949765, -15.975664666585184, -112.91638094921211, 581.0177922435546, 1253.9055673148864, -468.9693341397009, 370.1379188640323, -401.46346924392395, 728.916655538108, -511.4908207679229, -698.1877941676333, 611.0415811892672, -595.0891743911426, 281.21542611572977, -606.3515662910931, -90.19513113026915, -508.1992283141637, 876.7321808550373, -403.5367418766876, 209.11120125749738, -557.3656726443443, 117.84933120315509, -278.01745428183335, 64.35902455363836, -9.167061051141996, -11.134629730576954, -132.34545678381141, 162.40210439490536, -355.7541195643116, 64.78038849287576, -110.87043508409029, 367.77680486364767, -286.8780035009317, -33.18481930623272, 32.832895192951035, -522.5946606491977, 744.5268459508391, -257.3471328991707, 700.1464372647715, -472.0732561579864, 750.5184864409459, -408.41694495516344, 345.86498512966347, -579.5439980864384, 1105.348888230076, -93.2567310747848, -611.297736851983, 685.73841465482, -287.50446983596026, 849.9623877456859, -679.2921509702763, -223.47580551447135, -721.6214668018391, -51.560114757679294, -678.3151578098714, 116.9469728923859, -633.1166850050507, -215.03699535966408, -276.67334188880903, -249.460998429367, -165.4356808042864, -812.1718941965177, 230.46410876383794, -462.7722418266258, -100.08425700365417, 387.2376754349802, -73.57796508244249, -36.16934797281162, 193.27088398285878, -502.0704321618467], "episode_lengths": [116, 110, 131, 124, 117, 128, 121, 113, 163, 119, 120, 123, 138, 127, 126, 123, 28, 128, 124, 130, 31, 120, 129, 125, 112, 125, 124, 127, 107, 126, 118, 132, 107, 126, 141, 120, 119, 100, 129, 118, 96, 118, 122, 110, 120, 84, 123, 132, 87, 126, 123, 118, 126, 122, 115, 123, 132, 120, 80, 124, 106, 128, 115, 109, 122, 38, 131, 120, 129, 114, 128, 126, 126, 127, 131, 126, 134, 130, 110, 135, 118, 126, 132, 122, 111, 124, 109, 125, 108, 119, 106, 143, 127, 141, 120, 131, 115, 111, 124, 131], "policy_AGENT-2_reward": [186.8782799164967, -176.56866624048496, 81.0532776471884, -130.06546127333576, 139.01314216177389, -29.439520449780144, -83.00222906373601, -88.47929193524172, -96.52235304011785, 33.11364535409715, -100.49714648828157, -51.260113066945, 131.1287947726501, -58.559514026123026, 39.476045663695714, -194.3521380261137, -35.038438051209056, -83.75911932528311, -31.590593128392914, -80.97587346034051, -29.963969386946985, -117.3739955080201, -37.87902948583099, 9.405561297197494, 149.77834565086462, -5.412698537302557, -37.09552930901222, 22.517382780812405, -31.136590036634253, -13.419728517894443, -50.63596331364608, -14.97105710254255, 19.72968779706378, 132.6944375631061, 290.8858479930638, -123.25154240194122, 85.20734813617426, -71.60538922898192, 165.08350824488724, -137.9691557866821, -149.32416119272554, 147.2416144778368, -154.32983346895392, 76.68343087927653, -153.73492226590326, -1.5119296373396907, -97.93148254946992, 216.86728410525058, -77.97274505210837, 39.800952573001766, -151.47391895216748, -14.874988138428826, -10.472400182284217, -36.33093947746029, -20.40668100107404, 17.8332679123078, -12.676993269870888, 46.24438893508629, -113.62430637673735, 22.493471005719314, 4.2515711048564615, 90.14968563361319, -75.63208434246519, -0.467462936508408, -15.675154449279901, -158.0641082747047, 185.9285199907614, -117.44379244130668, 176.8766680025518, -48.262976815062615, 185.89632739527315, -58.2891743315751, 47.65949223871445, -154.13431617930175, 274.13359285782036, -77.63603912198603, -142.17469680126734, 159.8232608759416, -27.594684977158963, 183.89358870330602, -173.33971726147632, -35.49847946764381, -180.5914418654805, -36.243722899605835, -151.20749223288541, -7.372588078798259, -163.68063899304678, 34.57187182109254, -95.24867178738646, -47.31986091829666, -59.77713485856195, -162.7993966028563, 59.42296780288657, -10.365609071770145, -39.023839139255784, 8.304108472093908, -42.687322277441204, 5.303055029457057, 64.67435114506648, -64.7826553753255], "policy_AGENT-1_reward": [210.31590970028702, -103.41001049359048, 71.75630307593313, -129.63373716356284, 163.33663783802538, 58.16193902865807, 1.847063233185736, 31.203759387927104, -13.33361380059484, 27.05317394063362, -99.8544023907723, 85.1208377742041, 181.01175725676114, 104.79474812581869, 96.47555405261541, -177.9494520207694, -89.76899466658693, -8.37626819409002, -96.95168143645658, -195.94875989051576, -80.82050410049186, -116.85077572644975, 74.5909881694294, 10.003074693212753, 27.97524229680347, -81.8213678097824, -15.012993011960306, -8.312813453437709, -64.62759091072091, -84.64718079080927, -99.05948934804556, 8.975268963935298, -65.16280842742474, 139.1527947645714, 347.671143654877, -111.20830376704765, 99.74598409891757, -109.57961026741854, 200.02819215880734, -117.45317310621923, -199.83253579730166, 149.51947924662176, -136.37507545344195, 41.43356361537851, -147.28759185113225, -43.57399657570794, -152.2569591947466, 223.6348661818833, -123.83392898140792, 87.28965829875112, -126.15060466612253, 62.67505049079921, -104.79206015244306, -35.839000297183645, 5.1726395116654444, -1.8459414390508924, -77.32033724345337, 57.17854351831933, -64.22247701409513, 33.25794900351991, -60.16306195303631, 84.14395125868356, -76.1942792316635, -27.087491756255055, 32.8089359671335, -103.27410432259015, 193.64423945763153, -117.02725553762788, 178.94599015774122, -174.54297360079028, 192.45480996924346, -139.9480224718395, 146.58196993356947, -120.35949908759191, 301.19389957658126, 52.493363226053205, -131.41498151331206, 172.48494407589368, -116.30428719785283, 224.63758264988343, -144.59676651128362, -65.48103766135739, -176.31817726530073, 11.069307505716404, -187.9531242186286, 65.83996050608138, -174.76337263117563, -127.33592108291481, -71.23553609870639, -89.94261954188309, -45.62602571258377, -223.4792888511185, 60.880598619797965, -201.3202273992389, -38.57562002635263, 172.07573285268893, -17.377486580540932, -22.625697873287145, 21.181497556017323, -163.3183154704716], "policy_AGENT-0_reward": [187.59959811414646, -103.38226021696443, 64.28395462570577, -98.59968691018045, 139.85584910643502, 13.052624046188889, 24.34789817596568, 31.096170589279147, 17.613332473811884, 4.985054337349045, 92.23270151183758, 107.12194852110312, 208.54139980153684, 129.4913783419693, 49.383227738603736, -178.05827159262174, -89.79273668804326, -3.4814328683806135, -101.88091175701182, -221.1903348991576, -80.96438852300815, 10.64239615988405, 29.842470054455895, 124.28847690930961, 28.041914794140084, -130.98162724229888, -16.83299664366811, -55.67704970260476, -64.61249525131106, -133.85043720571846, -50.006954982590514, 5.074407359162606, -65.17140843728494, 168.71635121610882, 303.00040361477124, -112.195133675113, 99.92279911863727, -109.5864527421837, 198.67358531419495, -118.11326527434913, -199.61586789854334, 171.04307702613116, -136.24610113375812, 41.48576052342788, -148.9578651478316, -43.60558661116715, -97.35981694435628, 219.45206696060674, -123.6770314798098, 42.20253745256381, -128.189105102054, 85.14069365928466, -152.18908164912725, 48.365041010631266, 26.415945404488497, -44.69169105981088, -29.555726723671025, 7.622383597354414, -64.01198445163945, -16.273269723517856, -59.91233957365071, 107.45590472773492, -55.60101944704785, -27.14039981441697, 31.43494980563869, -103.2128101280085, 186.10259138833885, 2.7047966827599232, 170.45406906366054, -47.720716356840974, 187.80312866214587, -57.73566503608182, 103.93429317900566, -164.31078801351563, 255.94443980611422, 9.544055123999208, -174.41332494235706, 197.53682672458484, -116.13278895536756, 248.902930397042, -190.05717533633856, -87.01309239292908, -184.17609841004727, 9.71896101414737, -187.96051736939796, 65.91479883982815, -174.7407783209895, 35.12294131473544, -17.94019778783117, -64.8236885829429, -45.530407860547555, -262.9730228255763, 86.2810879919241, -240.78002867050228, -30.847795300726286, 198.49766454374344, -17.429320327857635, -22.34179005416246, 42.91644859650896, -209.11658964442233], "policy_AGENT-3_reward": [178.283620424454, -132.32024160838765, 81.0519884161912, -56.51247711698463, 138.87360164003013, -29.396217359041096, -83.16201810925135, -47.26174233201456, -97.20305070658577, 33.13053940022801, 64.13854352542695, -51.2709899648016, 130.81478292891546, -58.701801452801014, 39.40990842498616, -194.81651521538478, -35.1433952756123, -83.93700919244212, -31.44279054446952, -81.06292388950159, -30.01129777164936, 53.763955843730706, -37.82648474367185, 93.93235812294819, 127.74225633158466, -5.3653897363827365, -37.30584127891919, 22.204235590867412, 13.70034515708669, -13.407542760917028, -50.70121312521557, -15.0542838871405, -2.311851881566157, 140.45420869976772, 312.3481720521745, -122.31435429559932, 85.26178751030335, -110.69201700533988, 165.13136982021916, -137.95522660067272, -149.41522927906212, 143.2374104386769, -168.138164334989, 121.61267109764708, -156.37118702622595, -1.503618306054399, -160.65096962559025, 216.77796360729712, -78.0530363633614, 39.81805293318079, -151.55204392400032, -15.091424808499973, -10.563912297979044, 88.16392331765101, -20.348964966221917, 17.569734855977043, -12.792399546816132, 51.356788344145414, -113.89535172183969, 25.302238207154403, 4.953395337740331, 86.02726324361595, -79.45062047975516, 21.510535200947775, -15.735836130541223, -158.0436379238943, 178.85149511410762, -25.580881602996296, 173.8697100408179, -201.54658938529275, 184.3642204142833, -152.44408311566642, 47.68922977837374, -140.7393948060292, 274.07695598956076, -77.65811030285111, -163.29473359504746, 155.8933829783997, -27.47270870558078, 192.52828599545495, -171.29849186117787, -35.48319599254091, -180.5357492610106, -36.10466037793714, -151.19402398895863, -7.435198374725324, -119.93189505983847, -157.3958874125772, -92.24893621488499, -47.37482938624428, -14.502112372593103, -162.92018591696623, 23.879454349229384, -10.3063766851143, 8.362997462680479, 8.36016956645362, 3.916164103397367, 3.4950849251809633, 64.4985866852659, -64.85287167162697]}, "sampler_perf": {"mean_env_wait_ms": 58.78497046659786, "mean_raw_obs_processing_ms": 2.4521343590108606, "mean_inference_ms": 2.6546537141578885, "mean_action_processing_ms": 0.15071610781010672}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 29400, "timers": {"sample_time_ms": 95239.256, "sample_throughput": 44.099, "load_time_ms": 183.801, "load_throughput": 22850.842, "learn_time_ms": 10034.042, "learn_throughput": 418.575, "update_time_ms": 8.005}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 13.768516540527344, "policy_loss": -0.03684384003281593, "vf_loss": 13.802112579345703, "vf_explained_var": 0.8964039087295532, "kl": 0.016249125823378563, "entropy": 1.307007908821106, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 12.304384231567383, "policy_loss": -0.03366949409246445, "vf_loss": 12.334967613220215, "vf_explained_var": 0.889367938041687, "kl": 0.015446980483829975, "entropy": 1.3067219257354736, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 17.41278648376465, "policy_loss": -0.03320709243416786, "vf_loss": 17.442625045776367, "vf_explained_var": 0.8615129590034485, "kl": 0.016835344955325127, "entropy": 1.3198480606079102, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 15.771193504333496, "policy_loss": -0.03459283709526062, "vf_loss": 15.80270767211914, "vf_explained_var": 0.8864049911499023, "kl": 0.01538670714944601, "entropy": 1.3089994192123413, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 29400, "num_steps_trained": 29400}, "done": false, "episodes_total": 250, "training_iteration": 7, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-26-39", "timestamp": 1624217199, "time_this_iter_s": 89.96496987342834, "time_total_s": 741.1026921272278, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c8647dd0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c8647440>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c86479e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c86473b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c86470e0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c86479e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c86473b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c86470e0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c86479e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c86473b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c86470e0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c86479e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c86473b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c86470e0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c85d39e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 741.1026921272278, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 57.63203125, "ram_util_percent": 94.94218750000002}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1489.4532868532417, "episode_reward_min": -812.1718941965177, "episode_reward_mean": -69.40182250397991, "episode_len_mean": 118.78, "episodes_this_iter": 36, "policy_reward_min": {"AGENT-2": -194.3521380261137, "AGENT-1": -223.4792888511185, "AGENT-0": -262.9730228255763, "AGENT-3": -194.81651521538478}, "policy_reward_max": {"AGENT-2": 302.27034057631494, "AGENT-1": 403.50784597630116, "AGENT-0": 431.6583283904915, "AGENT-3": 352.0167719101322}, "policy_reward_mean": {"AGENT-2": -21.635499163697855, "AGENT-1": -19.07523379089398, "AGENT-0": -13.13579927181867, "AGENT-3": -15.555290277569425}, "custom_metrics": {"mean_ego_speed_mean": 41.831615, "mean_ego_speed_min": 32.964749999999995, "mean_ego_speed_max": 44.93724999999999, "distance_travelled_mean": 97.89686000000002, "distance_travelled_min": 27.659999999999997, "distance_travelled_max": 124.86825}, "hist_stats": {"episode_reward": [830.9132688682786, -555.1417793367094, 1489.4532868532417, -366.6850080067166, -0.03880780186607247, -482.59656331759055, 835.2375073356886, -474.71176844917693, 39.16806882241898, -397.64349268137767, -20.09635541933411, -229.93270399115914, -746.8529369372189, 93.63160177370777, -79.7253544806915, 63.913365986461585, -576.0521805541802, -243.91981505587268, -419.9667448932696, 495.73791669582613, -622.9813338172227, 15.51327972960727, -408.26998467259807, -38.916851498427306, -352.2777232252495, 4.2101405351943875, 281.9468891960184, 165.07469207707507, -399.31112883264683, -193.81032475185117, -406.7393655129145, -91.96115589316224, 277.2754364336334, -178.18507863731202, -108.8675456643137, -54.10770616728885, 750.5184864409459, -408.41694495516344, 345.86498512966347, -579.5439980864384, 1105.348888230076, -93.2567310747848, -611.297736851983, 685.73841465482, -287.50446983596026, 849.9623877456859, -679.2921509702763, -223.47580551447135, -721.6214668018391, -51.560114757679294, -678.3151578098714, 116.9469728923859, -633.1166850050507, -215.03699535966408, -276.67334188880903, -249.460998429367, -165.4356808042864, -812.1718941965177, 230.46410876383794, -462.7722418266258, -100.08425700365417, 387.2376754349802, -73.57796508244249, -36.16934797281162, 193.27088398285878, -502.0704321618467, 763.0774081553841, -515.6811785594278, 298.1455237650182, -414.8113624640638, 581.0792307462644, 12.378825266025736, -139.96928576383627, -73.44110429005, -189.4456850734867, 98.28241303230784, -43.98030384178924, 89.71168326356046, 651.4967347598631, 117.02481098886417, 224.74473587990084, -745.1763768548893, -249.74356468145155, -179.55382958019578, -261.8659768663308, -579.1778921395152, -221.7601597820964, -169.81841923085514, 28.72794399438235, 237.62947102266796, 333.53775907339315, -223.58108332576666, -106.2473602435601, -19.268244784362615, -146.67633104157957, -245.3248892753391, -250.40362076949765, -15.975664666585184, -112.91638094921211, 581.0177922435546], "episode_lengths": [123, 112, 155, 132, 121, 135, 128, 122, 44, 110, 74, 131, 134, 129, 122, 136, 120, 88, 112, 123, 70, 120, 117, 125, 126, 117, 130, 122, 112, 52, 121, 122, 121, 84, 132, 122, 128, 126, 126, 127, 131, 126, 134, 130, 110, 135, 118, 126, 132, 122, 111, 124, 109, 125, 108, 119, 106, 143, 127, 141, 120, 131, 115, 111, 124, 131, 116, 110, 131, 124, 117, 128, 121, 113, 163, 119, 120, 123, 138, 127, 126, 123, 28, 128, 124, 130, 31, 120, 129, 125, 112, 125, 124, 127, 107, 126, 118, 132, 107, 126], "policy_AGENT-2_reward": [203.070955823303, -167.3925744917915, 302.27034057631494, -81.22035518173874, -26.576894441262365, -128.4168206481503, 208.7867073567772, -125.80770371298559, -15.808168243062234, -48.641407212941246, -36.60288057406745, -121.96525583502864, -190.27863041740892, -38.69933345988716, -37.23766193196506, 40.5385691427313, -142.75513440334828, -33.43492236661852, -107.51190184770542, 55.595623298365034, -131.22248438914357, 44.86211286199684, -84.6492134484442, 44.48440891775458, -46.06410618378836, -12.938657130210252, 100.77466631727688, 53.40921585992423, -145.42919452042375, -13.251811418980846, -93.366642538598, -43.788609852785434, 26.72516614903048, -3.537508581246444, -8.018600810593817, -20.15592496334655, 185.89632739527315, -58.2891743315751, 47.65949223871445, -154.13431617930175, 274.13359285782036, -77.63603912198603, -142.17469680126734, 159.8232608759416, -27.594684977158963, 183.89358870330602, -173.33971726147632, -35.49847946764381, -180.5914418654805, -36.243722899605835, -151.20749223288541, -7.372588078798259, -163.68063899304678, 34.57187182109254, -95.24867178738646, -47.31986091829666, -59.77713485856195, -162.7993966028563, 59.42296780288657, -10.365609071770145, -39.023839139255784, 8.304108472093908, -42.687322277441204, 5.303055029457057, 64.67435114506648, -64.7826553753255, 186.8782799164967, -176.56866624048496, 81.0532776471884, -130.06546127333576, 139.01314216177389, -29.439520449780144, -83.00222906373601, -88.47929193524172, -96.52235304011785, 33.11364535409715, -100.49714648828157, -51.260113066945, 131.1287947726501, -58.559514026123026, 39.476045663695714, -194.3521380261137, -35.038438051209056, -83.75911932528311, -31.590593128392914, -80.97587346034051, -29.963969386946985, -117.3739955080201, -37.87902948583099, 9.405561297197494, 149.77834565086462, -5.412698537302557, -37.09552930901222, 22.517382780812405, -31.136590036634253, -13.419728517894443, -50.63596331364608, -14.97105710254255, 19.72968779706378, 132.6944375631061], "policy_AGENT-1_reward": [212.54779717732754, -109.87459892978855, 403.50784597630116, -77.47713141291374, 26.934055246735216, -91.41410045052756, 214.94812096461555, -112.4578651931042, 35.34505087330857, -139.2167243966516, 26.54498313138158, -121.53873406267587, -160.1700160767081, 107.82164080574826, 21.30555852640924, -12.193652566454645, -139.6336931445264, -88.52355556526568, -91.35929124050813, 56.26351761807073, -180.18561966125588, -31.762721230571813, -118.30562617273146, -57.93709939550815, -108.43762115237745, -12.509201678532577, 21.313770555013342, 58.735924405061716, -101.34964452636635, -83.68043911838062, -86.10720927115108, -43.27479214417071, 100.74573864798758, -85.48150692319638, -44.06852141626325, -19.728285229754746, 192.45480996924346, -139.9480224718395, 146.58196993356947, -120.35949908759191, 301.19389957658126, 52.493363226053205, -131.41498151331206, 172.48494407589368, -116.30428719785283, 224.63758264988343, -144.59676651128362, -65.48103766135739, -176.31817726530073, 11.069307505716404, -187.9531242186286, 65.83996050608138, -174.76337263117563, -127.33592108291481, -71.23553609870639, -89.94261954188309, -45.62602571258377, -223.4792888511185, 60.880598619797965, -201.3202273992389, -38.57562002635263, 172.07573285268893, -17.377486580540932, -22.625697873287145, 21.181497556017323, -163.3183154704716, 210.31590970028702, -103.41001049359048, 71.75630307593313, -129.63373716356284, 163.33663783802538, 58.16193902865807, 1.847063233185736, 31.203759387927104, -13.33361380059484, 27.05317394063362, -99.8544023907723, 85.1208377742041, 181.01175725676114, 104.79474812581869, 96.47555405261541, -177.9494520207694, -89.76899466658693, -8.37626819409002, -96.95168143645658, -195.94875989051576, -80.82050410049186, -116.85077572644975, 74.5909881694294, 10.003074693212753, 27.97524229680347, -81.8213678097824, -15.012993011960306, -8.312813453437709, -64.62759091072091, -84.64718079080927, -99.05948934804556, 8.975268963935298, -65.16280842742474, 139.1527947645714], "policy_AGENT-0_reward": [211.8990586347591, -109.86979723187606, 431.6583283904915, -123.24507754799498, 26.160435010144436, -134.20901020766462, 212.1213649729244, -112.60248178735824, 35.5128438519602, -48.1802039702842, 26.576584054507354, -12.083383429553457, -206.1477340896021, 63.17009479978384, -26.463992975671317, 41.0883496004712, -146.08250515965554, -88.55366442959453, -113.56686116614071, 170.81404791253013, -180.23257379328072, 45.41494388160156, -84.09321702562995, 45.033240540117994, -151.60327942304662, 28.326197185673355, 21.25850386258009, 11.377378966793664, -101.36672048641503, -83.61054216309995, -135.64595574020908, -22.273862023921176, 123.15993348973697, -85.52653558654922, -48.59100884652424, -28.72549257020526, 187.80312866214587, -57.73566503608182, 103.93429317900566, -164.31078801351563, 255.94443980611422, 9.544055123999208, -174.41332494235706, 197.53682672458484, -116.13278895536756, 248.902930397042, -190.05717533633856, -87.01309239292908, -184.17609841004727, 9.71896101414737, -187.96051736939796, 65.91479883982815, -174.7407783209895, 35.12294131473544, -17.94019778783117, -64.8236885829429, -45.530407860547555, -262.9730228255763, 86.2810879919241, -240.78002867050228, -30.847795300726286, 198.49766454374344, -17.429320327857635, -22.34179005416246, 42.91644859650896, -209.11658964442233, 187.59959811414646, -103.38226021696443, 64.28395462570577, -98.59968691018045, 139.85584910643502, 13.052624046188889, 24.34789817596568, 31.096170589279147, 17.613332473811884, 4.985054337349045, 92.23270151183758, 107.12194852110312, 208.54139980153684, 129.4913783419693, 49.383227738603736, -178.05827159262174, -89.79273668804326, -3.4814328683806135, -101.88091175701182, -221.1903348991576, -80.96438852300815, 10.64239615988405, 29.842470054455895, 124.28847690930961, 28.041914794140084, -130.98162724229888, -16.83299664366811, -55.67704970260476, -64.61249525131106, -133.85043720571846, -50.006954982590514, 5.074407359162606, -65.17140843728494, 168.71635121610882], "policy_AGENT-3_reward": [203.39545723288828, -168.0048086832529, 352.0167719101322, -84.74244386406947, -26.55640361748332, -128.5566320112479, 199.3813140413711, -123.84371775572882, -15.8816576597876, -161.60515710150068, -36.61504203115557, 25.6546693360988, -190.25655635349992, -38.66080037193707, -37.3292580994644, -5.519900190286304, -147.58084784665, -33.407672694393895, -107.52869063891521, 213.06472786685956, -131.34065597354274, -43.001055783419375, -121.22192802579283, -70.49740156079189, -46.172716466036974, 1.3318021582638677, 138.59994846114807, 41.55217284529563, -51.16556929944168, -13.267532051389793, -91.6195579629563, 17.3761081277151, 26.64459814687816, -3.6395275463199, -8.189414590932413, 14.501996596017674, 184.3642204142833, -152.44408311566642, 47.68922977837374, -140.7393948060292, 274.07695598956076, -77.65811030285111, -163.29473359504746, 155.8933829783997, -27.47270870558078, 192.52828599545495, -171.29849186117787, -35.48319599254091, -180.5357492610106, -36.10466037793714, -151.19402398895863, -7.435198374725324, -119.93189505983847, -157.3958874125772, -92.24893621488499, -47.37482938624428, -14.502112372593103, -162.92018591696623, 23.879454349229384, -10.3063766851143, 8.362997462680479, 8.36016956645362, 3.916164103397367, 3.4950849251809633, 64.4985866852659, -64.85287167162697, 178.283620424454, -132.32024160838765, 81.0519884161912, -56.51247711698463, 138.87360164003013, -29.396217359041096, -83.16201810925135, -47.26174233201456, -97.20305070658577, 33.13053940022801, 64.13854352542695, -51.2709899648016, 130.81478292891546, -58.701801452801014, 39.40990842498616, -194.81651521538478, -35.1433952756123, -83.93700919244212, -31.44279054446952, -81.06292388950159, -30.01129777164936, 53.763955843730706, -37.82648474367185, 93.93235812294819, 127.74225633158466, -5.3653897363827365, -37.30584127891919, 22.204235590867412, 13.70034515708669, -13.407542760917028, -50.70121312521557, -15.0542838871405, -2.311851881566157, 140.45420869976772]}, "sampler_perf": {"mean_env_wait_ms": 57.70629131562009, "mean_raw_obs_processing_ms": 2.424415810752093, "mean_inference_ms": 2.590760121607328, "mean_action_processing_ms": 0.14874179319369624}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 33600, "timers": {"sample_time_ms": 93981.589, "sample_throughput": 44.69, "load_time_ms": 162.7, "load_throughput": 25814.444, "learn_time_ms": 9872.293, "learn_throughput": 425.433, "update_time_ms": 7.959}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 12.751700401306152, "policy_loss": -0.038995470851659775, "vf_loss": 12.787464141845703, "vf_explained_var": 0.9137396812438965, "kl": 0.016144614666700363, "entropy": 1.2959004640579224, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 11.834362030029297, "policy_loss": -0.03989306464791298, "vf_loss": 11.871313095092773, "vf_explained_var": 0.9004720449447632, "kl": 0.014702964574098587, "entropy": 1.2870248556137085, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 13.521592140197754, "policy_loss": -0.03623013198375702, "vf_loss": 13.554607391357422, "vf_explained_var": 0.8953048586845398, "kl": 0.016074450686573982, "entropy": 1.2917550802230835, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 10.7424898147583, "policy_loss": -0.03938378393650055, "vf_loss": 10.778697967529297, "vf_explained_var": 0.9233022928237915, "kl": 0.01588178239762783, "entropy": 1.3039928674697876, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 33600, "num_steps_trained": 33600}, "done": false, "episodes_total": 286, "training_iteration": 8, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-28-13", "timestamp": 1624217293, "time_this_iter_s": 93.96153163909912, "time_total_s": 835.0642237663269, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c8594b90>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c8594320>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8594290>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85410e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541200>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541320>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8594290>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85410e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541200>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541320>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8594290>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85410e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541200>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541320>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8594290>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85410e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541200>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541320>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c85945f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 835.0642237663269, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 56.67985074626866, "ram_util_percent": 94.99701492537314}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1489.4532868532417, "episode_reward_min": -746.8529369372189, "episode_reward_mean": -39.55071108783582, "episode_len_mean": 118.38, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-2": -194.3521380261137, "AGENT-1": -198.92716445468412, "AGENT-0": -221.1903348991576, "AGENT-3": -213.8875211030394}, "policy_reward_max": {"AGENT-2": 302.27034057631494, "AGENT-1": 403.50784597630116, "AGENT-0": 431.6583283904915, "AGENT-3": 352.0167719101322}, "policy_reward_mean": {"AGENT-2": -12.280312498289993, "AGENT-1": -17.840056794123086, "AGENT-0": -6.386334336996806, "AGENT-3": -3.0440074584259906}, "custom_metrics": {"mean_ego_speed_mean": 42.01403500000001, "mean_ego_speed_min": 29.257749999999998, "mean_ego_speed_max": 47.136250000000004, "distance_travelled_mean": 95.08430500000003, "distance_travelled_min": 27.659999999999997, "distance_travelled_max": 124.86475000000002}, "hist_stats": {"episode_reward": [361.9305307460073, -182.73272165126548, 989.8373434782094, -249.30293333076204, 837.5562817499755, -524.4043140452815, 109.57618054009247, -197.96950921619506, 240.60089527677317, -349.4402138617176, 875.2894398818062, -500.9651592446663, -91.46910751161774, -448.33388326183393, 133.12773824653476, -543.223988736112, 542.274345675084, -304.32449584691403, 370.22546523190624, -224.25786331664492, 396.9112609000633, -683.8458100384028, 598.9465917219009, 438.7784105389514, 499.60614456021466, -229.67095430736276, 300.46559077360945, -572.7325499452925, 334.12495813293, -447.2618974725165, -79.38126351044167, -230.72686920685203, -145.31917825413774, -539.7670004975674, 17.297685944819904, 12.378825266025736, -139.96928576383627, -73.44110429005, -189.4456850734867, 98.28241303230784, -43.98030384178924, 89.71168326356046, 651.4967347598631, 117.02481098886417, 224.74473587990084, -745.1763768548893, -249.74356468145155, -179.55382958019578, -261.8659768663308, -579.1778921395152, -221.7601597820964, -169.81841923085514, 28.72794399438235, 237.62947102266796, 333.53775907339315, -223.58108332576666, -106.2473602435601, -19.268244784362615, -146.67633104157957, -245.3248892753391, -250.40362076949765, -15.975664666585184, -112.91638094921211, 581.0177922435546, 830.9132688682786, -555.1417793367094, 1489.4532868532417, -366.6850080067166, -0.03880780186607247, -482.59656331759055, 835.2375073356886, -474.71176844917693, 39.16806882241898, -397.64349268137767, -20.09635541933411, -229.93270399115914, -746.8529369372189, 93.63160177370777, -79.7253544806915, 63.913365986461585, -576.0521805541802, -243.91981505587268, -419.9667448932696, 495.73791669582613, -622.9813338172227, 15.51327972960727, -408.26998467259807, -38.916851498427306, -352.2777232252495, 4.2101405351943875, 281.9468891960184, 165.07469207707507, -399.31112883264683, -193.81032475185117, -406.7393655129145, -91.96115589316224, 277.2754364336334, -178.18507863731202, -108.8675456643137, -54.10770616728885], "episode_lengths": [81, 119, 127, 121, 183, 121, 133, 128, 130, 119, 119, 105, 127, 125, 134, 125, 130, 135, 123, 110, 120, 115, 120, 114, 125, 120, 113, 135, 117, 129, 116, 73, 137, 126, 119, 128, 121, 113, 163, 119, 120, 123, 138, 127, 126, 123, 28, 128, 124, 130, 31, 120, 129, 125, 112, 125, 124, 127, 107, 126, 118, 132, 107, 126, 123, 112, 155, 132, 121, 135, 128, 122, 44, 110, 74, 131, 134, 129, 122, 136, 120, 88, 112, 123, 70, 120, 117, 125, 126, 117, 130, 122, 112, 52, 121, 122, 121, 84, 132, 122], "policy_AGENT-2_reward": [64.66273629426458, -110.87310406631363, 248.16820566979703, -50.15319719680904, 284.7828169122402, -143.45060654944854, 44.38732939607923, -94.29206977971772, 96.1726976087931, -47.7981193615188, 236.01114276756908, -132.7448412757503, 44.191944106737125, -83.89555106474846, 27.553062247597296, -131.89916953308432, 125.21016376864168, -112.47792986631752, 104.76871272080865, -33.64764349080524, 178.07249977910865, -183.94364436099204, 37.67104584082904, 37.34840756279168, 143.7468818163399, -9.40384754111501, 72.6772693886235, -137.46895897874117, 66.81917339103165, -84.92169534996603, 40.61707893026555, -23.933578116458616, -14.411365291982868, -63.747602319013595, -64.05387120577896, -29.439520449780144, -83.00222906373601, -88.47929193524172, -96.52235304011785, 33.11364535409715, -100.49714648828157, -51.260113066945, 131.1287947726501, -58.559514026123026, 39.476045663695714, -194.3521380261137, -35.038438051209056, -83.75911932528311, -31.590593128392914, -80.97587346034051, -29.963969386946985, -117.3739955080201, -37.87902948583099, 9.405561297197494, 149.77834565086462, -5.412698537302557, -37.09552930901222, 22.517382780812405, -31.136590036634253, -13.419728517894443, -50.63596331364608, -14.97105710254255, 19.72968779706378, 132.6944375631061, 203.070955823303, -167.3925744917915, 302.27034057631494, -81.22035518173874, -26.576894441262365, -128.4168206481503, 208.7867073567772, -125.80770371298559, -15.808168243062234, -48.641407212941246, -36.60288057406745, -121.96525583502864, -190.27863041740892, -38.69933345988716, -37.23766193196506, 40.5385691427313, -142.75513440334828, -33.43492236661852, -107.51190184770542, 55.595623298365034, -131.22248438914357, 44.86211286199684, -84.6492134484442, 44.48440891775458, -46.06410618378836, -12.938657130210252, 100.77466631727688, 53.40921585992423, -145.42919452042375, -13.251811418980846, -93.366642538598, -43.788609852785434, 26.72516614903048, -3.537508581246444, -8.018600810593817, -20.15592496334655], "policy_AGENT-1_reward": [116.18067360344952, -110.43340120319999, 264.215115761996, -50.012806838238134, 163.83761945219914, -142.8382713800114, 14.489194471367133, -17.35391277955608, 29.26390578658472, -124.08577254754714, 188.22056704001213, -140.34656365498415, -85.55857979611736, -125.12044681239081, 62.89377858129885, -110.48675354854731, 159.5649150932213, -17.745781489032776, 83.54836850682062, -100.10590497020213, 34.62816184701909, -180.06634924454028, 38.166641679365455, 37.84964499618097, 145.6794220253905, -81.24728609701482, 79.1144361974561, -142.24186124577798, 104.4897123526528, -119.02956898272038, -67.02205152875686, -91.32814185748917, -55.7733132214202, -198.92716445468412, -63.61776383251522, 58.16193902865807, 1.847063233185736, 31.203759387927104, -13.33361380059484, 27.05317394063362, -99.8544023907723, 85.1208377742041, 181.01175725676114, 104.79474812581869, 96.47555405261541, -177.9494520207694, -89.76899466658693, -8.37626819409002, -96.95168143645658, -195.94875989051576, -80.82050410049186, -116.85077572644975, 74.5909881694294, 10.003074693212753, 27.97524229680347, -81.8213678097824, -15.012993011960306, -8.312813453437709, -64.62759091072091, -84.64718079080927, -99.05948934804556, 8.975268963935298, -65.16280842742474, 139.1527947645714, 212.54779717732754, -109.87459892978855, 403.50784597630116, -77.47713141291374, 26.934055246735216, -91.41410045052756, 214.94812096461555, -112.4578651931042, 35.34505087330857, -139.2167243966516, 26.54498313138158, -121.53873406267587, -160.1700160767081, 107.82164080574826, 21.30555852640924, -12.193652566454645, -139.6336931445264, -88.52355556526568, -91.35929124050813, 56.26351761807073, -180.18561966125588, -31.762721230571813, -118.30562617273146, -57.93709939550815, -108.43762115237745, -12.509201678532577, 21.313770555013342, 58.735924405061716, -101.34964452636635, -83.68043911838062, -86.10720927115108, -43.27479214417071, 100.74573864798758, -85.48150692319638, -44.06852141626325, -19.728285229754746], "policy_AGENT-0_reward": [116.36812565147801, -0.5113114805407406, 217.71444474510034, -96.56042020985863, 145.51625860445137, -138.66180219872902, 6.5089162871769535, 8.116798408562987, 96.72154418330481, -47.2519721513993, 210.05594444434342, -140.2845749039493, 44.76062269500016, -155.39082811074329, 15.084237640886222, -155.956923052006, 126.0356354291904, -61.62508653967848, 105.3299440259034, -100.13700671360672, 34.6675289368747, -180.03552658358703, 275.35917736234313, 193.42656489282228, 97.94512459903265, -129.6596668142539, 73.24392903372963, -181.61188253827703, 67.38952696531982, -158.3297586826323, -66.98123161077702, -91.30259970679307, -60.69124561768625, -63.20471262083075, 52.450680193342976, 13.052624046188889, 24.34789817596568, 31.096170589279147, 17.613332473811884, 4.985054337349045, 92.23270151183758, 107.12194852110312, 208.54139980153684, 129.4913783419693, 49.383227738603736, -178.05827159262174, -89.79273668804326, -3.4814328683806135, -101.88091175701182, -221.1903348991576, -80.96438852300815, 10.64239615988405, 29.842470054455895, 124.28847690930961, 28.041914794140084, -130.98162724229888, -16.83299664366811, -55.67704970260476, -64.61249525131106, -133.85043720571846, -50.006954982590514, 5.074407359162606, -65.17140843728494, 168.71635121610882, 211.8990586347591, -109.86979723187606, 431.6583283904915, -123.24507754799498, 26.160435010144436, -134.20901020766462, 212.1213649729244, -112.60248178735824, 35.5128438519602, -48.1802039702842, 26.576584054507354, -12.083383429553457, -206.1477340896021, 63.17009479978384, -26.463992975671317, 41.0883496004712, -146.08250515965554, -88.55366442959453, -113.56686116614071, 170.81404791253013, -180.23257379328072, 45.41494388160156, -84.09321702562995, 45.033240540117994, -151.60327942304662, 28.326197185673355, 21.25850386258009, 11.377378966793664, -101.36672048641503, -83.61054216309995, -135.64595574020908, -22.273862023921176, 123.15993348973697, -85.52653558654922, -48.59100884652424, -28.72549257020526], "policy_AGENT-3_reward": [64.7189951968153, 39.08509509878883, 259.73957730131605, -52.57650908585632, 243.41958678108477, -99.45363391709188, 44.19074038546901, -94.44032506548436, 18.442747698090283, -130.30434980125227, 241.00178562988063, -87.58917940998266, -94.86309451723757, -83.9270572739516, 27.596659776752247, -144.88114260247406, 131.46363138403095, -112.47569795188514, 76.57843997837347, 9.632691857969055, 149.54307033706104, -139.80028984928333, 247.74972683936332, 170.15379308715652, 112.23471611945178, -9.360153854979215, 75.42995615380038, -111.40984718249628, 95.42654542392563, -84.9808744571977, 14.004940698826644, -24.16254952611124, -14.44325412304835, -213.8875211030394, 92.51864078977118, -29.396217359041096, -83.16201810925135, -47.26174233201456, -97.20305070658577, 33.13053940022801, 64.13854352542695, -51.2709899648016, 130.81478292891546, -58.701801452801014, 39.40990842498616, -194.81651521538478, -35.1433952756123, -83.93700919244212, -31.44279054446952, -81.06292388950159, -30.01129777164936, 53.763955843730706, -37.82648474367185, 93.93235812294819, 127.74225633158466, -5.3653897363827365, -37.30584127891919, 22.204235590867412, 13.70034515708669, -13.407542760917028, -50.70121312521557, -15.0542838871405, -2.311851881566157, 140.45420869976772, 203.39545723288828, -168.0048086832529, 352.0167719101322, -84.74244386406947, -26.55640361748332, -128.5566320112479, 199.3813140413711, -123.84371775572882, -15.8816576597876, -161.60515710150068, -36.61504203115557, 25.6546693360988, -190.25655635349992, -38.66080037193707, -37.3292580994644, -5.519900190286304, -147.58084784665, -33.407672694393895, -107.52869063891521, 213.06472786685956, -131.34065597354274, -43.001055783419375, -121.22192802579283, -70.49740156079189, -46.172716466036974, 1.3318021582638677, 138.59994846114807, 41.55217284529563, -51.16556929944168, -13.267532051389793, -91.6195579629563, 17.3761081277151, 26.64459814687816, -3.6395275463199, -8.189414590932413, 14.501996596017674]}, "sampler_perf": {"mean_env_wait_ms": 56.71026653398729, "mean_raw_obs_processing_ms": 2.399653997460393, "mean_inference_ms": 2.538475106118912, "mean_action_processing_ms": 0.14700553986853357}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 37800, "timers": {"sample_time_ms": 92687.538, "sample_throughput": 45.314, "load_time_ms": 146.153, "load_throughput": 28737.05, "learn_time_ms": 9719.53, "learn_throughput": 432.12, "update_time_ms": 8.016}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 11.846580505371094, "policy_loss": -0.043415386229753494, "vf_loss": 11.886543273925781, "vf_explained_var": 0.9443159699440002, "kl": 0.017269957810640335, "entropy": 1.2805922031402588, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 10.35897159576416, "policy_loss": -0.04167518392205238, "vf_loss": 10.396784782409668, "vf_explained_var": 0.93668532371521, "kl": 0.019308429211378098, "entropy": 1.2658320665359497, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 12.58079719543457, "policy_loss": -0.043208085000514984, "vf_loss": 12.620582580566406, "vf_explained_var": 0.9330558776855469, "kl": 0.017116054892539978, "entropy": 1.2589446306228638, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 10.950997352600098, "policy_loss": -0.045250166207551956, "vf_loss": 10.992247581481934, "vf_explained_var": 0.9486904740333557, "kl": 0.020002080127596855, "entropy": 1.2846204042434692, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 37800, "num_steps_trained": 37800}, "done": false, "episodes_total": 321, "training_iteration": 9, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-29-44", "timestamp": 1624217384, "time_this_iter_s": 90.87414121627808, "time_total_s": 925.938364982605, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c8688050>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c8688b00>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688f80>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3dd0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3ef0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688f80>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3dd0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3ef0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688f80>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3dd0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3ef0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688f80>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3dd0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3ef0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c86479e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 925.938364982605, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 56.05153846153847, "ram_util_percent": 95.00153846153847}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1013.4831833632504, "episode_reward_min": -746.8529369372189, "episode_reward_mean": -30.066572940181377, "episode_len_mean": 117.83, "episodes_this_iter": 36, "policy_reward_min": {"AGENT-0": -206.1477340896021, "AGENT-3": -213.8875211030394, "AGENT-2": -190.27863041740892, "AGENT-1": -198.92716445468412}, "policy_reward_max": {"AGENT-0": 275.35917736234313, "AGENT-3": 304.5373093810452, "AGENT-2": 284.7828169122402, "AGENT-1": 264.215115761996}, "policy_reward_mean": {"AGENT-0": -4.993868063255691, "AGENT-3": -1.7962214294144783, "AGENT-2": -5.092859714774291, "AGENT-1": -18.183623732736947}, "custom_metrics": {"mean_ego_speed_mean": 42.4177, "mean_ego_speed_min": 29.257749999999998, "mean_ego_speed_max": 47.136250000000004, "distance_travelled_mean": 93.71218499999999, "distance_travelled_min": 36.320499999999996, "distance_travelled_max": 124.839}, "hist_stats": {"episode_reward": [-290.07279399055096, -89.9988376326201, -288.68650982659244, 985.3683813481786, -265.8451495050695, 642.2454367541443, -68.83843571339887, 64.72750045144102, -364.56158956435206, 17.106266012018587, -315.3344318819188, 1013.4831833632504, -368.12301987371103, 63.072365433384846, -632.7258233749525, 53.297847980664756, -592.1127132582814, -63.26523286139382, -379.1206316908028, 78.99639716910256, 154.48794217687865, 650.2488519444987, -32.32597754014702, 422.530719226379, -179.6315448428978, -150.74425850152608, -75.32648746691198, 451.2948872858793, 250.3627994002484, -484.4325095476723, -282.38530565414214, -485.21986054594936, 594.1666240500845, 26.04970329904249, 546.9181829957372, 494.1757401058481, -474.71176844917693, 39.16806882241898, -397.64349268137767, -20.09635541933411, -229.93270399115914, -746.8529369372189, 93.63160177370777, -79.7253544806915, 63.913365986461585, -576.0521805541802, -243.91981505587268, -419.9667448932696, 495.73791669582613, -622.9813338172227, 15.51327972960727, -408.26998467259807, -38.916851498427306, -352.2777232252495, 4.2101405351943875, 281.9468891960184, 165.07469207707507, -399.31112883264683, -193.81032475185117, -406.7393655129145, -91.96115589316224, 277.2754364336334, -178.18507863731202, -108.8675456643137, -54.10770616728885, 361.9305307460073, -182.73272165126548, 989.8373434782094, -249.30293333076204, 837.5562817499755, -524.4043140452815, 109.57618054009247, -197.96950921619506, 240.60089527677317, -349.4402138617176, 875.2894398818062, -500.9651592446663, -91.46910751161774, -448.33388326183393, 133.12773824653476, -543.223988736112, 542.274345675084, -304.32449584691403, 370.22546523190624, -224.25786331664492, 396.9112609000633, -683.8458100384028, 598.9465917219009, 438.7784105389514, 499.60614456021466, -229.67095430736276, 300.46559077360945, -572.7325499452925, 334.12495813293, -447.2618974725165, -79.38126351044167, -230.72686920685203, -145.31917825413774, -539.7670004975674, 17.297685944819904], "episode_lengths": [119, 123, 119, 134, 119, 119, 117, 129, 119, 109, 121, 126, 142, 122, 131, 118, 119, 121, 122, 118, 121, 128, 128, 122, 42, 73, 123, 113, 116, 131, 126, 110, 113, 118, 123, 137, 122, 44, 110, 74, 131, 134, 129, 122, 136, 120, 88, 112, 123, 70, 120, 117, 125, 126, 117, 130, 122, 112, 52, 121, 122, 121, 84, 132, 122, 81, 119, 127, 121, 183, 121, 133, 128, 130, 119, 119, 105, 127, 125, 134, 125, 130, 135, 123, 110, 120, 115, 120, 114, 125, 120, 113, 135, 117, 129, 116, 73, 137, 126, 119], "policy_AGENT-0_reward": [-39.028447468516404, 34.87238855593263, -45.27189353697274, 266.57380772362467, -41.054571171516415, 174.42015748798408, 30.270803098957543, 22.998385207057083, -46.559829291043414, 30.43356587511239, -60.99382330030752, 250.17176811681475, -93.85075085472673, 44.94124338988316, -167.18092573189875, 37.995545807688806, -189.32240110155058, 34.64699417517619, -99.46682200834927, 54.170366791275754, 119.8596142850635, 183.16768271199427, 9.176265734659005, 156.0429886367045, -77.91739822755784, -60.63789052585518, -25.95936368714913, 75.53493677013917, 27.332647376602242, -199.80753754048817, -155.053455769998, -86.85793874399471, 154.1753051326396, 59.04960742080131, 42.653202995425524, 86.20840729829001, -112.60248178735824, 35.5128438519602, -48.1802039702842, 26.576584054507354, -12.083383429553457, -206.1477340896021, 63.17009479978384, -26.463992975671317, 41.0883496004712, -146.08250515965554, -88.55366442959453, -113.56686116614071, 170.81404791253013, -180.23257379328072, 45.41494388160156, -84.09321702562995, 45.033240540117994, -151.60327942304662, 28.326197185673355, 21.25850386258009, 11.377378966793664, -101.36672048641503, -83.61054216309995, -135.64595574020908, -22.273862023921176, 123.15993348973697, -85.52653558654922, -48.59100884652424, -28.72549257020526, 116.36812565147801, -0.5113114805407406, 217.71444474510034, -96.56042020985863, 145.51625860445137, -138.66180219872902, 6.5089162871769535, 8.116798408562987, 96.72154418330481, -47.2519721513993, 210.05594444434342, -140.2845749039493, 44.76062269500016, -155.39082811074329, 15.084237640886222, -155.956923052006, 126.0356354291904, -61.62508653967848, 105.3299440259034, -100.13700671360672, 34.6675289368747, -180.03552658358703, 275.35917736234313, 193.42656489282228, 97.94512459903265, -129.6596668142539, 73.24392903372963, -181.61188253827703, 67.38952696531982, -158.3297586826323, -66.98123161077702, -91.30259970679307, -60.69124561768625, -63.20471262083075, 52.450680193342976], "policy_AGENT-3_reward": [-115.72468375654714, -86.28972474040467, -100.84221872244704, 304.5373093810452, -95.23016743612743, 133.35628172314557, 71.26989486169543, -14.400075585360476, -138.37899021175093, 2.1491924129197097, -19.04469854958517, 250.86637019766982, -142.5448676301192, -16.91093721677159, -179.453474937979, -13.30935577464889, -169.16306449693627, -71.68473861566702, -113.09933053028693, -17.274927805009437, -31.304850359873942, 150.54121482233694, -48.12189426451714, 195.94871250958883, -11.951523182682655, -14.688972026233733, 13.607905489292952, 137.12402796024236, 94.072858742429, -165.87050145639728, -9.029781082853205, -169.9117621606063, 129.36024730962095, 99.02889913571644, 226.13201474637714, 141.85624395838812, -123.84371775572882, -15.8816576597876, -161.60515710150068, -36.61504203115557, 25.6546693360988, -190.25655635349992, -38.66080037193707, -37.3292580994644, -5.519900190286304, -147.58084784665, -33.407672694393895, -107.52869063891521, 213.06472786685956, -131.34065597354274, -43.001055783419375, -121.22192802579283, -70.49740156079189, -46.172716466036974, 1.3318021582638677, 138.59994846114807, 41.55217284529563, -51.16556929944168, -13.267532051389793, -91.6195579629563, 17.3761081277151, 26.64459814687816, -3.6395275463199, -8.189414590932413, 14.501996596017674, 64.7189951968153, 39.08509509878883, 259.73957730131605, -52.57650908585632, 243.41958678108477, -99.45363391709188, 44.19074038546901, -94.44032506548436, 18.442747698090283, -130.30434980125227, 241.00178562988063, -87.58917940998266, -94.86309451723757, -83.9270572739516, 27.596659776752247, -144.88114260247406, 131.46363138403095, -112.47569795188514, 76.57843997837347, 9.632691857969055, 149.54307033706104, -139.80028984928333, 247.74972683936332, 170.15379308715652, 112.23471611945178, -9.360153854979215, 75.42995615380038, -111.40984718249628, 95.42654542392563, -84.9808744571977, 14.004940698826644, -24.16254952611124, -14.44325412304835, -213.8875211030394, 92.51864078977118], "policy_AGENT-2_reward": [-39.590134952290896, 34.32065397125123, -45.82464660308175, 206.76706112460081, -41.614055279926504, 160.1469159755691, -85.45003075471249, -14.386116654129125, -47.00363143592832, -45.877558462610516, -117.98951421306401, 249.60520974103892, -78.73190893811338, 44.38495339139406, -161.32065933969494, 37.430860320741566, -89.97969830468352, 34.09964370636211, -113.06450653014038, 53.60966182150792, -31.457949666002143, 156.71615830489523, -48.00161199078662, 35.01164757836498, -11.887450086899428, -14.56308429359492, -31.80597337876602, 163.0600240147326, 26.739263466709634, -59.66351053960056, -9.003663122404816, -87.4110749113755, 153.60823409886743, -66.22298818464667, 42.09717417444914, 138.99795291708284, -125.80770371298559, -15.808168243062234, -48.641407212941246, -36.60288057406745, -121.96525583502864, -190.27863041740892, -38.69933345988716, -37.23766193196506, 40.5385691427313, -142.75513440334828, -33.43492236661852, -107.51190184770542, 55.595623298365034, -131.22248438914357, 44.86211286199684, -84.6492134484442, 44.48440891775458, -46.06410618378836, -12.938657130210252, 100.77466631727688, 53.40921585992423, -145.42919452042375, -13.251811418980846, -93.366642538598, -43.788609852785434, 26.72516614903048, -3.537508581246444, -8.018600810593817, -20.15592496334655, 64.66273629426458, -110.87310406631363, 248.16820566979703, -50.15319719680904, 284.7828169122402, -143.45060654944854, 44.38732939607923, -94.29206977971772, 96.1726976087931, -47.7981193615188, 236.01114276756908, -132.7448412757503, 44.191944106737125, -83.89555106474846, 27.553062247597296, -131.89916953308432, 125.21016376864168, -112.47792986631752, 104.76871272080865, -33.64764349080524, 178.07249977910865, -183.94364436099204, 37.67104584082904, 37.34840756279168, 143.7468818163399, -9.40384754111501, 72.6772693886235, -137.46895897874117, 66.81917339103165, -84.92169534996603, 40.61707893026555, -23.933578116458616, -14.411365291982868, -63.747602319013595, -64.05387120577896], "policy_AGENT-1_reward": [-95.72952781319705, -72.90215541939936, -96.7477509640909, 207.49020311890746, -87.94635561749928, 174.32208156744562, -84.92910291933933, 70.51530748387357, -132.61913862562946, 30.40106618659706, -117.30639581896142, 262.83983530772707, -52.9954924507512, -9.342894131120822, -124.7707633653801, -8.81920237311671, -143.6475493551108, -60.32713212726508, -53.48997262202637, -11.508703638671694, 97.39112791769108, 159.82379610527173, 54.621262980497654, 35.5273705017207, -77.87517334575789, -60.854311655842245, -31.16905589028973, 75.57589854076537, 102.21802981450752, -59.09096001118629, -109.29840567888617, -141.03908472997313, 157.0228375089571, -65.80581507282854, 236.03579107948568, 127.11313593208709, -112.4578651931042, 35.34505087330857, -139.2167243966516, 26.54498313138158, -121.53873406267587, -160.1700160767081, 107.82164080574826, 21.30555852640924, -12.193652566454645, -139.6336931445264, -88.52355556526568, -91.35929124050813, 56.26351761807073, -180.18561966125588, -31.762721230571813, -118.30562617273146, -57.93709939550815, -108.43762115237745, -12.509201678532577, 21.313770555013342, 58.735924405061716, -101.34964452636635, -83.68043911838062, -86.10720927115108, -43.27479214417071, 100.74573864798758, -85.48150692319638, -44.06852141626325, -19.728285229754746, 116.18067360344952, -110.43340120319999, 264.215115761996, -50.012806838238134, 163.83761945219914, -142.8382713800114, 14.489194471367133, -17.35391277955608, 29.26390578658472, -124.08577254754714, 188.22056704001213, -140.34656365498415, -85.55857979611736, -125.12044681239081, 62.89377858129885, -110.48675354854731, 159.5649150932213, -17.745781489032776, 83.54836850682062, -100.10590497020213, 34.62816184701909, -180.06634924454028, 38.166641679365455, 37.84964499618097, 145.6794220253905, -81.24728609701482, 79.1144361974561, -142.24186124577798, 104.4897123526528, -119.02956898272038, -67.02205152875686, -91.32814185748917, -55.7733132214202, -198.92716445468412, -63.61776383251522]}, "sampler_perf": {"mean_env_wait_ms": 55.88139193500199, "mean_raw_obs_processing_ms": 2.383138046767328, "mean_inference_ms": 2.4977623509971267, "mean_action_processing_ms": 0.14555358463902554}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 42000, "timers": {"sample_time_ms": 91464.99, "sample_throughput": 45.919, "load_time_ms": 132.956, "load_throughput": 31589.301, "learn_time_ms": 9567.455, "learn_throughput": 438.988, "update_time_ms": 8.056}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 10.924358367919922, "policy_loss": -0.04309840127825737, "vf_loss": 10.963753700256348, "vf_explained_var": 0.9526052474975586, "kl": 0.01851259358227253, "entropy": 1.276408314704895, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 7.796721458435059, "policy_loss": -0.0405769869685173, "vf_loss": 7.833647727966309, "vf_explained_var": 0.9549921751022339, "kl": 0.01824798807501793, "entropy": 1.256578803062439, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 8.459568977355957, "policy_loss": -0.055805504322052, "vf_loss": 8.511645317077637, "vf_explained_var": 0.9547824859619141, "kl": 0.01864822767674923, "entropy": 1.2391499280929565, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 7.903412342071533, "policy_loss": -0.041391097009181976, "vf_loss": 7.93991231918335, "vf_explained_var": 0.9644429683685303, "kl": 0.01630122773349285, "entropy": 1.2683606147766113, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 42000, "num_steps_trained": 42000}, "done": false, "episodes_total": 357, "training_iteration": 10, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-31-13", "timestamp": 1624217473, "time_this_iter_s": 88.70534324645996, "time_total_s": 1014.6437082290649, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c8541c20>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c8541b00>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85418c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85417a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541440>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85418c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85417a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541440>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85418c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85417a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541440>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85418c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85417a0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541440>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8647b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1014.6437082290649, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 56.68976377952756, "ram_util_percent": 95.0}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1123.9671247421402, "episode_reward_min": -1222.747537744931, "episode_reward_mean": 3.0620467240474256, "episode_len_mean": 119.52, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-2": -309.5638432165305, "AGENT-1": -332.31130080401647, "AGENT-0": -331.98564691753813, "AGENT-3": -276.28913266649135}, "policy_reward_max": {"AGENT-2": 281.4832652177225, "AGENT-1": 295.98389407691855, "AGENT-0": 292.037958216218, "AGENT-3": 304.5373093810452}, "policy_reward_mean": {"AGENT-2": 2.5430235086109154, "AGENT-1": -9.056343450516216, "AGENT-0": 9.882485557238144, "AGENT-3": -0.3071188912854166}, "custom_metrics": {"mean_ego_speed_mean": 42.335637500000004, "mean_ego_speed_min": 29.257749999999998, "mean_ego_speed_max": 47.136250000000004, "distance_travelled_mean": 91.94703000000001, "distance_travelled_min": 30.45075, "distance_travelled_max": 124.96375}, "hist_stats": {"episode_reward": [1123.9671247421402, -236.39132117344772, -94.59949148207205, -791.4109862365663, 914.5976878863378, -222.6127177083526, 842.5485769257233, -636.5355784187409, 1076.7621922718956, 656.263915452058, -329.2874186338901, 175.3807244683703, -9.873095481826695, -744.270074236772, -142.90667524568133, -114.75518101436859, -92.84101991527383, -852.8407113225744, 73.38304772606293, -1222.747537744931, 403.6513163933723, -74.16643202627122, -450.5839563549097, -262.36772426573305, -451.6112258838151, 256.7092367509499, 366.0549173237278, 240.6360043135787, -388.51459511260947, 272.8537033608936, 123.44627605515711, 472.5817527043314, -543.6957392375939, 134.44236912120013, 466.62062948407157, 109.57618054009247, -197.96950921619506, 240.60089527677317, -349.4402138617176, 875.2894398818062, -500.9651592446663, -91.46910751161774, -448.33388326183393, 133.12773824653476, -543.223988736112, 542.274345675084, -304.32449584691403, 370.22546523190624, -224.25786331664492, 396.9112609000633, -683.8458100384028, 598.9465917219009, 438.7784105389514, 499.60614456021466, -229.67095430736276, 300.46559077360945, -572.7325499452925, 334.12495813293, -447.2618974725165, -79.38126351044167, -230.72686920685203, -145.31917825413774, -539.7670004975674, 17.297685944819904, -290.07279399055096, -89.9988376326201, -288.68650982659244, 985.3683813481786, -265.8451495050695, 642.2454367541443, -68.83843571339887, 64.72750045144102, -364.56158956435206, 17.106266012018587, -315.3344318819188, 1013.4831833632504, -368.12301987371103, 63.072365433384846, -632.7258233749525, 53.297847980664756, -592.1127132582814, -63.26523286139382, -379.1206316908028, 78.99639716910256, 154.48794217687865, 650.2488519444987, -32.32597754014702, 422.530719226379, -179.6315448428978, -150.74425850152608, -75.32648746691198, 451.2948872858793, 250.3627994002484, -484.4325095476723, -282.38530565414214, -485.21986054594936, 594.1666240500845, 26.04970329904249, 546.9181829957372, 494.1757401058481], "episode_lengths": [135, 121, 107, 117, 142, 129, 153, 106, 122, 130, 118, 92, 121, 81, 122, 104, 117, 99, 127, 127, 120, 126, 147, 28, 121, 129, 115, 107, 118, 139, 118, 136, 133, 118, 134, 133, 128, 130, 119, 119, 105, 127, 125, 134, 125, 130, 135, 123, 110, 120, 115, 120, 114, 125, 120, 113, 135, 117, 129, 116, 73, 137, 126, 119, 119, 123, 119, 134, 119, 119, 117, 129, 119, 109, 121, 126, 142, 122, 131, 118, 119, 121, 122, 118, 121, 128, 128, 122, 42, 73, 123, 113, 116, 131, 126, 110, 113, 118, 123, 137], "policy_AGENT-2_reward": [281.4832652177225, -39.040471777989296, -69.17792639284059, -309.5638432165305, 240.22351578406594, -120.0916919291547, 241.65727288211662, -224.35743956975642, 261.0727475880771, 131.57660451311375, -41.278730488698365, 34.00204245182636, 41.37787996003321, -208.4962178697195, 32.30557771427813, 68.6494115584542, 21.581724409284718, -234.1319552312245, -30.851295331837942, -282.1614573568852, 108.49249291323434, -76.33596937415656, 26.945640140245246, -39.155287229272616, -65.34399889771807, -3.506667092746696, 32.46435054719667, 9.87779835576671, -69.15051038423547, -37.5579334221674, -36.18532360167931, 136.86076395979728, -34.906140320155494, -45.66302055199051, 220.3339741502974, 44.38732939607923, -94.29206977971772, 96.1726976087931, -47.7981193615188, 236.01114276756908, -132.7448412757503, 44.191944106737125, -83.89555106474846, 27.553062247597296, -131.89916953308432, 125.21016376864168, -112.47792986631752, 104.76871272080865, -33.64764349080524, 178.07249977910865, -183.94364436099204, 37.67104584082904, 37.34840756279168, 143.7468818163399, -9.40384754111501, 72.6772693886235, -137.46895897874117, 66.81917339103165, -84.92169534996603, 40.61707893026555, -23.933578116458616, -14.411365291982868, -63.747602319013595, -64.05387120577896, -39.590134952290896, 34.32065397125123, -45.82464660308175, 206.76706112460081, -41.614055279926504, 160.1469159755691, -85.45003075471249, -14.386116654129125, -47.00363143592832, -45.877558462610516, -117.98951421306401, 249.60520974103892, -78.73190893811338, 44.38495339139406, -161.32065933969494, 37.430860320741566, -89.97969830468352, 34.09964370636211, -113.06450653014038, 53.60966182150792, -31.457949666002143, 156.71615830489523, -48.00161199078662, 35.01164757836498, -11.887450086899428, -14.56308429359492, -31.80597337876602, 163.0600240147326, 26.739263466709634, -59.66351053960056, -9.003663122404816, -87.4110749113755, 153.60823409886743, -66.22298818464667, 42.09717417444914, 138.99795291708284], "policy_AGENT-1_reward": [295.98389407691855, -75.27984087952615, 21.900900094507012, -108.27605484432397, 238.48483468750905, -119.57150653490692, 234.0991459731709, -118.10677964039658, 261.6902974471453, 179.06854369359655, -119.63611479335017, 34.30901566770965, -42.99430128440967, -163.53045152839834, -100.02128416784028, -105.5947688702305, -62.182350792982035, -192.42640314385457, 54.64175219868373, -332.31130080401647, 99.56986992210884, 61.46687158042222, -244.23701918749268, -92.00276111900189, -155.4938310063444, -2.8640329569408394, 154.65661958500795, 122.87213479021773, -120.38629233805811, -37.1252642090958, 85.75833807200546, 141.9112328344301, -34.30986774745817, -45.164524125120536, 28.9326213654095, 14.489194471367133, -17.35391277955608, 29.26390578658472, -124.08577254754714, 188.22056704001213, -140.34656365498415, -85.55857979611736, -125.12044681239081, 62.89377858129885, -110.48675354854731, 159.5649150932213, -17.745781489032776, 83.54836850682062, -100.10590497020213, 34.62816184701909, -180.06634924454028, 38.166641679365455, 37.84964499618097, 145.6794220253905, -81.24728609701482, 79.1144361974561, -142.24186124577798, 104.4897123526528, -119.02956898272038, -67.02205152875686, -91.32814185748917, -55.7733132214202, -198.92716445468412, -63.61776383251522, -95.72952781319705, -72.90215541939936, -96.7477509640909, 207.49020311890746, -87.94635561749928, 174.32208156744562, -84.92910291933933, 70.51530748387357, -132.61913862562946, 30.40106618659706, -117.30639581896142, 262.83983530772707, -52.9954924507512, -9.342894131120822, -124.7707633653801, -8.81920237311671, -143.6475493551108, -60.32713212726508, -53.48997262202637, -11.508703638671694, 97.39112791769108, 159.82379610527173, 54.621262980497654, 35.5273705017207, -77.87517334575789, -60.854311655842245, -31.16905589028973, 75.57589854076537, 102.21802981450752, -59.09096001118629, -109.29840567888617, -141.03908472997313, 157.0228375089571, -65.80581507282854, 236.03579107948568, 127.11313593208709], "policy_AGENT-0_reward": [248.88402822389298, -38.473937162556965, 21.952537661897203, -108.23089535261502, 226.36121593632177, 15.081027248234758, 200.3283175613414, -118.00788156775666, 292.037958216218, 170.43269428072347, -40.85030516228735, 34.55270518264559, 41.9224625460607, -163.59126229279457, 32.723111832618095, -105.6323183017713, 22.14090216781047, -192.12322599246284, 80.44095786996894, -331.98564691753813, 109.05797339932985, 17.17674351365102, 27.50373600112187, -92.03664689324795, -64.89970447532524, 146.9993187240445, 33.03305921199508, 10.446816742461333, -68.59767798917902, 154.97869754041102, 110.03750060467787, 94.58963115397827, -254.36687268077418, 127.09710565141606, 28.900634157789273, 6.5089162871769535, 8.116798408562987, 96.72154418330481, -47.2519721513993, 210.05594444434342, -140.2845749039493, 44.76062269500016, -155.39082811074329, 15.084237640886222, -155.956923052006, 126.0356354291904, -61.62508653967848, 105.3299440259034, -100.13700671360672, 34.6675289368747, -180.03552658358703, 275.35917736234313, 193.42656489282228, 97.94512459903265, -129.6596668142539, 73.24392903372963, -181.61188253827703, 67.38952696531982, -158.3297586826323, -66.98123161077702, -91.30259970679307, -60.69124561768625, -63.20471262083075, 52.450680193342976, -39.028447468516404, 34.87238855593263, -45.27189353697274, 266.57380772362467, -41.054571171516415, 174.42015748798408, 30.270803098957543, 22.998385207057083, -46.559829291043414, 30.43356587511239, -60.99382330030752, 250.17176811681475, -93.85075085472673, 44.94124338988316, -167.18092573189875, 37.995545807688806, -189.32240110155058, 34.64699417517619, -99.46682200834927, 54.170366791275754, 119.8596142850635, 183.16768271199427, 9.176265734659005, 156.0429886367045, -77.91739822755784, -60.63789052585518, -25.95936368714913, 75.53493677013917, 27.332647376602242, -199.80753754048817, -155.053455769998, -86.85793874399471, 154.1753051326396, 59.04960742080131, 42.653202995425524, 86.20840729829001], "policy_AGENT-3_reward": [297.6159372236055, -83.59707135337544, -69.27500284563573, -265.3401928230967, 209.52812147844196, 1.969453507474011, 166.46384050909438, -176.06347764083102, 261.96118902045583, 175.18607296462463, -127.52226818955427, 72.5169611661887, -50.179136703510906, -208.65214254585962, -107.91408062473728, 27.82249459917903, -74.381295699387, -234.15912695503198, -30.84836701075182, -276.28913266649135, 86.53098015869921, -76.47407774618779, -260.7963133087843, -39.17302902421054, -165.87369150442728, 116.08061807659301, 145.90088797952808, 97.43925442513297, -130.38011440113684, 192.55820345174578, -36.164239019846875, 99.2201247561255, -220.11285848920596, 98.1728081468951, 188.4533998105752, 44.19074038546901, -94.44032506548436, 18.442747698090283, -130.30434980125227, 241.00178562988063, -87.58917940998266, -94.86309451723757, -83.9270572739516, 27.596659776752247, -144.88114260247406, 131.46363138403095, -112.47569795188514, 76.57843997837347, 9.632691857969055, 149.54307033706104, -139.80028984928333, 247.74972683936332, 170.15379308715652, 112.23471611945178, -9.360153854979215, 75.42995615380038, -111.40984718249628, 95.42654542392563, -84.9808744571977, 14.004940698826644, -24.16254952611124, -14.44325412304835, -213.8875211030394, 92.51864078977118, -115.72468375654714, -86.28972474040467, -100.84221872244704, 304.5373093810452, -95.23016743612743, 133.35628172314557, 71.26989486169543, -14.400075585360476, -138.37899021175093, 2.1491924129197097, -19.04469854958517, 250.86637019766982, -142.5448676301192, -16.91093721677159, -179.453474937979, -13.30935577464889, -169.16306449693627, -71.68473861566702, -113.09933053028693, -17.274927805009437, -31.304850359873942, 150.54121482233694, -48.12189426451714, 195.94871250958883, -11.951523182682655, -14.688972026233733, 13.607905489292952, 137.12402796024236, 94.072858742429, -165.87050145639728, -9.029781082853205, -169.9117621606063, 129.36024730962095, 99.02889913571644, 226.13201474637714, 141.85624395838812]}, "sampler_perf": {"mean_env_wait_ms": 55.04387901434069, "mean_raw_obs_processing_ms": 2.3661484329142177, "mean_inference_ms": 2.4588674100229775, "mean_action_processing_ms": 0.14417277172010776}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 46200, "timers": {"sample_time_ms": 88462.664, "sample_throughput": 47.478, "load_time_ms": 16.14, "load_throughput": 260227.917, "learn_time_ms": 8705.563, "learn_throughput": 482.45, "update_time_ms": 7.632}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 16.93398666381836, "policy_loss": -0.04520649090409279, "vf_loss": 16.975997924804688, "vf_explained_var": 0.9473451972007751, "kl": 0.015980806201696396, "entropy": 1.2750989198684692, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 13.036416053771973, "policy_loss": -0.04276636242866516, "vf_loss": 13.07571792602539, "vf_explained_var": 0.944020688533783, "kl": 0.01731548085808754, "entropy": 1.232833743095398, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 20.822364807128906, "policy_loss": -0.04335694760084152, "vf_loss": 20.862178802490234, "vf_explained_var": 0.9276915788650513, "kl": 0.017716633155941963, "entropy": 1.216296672821045, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 16.785892486572266, "policy_loss": -0.03866055607795715, "vf_loss": 16.82034683227539, "vf_explained_var": 0.9479840397834778, "kl": 0.014020726084709167, "entropy": 1.2544174194335938, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 46200, "num_steps_trained": 46200}, "done": false, "episodes_total": 392, "training_iteration": 11, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-32-40", "timestamp": 1624217560, "time_this_iter_s": 86.89677906036377, "time_total_s": 1101.5404872894287, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c8647200>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c86475f0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647680>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c86477a0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647050>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647680>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c86477a0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647050>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647680>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c86477a0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647050>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647680>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c86477a0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647050>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c85413b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1101.5404872894287, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 54.858870967741936, "ram_util_percent": 95.10564516129031}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1169.3550897300138, "episode_reward_min": -1222.747537744931, "episode_reward_mean": 30.031201767828914, "episode_len_mean": 119.37, "episodes_this_iter": 36, "policy_reward_min": {"AGENT-2": -309.5638432165305, "AGENT-1": -446.96694041788294, "AGENT-0": -463.9075497227087, "AGENT-3": -276.28913266649135}, "policy_reward_max": {"AGENT-2": 281.4832652177225, "AGENT-1": 295.98389407691855, "AGENT-0": 324.974772047319, "AGENT-3": 297.6159372236055}, "policy_reward_mean": {"AGENT-2": 7.499360757578432, "AGENT-1": -4.205192229443931, "AGENT-0": 15.939720523493486, "AGENT-3": 10.797312716200942}, "custom_metrics": {"mean_ego_speed_mean": 42.3077975, "mean_ego_speed_min": 30.691000000000003, "mean_ego_speed_max": 45.7085, "distance_travelled_mean": 91.2817025, "distance_travelled_min": 28.844, "distance_travelled_max": 124.96375}, "hist_stats": {"episode_reward": [-971.1606757552807, -12.249442910184296, 588.3957033862671, 714.5000483244642, -397.02659474365237, 890.3981335879661, 886.3808622569775, 127.70804558580923, 1169.3550897300138, -108.46123613076585, 350.3085126509393, 4.841499908745403, -616.5784784664836, 97.0509269009645, -381.1086574618594, -266.05111145280847, -823.9935528068307, 382.43497180553373, -819.2376031359282, -170.79984812273761, -524.2957614757379, -264.638818415374, -213.28427387082823, -32.91909520022768, 0.7291778135493452, 624.66553526417, 67.25525184169325, 621.1876594006363, 312.7251346925859, 536.4518612062824, 267.1402519399047, 459.2521890810806, 108.90900686243457, -336.51766105721265, 360.31731371572164, -42.061805941176665, 64.72750045144102, -364.56158956435206, 17.106266012018587, -315.3344318819188, 1013.4831833632504, -368.12301987371103, 63.072365433384846, -632.7258233749525, 53.297847980664756, -592.1127132582814, -63.26523286139382, -379.1206316908028, 78.99639716910256, 154.48794217687865, 650.2488519444987, -32.32597754014702, 422.530719226379, -179.6315448428978, -150.74425850152608, -75.32648746691198, 451.2948872858793, 250.3627994002484, -484.4325095476723, -282.38530565414214, -485.21986054594936, 594.1666240500845, 26.04970329904249, 546.9181829957372, 494.1757401058481, 1123.9671247421402, -236.39132117344772, -94.59949148207205, -791.4109862365663, 914.5976878863378, -222.6127177083526, 842.5485769257233, -636.5355784187409, 1076.7621922718956, 656.263915452058, -329.2874186338901, 175.3807244683703, -9.873095481826695, -744.270074236772, -142.90667524568133, -114.75518101436859, -92.84101991527383, -852.8407113225744, 73.38304772606293, -1222.747537744931, 403.6513163933723, -74.16643202627122, -450.5839563549097, -262.36772426573305, -451.6112258838151, 256.7092367509499, 366.0549173237278, 240.6360043135787, -388.51459511260947, 272.8537033608936, 123.44627605515711, 472.5817527043314, -543.6957392375939, 134.44236912120013, 466.62062948407157], "episode_lengths": [201, 124, 129, 117, 108, 118, 164, 131, 124, 117, 121, 117, 120, 130, 131, 34, 133, 125, 98, 127, 121, 54, 125, 126, 94, 121, 120, 125, 147, 128, 125, 121, 129, 117, 115, 120, 129, 119, 109, 121, 126, 142, 122, 131, 118, 119, 121, 122, 118, 121, 128, 128, 122, 42, 73, 123, 113, 116, 131, 126, 110, 113, 118, 123, 137, 135, 121, 107, 117, 142, 129, 153, 106, 122, 130, 118, 92, 121, 81, 122, 104, 117, 99, 127, 127, 120, 126, 147, 28, 121, 129, 115, 107, 118, 139, 118, 136, 133, 118, 134], "policy_AGENT-2_reward": [-30.09963186381642, -70.42945955061028, 129.5316922437498, 127.2932827336114, -44.467717078649216, 179.4369737329396, 265.6762321552829, -91.38425875162532, 274.08454347707703, -96.79488270860377, 114.70818164379143, 32.601738574552755, -158.98996713590532, -35.9692497895419, -120.70497884781291, -36.033059557730795, -206.53162913030266, 21.3201463547043, -230.28846494099145, 36.66013154352735, -118.30223867218106, -29.269408989589174, 7.313612026045755, 55.26691178669776, -27.749947407489156, 156.30111657447165, -38.09328485409503, 151.75539145303003, 70.77787674928533, 158.45794090867176, -25.706554719515296, 71.03762241235367, 135.6530989026595, -24.041859218928792, 92.07803516378452, 25.89907494853874, -14.386116654129125, -47.00363143592832, -45.877558462610516, -117.98951421306401, 249.60520974103892, -78.73190893811338, 44.38495339139406, -161.32065933969494, 37.430860320741566, -89.97969830468352, 34.09964370636211, -113.06450653014038, 53.60966182150792, -31.457949666002143, 156.71615830489523, -48.00161199078662, 35.01164757836498, -11.887450086899428, -14.56308429359492, -31.80597337876602, 163.0600240147326, 26.739263466709634, -59.66351053960056, -9.003663122404816, -87.4110749113755, 153.60823409886743, -66.22298818464667, 42.09717417444914, 138.99795291708284, 281.4832652177225, -39.040471777989296, -69.17792639284059, -309.5638432165305, 240.22351578406594, -120.0916919291547, 241.65727288211662, -224.35743956975642, 261.0727475880771, 131.57660451311375, -41.278730488698365, 34.00204245182636, 41.37787996003321, -208.4962178697195, 32.30557771427813, 68.6494115584542, 21.581724409284718, -234.1319552312245, -30.851295331837942, -282.1614573568852, 108.49249291323434, -76.33596937415656, 26.945640140245246, -39.155287229272616, -65.34399889771807, -3.506667092746696, 32.46435054719667, 9.87779835576671, -69.15051038423547, -37.5579334221674, -36.18532360167931, 136.86076395979728, -34.906140320155494, -45.66302055199051, 220.3339741502974], "policy_AGENT-1_reward": [-446.96694041788294, 52.36432056820442, 144.8971770131278, 127.72640506374532, -142.29414126442003, 220.74968331379296, 220.87673323860494, -90.77516292073082, 274.5040592132369, -96.38180472294852, 66.4332842978719, -25.211051904864235, -160.1520712052303, 106.01769635185367, -95.92758316957986, -97.08152541816584, -181.39670071565428, 21.81196355933891, -204.0646264368453, -115.19661137667178, -113.67969613604258, -103.20409431570516, -99.63241713221116, -68.25394044600378, -27.262982999693513, 161.96400926391368, -37.56169149723855, 152.19544129006232, 71.27603824473877, 90.29541224596571, -25.001962639597156, 162.90706629723397, -66.33061551742995, -23.608890419277248, 99.51757925173571, -67.02831198310578, 70.51530748387357, -132.61913862562946, 30.40106618659706, -117.30639581896142, 262.83983530772707, -52.9954924507512, -9.342894131120822, -124.7707633653801, -8.81920237311671, -143.6475493551108, -60.32713212726508, -53.48997262202637, -11.508703638671694, 97.39112791769108, 159.82379610527173, 54.621262980497654, 35.5273705017207, -77.87517334575789, -60.854311655842245, -31.16905589028973, 75.57589854076537, 102.21802981450752, -59.09096001118629, -109.29840567888617, -141.03908472997313, 157.0228375089571, -65.80581507282854, 236.03579107948568, 127.11313593208709, 295.98389407691855, -75.27984087952615, 21.900900094507012, -108.27605484432397, 238.48483468750905, -119.57150653490692, 234.0991459731709, -118.10677964039658, 261.6902974471453, 179.06854369359655, -119.63611479335017, 34.30901566770965, -42.99430128440967, -163.53045152839834, -100.02128416784028, -105.5947688702305, -62.182350792982035, -192.42640314385457, 54.64175219868373, -332.31130080401647, 99.56986992210884, 61.46687158042222, -244.23701918749268, -92.00276111900189, -155.4938310063444, -2.8640329569408394, 154.65661958500795, 122.87213479021773, -120.38629233805811, -37.1252642090958, 85.75833807200546, 141.9112328344301, -34.30986774745817, -45.164524125120536, 28.9326213654095], "policy_AGENT-0_reward": [-463.9075497227087, 76.42713613865429, 130.10888046770134, 244.1050158616443, -43.904105424095505, 220.92393563224337, 185.92177784783814, 160.8335515888039, 324.974772047319, 21.666924317545202, 115.27590050366305, 33.15052681667093, -137.7634796544448, 62.83869177171182, -67.88987903414969, -96.92498118497718, -228.43422724018131, 175.52579052859767, -204.00462542629816, 37.09199782595852, -162.50588073741156, -102.9095674265811, -99.67723648482531, 55.80731506959936, 11.137276714717661, 157.03820918806443, 85.13038215580802, 115.95205825902048, 67.1033593085784, 90.43732372994982, 174.06803181062193, 71.61114384958599, -66.36234246345566, -167.16485645717867, 92.6353293843846, -67.17769879573416, 22.998385207057083, -46.559829291043414, 30.43356587511239, -60.99382330030752, 250.17176811681475, -93.85075085472673, 44.94124338988316, -167.18092573189875, 37.995545807688806, -189.32240110155058, 34.64699417517619, -99.46682200834927, 54.170366791275754, 119.8596142850635, 183.16768271199427, 9.176265734659005, 156.0429886367045, -77.91739822755784, -60.63789052585518, -25.95936368714913, 75.53493677013917, 27.332647376602242, -199.80753754048817, -155.053455769998, -86.85793874399471, 154.1753051326396, 59.04960742080131, 42.653202995425524, 86.20840729829001, 248.88402822389298, -38.473937162556965, 21.952537661897203, -108.23089535261502, 226.36121593632177, 15.081027248234758, 200.3283175613414, -118.00788156775666, 292.037958216218, 170.43269428072347, -40.85030516228735, 34.55270518264559, 41.9224625460607, -163.59126229279457, 32.723111832618095, -105.6323183017713, 22.14090216781047, -192.12322599246284, 80.44095786996894, -331.98564691753813, 109.05797339932985, 17.17674351365102, 27.50373600112187, -92.03664689324795, -64.89970447532524, 146.9993187240445, 33.03305921199508, 10.446816742461333, -68.59767798917902, 154.97869754041102, 110.03750060467787, 94.58963115397827, -254.36687268077418, 127.09710565141606, 28.900634157789273], "policy_AGENT-3_reward": [-30.186553750871838, -70.6114400664328, 183.85795366168733, 215.3753446654632, -166.36063097648758, 269.2875409089905, 213.9061190152517, 149.03391566936133, 295.7917149923807, 63.04852698324141, 53.891146205612934, -35.699713577613956, -159.6729604709034, -35.836211433059084, -96.58621641031694, -36.01154529193465, -207.63099572069288, 163.7770713628931, -180.8798863317934, -129.3553661155517, -129.80794593010341, -29.255747683498612, -21.288232279837395, -75.73938161052105, 44.60483150601432, 149.36220023772034, 57.77984603721889, 201.28476839852416, 103.56786038998347, 197.26118432169494, 143.7807374883952, 153.69635652190695, 105.9488659406605, -121.70205496182828, 76.08636991581666, 66.24512988912443, -14.400075585360476, -138.37899021175093, 2.1491924129197097, -19.04469854958517, 250.86637019766982, -142.5448676301192, -16.91093721677159, -179.453474937979, -13.30935577464889, -169.16306449693627, -71.68473861566702, -113.09933053028693, -17.274927805009437, -31.304850359873942, 150.54121482233694, -48.12189426451714, 195.94871250958883, -11.951523182682655, -14.688972026233733, 13.607905489292952, 137.12402796024236, 94.072858742429, -165.87050145639728, -9.029781082853205, -169.9117621606063, 129.36024730962095, 99.02889913571644, 226.13201474637714, 141.85624395838812, 297.6159372236055, -83.59707135337544, -69.27500284563573, -265.3401928230967, 209.52812147844196, 1.969453507474011, 166.46384050909438, -176.06347764083102, 261.96118902045583, 175.18607296462463, -127.52226818955427, 72.5169611661887, -50.179136703510906, -208.65214254585962, -107.91408062473728, 27.82249459917903, -74.381295699387, -234.15912695503198, -30.84836701075182, -276.28913266649135, 86.53098015869921, -76.47407774618779, -260.7963133087843, -39.17302902421054, -165.87369150442728, 116.08061807659301, 145.90088797952808, 97.43925442513297, -130.38011440113684, 192.55820345174578, -36.164239019846875, 99.2201247561255, -220.11285848920596, 98.1728081468951, 188.4533998105752]}, "sampler_perf": {"mean_env_wait_ms": 54.34925255631781, "mean_raw_obs_processing_ms": 2.35326782154436, "mean_inference_ms": 2.4266971966446333, "mean_action_processing_ms": 0.14299427250715532}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 50400, "timers": {"sample_time_ms": 86946.296, "sample_throughput": 48.306, "load_time_ms": 15.269, "load_throughput": 275060.377, "learn_time_ms": 8518.452, "learn_throughput": 493.047, "update_time_ms": 7.53}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 19.710359573364258, "policy_loss": -0.04307807609438896, "vf_loss": 19.749963760375977, "vf_explained_var": 0.9488571286201477, "kl": 0.017364555969834328, "entropy": 1.2460931539535522, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 15.323400497436523, "policy_loss": -0.04250410199165344, "vf_loss": 15.362061500549316, "vf_explained_var": 0.9478740096092224, "kl": 0.019220048561692238, "entropy": 1.2231881618499756, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 19.919307708740234, "policy_loss": -0.04358980059623718, "vf_loss": 19.959253311157227, "vf_explained_var": 0.9298370480537415, "kl": 0.018224749714136124, "entropy": 1.1981455087661743, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 15.688436508178711, "policy_loss": -0.03871883079409599, "vf_loss": 15.722049713134766, "vf_explained_var": 0.9601129293441772, "kl": 0.01702110841870308, "entropy": 1.2272095680236816, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 50400, "num_steps_trained": 50400}, "done": false, "episodes_total": 428, "training_iteration": 12, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-34-09", "timestamp": 1624217649, "time_this_iter_s": 89.18443322181702, "time_total_s": 1190.7249205112457, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c84ab0e0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c84ab200>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab440>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab7a0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab440>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab7a0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab440>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab7a0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab440>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab560>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab7a0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c85d38c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1190.7249205112457, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 55.828125, "ram_util_percent": 95.05703124999998}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1338.078454709274, "episode_reward_min": -1222.747537744931, "episode_reward_mean": -23.16369286770156, "episode_len_mean": 123.29, "episodes_this_iter": 30, "policy_reward_min": {"AGENT-0": -463.9075497227087, "AGENT-3": -276.28913266649135, "AGENT-2": -309.5638432165305, "AGENT-1": -446.96694041788294}, "policy_reward_max": {"AGENT-0": 338.96998024767873, "AGENT-3": 295.7917149923807, "AGENT-2": 345.40129978280356, "AGENT-1": 362.1113197341735}, "policy_reward_mean": {"AGENT-0": 4.41861995314607, "AGENT-3": -0.7194978783791328, "AGENT-2": -1.575093106023112, "AGENT-1": -25.287721836445353}, "custom_metrics": {"mean_ego_speed_mean": 41.935765, "mean_ego_speed_min": 30.691000000000003, "mean_ego_speed_max": 45.644999999999996, "distance_travelled_mean": 91.05088499999998, "distance_travelled_min": 28.844, "distance_travelled_max": 124.96375}, "hist_stats": {"episode_reward": [104.4683502458807, 133.00094624865793, -280.4031342331337, -46.02334019000543, -697.4300662148413, -66.52481496173678, -394.4771983009137, 1338.078454709274, -348.07210792624034, -618.3040225072507, -274.41772004375065, -57.30938297005787, -514.1951480910211, 136.33552678572383, -375.59787384478426, -418.8025427849244, -584.6052118693004, 222.27284275694723, -456.1264791929695, 511.7022933977542, -894.6823209872492, -431.1326298424315, 70.05819047943041, 532.2030651087564, 132.463394522192, -368.5392095264938, -241.2723900937294, -442.89667532329423, 136.39387152840362, 473.92261860000133, -236.39132117344772, -94.59949148207205, -791.4109862365663, 914.5976878863378, -222.6127177083526, 842.5485769257233, -636.5355784187409, 1076.7621922718956, 656.263915452058, -329.2874186338901, 175.3807244683703, -9.873095481826695, -744.270074236772, -142.90667524568133, -114.75518101436859, -92.84101991527383, -852.8407113225744, 73.38304772606293, -1222.747537744931, 403.6513163933723, -74.16643202627122, -450.5839563549097, -262.36772426573305, -451.6112258838151, 256.7092367509499, 366.0549173237278, 240.6360043135787, -388.51459511260947, 272.8537033608936, 123.44627605515711, 472.5817527043314, -543.6957392375939, 134.44236912120013, 466.62062948407157, -971.1606757552807, -12.249442910184296, 588.3957033862671, 714.5000483244642, -397.02659474365237, 890.3981335879661, 886.3808622569775, 127.70804558580923, 1169.3550897300138, -108.46123613076585, 350.3085126509393, 4.841499908745403, -616.5784784664836, 97.0509269009645, -381.1086574618594, -266.05111145280847, -823.9935528068307, 382.43497180553373, -819.2376031359282, -170.79984812273761, -524.2957614757379, -264.638818415374, -213.28427387082823, -32.91909520022768, 0.7291778135493452, 624.66553526417, 67.25525184169325, 621.1876594006363, 312.7251346925859, 536.4518612062824, 267.1402519399047, 459.2521890810806, 108.90900686243457, -336.51766105721265, 360.31731371572164, -42.061805941176665], "episode_lengths": [116, 154, 137, 117, 118, 109, 119, 141, 119, 163, 113, 117, 125, 127, 137, 128, 116, 116, 132, 128, 121, 123, 123, 231, 182, 133, 124, 123, 127, 129, 121, 107, 117, 142, 129, 153, 106, 122, 130, 118, 92, 121, 81, 122, 104, 117, 99, 127, 127, 120, 126, 147, 28, 121, 129, 115, 107, 118, 139, 118, 136, 133, 118, 134, 201, 124, 129, 117, 108, 118, 164, 131, 124, 117, 121, 117, 120, 130, 131, 34, 133, 125, 98, 127, 121, 54, 125, 126, 94, 121, 120, 125, 147, 128, 125, 121, 129, 117, 115, 120], "policy_AGENT-0_reward": [34.34725683488483, 47.67052283948517, -27.049336843213222, 43.07176937784603, -96.00260044313269, 26.95093885451305, -50.198103600387036, 338.96998024767873, -46.90459127125283, -310.4790239113461, 7.47430684585955, 23.49462059541247, -152.878354518261, 76.26175021494097, -21.07259123851654, 22.654080326258264, -144.5323166427247, 85.26755932802973, -75.4858304499943, 140.52767053621753, -213.91390795331094, -189.8640285224932, 71.82195115175978, 35.41163433740079, -69.37003192824113, -195.7752166412464, -94.58576937741952, -187.9578744058806, 110.73048258051645, 33.13941580817637, -38.473937162556965, 21.952537661897203, -108.23089535261502, 226.36121593632177, 15.081027248234758, 200.3283175613414, -118.00788156775666, 292.037958216218, 170.43269428072347, -40.85030516228735, 34.55270518264559, 41.9224625460607, -163.59126229279457, 32.723111832618095, -105.6323183017713, 22.14090216781047, -192.12322599246284, 80.44095786996894, -331.98564691753813, 109.05797339932985, 17.17674351365102, 27.50373600112187, -92.03664689324795, -64.89970447532524, 146.9993187240445, 33.03305921199508, 10.446816742461333, -68.59767798917902, 154.97869754041102, 110.03750060467787, 94.58963115397827, -254.36687268077418, 127.09710565141606, 28.900634157789273, -463.9075497227087, 76.42713613865429, 130.10888046770134, 244.1050158616443, -43.904105424095505, 220.92393563224337, 185.92177784783814, 160.8335515888039, 324.974772047319, 21.666924317545202, 115.27590050366305, 33.15052681667093, -137.7634796544448, 62.83869177171182, -67.88987903414969, -96.92498118497718, -228.43422724018131, 175.52579052859767, -204.00462542629816, 37.09199782595852, -162.50588073741156, -102.9095674265811, -99.67723648482531, 55.80731506959936, 11.137276714717661, 157.03820918806443, 85.13038215580802, 115.95205825902048, 67.1033593085784, 90.43732372994982, 174.06803181062193, 71.61114384958599, -66.36234246345566, -167.16485645717867, 92.6353293843846, -67.17769879573416], "policy_AGENT-3_reward": [-1.15047294601941, -2.3997618748426177, -96.65551869714173, -43.71671736374926, -230.98166816586848, -74.18753396649939, -150.61791324036616, 291.5958549446196, -132.02915317984787, -6.9938210032493515, -17.511067120732942, -56.36343374421105, -84.53736122315362, -29.6099826914921, -152.24984591265786, -246.7871862914591, -103.61253305109219, 46.29473981798178, -140.73359152524284, 108.94063252481556, -203.95564251305092, -45.244995064996445, 111.09371024897858, 246.38930521861693, 156.47295281090993, -11.748199523988038, -12.796385544300563, -214.68393390161262, 149.2346395175455, 189.02370262500784, -83.59707135337544, -69.27500284563573, -265.3401928230967, 209.52812147844196, 1.969453507474011, 166.46384050909438, -176.06347764083102, 261.96118902045583, 175.18607296462463, -127.52226818955427, 72.5169611661887, -50.179136703510906, -208.65214254585962, -107.91408062473728, 27.82249459917903, -74.381295699387, -234.15912695503198, -30.84836701075182, -276.28913266649135, 86.53098015869921, -76.47407774618779, -260.7963133087843, -39.17302902421054, -165.87369150442728, 116.08061807659301, 145.90088797952808, 97.43925442513297, -130.38011440113684, 192.55820345174578, -36.164239019846875, 99.2201247561255, -220.11285848920596, 98.1728081468951, 188.4533998105752, -30.186553750871838, -70.6114400664328, 183.85795366168733, 215.3753446654632, -166.36063097648758, 269.2875409089905, 213.9061190152517, 149.03391566936133, 295.7917149923807, 63.04852698324141, 53.891146205612934, -35.699713577613956, -159.6729604709034, -35.836211433059084, -96.58621641031694, -36.01154529193465, -207.63099572069288, 163.7770713628931, -180.8798863317934, -129.3553661155517, -129.80794593010341, -29.255747683498612, -21.288232279837395, -75.73938161052105, 44.60483150601432, 149.36220023772034, 57.77984603721889, 201.28476839852416, 103.56786038998347, 197.26118432169494, 143.7807374883952, 153.69635652190695, 105.9488659406605, -121.70205496182828, 76.08636991581666, 66.24512988912443], "policy_AGENT-2_reward": [33.775657376939925, -2.298131103541685, -103.01742126814302, 42.52431364622885, -274.5591712731368, 26.400229212776132, -50.76947686960089, 345.40129978280356, -47.45179385046309, -6.9100423232153005, -132.4793039261587, 23.066154272654202, -123.84736797705388, -29.630724395204197, -152.18883897069412, 22.070826227459996, -168.55378676839604, 84.7071058625353, -139.82047518012732, 139.96453197637908, -238.71172545079332, -151.34386265550648, -56.64477644247403, 215.05953018305095, 114.72601500492476, -11.726154147805245, -12.821786005573276, -20.45488939776031, -62.003895579988665, 218.56572238115737, -39.040471777989296, -69.17792639284059, -309.5638432165305, 240.22351578406594, -120.0916919291547, 241.65727288211662, -224.35743956975642, 261.0727475880771, 131.57660451311375, -41.278730488698365, 34.00204245182636, 41.37787996003321, -208.4962178697195, 32.30557771427813, 68.6494115584542, 21.581724409284718, -234.1319552312245, -30.851295331837942, -282.1614573568852, 108.49249291323434, -76.33596937415656, 26.945640140245246, -39.155287229272616, -65.34399889771807, -3.506667092746696, 32.46435054719667, 9.87779835576671, -69.15051038423547, -37.5579334221674, -36.18532360167931, 136.86076395979728, -34.906140320155494, -45.66302055199051, 220.3339741502974, -30.09963186381642, -70.42945955061028, 129.5316922437498, 127.2932827336114, -44.467717078649216, 179.4369737329396, 265.6762321552829, -91.38425875162532, 274.08454347707703, -96.79488270860377, 114.70818164379143, 32.601738574552755, -158.98996713590532, -35.9692497895419, -120.70497884781291, -36.033059557730795, -206.53162913030266, 21.3201463547043, -230.28846494099145, 36.66013154352735, -118.30223867218106, -29.269408989589174, 7.313612026045755, 55.26691178669776, -27.749947407489156, 156.30111657447165, -38.09328485409503, 151.75539145303003, 70.77787674928533, 158.45794090867176, -25.706554719515296, 71.03762241235367, 135.6530989026595, -24.041859218928792, 92.07803516378452, 25.89907494853874], "policy_AGENT-1_reward": [37.495908980075185, 90.02831638755717, -53.6808574246361, -87.90270585033105, -95.88662633270332, -45.688449062526516, -142.89170459055998, 362.1113197341735, -121.68656962467651, -293.9211352694402, -131.90165584271813, -47.506724093913476, -152.9320643725526, 119.31448365747924, -50.086597722915606, -216.74026304718333, -167.90657540708787, 6.00343774840033, -100.08658203760521, 122.26945836034173, -238.10104507009396, -44.679743599435, -56.21269447883381, 35.34259536968774, -69.36554136540137, -149.28963921345417, -121.06844916643598, -19.799977618040643, -61.567354989669624, 33.19377778565969, -75.27984087952615, 21.900900094507012, -108.27605484432397, 238.48483468750905, -119.57150653490692, 234.0991459731709, -118.10677964039658, 261.6902974471453, 179.06854369359655, -119.63611479335017, 34.30901566770965, -42.99430128440967, -163.53045152839834, -100.02128416784028, -105.5947688702305, -62.182350792982035, -192.42640314385457, 54.64175219868373, -332.31130080401647, 99.56986992210884, 61.46687158042222, -244.23701918749268, -92.00276111900189, -155.4938310063444, -2.8640329569408394, 154.65661958500795, 122.87213479021773, -120.38629233805811, -37.1252642090958, 85.75833807200546, 141.9112328344301, -34.30986774745817, -45.164524125120536, 28.9326213654095, -446.96694041788294, 52.36432056820442, 144.8971770131278, 127.72640506374532, -142.29414126442003, 220.74968331379296, 220.87673323860494, -90.77516292073082, 274.5040592132369, -96.38180472294852, 66.4332842978719, -25.211051904864235, -160.1520712052303, 106.01769635185367, -95.92758316957986, -97.08152541816584, -181.39670071565428, 21.81196355933891, -204.0646264368453, -115.19661137667178, -113.67969613604258, -103.20409431570516, -99.63241713221116, -68.25394044600378, -27.262982999693513, 161.96400926391368, -37.56169149723855, 152.19544129006232, 71.27603824473877, 90.29541224596571, -25.001962639597156, 162.90706629723397, -66.33061551742995, -23.608890419277248, 99.51757925173571, -67.02831198310578]}, "sampler_perf": {"mean_env_wait_ms": 53.73554210174635, "mean_raw_obs_processing_ms": 2.3333621190917277, "mean_inference_ms": 2.3995316752997864, "mean_action_processing_ms": 0.14191327606281162}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 54600, "timers": {"sample_time_ms": 84251.804, "sample_throughput": 49.851, "load_time_ms": 14.626, "load_throughput": 287151.849, "learn_time_ms": 8329.535, "learn_throughput": 504.23, "update_time_ms": 7.489}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 14.996245384216309, "policy_loss": -0.045117754489183426, "vf_loss": 15.03754997253418, "vf_explained_var": 0.9626846313476562, "kl": 0.01906009577214718, "entropy": 1.2274532318115234, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 13.546089172363281, "policy_loss": -0.042044173926115036, "vf_loss": 13.583928108215332, "vf_explained_var": 0.9523992538452148, "kl": 0.021023735404014587, "entropy": 1.2228503227233887, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 19.700382232666016, "policy_loss": -0.04270464554429054, "vf_loss": 19.738922119140625, "vf_explained_var": 0.934954047203064, "kl": 0.02081880159676075, "entropy": 1.194573163986206, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 16.03507423400879, "policy_loss": -0.04180409014225006, "vf_loss": 16.072296142578125, "vf_explained_var": 0.9566282629966736, "kl": 0.01526719145476818, "entropy": 1.2329070568084717, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 54600, "num_steps_trained": 54600}, "done": false, "episodes_total": 458, "training_iteration": 13, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-35-37", "timestamp": 1624217737, "time_this_iter_s": 86.90616273880005, "time_total_s": 1277.6310832500458, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c8688b00>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c8688f80>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541f80>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3b90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541f80>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3b90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541f80>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3b90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541ef0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541f80>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3b90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c84ab9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1277.6310832500458, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 54.978225806451604, "ram_util_percent": 94.72580645161297}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1338.078454709274, "episode_reward_min": -971.1606757552807, "episode_reward_mean": -2.3453358662475683, "episode_len_mean": 128.26, "episodes_this_iter": 32, "policy_reward_min": {"AGENT-0": -463.9075497227087, "AGENT-3": -246.7871862914591, "AGENT-2": -274.5591712731368, "AGENT-1": -446.96694041788294}, "policy_reward_max": {"AGENT-0": 338.96998024767873, "AGENT-3": 295.7917149923807, "AGENT-2": 345.40129978280356, "AGENT-1": 362.1113197341735}, "policy_reward_mean": {"AGENT-0": 7.241003874501322, "AGENT-3": 7.155119777153495, "AGENT-2": 7.2506456311371865, "AGENT-1": -23.992105149039574}, "custom_metrics": {"mean_ego_speed_mean": 41.706810000000004, "mean_ego_speed_min": 31.91975, "mean_ego_speed_max": 46.233000000000004, "distance_travelled_mean": 93.25430000000001, "distance_travelled_min": 28.844, "distance_travelled_max": 124.83225}, "hist_stats": {"episode_reward": [144.3267253583196, 888.349766621139, 149.80922138455924, 1169.1211469157768, -248.8657271421518, 569.9654149416393, -324.0113581608554, -170.30197992063268, -167.45432902961787, -220.702537308861, 132.57772961330326, -509.51689984227454, -210.41204612152632, -461.02815487220465, 12.649879620128297, -123.84523338899442, -35.63954192927045, -551.202385150872, 53.74589301593174, -304.47165201250726, -269.6709845079819, 305.5164925929731, -654.5430320570771, 213.9866357631233, -917.1280752305763, 625.752139115036, -295.87667756169674, 191.5966983481474, 467.04585325857795, 137.4770474909412, -281.27204326493927, 978.7155837448704, 134.44236912120013, 466.62062948407157, -971.1606757552807, -12.249442910184296, 588.3957033862671, 714.5000483244642, -397.02659474365237, 890.3981335879661, 886.3808622569775, 127.70804558580923, 1169.3550897300138, -108.46123613076585, 350.3085126509393, 4.841499908745403, -616.5784784664836, 97.0509269009645, -381.1086574618594, -266.05111145280847, -823.9935528068307, 382.43497180553373, -819.2376031359282, -170.79984812273761, -524.2957614757379, -264.638818415374, -213.28427387082823, -32.91909520022768, 0.7291778135493452, 624.66553526417, 67.25525184169325, 621.1876594006363, 312.7251346925859, 536.4518612062824, 267.1402519399047, 459.2521890810806, 108.90900686243457, -336.51766105721265, 360.31731371572164, -42.061805941176665, 104.4683502458807, 133.00094624865793, -280.4031342331337, -46.02334019000543, -697.4300662148413, -66.52481496173678, -394.4771983009137, 1338.078454709274, -348.07210792624034, -618.3040225072507, -274.41772004375065, -57.30938297005787, -514.1951480910211, 136.33552678572383, -375.59787384478426, -418.8025427849244, -584.6052118693004, 222.27284275694723, -456.1264791929695, 511.7022933977542, -894.6823209872492, -431.1326298424315, 70.05819047943041, 532.2030651087564, 132.463394522192, -368.5392095264938, -241.2723900937294, -442.89667532329423, 136.39387152840362, 473.92261860000133], "episode_lengths": [120, 137, 120, 127, 106, 162, 121, 131, 247, 155, 121, 119, 134, 134, 104, 120, 124, 125, 116, 129, 136, 123, 137, 133, 149, 151, 125, 146, 123, 111, 128, 155, 118, 134, 201, 124, 129, 117, 108, 118, 164, 131, 124, 117, 121, 117, 120, 130, 131, 34, 133, 125, 98, 127, 121, 54, 125, 126, 94, 121, 120, 125, 147, 128, 125, 121, 129, 117, 115, 120, 116, 154, 137, 117, 118, 109, 119, 141, 119, 163, 113, 117, 125, 127, 137, 128, 116, 116, 132, 128, 121, 123, 123, 231, 182, 133, 124, 123, 127, 129], "policy_AGENT-0_reward": [117.57973365951264, 219.78648325926397, 121.59926522854627, 292.0174097328255, -46.30800162041214, 155.0416093703433, -48.34305056939008, -68.70199704548311, 8.76154658687738, -112.2976522172797, 63.67197605484194, -130.552291460322, 64.35617488766275, -139.69885806079546, 24.371817906068838, 20.2304936302122, 43.027439518815264, -65.27013802383877, 56.71484237409639, -52.55128895483577, 40.15543502293095, 90.98855536060267, -201.5846708237195, 50.72254286814401, -275.97808678114365, 168.21338582007922, -135.60713747109912, 121.78393289807377, 31.152202825229576, -13.902517822885775, -118.68420307761046, 264.5444316674157, 127.09710565141606, 28.900634157789273, -463.9075497227087, 76.42713613865429, 130.10888046770134, 244.1050158616443, -43.904105424095505, 220.92393563224337, 185.92177784783814, 160.8335515888039, 324.974772047319, 21.666924317545202, 115.27590050366305, 33.15052681667093, -137.7634796544448, 62.83869177171182, -67.88987903414969, -96.92498118497718, -228.43422724018131, 175.52579052859767, -204.00462542629816, 37.09199782595852, -162.50588073741156, -102.9095674265811, -99.67723648482531, 55.80731506959936, 11.137276714717661, 157.03820918806443, 85.13038215580802, 115.95205825902048, 67.1033593085784, 90.43732372994982, 174.06803181062193, 71.61114384958599, -66.36234246345566, -167.16485645717867, 92.6353293843846, -67.17769879573416, 34.34725683488483, 47.67052283948517, -27.049336843213222, 43.07176937784603, -96.00260044313269, 26.95093885451305, -50.198103600387036, 338.96998024767873, -46.90459127125283, -310.4790239113461, 7.47430684585955, 23.49462059541247, -152.878354518261, 76.26175021494097, -21.07259123851654, 22.654080326258264, -144.5323166427247, 85.26755932802973, -75.4858304499943, 140.52767053621753, -213.91390795331094, -189.8640285224932, 71.82195115175978, 35.41163433740079, -69.37003192824113, -195.7752166412464, -94.58576937741952, -187.9578744058806, 110.73048258051645, 33.13941580817637], "policy_AGENT-3_reward": [-32.85768090529177, 208.09801360829417, -33.86367350091514, 272.1623492028411, -88.75800160108024, 157.12181439382758, -135.88313476664288, -18.418372493185473, 65.72874609572358, -19.381089164033693, -3.2540011619452662, -110.31779194987355, -184.50551851528306, -93.97016583828113, -30.381565257254007, 60.88796489467599, -66.81626447604275, -216.94338966233278, -34.325877492972, -83.59090733720664, -180.48563835780305, 69.17265823212183, -129.90190224037948, 71.84023422078872, -174.63749172876385, 19.17179511817965, -36.48994589490023, 106.97668218553491, 187.980914105172, 81.46897900075729, -10.205935233127283, 191.82254561388072, 98.1728081468951, 188.4533998105752, -30.186553750871838, -70.6114400664328, 183.85795366168733, 215.3753446654632, -166.36063097648758, 269.2875409089905, 213.9061190152517, 149.03391566936133, 295.7917149923807, 63.04852698324141, 53.891146205612934, -35.699713577613956, -159.6729604709034, -35.836211433059084, -96.58621641031694, -36.01154529193465, -207.63099572069288, 163.7770713628931, -180.8798863317934, -129.3553661155517, -129.80794593010341, -29.255747683498612, -21.288232279837395, -75.73938161052105, 44.60483150601432, 149.36220023772034, 57.77984603721889, 201.28476839852416, 103.56786038998347, 197.26118432169494, 143.7807374883952, 153.69635652190695, 105.9488659406605, -121.70205496182828, 76.08636991581666, 66.24512988912443, -1.15047294601941, -2.3997618748426177, -96.65551869714173, -43.71671736374926, -230.98166816586848, -74.18753396649939, -150.61791324036616, 291.5958549446196, -132.02915317984787, -6.9938210032493515, -17.511067120732942, -56.36343374421105, -84.53736122315362, -29.6099826914921, -152.24984591265786, -246.7871862914591, -103.61253305109219, 46.29473981798178, -140.73359152524284, 108.94063252481556, -203.95564251305092, -45.244995064996445, 111.09371024897858, 246.38930521861693, 156.47295281090993, -11.748199523988038, -12.796385544300563, -214.68393390161262, 149.2346395175455, 189.02370262500784], "policy_AGENT-2_reward": [-32.929899994444014, 232.0766792132424, -33.887716732550494, 290.9006501852648, -46.868800847376285, 120.66998476953503, -48.90660895024059, -18.373057198363504, -121.19114144534713, -19.195511414515696, 63.11177109405633, -159.0667978893524, 63.80242168094789, -93.83938352663431, 23.792094146453937, -102.69658310666853, 42.45661225243155, -65.84559094482948, -34.465675302583236, -90.40032578736312, 39.5629784140806, 67.67747407514355, -159.64861230564392, 72.15104670082333, -228.4081087722468, 210.10654616620374, -36.540475995447146, -18.811388738983634, 216.76035568984136, -14.339681223350718, -10.335488760693078, 241.05107155536106, -45.66302055199051, 220.3339741502974, -30.09963186381642, -70.42945955061028, 129.5316922437498, 127.2932827336114, -44.467717078649216, 179.4369737329396, 265.6762321552829, -91.38425875162532, 274.08454347707703, -96.79488270860377, 114.70818164379143, 32.601738574552755, -158.98996713590532, -35.9692497895419, -120.70497884781291, -36.033059557730795, -206.53162913030266, 21.3201463547043, -230.28846494099145, 36.66013154352735, -118.30223867218106, -29.269408989589174, 7.313612026045755, 55.26691178669776, -27.749947407489156, 156.30111657447165, -38.09328485409503, 151.75539145303003, 70.77787674928533, 158.45794090867176, -25.706554719515296, 71.03762241235367, 135.6530989026595, -24.041859218928792, 92.07803516378452, 25.89907494853874, 33.775657376939925, -2.298131103541685, -103.01742126814302, 42.52431364622885, -274.5591712731368, 26.400229212776132, -50.76947686960089, 345.40129978280356, -47.45179385046309, -6.9100423232153005, -132.4793039261587, 23.066154272654202, -123.84736797705388, -29.630724395204197, -152.18883897069412, 22.070826227459996, -168.55378676839604, 84.7071058625353, -139.82047518012732, 139.96453197637908, -238.71172545079332, -151.34386265550648, -56.64477644247403, 215.05953018305095, 114.72601500492476, -11.726154147805245, -12.821786005573276, -20.45488939776031, -62.003895579988665, 218.56572238115737], "policy_AGENT-1_reward": [92.53457259854272, 228.38859054033932, 95.96134638947842, 314.04073779484486, -66.93092307328276, 137.13200640793386, -90.87856387458203, -64.80855318360074, -120.75348026687145, -69.82828451303197, 9.047983626350138, -109.58001854272646, -154.06512417485396, -133.5197474464938, -5.132467175140484, -102.26710880721393, -54.30732922447457, -203.14326651987054, 65.82260343739068, -77.929129933102, -168.9037595871906, 77.6778049251049, -163.40784668733446, 19.272811973367165, -238.10438794842221, 228.26041201057348, -87.2391182002504, -18.352527996477708, 31.152380638335355, 84.25026753642038, -142.04641619350863, 281.29753490821264, -45.164524125120536, 28.9326213654095, -446.96694041788294, 52.36432056820442, 144.8971770131278, 127.72640506374532, -142.29414126442003, 220.74968331379296, 220.87673323860494, -90.77516292073082, 274.5040592132369, -96.38180472294852, 66.4332842978719, -25.211051904864235, -160.1520712052303, 106.01769635185367, -95.92758316957986, -97.08152541816584, -181.39670071565428, 21.81196355933891, -204.0646264368453, -115.19661137667178, -113.67969613604258, -103.20409431570516, -99.63241713221116, -68.25394044600378, -27.262982999693513, 161.96400926391368, -37.56169149723855, 152.19544129006232, 71.27603824473877, 90.29541224596571, -25.001962639597156, 162.90706629723397, -66.33061551742995, -23.608890419277248, 99.51757925173571, -67.02831198310578, 37.495908980075185, 90.02831638755717, -53.6808574246361, -87.90270585033105, -95.88662633270332, -45.688449062526516, -142.89170459055998, 362.1113197341735, -121.68656962467651, -293.9211352694402, -131.90165584271813, -47.506724093913476, -152.9320643725526, 119.31448365747924, -50.086597722915606, -216.74026304718333, -167.90657540708787, 6.00343774840033, -100.08658203760521, 122.26945836034173, -238.10104507009396, -44.679743599435, -56.21269447883381, 35.34259536968774, -69.36554136540137, -149.28963921345417, -121.06844916643598, -19.799977618040643, -61.567354989669624, 33.19377778565969]}, "sampler_perf": {"mean_env_wait_ms": 53.324340085763524, "mean_raw_obs_processing_ms": 2.322917267956655, "mean_inference_ms": 2.3800700284656897, "mean_action_processing_ms": 0.14121791588108334}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 58800, "timers": {"sample_time_ms": 83684.666, "sample_throughput": 50.188, "load_time_ms": 13.844, "load_throughput": 303376.057, "learn_time_ms": 8119.383, "learn_throughput": 517.281, "update_time_ms": 7.572}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 16.54569435119629, "policy_loss": -0.044055595993995667, "vf_loss": 16.586084365844727, "vf_explained_var": 0.9598729014396667, "kl": 0.01832355000078678, "entropy": 1.2377713918685913, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 9.743861198425293, "policy_loss": -0.044859785586595535, "vf_loss": 9.782843589782715, "vf_explained_var": 0.9681465029716492, "kl": 0.01959509775042534, "entropy": 1.2087516784667969, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 15.090054512023926, "policy_loss": -0.05115541070699692, "vf_loss": 15.134986877441406, "vf_explained_var": 0.9556586742401123, "kl": 0.02074621245265007, "entropy": 1.2030702829360962, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 13.432648658752441, "policy_loss": -0.04471835866570473, "vf_loss": 13.47221565246582, "vf_explained_var": 0.9684279561042786, "kl": 0.017167743295431137, "entropy": 1.2308101654052734, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 58800, "num_steps_trained": 58800}, "done": false, "episodes_total": 490, "training_iteration": 14, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-37-11", "timestamp": 1624217831, "time_this_iter_s": 94.28810214996338, "time_total_s": 1371.9191854000092, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc22826a5f0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c84ab950>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84abd40>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b63b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6290>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84abd40>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b63b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6290>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84abd40>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b63b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6290>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84abd40>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ab8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b63b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6290>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8647050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1371.9191854000092, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 54.88296296296297, "ram_util_percent": 94.70074074074076}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1338.078454709274, "episode_reward_min": -917.1280752305763, "episode_reward_mean": -42.590630047662344, "episode_len_mean": 131.1, "episodes_this_iter": 33, "policy_reward_min": {"AGENT-0": -437.3736239144263, "AGENT-3": -246.7871862914591, "AGENT-2": -274.5591712731368, "AGENT-1": -419.28533102102676}, "policy_reward_max": {"AGENT-0": 338.96998024767873, "AGENT-3": 291.5958549446196, "AGENT-2": 345.40129978280356, "AGENT-1": 362.1113197341735}, "policy_reward_mean": {"AGENT-0": -4.438937494789752, "AGENT-3": -9.023814322230402, "AGENT-2": 3.6584736444649235, "AGENT-1": -32.78635187510712}, "custom_metrics": {"mean_ego_speed_mean": 41.754585000000006, "mean_ego_speed_min": 31.91975, "mean_ego_speed_max": 46.233000000000004, "distance_travelled_mean": 92.58394249999998, "distance_travelled_min": 54.44275, "distance_travelled_max": 124.83225}, "hist_stats": {"episode_reward": [-285.12115847031066, 513.6214323764816, -48.383141043014525, 793.8520406558267, -272.4307877455545, -259.16984768865973, 862.5131563826789, 214.37271606102735, -884.5034690123919, -328.7138019727788, 13.77009261368316, 100.78794416600381, -27.66274171214667, -449.58139765623963, 22.596255779682835, 153.23488918250365, -68.39685020373328, -575.4614235456736, -25.311054580893142, -88.49617623314654, -169.55182163316704, -401.8129240037761, 523.2088407163812, 202.07047632481235, 529.0629749981605, -184.38434762222602, -442.5481935027889, 261.204227881269, -455.59909875820495, 193.69171179909372, -357.47730042519487, 1.834760426028609, -444.95888674213506, 459.2521890810806, 108.90900686243457, -336.51766105721265, 360.31731371572164, -42.061805941176665, 104.4683502458807, 133.00094624865793, -280.4031342331337, -46.02334019000543, -697.4300662148413, -66.52481496173678, -394.4771983009137, 1338.078454709274, -348.07210792624034, -618.3040225072507, -274.41772004375065, -57.30938297005787, -514.1951480910211, 136.33552678572383, -375.59787384478426, -418.8025427849244, -584.6052118693004, 222.27284275694723, -456.1264791929695, 511.7022933977542, -894.6823209872492, -431.1326298424315, 70.05819047943041, 532.2030651087564, 132.463394522192, -368.5392095264938, -241.2723900937294, -442.89667532329423, 136.39387152840362, 473.92261860000133, 144.3267253583196, 888.349766621139, 149.80922138455924, 1169.1211469157768, -248.8657271421518, 569.9654149416393, -324.0113581608554, -170.30197992063268, -167.45432902961787, -220.702537308861, 132.57772961330326, -509.51689984227454, -210.41204612152632, -461.02815487220465, 12.649879620128297, -123.84523338899442, -35.63954192927045, -551.202385150872, 53.74589301593174, -304.47165201250726, -269.6709845079819, 305.5164925929731, -654.5430320570771, 213.9866357631233, -917.1280752305763, 625.752139115036, -295.87667756169674, 191.5966983481474, 467.04585325857795, 137.4770474909412, -281.27204326493927, 978.7155837448704], "episode_lengths": [216, 137, 114, 131, 141, 117, 144, 215, 202, 133, 117, 128, 117, 125, 112, 123, 123, 109, 112, 127, 119, 124, 107, 133, 116, 132, 117, 139, 121, 113, 123, 137, 67, 121, 129, 117, 115, 120, 116, 154, 137, 117, 118, 109, 119, 141, 119, 163, 113, 117, 125, 127, 137, 128, 116, 116, 132, 128, 121, 123, 123, 231, 182, 133, 124, 123, 127, 129, 120, 137, 120, 127, 106, 162, 121, 131, 247, 155, 121, 119, 134, 134, 104, 120, 124, 125, 116, 129, 136, 123, 137, 133, 149, 151, 125, 146, 123, 111, 128, 155], "policy_AGENT-0_reward": [-28.281357297948457, 122.92520421754064, 87.52916732670636, 185.5678661240418, -155.6808925591634, -45.295063907608764, 241.6505914412547, 204.42841253021473, -437.3736239144263, -65.8960586293769, 39.93517265880786, 58.885238474813235, 27.334828004671653, -75.11667451423762, 20.172390325106562, 130.0958949056964, 34.02439754274557, -122.475632508947, 18.2930026712824, -99.23623181146186, 31.280669688729112, -148.02741613495124, 133.46992915911508, 108.91530124040546, 246.04729020295173, -138.5197221831382, -64.07235858487422, -67.25904737514983, -96.51713353868737, 25.924825490408576, -111.10469389962095, -68.90636136399557, -67.11698565176775, 71.61114384958599, -66.36234246345566, -167.16485645717867, 92.6353293843846, -67.17769879573416, 34.34725683488483, 47.67052283948517, -27.049336843213222, 43.07176937784603, -96.00260044313269, 26.95093885451305, -50.198103600387036, 338.96998024767873, -46.90459127125283, -310.4790239113461, 7.47430684585955, 23.49462059541247, -152.878354518261, 76.26175021494097, -21.07259123851654, 22.654080326258264, -144.5323166427247, 85.26755932802973, -75.4858304499943, 140.52767053621753, -213.91390795331094, -189.8640285224932, 71.82195115175978, 35.41163433740079, -69.37003192824113, -195.7752166412464, -94.58576937741952, -187.9578744058806, 110.73048258051645, 33.13941580817637, 117.57973365951264, 219.78648325926397, 121.59926522854627, 292.0174097328255, -46.30800162041214, 155.0416093703433, -48.34305056939008, -68.70199704548311, 8.76154658687738, -112.2976522172797, 63.67197605484194, -130.552291460322, 64.35617488766275, -139.69885806079546, 24.371817906068838, 20.2304936302122, 43.027439518815264, -65.27013802383877, 56.71484237409639, -52.55128895483577, 40.15543502293095, 90.98855536060267, -201.5846708237195, 50.72254286814401, -275.97808678114365, 168.21338582007922, -135.60713747109912, 121.78393289807377, 31.152202825229576, -13.902517822885775, -118.68420307761046, 264.5444316674157], "policy_AGENT-3_reward": [-116.49058932988301, 126.3929989649581, 62.288474500245236, 226.18651296264414, 13.64874869485859, -87.7298631843999, 175.347968171059, -85.95487523486264, -13.934541210524202, -119.56838630996783, -34.391780535499464, -29.654782912939947, -46.494416831006035, -144.42006776783634, -8.32602097072754, -40.31938374739321, -71.07918405604377, -145.71625728143263, -31.90283069706018, 40.415286057597626, -94.135856492344, -149.11595476220194, 92.6407607967986, 146.27220976284684, 217.87421542965237, 27.48641946844556, -160.3541393554004, 183.13855072151986, -135.96083737288546, 93.22449676625106, -53.22270678596665, 88.64432478851913, -155.36776003312576, 153.69635652190695, 105.9488659406605, -121.70205496182828, 76.08636991581666, 66.24512988912443, -1.15047294601941, -2.3997618748426177, -96.65551869714173, -43.71671736374926, -230.98166816586848, -74.18753396649939, -150.61791324036616, 291.5958549446196, -132.02915317984787, -6.9938210032493515, -17.511067120732942, -56.36343374421105, -84.53736122315362, -29.6099826914921, -152.24984591265786, -246.7871862914591, -103.61253305109219, 46.29473981798178, -140.73359152524284, 108.94063252481556, -203.95564251305092, -45.244995064996445, 111.09371024897858, 246.38930521861693, 156.47295281090993, -11.748199523988038, -12.796385544300563, -214.68393390161262, 149.2346395175455, 189.02370262500784, -32.85768090529177, 208.09801360829417, -33.86367350091514, 272.1623492028411, -88.75800160108024, 157.12181439382758, -135.88313476664288, -18.418372493185473, 65.72874609572358, -19.381089164033693, -3.2540011619452662, -110.31779194987355, -184.50551851528306, -93.97016583828113, -30.381565257254007, 60.88796489467599, -66.81626447604275, -216.94338966233278, -34.325877492972, -83.59090733720664, -180.48563835780305, 69.17265823212183, -129.90190224037948, 71.84023422078872, -174.63749172876385, 19.17179511817965, -36.48994589490023, 106.97668218553491, 187.980914105172, 81.46897900075729, -10.205935233127283, 191.82254561388072], "policy_AGENT-2_reward": [26.10158430298366, 129.53583501947566, -99.39096047570672, 184.992683442567, 13.646676580479976, -45.72350396764732, 242.7514109109962, -85.894536335771, -13.909972866415096, -119.35819863369795, 39.37426841575684, -29.682261334170157, 26.758505799686, -129.97709395089004, 19.619431374740113, -40.36061827297968, 33.56486391585952, -153.97408514402602, 17.739399764249658, 69.56167085833988, 30.855997599041427, -52.623365222220805, 132.88888432499823, -26.89937452733851, 32.35494158272327, 27.69951789974094, -64.63312993110691, 212.49648535648822, -97.08320522565678, 25.32911988259237, -53.23800211803995, 50.97271208470473, -67.67088821969693, 71.03762241235367, 135.6530989026595, -24.041859218928792, 92.07803516378452, 25.89907494853874, 33.775657376939925, -2.298131103541685, -103.01742126814302, 42.52431364622885, -274.5591712731368, 26.400229212776132, -50.76947686960089, 345.40129978280356, -47.45179385046309, -6.9100423232153005, -132.4793039261587, 23.066154272654202, -123.84736797705388, -29.630724395204197, -152.18883897069412, 22.070826227459996, -168.55378676839604, 84.7071058625353, -139.82047518012732, 139.96453197637908, -238.71172545079332, -151.34386265550648, -56.64477644247403, 215.05953018305095, 114.72601500492476, -11.726154147805245, -12.821786005573276, -20.45488939776031, -62.003895579988665, 218.56572238115737, -32.929899994444014, 232.0766792132424, -33.887716732550494, 290.9006501852648, -46.868800847376285, 120.66998476953503, -48.90660895024059, -18.373057198363504, -121.19114144534713, -19.195511414515696, 63.11177109405633, -159.0667978893524, 63.80242168094789, -93.83938352663431, 23.792094146453937, -102.69658310666853, 42.45661225243155, -65.84559094482948, -34.465675302583236, -90.40032578736312, 39.5629784140806, 67.67747407514355, -159.64861230564392, 72.15104670082333, -228.4081087722468, 210.10654616620374, -36.540475995447146, -18.811388738983634, 216.76035568984136, -14.339681223350718, -10.335488760693078, 241.05107155536106], "policy_AGENT-1_reward": [-166.45079614546296, 134.7673941745069, -98.80982239425924, 197.10497812657374, -144.04532046172963, -80.42141662900384, 202.76318585936917, 181.79371510144625, -419.28533102102676, -23.89115839973634, -31.14756792538205, 101.23974993830056, -35.261658685498304, -100.06756142327541, -8.869544949436332, 103.81899629718026, -64.90692760629462, -153.295448611268, -29.440626319365016, -99.23690133762256, -137.5526324285935, -52.04618788440193, 164.20926643546932, -26.217660151101402, 32.78652778283337, -101.0505628072743, -153.48856563140734, -67.17176082158923, -126.03792262097552, 49.213269659841714, -139.91189762156748, -68.87591508319974, -154.80325283754473, 162.90706629723397, -66.33061551742995, -23.608890419277248, 99.51757925173571, -67.02831198310578, 37.495908980075185, 90.02831638755717, -53.6808574246361, -87.90270585033105, -95.88662633270332, -45.688449062526516, -142.89170459055998, 362.1113197341735, -121.68656962467651, -293.9211352694402, -131.90165584271813, -47.506724093913476, -152.9320643725526, 119.31448365747924, -50.086597722915606, -216.74026304718333, -167.90657540708787, 6.00343774840033, -100.08658203760521, 122.26945836034173, -238.10104507009396, -44.679743599435, -56.21269447883381, 35.34259536968774, -69.36554136540137, -149.28963921345417, -121.06844916643598, -19.799977618040643, -61.567354989669624, 33.19377778565969, 92.53457259854272, 228.38859054033932, 95.96134638947842, 314.04073779484486, -66.93092307328276, 137.13200640793386, -90.87856387458203, -64.80855318360074, -120.75348026687145, -69.82828451303197, 9.047983626350138, -109.58001854272646, -154.06512417485396, -133.5197474464938, -5.132467175140484, -102.26710880721393, -54.30732922447457, -203.14326651987054, 65.82260343739068, -77.929129933102, -168.9037595871906, 77.6778049251049, -163.40784668733446, 19.272811973367165, -238.10438794842221, 228.26041201057348, -87.2391182002504, -18.352527996477708, 31.152380638335355, 84.25026753642038, -142.04641619350863, 281.29753490821264]}, "sampler_perf": {"mean_env_wait_ms": 52.88227786586159, "mean_raw_obs_processing_ms": 2.312663858505075, "mean_inference_ms": 2.3611423970718635, "mean_action_processing_ms": 0.1406398882555098}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 63000, "timers": {"sample_time_ms": 81867.267, "sample_throughput": 51.303, "load_time_ms": 13.63, "load_throughput": 308133.363, "learn_time_ms": 7926.947, "learn_throughput": 529.838, "update_time_ms": 7.792}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 20.937532424926758, "policy_loss": -0.04322338104248047, "vf_loss": 20.977073669433594, "vf_explained_var": 0.9524411559104919, "kl": 0.01839524507522583, "entropy": 1.2213610410690308, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 15.749794960021973, "policy_loss": -0.037662845104932785, "vf_loss": 15.782758712768555, "vf_explained_var": 0.957531213760376, "kl": 0.015664830803871155, "entropy": 1.1987603902816772, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 24.214784622192383, "policy_loss": -0.0418662466108799, "vf_loss": 24.250444412231445, "vf_explained_var": 0.9336966276168823, "kl": 0.013805587776005268, "entropy": 1.1781169176101685, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 17.98480796813965, "policy_loss": -0.03765444830060005, "vf_loss": 18.01746940612793, "vf_explained_var": 0.9628362655639648, "kl": 0.016648687422275543, "entropy": 1.2085435390472412, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 63000, "num_steps_trained": 63000}, "done": false, "episodes_total": 523, "training_iteration": 15, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-38-33", "timestamp": 1624217913, "time_this_iter_s": 82.16297364234924, "time_total_s": 1454.0821590423584, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c8688050>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c8688320>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688830>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85413b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6f80>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688830>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85413b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6f80>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688830>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85413b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6f80>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688830>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85413b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6f80>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c84b65f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1454.0821590423584, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 57.72991452991454, "ram_util_percent": 94.9153846153846}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1169.1211469157768, "episode_reward_min": -917.1280752305763, "episode_reward_mean": 15.061920721462691, "episode_len_mean": 128.28, "episodes_this_iter": 34, "policy_reward_min": {"AGENT-0": -437.3736239144263, "AGENT-3": -216.94338966233278, "AGENT-2": -228.4081087722468, "AGENT-1": -419.28533102102676}, "policy_reward_max": {"AGENT-0": 292.0174097328255, "AGENT-3": 272.1623492028411, "AGENT-2": 317.3948143300014, "AGENT-1": 314.04073779484486}, "policy_reward_mean": {"AGENT-0": 13.148324827131221, "AGENT-3": 3.9859824893637725, "AGENT-2": 16.125004749546672, "AGENT-1": -18.197391344579}, "custom_metrics": {"mean_ego_speed_mean": 42.28526750000001, "mean_ego_speed_min": 33.29624999999999, "mean_ego_speed_max": 46.233000000000004, "distance_travelled_mean": 91.24956, "distance_travelled_min": 53.8345, "distance_travelled_max": 124.83225}, "hist_stats": {"episode_reward": [-336.5955601729968, -251.071636610381, -70.5646949122565, 1053.2635429288039, -361.4474052511917, 943.1799307845514, 138.5396704448038, 454.79080425058646, -305.8052742855735, 270.95428315808897, -335.6122323779254, -61.77732895351343, 24.222996654864424, -734.9508107974576, 1.3900906082991966, -396.4020596434708, -167.77989574553254, -494.385456175209, 655.8062716051431, -350.7135808664702, 122.96700015112864, -253.6978565748819, -42.866071606886564, -116.35242796089359, 298.8062077318347, 843.4045818737676, -10.352885094499513, 443.1725790997717, -322.11327035354236, 259.1939513173246, 551.8225405969738, 627.7690642671193, -274.0143098319141, 318.53802819377785, 473.92261860000133, 144.3267253583196, 888.349766621139, 149.80922138455924, 1169.1211469157768, -248.8657271421518, 569.9654149416393, -324.0113581608554, -170.30197992063268, -167.45432902961787, -220.702537308861, 132.57772961330326, -509.51689984227454, -210.41204612152632, -461.02815487220465, 12.649879620128297, -123.84523338899442, -35.63954192927045, -551.202385150872, 53.74589301593174, -304.47165201250726, -269.6709845079819, 305.5164925929731, -654.5430320570771, 213.9866357631233, -917.1280752305763, 625.752139115036, -295.87667756169674, 191.5966983481474, 467.04585325857795, 137.4770474909412, -281.27204326493927, 978.7155837448704, -285.12115847031066, 513.6214323764816, -48.383141043014525, 793.8520406558267, -272.4307877455545, -259.16984768865973, 862.5131563826789, 214.37271606102735, -884.5034690123919, -328.7138019727788, 13.77009261368316, 100.78794416600381, -27.66274171214667, -449.58139765623963, 22.596255779682835, 153.23488918250365, -68.39685020373328, -575.4614235456736, -25.311054580893142, -88.49617623314654, -169.55182163316704, -401.8129240037761, 523.2088407163812, 202.07047632481235, 529.0629749981605, -184.38434762222602, -442.5481935027889, 261.204227881269, -455.59909875820495, 193.69171179909372, -357.47730042519487, 1.834760426028609, -444.95888674213506], "episode_lengths": [113, 149, 106, 148, 110, 182, 121, 128, 116, 117, 116, 118, 108, 104, 113, 132, 124, 118, 136, 117, 114, 120, 105, 121, 113, 106, 143, 103, 116, 126, 134, 106, 129, 127, 129, 120, 137, 120, 127, 106, 162, 121, 131, 247, 155, 121, 119, 134, 134, 104, 120, 124, 125, 116, 129, 136, 123, 137, 133, 149, 151, 125, 146, 123, 111, 128, 155, 216, 137, 114, 131, 141, 117, 144, 215, 202, 133, 117, 128, 117, 125, 112, 123, 123, 109, 112, 127, 119, 124, 107, 133, 116, 132, 117, 139, 121, 113, 123, 137, 67], "policy_AGENT-0_reward": [-43.796128905047404, -152.89173148771732, -17.340424642527385, 289.04133357012495, -42.2745909858627, 175.1685202004703, 119.16086243398249, 143.4353288004058, -41.132010388068636, 102.76904881217172, -44.84925174789122, -5.144091755307063, 30.836851133245794, -189.0741051260149, 57.24828769122894, -84.81185463330621, 24.994388121673968, -97.58046255567056, 37.45992994370351, -60.506307876977154, 16.628804469050138, 21.270601335384313, 23.637062858432436, -6.2652381424757735, 22.863402576949643, 187.3108146693694, -67.47552827422751, 75.26884518194738, -106.51909427315272, 179.42121730873004, 34.98303470017691, 138.63632971883234, -117.40420033060776, 207.7831116320566, 33.13941580817637, 117.57973365951264, 219.78648325926397, 121.59926522854627, 292.0174097328255, -46.30800162041214, 155.0416093703433, -48.34305056939008, -68.70199704548311, 8.76154658687738, -112.2976522172797, 63.67197605484194, -130.552291460322, 64.35617488766275, -139.69885806079546, 24.371817906068838, 20.2304936302122, 43.027439518815264, -65.27013802383877, 56.71484237409639, -52.55128895483577, 40.15543502293095, 90.98855536060267, -201.5846708237195, 50.72254286814401, -275.97808678114365, 168.21338582007922, -135.60713747109912, 121.78393289807377, 31.152202825229576, -13.902517822885775, -118.68420307761046, 264.5444316674157, -28.281357297948457, 122.92520421754064, 87.52916732670636, 185.5678661240418, -155.6808925591634, -45.295063907608764, 241.6505914412547, 204.42841253021473, -437.3736239144263, -65.8960586293769, 39.93517265880786, 58.885238474813235, 27.334828004671653, -75.11667451423762, 20.172390325106562, 130.0958949056964, 34.02439754274557, -122.475632508947, 18.2930026712824, -99.23623181146186, 31.280669688729112, -148.02741613495124, 133.46992915911508, 108.91530124040546, 246.04729020295173, -138.5197221831382, -64.07235858487422, -67.25904737514983, -96.51713353868737, 25.924825490408576, -111.10469389962095, -68.90636136399557, -67.11698565176775], "policy_AGENT-3_reward": [-101.41919876820465, 22.38924313103992, -29.964536613811667, 212.5611126304641, -114.56967092978115, 257.2011967712975, -36.76402647641986, 103.70560494906303, -115.73046767045949, 18.7857409515985, -127.91116042470048, -36.40928605409796, -31.807447663555944, -155.60645323447156, -69.1154871765678, -133.38550651911297, -114.02533904138704, -130.8366475117467, 147.06901422921297, -115.84270942403055, 49.46716060282352, -5.742409185665295, -33.00169924279403, 36.122770958164, 123.2558335403624, 222.9428239178676, 81.29745988109136, 134.63148153228025, -130.7513129358378, 148.9708529632918, 225.53421954600964, 162.67243016551967, -8.71964310014313, 177.70552120569292, 189.02370262500784, -32.85768090529177, 208.09801360829417, -33.86367350091514, 272.1623492028411, -88.75800160108024, 157.12181439382758, -135.88313476664288, -18.418372493185473, 65.72874609572358, -19.381089164033693, -3.2540011619452662, -110.31779194987355, -184.50551851528306, -93.97016583828113, -30.381565257254007, 60.88796489467599, -66.81626447604275, -216.94338966233278, -34.325877492972, -83.59090733720664, -180.48563835780305, 69.17265823212183, -129.90190224037948, 71.84023422078872, -174.63749172876385, 19.17179511817965, -36.48994589490023, 106.97668218553491, 187.980914105172, 81.46897900075729, -10.205935233127283, 191.82254561388072, -116.49058932988301, 126.3929989649581, 62.288474500245236, 226.18651296264414, 13.64874869485859, -87.7298631843999, 175.347968171059, -85.95487523486264, -13.934541210524202, -119.56838630996783, -34.391780535499464, -29.654782912939947, -46.494416831006035, -144.42006776783634, -8.32602097072754, -40.31938374739321, -71.07918405604377, -145.71625728143263, -31.90283069706018, 40.415286057597626, -94.135856492344, -149.11595476220194, 92.6407607967986, 146.27220976284684, 217.87421542965237, 27.48641946844556, -160.3541393554004, 183.13855072151986, -135.96083737288546, 93.22449676625106, -53.22270678596665, 88.64432478851913, -155.36776003312576], "policy_AGENT-2_reward": [-44.37844239950981, 22.334815361564154, -17.93654595776203, 269.78766983439147, -42.73606394918534, 317.3948143300014, -36.84232883549807, 89.14316014354351, -41.570000985641606, 102.21639962352879, -45.286369556162974, -36.354102974757275, 30.29270730974824, -201.25351934331314, 56.70184807157775, -133.1183508987115, 24.544314749462107, -135.69518711912764, 249.05748186072407, -61.057692225778915, 28.227693083809974, -134.93681475917768, 23.05826408443993, -73.31678539032455, 22.313459862353557, 186.7363865187023, 43.21534219442946, 74.71302134738792, -42.65324584499222, -34.817589494917215, 256.2935137965044, 138.0392158786231, -8.680546487746293, -33.69539915148739, 218.56572238115737, -32.929899994444014, 232.0766792132424, -33.887716732550494, 290.9006501852648, -46.868800847376285, 120.66998476953503, -48.90660895024059, -18.373057198363504, -121.19114144534713, -19.195511414515696, 63.11177109405633, -159.0667978893524, 63.80242168094789, -93.83938352663431, 23.792094146453937, -102.69658310666853, 42.45661225243155, -65.84559094482948, -34.465675302583236, -90.40032578736312, 39.5629784140806, 67.67747407514355, -159.64861230564392, 72.15104670082333, -228.4081087722468, 210.10654616620374, -36.540475995447146, -18.811388738983634, 216.76035568984136, -14.339681223350718, -10.335488760693078, 241.05107155536106, 26.10158430298366, 129.53583501947566, -99.39096047570672, 184.992683442567, 13.646676580479976, -45.72350396764732, 242.7514109109962, -85.894536335771, -13.909972866415096, -119.35819863369795, 39.37426841575684, -29.682261334170157, 26.758505799686, -129.97709395089004, 19.619431374740113, -40.36061827297968, 33.56486391585952, -153.97408514402602, 17.739399764249658, 69.56167085833988, 30.855997599041427, -52.623365222220805, 132.88888432499823, -26.89937452733851, 32.35494158272327, 27.69951789974094, -64.63312993110691, 212.49648535648822, -97.08320522565678, 25.32911988259237, -53.23800211803995, 50.97271208470473, -67.67088821969693], "policy_AGENT-1_reward": [-147.00179010023535, -142.90396361526786, -5.323187698155465, 281.8734268938223, -161.8670793863625, 193.4153994827817, 92.98516332273921, 118.50671035757426, -107.37279524140385, 47.183093770790066, -117.56545064917091, 16.13015183064877, -5.099114124573642, -189.0167330936576, -43.44455797793955, -45.0863475923402, -103.29325957528145, -130.2731589886638, 222.2198455715031, -113.30687133968324, 28.643341995445, -134.28923396542362, -56.55969930696489, -72.89317538625734, 130.37351175216912, 246.41455676782786, -67.39015889579265, 158.5592310381561, -42.189617299559096, -34.38052945977997, 35.01177255428306, 188.42108850414445, -139.20991991341734, -33.25520549248462, 33.19377778565969, 92.53457259854272, 228.38859054033932, 95.96134638947842, 314.04073779484486, -66.93092307328276, 137.13200640793386, -90.87856387458203, -64.80855318360074, -120.75348026687145, -69.82828451303197, 9.047983626350138, -109.58001854272646, -154.06512417485396, -133.5197474464938, -5.132467175140484, -102.26710880721393, -54.30732922447457, -203.14326651987054, 65.82260343739068, -77.929129933102, -168.9037595871906, 77.6778049251049, -163.40784668733446, 19.272811973367165, -238.10438794842221, 228.26041201057348, -87.2391182002504, -18.352527996477708, 31.152380638335355, 84.25026753642038, -142.04641619350863, 281.29753490821264, -166.45079614546296, 134.7673941745069, -98.80982239425924, 197.10497812657374, -144.04532046172963, -80.42141662900384, 202.76318585936917, 181.79371510144625, -419.28533102102676, -23.89115839973634, -31.14756792538205, 101.23974993830056, -35.261658685498304, -100.06756142327541, -8.869544949436332, 103.81899629718026, -64.90692760629462, -153.295448611268, -29.440626319365016, -99.23690133762256, -137.5526324285935, -52.04618788440193, 164.20926643546932, -26.217660151101402, 32.78652778283337, -101.0505628072743, -153.48856563140734, -67.17176082158923, -126.03792262097552, 49.213269659841714, -139.91189762156748, -68.87591508319974, -154.80325283754473]}, "sampler_perf": {"mean_env_wait_ms": 52.736442074335315, "mean_raw_obs_processing_ms": 2.322223177858763, "mean_inference_ms": 2.354131889716156, "mean_action_processing_ms": 0.140717825490126}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 67200, "timers": {"sample_time_ms": 83242.982, "sample_throughput": 50.455, "load_time_ms": 13.827, "load_throughput": 303761.599, "learn_time_ms": 8036.149, "learn_throughput": 522.638, "update_time_ms": 7.955}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.20000000298023224, "cur_lr": 0.0003000000142492354, "total_loss": 19.031164169311523, "policy_loss": -0.04567328467965126, "vf_loss": 19.072830200195312, "vf_explained_var": 0.962566614151001, "kl": 0.020034780725836754, "entropy": 1.2196565866470337, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 15.33575439453125, "policy_loss": -0.04177108034491539, "vf_loss": 15.37276554107666, "vf_explained_var": 0.9580825567245483, "kl": 0.015865541994571686, "entropy": 1.1854456663131714, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 18.400066375732422, "policy_loss": -0.042535196989774704, "vf_loss": 18.436084747314453, "vf_explained_var": 0.9520135521888733, "kl": 0.014475734904408455, "entropy": 1.1585218906402588, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 19.915151596069336, "policy_loss": -0.04323204606771469, "vf_loss": 19.953336715698242, "vf_explained_var": 0.962705671787262, "kl": 0.016824698075652122, "entropy": 1.2022055387496948, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 67200, "num_steps_trained": 67200}, "done": false, "episodes_total": 557, "training_iteration": 16, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-40-24", "timestamp": 1624218024, "time_this_iter_s": 110.27890014648438, "time_total_s": 1564.3610591888428, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c84b6950>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c84b6830>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b60e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6200>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae200>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae320>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b60e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6200>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae200>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae320>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b60e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6200>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae200>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae320>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b60e0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6200>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae200>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae320>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8647dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1564.3610591888428, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 58.189240506329114, "ram_util_percent": 94.9493670886076}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1053.2635429288039, "episode_reward_min": -884.5034690123919, "episode_reward_mean": 43.18321826091088, "episode_len_mean": 127.65, "episodes_this_iter": 32, "policy_reward_min": {"AGENT-2": -201.25351934331314, "AGENT-1": -419.28533102102676, "AGENT-0": -437.3736239144263, "AGENT-3": -160.3541393554004}, "policy_reward_max": {"AGENT-2": 317.3948143300014, "AGENT-1": 281.8734268938223, "AGENT-0": 289.04133357012495, "AGENT-3": 275.7701569975682}, "policy_reward_mean": {"AGENT-2": 18.519181726995356, "AGENT-1": -8.393567649092669, "AGENT-0": 16.892531637800047, "AGENT-3": 16.165072545208087}, "custom_metrics": {"mean_ego_speed_mean": 42.91446749999999, "mean_ego_speed_min": 33.29624999999999, "mean_ego_speed_max": 45.94449999999999, "distance_travelled_mean": 90.33552500000002, "distance_travelled_min": 53.8345, "distance_travelled_max": 124.96275}, "hist_stats": {"episode_reward": [142.90474377414856, -298.5468113203889, 225.4788998519318, -20.29441087754599, 769.976293879795, 159.3293504041263, -54.88265859769503, 976.5192791372377, -734.1883876305947, -268.9791295778042, 925.646625742574, -122.80049651574024, -27.813953003641963, -668.9043260967233, -30.898172126457816, -396.1544803553946, -217.2926104451655, 64.2196328619554, -9.875289676074857, -513.9851942119243, -95.98830118526845, 139.33076880623813, 336.3267953547941, 324.19504484276035, -196.31383014658095, 451.56518953880493, 802.8142299089279, -351.1822677527035, -3.935157192207239, 538.3977156448767, 293.23776047544663, 464.12350557067157, 978.7155837448704, -285.12115847031066, 513.6214323764816, -48.383141043014525, 793.8520406558267, -272.4307877455545, -259.16984768865973, 862.5131563826789, 214.37271606102735, -884.5034690123919, -328.7138019727788, 13.77009261368316, 100.78794416600381, -27.66274171214667, -449.58139765623963, 22.596255779682835, 153.23488918250365, -68.39685020373328, -575.4614235456736, -25.311054580893142, -88.49617623314654, -169.55182163316704, -401.8129240037761, 523.2088407163812, 202.07047632481235, 529.0629749981605, -184.38434762222602, -442.5481935027889, 261.204227881269, -455.59909875820495, 193.69171179909372, -357.47730042519487, 1.834760426028609, -444.95888674213506, -336.5955601729968, -251.071636610381, -70.5646949122565, 1053.2635429288039, -361.4474052511917, 943.1799307845514, 138.5396704448038, 454.79080425058646, -305.8052742855735, 270.95428315808897, -335.6122323779254, -61.77732895351343, 24.222996654864424, -734.9508107974576, 1.3900906082991966, -396.4020596434708, -167.77989574553254, -494.385456175209, 655.8062716051431, -350.7135808664702, 122.96700015112864, -253.6978565748819, -42.866071606886564, -116.35242796089359, 298.8062077318347, 843.4045818737676, -10.352885094499513, 443.1725790997717, -322.11327035354236, 259.1939513173246, 551.8225405969738, 627.7690642671193, -274.0143098319141, 318.53802819377785], "episode_lengths": [102, 108, 121, 118, 137, 131, 118, 151, 195, 105, 131, 127, 115, 125, 118, 134, 126, 327, 106, 125, 111, 127, 137, 112, 131, 119, 134, 122, 96, 122, 138, 111, 155, 216, 137, 114, 131, 141, 117, 144, 215, 202, 133, 117, 128, 117, 125, 112, 123, 123, 109, 112, 127, 119, 124, 107, 133, 116, 132, 117, 139, 121, 113, 123, 137, 67, 113, 149, 106, 148, 110, 182, 121, 128, 116, 117, 116, 118, 108, 104, 113, 132, 124, 118, 136, 117, 114, 120, 105, 121, 113, 106, 143, 103, 116, 126, 134, 106, 129, 127], "policy_AGENT-2_reward": [56.74410422084183, -39.14410097960711, 95.52245054108081, -11.648435767865134, 178.9127369792161, -24.873147851270733, -86.27896064001345, 227.44689589897897, -30.919056575572256, -40.2372037896691, 233.27849012618404, -102.66574113049488, 23.942773702625317, -181.74390144050795, 16.491631274226506, -85.83440443134026, 33.24662699125311, 117.1008994009022, 33.82089030874791, -107.4096955999243, 35.11179399119146, 18.557664662533924, 4.051030066361726, 17.42246466560071, -50.864497410076964, 39.11384384805015, 206.5460825699426, -49.05594146320009, -33.26204141979044, 91.71491690437854, -45.80175045010597, 26.01476837473967, 241.05107155536106, 26.10158430298366, 129.53583501947566, -99.39096047570672, 184.992683442567, 13.646676580479976, -45.72350396764732, 242.7514109109962, -85.894536335771, -13.909972866415096, -119.35819863369795, 39.37426841575684, -29.682261334170157, 26.758505799686, -129.97709395089004, 19.619431374740113, -40.36061827297968, 33.56486391585952, -153.97408514402602, 17.739399764249658, 69.56167085833988, 30.855997599041427, -52.623365222220805, 132.88888432499823, -26.89937452733851, 32.35494158272327, 27.69951789974094, -64.63312993110691, 212.49648535648822, -97.08320522565678, 25.32911988259237, -53.23800211803995, 50.97271208470473, -67.67088821969693, -44.37844239950981, 22.334815361564154, -17.93654595776203, 269.78766983439147, -42.73606394918534, 317.3948143300014, -36.84232883549807, 89.14316014354351, -41.570000985641606, 102.21639962352879, -45.286369556162974, -36.354102974757275, 30.29270730974824, -201.25351934331314, 56.70184807157775, -133.1183508987115, 24.544314749462107, -135.69518711912764, 249.05748186072407, -61.057692225778915, 28.227693083809974, -134.93681475917768, 23.05826408443993, -73.31678539032455, 22.313459862353557, 186.7363865187023, 43.21534219442946, 74.71302134738792, -42.65324584499222, -34.817589494917215, 256.2935137965044, 138.0392158786231, -8.680546487746293, -33.69539915148739], "policy_AGENT-1_reward": [2.2631020696101416, -98.71462610182019, 20.812059635583466, -0.6645061013829228, 193.19263965645652, 125.05126612945121, -85.51255983183344, 245.2924819957885, -332.1324828076968, -83.2589573709756, 236.07386394264608, 27.42082284622323, -35.84946263110571, -181.12330953466716, -27.744134342160574, -83.36208028175704, -136.8811270372181, -106.18047856272776, -27.48912651097902, -109.34093998106367, -68.69942462704464, 72.71860185273167, 4.651962697668445, 148.34827915942705, -50.43059130427326, 191.07296725085482, 212.18934928037433, -48.62513564435909, -32.82811585259981, 182.06207498838285, -45.364379608021565, 218.97157849103348, 281.29753490821264, -166.45079614546296, 134.7673941745069, -98.80982239425924, 197.10497812657374, -144.04532046172963, -80.42141662900384, 202.76318585936917, 181.79371510144625, -419.28533102102676, -23.89115839973634, -31.14756792538205, 101.23974993830056, -35.261658685498304, -100.06756142327541, -8.869544949436332, 103.81899629718026, -64.90692760629462, -153.295448611268, -29.440626319365016, -99.23690133762256, -137.5526324285935, -52.04618788440193, 164.20926643546932, -26.217660151101402, 32.78652778283337, -101.0505628072743, -153.48856563140734, -67.17176082158923, -126.03792262097552, 49.213269659841714, -139.91189762156748, -68.87591508319974, -154.80325283754473, -147.00179010023535, -142.90396361526786, -5.323187698155465, 281.8734268938223, -161.8670793863625, 193.4153994827817, 92.98516332273921, 118.50671035757426, -107.37279524140385, 47.183093770790066, -117.56545064917091, 16.13015183064877, -5.099114124573642, -189.0167330936576, -43.44455797793955, -45.0863475923402, -103.29325957528145, -130.2731589886638, 222.2198455715031, -113.30687133968324, 28.643341995445, -134.28923396542362, -56.55969930696489, -72.89317538625734, 130.37351175216912, 246.41455676782786, -67.39015889579265, 158.5592310381561, -42.189617299559096, -34.38052945977997, 35.01177255428306, 188.42108850414445, -139.20991991341734, -33.25520549248462], "policy_AGENT-0_reward": [57.299703166045425, -38.58475409105982, 96.09796199728633, -11.098173284295882, 179.4767880773978, 83.99516676729269, 38.13815265938352, 228.00974424490158, -340.1593188455276, -39.79586993171853, 229.38358648182577, 55.22615858072197, 24.384461080398914, -153.79266106620835, 16.91410790767793, -131.52998927674253, 33.68404787092404, -106.32059113823138, 34.24425360707963, -155.5369442661396, 35.69681508468568, 29.445069993215334, 144.92238752967384, 18.002777680915674, -64.55518872126267, 39.66566132973632, 228.42896906411892, -148.89637801190986, 13.184565034124077, 92.28506651659876, 173.47276094403867, 26.56671296542423, 264.5444316674157, -28.281357297948457, 122.92520421754064, 87.52916732670636, 185.5678661240418, -155.6808925591634, -45.295063907608764, 241.6505914412547, 204.42841253021473, -437.3736239144263, -65.8960586293769, 39.93517265880786, 58.885238474813235, 27.334828004671653, -75.11667451423762, 20.172390325106562, 130.0958949056964, 34.02439754274557, -122.475632508947, 18.2930026712824, -99.23623181146186, 31.280669688729112, -148.02741613495124, 133.46992915911508, 108.91530124040546, 246.04729020295173, -138.5197221831382, -64.07235858487422, -67.25904737514983, -96.51713353868737, 25.924825490408576, -111.10469389962095, -68.90636136399557, -67.11698565176775, -43.796128905047404, -152.89173148771732, -17.340424642527385, 289.04133357012495, -42.2745909858627, 175.1685202004703, 119.16086243398249, 143.4353288004058, -41.132010388068636, 102.76904881217172, -44.84925174789122, -5.144091755307063, 30.836851133245794, -189.0741051260149, 57.24828769122894, -84.81185463330621, 24.994388121673968, -97.58046255567056, 37.45992994370351, -60.506307876977154, 16.628804469050138, 21.270601335384313, 23.637062858432436, -6.2652381424757735, 22.863402576949643, 187.3108146693694, -67.47552827422751, 75.26884518194738, -106.51909427315272, 179.42121730873004, 34.98303470017691, 138.63632971883234, -117.40420033060776, 207.7831116320566], "policy_AGENT-3_reward": [26.597834317651078, -122.10333014790204, 13.04642767798094, 3.1167042759978996, 218.39412916672427, -24.843934641346916, 78.77070921476813, 275.7701569975682, -30.977529401798133, -105.68709848544097, 226.91068519191862, -102.78173681219039, -40.291725155560464, -152.24445405534001, -36.55977696620168, -95.42800636555471, -147.34215827012446, 159.61980316201235, -50.451307080923264, -141.69761436479754, -98.09748563410103, 18.60943229775708, 182.70141506108982, 140.42152333681682, -30.463552710967953, 181.71271711016377, 155.6498289944922, -104.60481263323457, 48.970435046058924, 172.33565723551635, 210.93112958953554, 192.5704457394742, 191.82254561388072, -116.49058932988301, 126.3929989649581, 62.288474500245236, 226.18651296264414, 13.64874869485859, -87.7298631843999, 175.347968171059, -85.95487523486264, -13.934541210524202, -119.56838630996783, -34.391780535499464, -29.654782912939947, -46.494416831006035, -144.42006776783634, -8.32602097072754, -40.31938374739321, -71.07918405604377, -145.71625728143263, -31.90283069706018, 40.415286057597626, -94.135856492344, -149.11595476220194, 92.6407607967986, 146.27220976284684, 217.87421542965237, 27.48641946844556, -160.3541393554004, 183.13855072151986, -135.96083737288546, 93.22449676625106, -53.22270678596665, 88.64432478851913, -155.36776003312576, -101.41919876820465, 22.38924313103992, -29.964536613811667, 212.5611126304641, -114.56967092978115, 257.2011967712975, -36.76402647641986, 103.70560494906303, -115.73046767045949, 18.7857409515985, -127.91116042470048, -36.40928605409796, -31.807447663555944, -155.60645323447156, -69.1154871765678, -133.38550651911297, -114.02533904138704, -130.8366475117467, 147.06901422921297, -115.84270942403055, 49.46716060282352, -5.742409185665295, -33.00169924279403, 36.122770958164, 123.2558335403624, 222.9428239178676, 81.29745988109136, 134.63148153228025, -130.7513129358378, 148.9708529632918, 225.53421954600964, 162.67243016551967, -8.71964310014313, 177.70552120569292]}, "sampler_perf": {"mean_env_wait_ms": 52.741168715664955, "mean_raw_obs_processing_ms": 2.3323612129459157, "mean_inference_ms": 2.3517661471344047, "mean_action_processing_ms": 0.14102917144344984}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 71400, "timers": {"sample_time_ms": 84348.529, "sample_throughput": 49.793, "load_time_ms": 13.775, "load_throughput": 304895.103, "learn_time_ms": 7983.589, "learn_throughput": 526.079, "update_time_ms": 8.152}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 22.915016174316406, "policy_loss": -0.04245959222316742, "vf_loss": 22.952255249023438, "vf_explained_var": 0.9610670208930969, "kl": 0.017389819025993347, "entropy": 1.193261981010437, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 17.094192504882812, "policy_loss": -0.03954104334115982, "vf_loss": 17.1295108795166, "vf_explained_var": 0.9575121402740479, "kl": 0.014075049199163914, "entropy": 1.1423535346984863, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 26.877344131469727, "policy_loss": -0.043199602514505386, "vf_loss": 26.915193557739258, "vf_explained_var": 0.9329615831375122, "kl": 0.011891968548297882, "entropy": 1.1558449268341064, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 20.402786254882812, "policy_loss": -0.039156224578619, "vf_loss": 20.437646865844727, "vf_explained_var": 0.9651957154273987, "kl": 0.014312932267785072, "entropy": 1.167365550994873, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 71400, "num_steps_trained": 71400}, "done": false, "episodes_total": 589, "training_iteration": 17, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-42-04", "timestamp": 1624218124, "time_this_iter_s": 100.49621272087097, "time_total_s": 1664.8572719097137, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c84aba70>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c8688f80>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541f80>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647170>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541f80>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647170>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541f80>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647170>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541f80>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647170>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c84b6440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1664.8572719097137, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 55.22797202797203, "ram_util_percent": 95.02167832167831}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1174.0557421936448, "episode_reward_min": -759.3883559442911, "episode_reward_mean": 34.25406552680906, "episode_len_mean": 126.2, "episodes_this_iter": 33, "policy_reward_min": {"AGENT-0": -340.1593188455276, "AGENT-3": -221.89467144025176, "AGENT-2": -201.25351934331314, "AGENT-1": -332.1324828076968}, "policy_reward_max": {"AGENT-0": 354.70751613918924, "AGENT-3": 275.7701569975682, "AGENT-2": 351.74227133064846, "AGENT-1": 335.5997067905722}, "policy_reward_mean": {"AGENT-0": 10.352578205664594, "AGENT-3": 7.637942331634039, "AGENT-2": 16.47101649104218, "AGENT-1": -0.20747150153179802}, "custom_metrics": {"mean_ego_speed_mean": 42.99090000000001, "mean_ego_speed_min": 33.5975, "mean_ego_speed_max": 45.94449999999999, "distance_travelled_mean": 91.14267249999997, "distance_travelled_min": 53.8345, "distance_travelled_max": 124.96275}, "hist_stats": {"episode_reward": [-274.89012227505464, 1174.0557421936448, 806.8284101856581, 957.8889687592275, -277.8261537757986, 458.4410482539562, -386.72733809984487, 530.789296094651, 57.632571103192035, -678.4041680925133, -105.00203164879831, -479.30038153727196, -52.85437509950021, -644.0648062148186, -12.820053290510113, -759.3883559442911, -60.63983097987048, -654.5213348011561, -137.18288072850203, -628.2470835245949, -54.95596379721134, -120.05403330804114, 360.3945266073495, 674.4862551704299, -416.5853856130682, 534.3989989689306, 617.0701492415864, -462.33973930481454, -531.9264778359878, -267.3983559697931, -340.3852006432527, 945.9090521014892, -625.3646523070015, -444.95888674213506, -336.5955601729968, -251.071636610381, -70.5646949122565, 1053.2635429288039, -361.4474052511917, 943.1799307845514, 138.5396704448038, 454.79080425058646, -305.8052742855735, 270.95428315808897, -335.6122323779254, -61.77732895351343, 24.222996654864424, -734.9508107974576, 1.3900906082991966, -396.4020596434708, -167.77989574553254, -494.385456175209, 655.8062716051431, -350.7135808664702, 122.96700015112864, -253.6978565748819, -42.866071606886564, -116.35242796089359, 298.8062077318347, 843.4045818737676, -10.352885094499513, 443.1725790997717, -322.11327035354236, 259.1939513173246, 551.8225405969738, 627.7690642671193, -274.0143098319141, 318.53802819377785, 142.90474377414856, -298.5468113203889, 225.4788998519318, -20.29441087754599, 769.976293879795, 159.3293504041263, -54.88265859769503, 976.5192791372377, -734.1883876305947, -268.9791295778042, 925.646625742574, -122.80049651574024, -27.813953003641963, -668.9043260967233, -30.898172126457816, -396.1544803553946, -217.2926104451655, 64.2196328619554, -9.875289676074857, -513.9851942119243, -95.98830118526845, 139.33076880623813, 336.3267953547941, 324.19504484276035, -196.31383014658095, 451.56518953880493, 802.8142299089279, -351.1822677527035, -3.935157192207239, 538.3977156448767, 293.23776047544663, 464.12350557067157], "episode_lengths": [107, 170, 386, 125, 109, 106, 118, 125, 102, 128, 119, 118, 122, 124, 106, 130, 119, 120, 90, 125, 84, 145, 104, 114, 111, 143, 121, 133, 125, 119, 120, 136, 130, 67, 113, 149, 106, 148, 110, 182, 121, 128, 116, 117, 116, 118, 108, 104, 113, 132, 124, 118, 136, 117, 114, 120, 105, 121, 113, 106, 143, 103, 116, 126, 134, 106, 129, 127, 102, 108, 121, 118, 137, 131, 118, 151, 195, 105, 131, 127, 115, 125, 118, 134, 126, 327, 106, 125, 111, 127, 137, 112, 131, 119, 134, 122, 96, 122, 138, 111], "policy_AGENT-0_reward": [-42.713516318153474, 354.70751613918924, -42.84938923212408, 232.19176572144517, -49.10867952450211, 133.88673715899753, -54.80715518193072, 146.43218216042294, 12.820080081585475, -131.03631999133054, 24.748203351660514, -121.48057148010163, 26.97403353500239, -192.2838955327219, 34.76345137976806, -229.13717310016972, 35.52956845504942, -162.78256102987513, 22.555172769164752, -184.50193674997348, 30.902704146183346, -67.24362457176085, 38.85098253968154, 146.52819828866635, -67.53549063108751, 127.45219075304746, 84.27068088882545, -191.55668225011163, -64.22469090720246, -119.5825875736307, -131.36342252431723, 264.3921487851612, -261.5309173200837, -67.11698565176775, -43.796128905047404, -152.89173148771732, -17.340424642527385, 289.04133357012495, -42.2745909858627, 175.1685202004703, 119.16086243398249, 143.4353288004058, -41.132010388068636, 102.76904881217172, -44.84925174789122, -5.144091755307063, 30.836851133245794, -189.0741051260149, 57.24828769122894, -84.81185463330621, 24.994388121673968, -97.58046255567056, 37.45992994370351, -60.506307876977154, 16.628804469050138, 21.270601335384313, 23.637062858432436, -6.2652381424757735, 22.863402576949643, 187.3108146693694, -67.47552827422751, 75.26884518194738, -106.51909427315272, 179.42121730873004, 34.98303470017691, 138.63632971883234, -117.40420033060776, 207.7831116320566, 57.299703166045425, -38.58475409105982, 96.09796199728633, -11.098173284295882, 179.4767880773978, 83.99516676729269, 38.13815265938352, 228.00974424490158, -340.1593188455276, -39.79586993171853, 229.38358648182577, 55.22615858072197, 24.384461080398914, -153.79266106620835, 16.91410790767793, -131.52998927674253, 33.68404787092404, -106.32059113823138, 34.24425360707963, -155.5369442661396, 35.69681508468568, 29.445069993215334, 144.92238752967384, 18.002777680915674, -64.55518872126267, 39.66566132973632, 228.42896906411892, -148.89637801190986, 13.184565034124077, 92.28506651659876, 173.47276094403867, 26.56671296542423], "policy_AGENT-3_reward": [-94.80327294853296, 164.17418045067592, 165.71083852858717, 271.1344485065089, -101.40139042524656, 117.76002666896204, -142.94465353583732, 114.72341848028499, 3.962947727745231, -194.10021239907644, -81.68241100428267, -119.94676811133986, -55.15915045336244, -157.04778390094984, -52.35256212474804, -144.8242433932382, -71.54333116182765, -119.11184335601227, -91.15002506706753, -155.40726383077276, -58.39236478917885, -29.39082305250369, 129.04418142088136, 186.88269438237108, -151.9424635138071, 166.21080195055526, 219.2927943574108, -113.7196527006394, -205.46279840006142, -14.118624253826706, -86.97591223663426, 188.37390612871184, -221.89467144025176, -155.36776003312576, -101.41919876820465, 22.38924313103992, -29.964536613811667, 212.5611126304641, -114.56967092978115, 257.2011967712975, -36.76402647641986, 103.70560494906303, -115.73046767045949, 18.7857409515985, -127.91116042470048, -36.40928605409796, -31.807447663555944, -155.60645323447156, -69.1154871765678, -133.38550651911297, -114.02533904138704, -130.8366475117467, 147.06901422921297, -115.84270942403055, 49.46716060282352, -5.742409185665295, -33.00169924279403, 36.122770958164, 123.2558335403624, 222.9428239178676, 81.29745988109136, 134.63148153228025, -130.7513129358378, 148.9708529632918, 225.53421954600964, 162.67243016551967, -8.71964310014313, 177.70552120569292, 26.597834317651078, -122.10333014790204, 13.04642767798094, 3.1167042759978996, 218.39412916672427, -24.843934641346916, 78.77070921476813, 275.7701569975682, -30.977529401798133, -105.68709848544097, 226.91068519191862, -102.78173681219039, -40.291725155560464, -152.24445405534001, -36.55977696620168, -95.42800636555471, -147.34215827012446, 159.61980316201235, -50.451307080923264, -141.69761436479754, -98.09748563410103, 18.60943229775708, 182.70141506108982, 140.42152333681682, -30.463552710967953, 181.71271711016377, 155.6498289944922, -104.60481263323457, 48.970435046058924, 172.33565723551635, 210.93112958953554, 192.5704457394742], "policy_AGENT-2_reward": [-43.27673789593063, 319.574338813208, 351.74227133064846, 227.06737832740976, -49.53819798441336, 72.86460828383946, -55.39043866571251, 145.86224951281642, 12.223281300539476, -195.70045069203917, 24.187228421964967, -122.04187454213564, 26.505672282758137, -148.99526294935748, 34.218917264497286, -192.92744657155478, 35.08999761223304, -186.5332499811311, 21.996578604395538, -150.0660888928458, 30.35890858126607, -11.942529876487619, 38.28012152011211, 145.93999414299657, -68.09309508149437, 120.15013259015143, 83.68108116412964, -150.18032475692377, -64.65912443303878, -13.985339573167977, -61.236986290283156, 235.88431414098986, -71.32969663763971, -67.67088821969693, -44.37844239950981, 22.334815361564154, -17.93654595776203, 269.78766983439147, -42.73606394918534, 317.3948143300014, -36.84232883549807, 89.14316014354351, -41.570000985641606, 102.21639962352879, -45.286369556162974, -36.354102974757275, 30.29270730974824, -201.25351934331314, 56.70184807157775, -133.1183508987115, 24.544314749462107, -135.69518711912764, 249.05748186072407, -61.057692225778915, 28.227693083809974, -134.93681475917768, 23.05826408443993, -73.31678539032455, 22.313459862353557, 186.7363865187023, 43.21534219442946, 74.71302134738792, -42.65324584499222, -34.817589494917215, 256.2935137965044, 138.0392158786231, -8.680546487746293, -33.69539915148739, 56.74410422084183, -39.14410097960711, 95.52245054108081, -11.648435767865134, 178.9127369792161, -24.873147851270733, -86.27896064001345, 227.44689589897897, -30.919056575572256, -40.2372037896691, 233.27849012618404, -102.66574113049488, 23.942773702625317, -181.74390144050795, 16.491631274226506, -85.83440443134026, 33.24662699125311, 117.1008994009022, 33.82089030874791, -107.4096955999243, 35.11179399119146, 18.557664662533924, 4.051030066361726, 17.42246466560071, -50.864497410076964, 39.11384384805015, 206.5460825699426, -49.05594146320009, -33.26204141979044, 91.71491690437854, -45.80175045010597, 26.01476837473967], "policy_AGENT-1_reward": [-94.09659511243746, 335.5997067905722, 332.22468955854697, 227.49537620386423, -77.77788584163682, 133.92967614215695, -133.58509071636422, 123.771445941127, 28.626261993321762, -157.56718501006713, -72.25505241814109, -115.83116740369536, -51.17493046389828, -145.73786383178944, -29.449859810027494, -192.49949287932768, -59.716065885325314, -186.09368043413735, -90.58460703499482, -138.2717940510038, -57.82521173548195, -11.477055807289005, 154.21924112667455, 195.13536835639607, -129.01433638667953, 120.58587367517647, 229.82559283122046, -6.883079597139677, -197.57986409568528, -119.71180456916771, -60.80887959201845, 257.2586830466264, -70.60936690902606, -154.80325283754473, -147.00179010023535, -142.90396361526786, -5.323187698155465, 281.8734268938223, -161.8670793863625, 193.4153994827817, 92.98516332273921, 118.50671035757426, -107.37279524140385, 47.183093770790066, -117.56545064917091, 16.13015183064877, -5.099114124573642, -189.0167330936576, -43.44455797793955, -45.0863475923402, -103.29325957528145, -130.2731589886638, 222.2198455715031, -113.30687133968324, 28.643341995445, -134.28923396542362, -56.55969930696489, -72.89317538625734, 130.37351175216912, 246.41455676782786, -67.39015889579265, 158.5592310381561, -42.189617299559096, -34.38052945977997, 35.01177255428306, 188.42108850414445, -139.20991991341734, -33.25520549248462, 2.2631020696101416, -98.71462610182019, 20.812059635583466, -0.6645061013829228, 193.19263965645652, 125.05126612945121, -85.51255983183344, 245.2924819957885, -332.1324828076968, -83.2589573709756, 236.07386394264608, 27.42082284622323, -35.84946263110571, -181.12330953466716, -27.744134342160574, -83.36208028175704, -136.8811270372181, -106.18047856272776, -27.48912651097902, -109.34093998106367, -68.69942462704464, 72.71860185273167, 4.651962697668445, 148.34827915942705, -50.43059130427326, 191.07296725085482, 212.18934928037433, -48.62513564435909, -32.82811585259981, 182.06207498838285, -45.364379608021565, 218.97157849103348]}, "sampler_perf": {"mean_env_wait_ms": 52.86501766463961, "mean_raw_obs_processing_ms": 2.345594922357106, "mean_inference_ms": 2.3622960650697054, "mean_action_processing_ms": 0.1415490599063318}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 75600, "timers": {"sample_time_ms": 84455.649, "sample_throughput": 49.73, "load_time_ms": 13.702, "load_throughput": 306529.147, "learn_time_ms": 7970.527, "learn_throughput": 526.941, "update_time_ms": 8.249}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 12.710213661193848, "policy_loss": -0.053013939410448074, "vf_loss": 12.756996154785156, "vf_explained_var": 0.9787116050720215, "kl": 0.020775582641363144, "entropy": 1.2000032663345337, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 13.462383270263672, "policy_loss": -0.045031238347291946, "vf_loss": 13.502323150634766, "vf_explained_var": 0.9704504609107971, "kl": 0.016963107511401176, "entropy": 1.1766968965530396, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 12.108327865600586, "policy_loss": -0.0466233529150486, "vf_loss": 12.147500038146973, "vf_explained_var": 0.9733222723007202, "kl": 0.016558799892663956, "entropy": 1.1348083019256592, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 16.63866424560547, "policy_loss": -0.03953459858894348, "vf_loss": 16.673364639282227, "vf_explained_var": 0.9718674421310425, "kl": 0.016113370656967163, "entropy": 1.1810654401779175, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 75600, "num_steps_trained": 75600}, "done": false, "episodes_total": 622, "training_iteration": 18, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-43-39", "timestamp": 1624218219, "time_this_iter_s": 94.90381264686584, "time_total_s": 1759.7610845565796, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c84aeb00>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c84ae9e0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae7a0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae440>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae0e0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae7a0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae440>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae0e0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae7a0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae440>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae0e0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae7a0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae440>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84ae0e0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c84b6050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1759.7610845565796, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 55.481617647058826, "ram_util_percent": 95.0}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1174.0557421936448, "episode_reward_min": -759.3883559442911, "episode_reward_mean": 47.31137999945486, "episode_len_mean": 131.65, "episodes_this_iter": 30, "policy_reward_min": {"AGENT-2": -195.70045069203917, "AGENT-1": -332.1324828076968, "AGENT-0": -340.1593188455276, "AGENT-3": -221.89467144025176}, "policy_reward_max": {"AGENT-2": 351.74227133064846, "AGENT-1": 335.5997067905722, "AGENT-0": 354.70751613918924, "AGENT-3": 275.7701569975682}, "policy_reward_mean": {"AGENT-2": 17.910956895205267, "AGENT-1": 3.206204862714937, "AGENT-0": 15.466659872576598, "AGENT-3": 10.727558368958022}, "custom_metrics": {"mean_ego_speed_mean": 42.714012499999995, "mean_ego_speed_min": 33.5975, "mean_ego_speed_max": 45.59375, "distance_travelled_mean": 91.328135, "distance_travelled_min": 60.993750000000006, "distance_travelled_max": 124.96275}, "hist_stats": {"episode_reward": [837.7852751941094, -277.18979173180185, 868.11283635818, -43.16810381513511, 580.8476760299131, 93.18179016769778, 653.0527239954503, -88.00478340044825, 681.6961451086839, 986.2083849700139, 255.6236658162204, -345.8530490983888, -84.24786856046354, -473.1952844969986, -51.478856324366575, -443.9236301376318, -88.57488236588088, -511.3503405099593, -45.675216268451656, -582.7923056612789, 426.3358082890508, -499.54140138615213, -56.81897760563705, -178.83938687770413, -326.41747211878953, 199.98469578304204, -415.6202784158596, 374.6428511858307, 378.7202844906946, -324.7184361825337, 259.1939513173246, 551.8225405969738, 627.7690642671193, -274.0143098319141, 318.53802819377785, 142.90474377414856, -298.5468113203889, 225.4788998519318, -20.29441087754599, 769.976293879795, 159.3293504041263, -54.88265859769503, 976.5192791372377, -734.1883876305947, -268.9791295778042, 925.646625742574, -122.80049651574024, -27.813953003641963, -668.9043260967233, -30.898172126457816, -396.1544803553946, -217.2926104451655, 64.2196328619554, -9.875289676074857, -513.9851942119243, -95.98830118526845, 139.33076880623813, 336.3267953547941, 324.19504484276035, -196.31383014658095, 451.56518953880493, 802.8142299089279, -351.1822677527035, -3.935157192207239, 538.3977156448767, 293.23776047544663, 464.12350557067157, -274.89012227505464, 1174.0557421936448, 806.8284101856581, 957.8889687592275, -277.8261537757986, 458.4410482539562, -386.72733809984487, 530.789296094651, 57.632571103192035, -678.4041680925133, -105.00203164879831, -479.30038153727196, -52.85437509950021, -644.0648062148186, -12.820053290510113, -759.3883559442911, -60.63983097987048, -654.5213348011561, -137.18288072850203, -628.2470835245949, -54.95596379721134, -120.05403330804114, 360.3945266073495, 674.4862551704299, -416.5853856130682, 534.3989989689306, 617.0701492415864, -462.33973930481454, -531.9264778359878, -267.3983559697931, -340.3852006432527, 945.9090521014892, -625.3646523070015], "episode_lengths": [140, 104, 137, 116, 147, 122, 149, 122, 189, 135, 127, 116, 114, 109, 118, 135, 119, 392, 109, 121, 103, 123, 199, 117, 120, 156, 111, 134, 113, 132, 126, 134, 106, 129, 127, 102, 108, 121, 118, 137, 131, 118, 151, 195, 105, 131, 127, 115, 125, 118, 134, 126, 327, 106, 125, 111, 127, 137, 112, 131, 119, 134, 122, 96, 122, 138, 111, 107, 170, 386, 125, 109, 106, 118, 125, 102, 128, 119, 118, 122, 124, 106, 130, 119, 120, 90, 125, 84, 145, 104, 114, 111, 143, 121, 133, 125, 119, 120, 136, 130], "policy_AGENT-2_reward": [212.77670319106633, -46.74918949702279, 220.96029862098757, -1.6287985621754988, 177.47323142346738, -47.372494573288, 196.08217768310217, -102.20880787968991, 171.51004101476173, 251.07319972480198, -37.873643624163975, -59.13204413109171, 16.454520348891485, -73.8163886571448, 30.041464766818404, -120.81264277754377, 35.50466212400608, -164.70158468921298, 19.474211876510584, -159.59291118353872, 66.92875296202902, -53.85005232315103, -21.634446426990383, -16.505267423260896, -52.70024252028282, 183.5564876156223, -76.25382323435697, -19.64751931726029, 43.61956259441489, -2.050376793972757, -34.817589494917215, 256.2935137965044, 138.0392158786231, -8.680546487746293, -33.69539915148739, 56.74410422084183, -39.14410097960711, 95.52245054108081, -11.648435767865134, 178.9127369792161, -24.873147851270733, -86.27896064001345, 227.44689589897897, -30.919056575572256, -40.2372037896691, 233.27849012618404, -102.66574113049488, 23.942773702625317, -181.74390144050795, 16.491631274226506, -85.83440443134026, 33.24662699125311, 117.1008994009022, 33.82089030874791, -107.4096955999243, 35.11179399119146, 18.557664662533924, 4.051030066361726, 17.42246466560071, -50.864497410076964, 39.11384384805015, 206.5460825699426, -49.05594146320009, -33.26204141979044, 91.71491690437854, -45.80175045010597, 26.01476837473967, -43.27673789593063, 319.574338813208, 351.74227133064846, 227.06737832740976, -49.53819798441336, 72.86460828383946, -55.39043866571251, 145.86224951281642, 12.223281300539476, -195.70045069203917, 24.187228421964967, -122.04187454213564, 26.505672282758137, -148.99526294935748, 34.218917264497286, -192.92744657155478, 35.08999761223304, -186.5332499811311, 21.996578604395538, -150.0660888928458, 30.35890858126607, -11.942529876487619, 38.28012152011211, 145.93999414299657, -68.09309508149437, 120.15013259015143, 83.68108116412964, -150.18032475692377, -64.65912443303878, -13.985339573167977, -61.236986290283156, 235.88431414098986, -71.32969663763971], "policy_AGENT-1_reward": [215.7461552830982, -91.7219604214623, 250.60904618888296, -15.258830563708836, 122.14974207307617, 82.33432361361722, 139.87915390286472, -101.76828617108171, 177.3965366913541, 257.0157485995059, 151.29295306318792, -111.77347687126063, -54.29557111087469, -183.68796420777383, -50.336215166509135, -120.19842974220572, -74.34204367120803, -103.9488647580063, -41.9269671834143, -159.09526811901702, 158.33783809437261, -53.107217192917666, -21.20248385723347, -84.92417027187355, -52.154574785926634, -68.03903673854997, -120.67372691065466, -19.100401340825847, 149.85195221287424, -139.06533850447644, -34.38052945977997, 35.01177255428306, 188.42108850414445, -139.20991991341734, -33.25520549248462, 2.2631020696101416, -98.71462610182019, 20.812059635583466, -0.6645061013829228, 193.19263965645652, 125.05126612945121, -85.51255983183344, 245.2924819957885, -332.1324828076968, -83.2589573709756, 236.07386394264608, 27.42082284622323, -35.84946263110571, -181.12330953466716, -27.744134342160574, -83.36208028175704, -136.8811270372181, -106.18047856272776, -27.48912651097902, -109.34093998106367, -68.69942462704464, 72.71860185273167, 4.651962697668445, 148.34827915942705, -50.43059130427326, 191.07296725085482, 212.18934928037433, -48.62513564435909, -32.82811585259981, 182.06207498838285, -45.364379608021565, 218.97157849103348, -94.09659511243746, 335.5997067905722, 332.22468955854697, 227.49537620386423, -77.77788584163682, 133.92967614215695, -133.58509071636422, 123.771445941127, 28.626261993321762, -157.56718501006713, -72.25505241814109, -115.83116740369536, -51.17493046389828, -145.73786383178944, -29.449859810027494, -192.49949287932768, -59.716065885325314, -186.09368043413735, -90.58460703499482, -138.2717940510038, -57.82521173548195, -11.477055807289005, 154.21924112667455, 195.13536835639607, -129.01433638667953, 120.58587367517647, 229.82559283122046, -6.883079597139677, -197.57986409568528, -119.71180456916771, -60.80887959201845, 257.2586830466264, -70.60936690902606], "policy_AGENT-0_reward": [213.37001523617488, -46.28467613513603, 229.86585297775932, -1.04568286991887, 178.15090385386077, 105.8777104517907, 196.65503004124017, 37.15471463533777, 172.07583706427764, 254.31277361407257, 180.2009010976398, -58.582027694758544, 17.02199452386707, -73.26573139306308, 30.498502170198567, -91.19022082347267, 35.93572559596423, -104.06793957317824, 20.037275713562412, -150.99223237008738, 67.49940688702705, -182.28409316656249, -1.8966020097989755, -60.88094167204565, -97.52471732695668, -68.07032888524175, -75.65430415366922, 222.1413831760734, 44.18623846891621, -181.5203253905462, 179.42121730873004, 34.98303470017691, 138.63632971883234, -117.40420033060776, 207.7831116320566, 57.299703166045425, -38.58475409105982, 96.09796199728633, -11.098173284295882, 179.4767880773978, 83.99516676729269, 38.13815265938352, 228.00974424490158, -340.1593188455276, -39.79586993171853, 229.38358648182577, 55.22615858072197, 24.384461080398914, -153.79266106620835, 16.91410790767793, -131.52998927674253, 33.68404787092404, -106.32059113823138, 34.24425360707963, -155.5369442661396, 35.69681508468568, 29.445069993215334, 144.92238752967384, 18.002777680915674, -64.55518872126267, 39.66566132973632, 228.42896906411892, -148.89637801190986, 13.184565034124077, 92.28506651659876, 173.47276094403867, 26.56671296542423, -42.713516318153474, 354.70751613918924, -42.84938923212408, 232.19176572144517, -49.10867952450211, 133.88673715899753, -54.80715518193072, 146.43218216042294, 12.820080081585475, -131.03631999133054, 24.748203351660514, -121.48057148010163, 26.97403353500239, -192.2838955327219, 34.76345137976806, -229.13717310016972, 35.52956845504942, -162.78256102987513, 22.555172769164752, -184.50193674997348, 30.902704146183346, -67.24362457176085, 38.85098253968154, 146.52819828866635, -67.53549063108751, 127.45219075304746, 84.27068088882545, -191.55668225011163, -64.22469090720246, -119.5825875736307, -131.36342252431723, 264.3921487851612, -261.5309173200837], "policy_AGENT-3_reward": [195.89240148376976, -92.43396567818095, 166.6776385705502, -25.234791819331694, 103.07379867950841, -47.65774932442241, 120.4363623682433, 78.81759601498568, 160.71373033829036, 223.8066630316335, -37.996544720443346, -116.36550040127783, -63.428812322347426, -142.42520023901713, -61.68260809487445, -111.72233679440944, -85.67322641464312, -138.63195148956177, -43.25973667511036, -113.11189398863547, 133.5698103456222, -210.30003870352095, -12.085445311614219, -16.529007510523755, -124.0379374856234, 152.53757379121157, -143.03842411717935, 191.2493886678435, 141.06253121448933, -2.0823954935381788, 148.9708529632918, 225.53421954600964, 162.67243016551967, -8.71964310014313, 177.70552120569292, 26.597834317651078, -122.10333014790204, 13.04642767798094, 3.1167042759978996, 218.39412916672427, -24.843934641346916, 78.77070921476813, 275.7701569975682, -30.977529401798133, -105.68709848544097, 226.91068519191862, -102.78173681219039, -40.291725155560464, -152.24445405534001, -36.55977696620168, -95.42800636555471, -147.34215827012446, 159.61980316201235, -50.451307080923264, -141.69761436479754, -98.09748563410103, 18.60943229775708, 182.70141506108982, 140.42152333681682, -30.463552710967953, 181.71271711016377, 155.6498289944922, -104.60481263323457, 48.970435046058924, 172.33565723551635, 210.93112958953554, 192.5704457394742, -94.80327294853296, 164.17418045067592, 165.71083852858717, 271.1344485065089, -101.40139042524656, 117.76002666896204, -142.94465353583732, 114.72341848028499, 3.962947727745231, -194.10021239907644, -81.68241100428267, -119.94676811133986, -55.15915045336244, -157.04778390094984, -52.35256212474804, -144.8242433932382, -71.54333116182765, -119.11184335601227, -91.15002506706753, -155.40726383077276, -58.39236478917885, -29.39082305250369, 129.04418142088136, 186.88269438237108, -151.9424635138071, 166.21080195055526, 219.2927943574108, -113.7196527006394, -205.46279840006142, -14.118624253826706, -86.97591223663426, 188.37390612871184, -221.89467144025176]}, "sampler_perf": {"mean_env_wait_ms": 52.948845533547065, "mean_raw_obs_processing_ms": 2.3485647206373224, "mean_inference_ms": 2.3699744480200526, "mean_action_processing_ms": 0.14192073202368}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 79800, "timers": {"sample_time_ms": 86354.694, "sample_throughput": 48.637, "load_time_ms": 14.383, "load_throughput": 292015.635, "learn_time_ms": 8009.517, "learn_throughput": 524.376, "update_time_ms": 8.254}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 21.7702693939209, "policy_loss": -0.042766716331243515, "vf_loss": 21.80680274963379, "vf_explained_var": 0.9657678008079529, "kl": 0.013850647956132889, "entropy": 1.1802732944488525, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 16.526155471801758, "policy_loss": -0.036654774099588394, "vf_loss": 16.5585994720459, "vf_explained_var": 0.9669246077537537, "kl": 0.01403939351439476, "entropy": 1.147051453590393, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 22.885772705078125, "policy_loss": -0.03740689903497696, "vf_loss": 22.917932510375977, "vf_explained_var": 0.9534132480621338, "kl": 0.011659896932542324, "entropy": 1.1292800903320312, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 24.330841064453125, "policy_loss": -0.03672630339860916, "vf_loss": 24.36248779296875, "vf_explained_var": 0.9675455093383789, "kl": 0.016928335651755333, "entropy": 1.1451189517974854, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 79800, "num_steps_trained": 79800}, "done": false, "episodes_total": 652, "training_iteration": 19, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-45-30", "timestamp": 1624218330, "time_this_iter_s": 110.27226948738098, "time_total_s": 1870.0333540439606, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c85d3cb0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c85d3f80>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c86d5e60>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6ef0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6a70>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c86d5e60>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6ef0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6a70>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c86d5e60>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6ef0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6a70>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c86d5e60>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6ef0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6a70>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c84ae050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1870.0333540439606, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 56.721518987341774, "ram_util_percent": 95.04873417721521}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1174.0557421936448, "episode_reward_min": -852.036659109806, "episode_reward_mean": -36.321991080039794, "episode_len_mean": 128.38, "episodes_this_iter": 35, "policy_reward_min": {"AGENT-2": -195.70045069203917, "AGENT-1": -395.9454925492917, "AGENT-0": -414.1814635729316, "AGENT-3": -231.49913210860547}, "policy_reward_max": {"AGENT-2": 351.74227133064846, "AGENT-1": 335.5997067905722, "AGENT-0": 354.70751613918924, "AGENT-3": 271.1344485065089}, "policy_reward_mean": {"AGENT-2": 0.9738212260945762, "AGENT-1": -15.742557652686342, "AGENT-0": -3.1386062909507473, "AGENT-3": -18.41464836249728}, "custom_metrics": {"mean_ego_speed_mean": 42.357240000000004, "mean_ego_speed_min": 32.231750000000005, "mean_ego_speed_max": 45.662000000000006, "distance_travelled_mean": 88.95076, "distance_travelled_min": 28.3675, "distance_travelled_max": 124.87650000000001}, "hist_stats": {"episode_reward": [505.06949445889234, -245.40021568119073, -59.081609540826605, -545.7057553887313, 107.19660284935051, -344.0333864161374, 178.44475669516873, -36.193204772980586, 553.9490443077012, -344.88369858790134, -852.036659109806, -349.2776754562645, -96.36987357697636, -175.21491132415872, -74.96340725221502, -318.9527480423273, -152.35072368019502, -427.88723786082494, -133.50936383864905, -272.87666424576776, -65.54597816753608, -493.031457500863, -96.4473830683564, -413.4099189990901, -709.9170360045662, -5.050293693492328, 328.6504348382733, -321.9141421789134, -512.8459000303535, 270.4416261855688, -550.9572814804092, 801.9665916994662, -564.795223545505, 24.438224350812597, 357.13623368888125, 293.23776047544663, 464.12350557067157, -274.89012227505464, 1174.0557421936448, 806.8284101856581, 957.8889687592275, -277.8261537757986, 458.4410482539562, -386.72733809984487, 530.789296094651, 57.632571103192035, -678.4041680925133, -105.00203164879831, -479.30038153727196, -52.85437509950021, -644.0648062148186, -12.820053290510113, -759.3883559442911, -60.63983097987048, -654.5213348011561, -137.18288072850203, -628.2470835245949, -54.95596379721134, -120.05403330804114, 360.3945266073495, 674.4862551704299, -416.5853856130682, 534.3989989689306, 617.0701492415864, -462.33973930481454, -531.9264778359878, -267.3983559697931, -340.3852006432527, 945.9090521014892, -625.3646523070015, 837.7852751941094, -277.18979173180185, 868.11283635818, -43.16810381513511, 580.8476760299131, 93.18179016769778, 653.0527239954503, -88.00478340044825, 681.6961451086839, 986.2083849700139, 255.6236658162204, -345.8530490983888, -84.24786856046354, -473.1952844969986, -51.478856324366575, -443.9236301376318, -88.57488236588088, -511.3503405099593, -45.675216268451656, -582.7923056612789, 426.3358082890508, -499.54140138615213, -56.81897760563705, -178.83938687770413, -326.41747211878953, 199.98469578304204, -415.6202784158596, 374.6428511858307, 378.7202844906946, -324.7184361825337], "episode_lengths": [152, 30, 61, 133, 141, 108, 143, 113, 123, 94, 173, 98, 120, 119, 114, 128, 100, 139, 73, 129, 107, 116, 117, 142, 135, 254, 112, 124, 122, 129, 145, 110, 114, 94, 114, 138, 111, 107, 170, 386, 125, 109, 106, 118, 125, 102, 128, 119, 118, 122, 124, 106, 130, 119, 120, 90, 125, 84, 145, 104, 114, 111, 143, 121, 133, 125, 119, 120, 136, 130, 140, 104, 137, 116, 147, 122, 149, 122, 189, 135, 127, 116, 114, 109, 118, 135, 119, 392, 109, 121, 103, 123, 199, 117, 120, 156, 111, 134, 113, 132], "policy_AGENT-2_reward": [182.48104716406058, -33.44860075032633, -50.893925034705184, -157.73238272088687, -27.764691085488824, -40.31541597188328, -31.881762069757468, -100.68639348940596, 186.5161572283023, -50.473148004194016, -20.909000678294795, -93.51672681152111, 32.06235251748104, -109.20798177285056, 19.71318179699071, -77.37186056051509, 18.47169016885291, -83.74633101569528, 14.996559674996643, -95.59980230226238, 17.323913086564215, -111.240353586601, 24.402191872668862, -90.71070178058935, -129.9431467566178, -33.92462073310092, 47.7098161416057, -11.471460537934322, -62.47115324458072, 53.07476890758958, -95.27179138717308, 193.25891804491164, -63.66604178016519, -34.85835248425343, 25.608843237469696, -45.80175045010597, 26.01476837473967, -43.27673789593063, 319.574338813208, 351.74227133064846, 227.06737832740976, -49.53819798441336, 72.86460828383946, -55.39043866571251, 145.86224951281642, 12.223281300539476, -195.70045069203917, 24.187228421964967, -122.04187454213564, 26.505672282758137, -148.99526294935748, 34.218917264497286, -192.92744657155478, 35.08999761223304, -186.5332499811311, 21.996578604395538, -150.0660888928458, 30.35890858126607, -11.942529876487619, 38.28012152011211, 145.93999414299657, -68.09309508149437, 120.15013259015143, 83.68108116412964, -150.18032475692377, -64.65912443303878, -13.985339573167977, -61.236986290283156, 235.88431414098986, -71.32969663763971, 212.77670319106633, -46.74918949702279, 220.96029862098757, -1.6287985621754988, 177.47323142346738, -47.372494573288, 196.08217768310217, -102.20880787968991, 171.51004101476173, 251.07319972480198, -37.873643624163975, -59.13204413109171, 16.454520348891485, -73.8163886571448, 30.041464766818404, -120.81264277754377, 35.50466212400608, -164.70158468921298, 19.474211876510584, -159.59291118353872, 66.92875296202902, -53.85005232315103, -21.634446426990383, -16.505267423260896, -52.70024252028282, 183.5564876156223, -76.25382323435697, -19.64751931726029, 43.61956259441489, -2.050376793972757], "policy_AGENT-1_reward": [79.61017091296806, -89.26913742942548, 21.332416830562206, -94.54616507848299, 101.89812987882382, -120.54894876845317, 141.87547993549362, -100.23342407570692, 92.60966660039624, -141.5841677555984, -395.9454925492917, -92.82040656182794, -76.60923648916229, -108.77115775804, -55.12510545481256, -73.22120853929641, -94.64961473236608, -74.21950765729774, -81.75496988900159, -20.780374398560056, -37.252586571499485, -132.23020862618634, -67.64013929577273, -85.5843362250639, -129.35773989872538, -33.495175743019935, 94.9025743486909, -126.62565319472291, -187.44834248535827, 94.39638509612796, -94.83839818372847, 246.08681810151873, -206.42100289732645, -34.42660332311323, 156.7108295114103, -45.364379608021565, 218.97157849103348, -94.09659511243746, 335.5997067905722, 332.22468955854697, 227.49537620386423, -77.77788584163682, 133.92967614215695, -133.58509071636422, 123.771445941127, 28.626261993321762, -157.56718501006713, -72.25505241814109, -115.83116740369536, -51.17493046389828, -145.73786383178944, -29.449859810027494, -192.49949287932768, -59.716065885325314, -186.09368043413735, -90.58460703499482, -138.2717940510038, -57.82521173548195, -11.477055807289005, 154.21924112667455, 195.13536835639607, -129.01433638667953, 120.58587367517647, 229.82559283122046, -6.883079597139677, -197.57986409568528, -119.71180456916771, -60.80887959201845, 257.2586830466264, -70.60936690902606, 215.7461552830982, -91.7219604214623, 250.60904618888296, -15.258830563708836, 122.14974207307617, 82.33432361361722, 139.87915390286472, -101.76828617108171, 177.3965366913541, 257.0157485995059, 151.29295306318792, -111.77347687126063, -54.29557111087469, -183.68796420777383, -50.336215166509135, -120.19842974220572, -74.34204367120803, -103.9488647580063, -41.9269671834143, -159.09526811901702, 158.33783809437261, -53.107217192917666, -21.20248385723347, -84.92417027187355, -52.154574785926634, -68.03903673854997, -120.67372691065466, -19.100401340825847, 149.85195221287424, -139.06533850447644], "policy_AGENT-0_reward": [183.05214714150594, -89.34613950745288, 21.323648402955723, -135.44054871924786, 60.77789757672265, -39.74206681287394, 100.48492431028495, 95.63280826704553, 144.77105269866064, -50.03729285325021, -414.1814635729316, -92.94855043887657, 32.61779307918476, 1.0928134891461525, 20.285323732083715, -52.38487904006679, 19.036496426912827, -127.61284863624628, 15.570492187399344, -60.676739210412116, 17.890870763374032, -110.68399251077768, 24.838149002066846, -124.90134495393657, -243.465458814846, -4.4186927960141205, 48.28100177329617, -172.37600586077355, -62.04003443996547, 76.47428084915032, -196.4593466685152, 193.83662627966413, -63.209046759407755, 28.88423142660109, 26.182346906901596, 173.47276094403867, 26.56671296542423, -42.713516318153474, 354.70751613918924, -42.84938923212408, 232.19176572144517, -49.10867952450211, 133.88673715899753, -54.80715518193072, 146.43218216042294, 12.820080081585475, -131.03631999133054, 24.748203351660514, -121.48057148010163, 26.97403353500239, -192.2838955327219, 34.76345137976806, -229.13717310016972, 35.52956845504942, -162.78256102987513, 22.555172769164752, -184.50193674997348, 30.902704146183346, -67.24362457176085, 38.85098253968154, 146.52819828866635, -67.53549063108751, 127.45219075304746, 84.27068088882545, -191.55668225011163, -64.22469090720246, -119.5825875736307, -131.36342252431723, 264.3921487851612, -261.5309173200837, 213.37001523617488, -46.28467613513603, 229.86585297775932, -1.04568286991887, 178.15090385386077, 105.8777104517907, 196.65503004124017, 37.15471463533777, 172.07583706427764, 254.31277361407257, 180.2009010976398, -58.582027694758544, 17.02199452386707, -73.26573139306308, 30.498502170198567, -91.19022082347267, 35.93572559596423, -104.06793957317824, 20.037275713562412, -150.99223237008738, 67.49940688702705, -182.28409316656249, -1.8966020097989755, -60.88094167204565, -97.52471732695668, -68.07032888524175, -75.65430415366922, 222.1413831760734, 44.18623846891621, -181.5203253905462], "policy_AGENT-3_reward": [59.92612924035741, -33.33633799398599, -50.84374973963938, -157.98665887011256, -27.71473352070704, -143.42695486292712, -32.03388548085232, 69.0938045250869, 130.0521677803418, -102.7890899748586, -21.000702309288044, -69.99199164403898, -84.44078268447993, 41.67141471758589, -59.83680732647692, -115.97479990244908, -95.20929554359468, -142.30855055158608, -82.32144581204344, -95.81974833453275, -63.508175445974835, -138.87690277729837, -78.04758464731935, -112.21353603950062, -207.15069053437725, 66.78819557864261, 137.7570425746808, -11.441022585482857, -200.8863698604491, 46.49619133270101, -164.38774524099264, 168.7842292733717, -231.49913210860547, 64.8389487315782, 148.63421403309954, 210.93112958953554, 192.5704457394742, -94.80327294853296, 164.17418045067592, 165.71083852858717, 271.1344485065089, -101.40139042524656, 117.76002666896204, -142.94465353583732, 114.72341848028499, 3.962947727745231, -194.10021239907644, -81.68241100428267, -119.94676811133986, -55.15915045336244, -157.04778390094984, -52.35256212474804, -144.8242433932382, -71.54333116182765, -119.11184335601227, -91.15002506706753, -155.40726383077276, -58.39236478917885, -29.39082305250369, 129.04418142088136, 186.88269438237108, -151.9424635138071, 166.21080195055526, 219.2927943574108, -113.7196527006394, -205.46279840006142, -14.118624253826706, -86.97591223663426, 188.37390612871184, -221.89467144025176, 195.89240148376976, -92.43396567818095, 166.6776385705502, -25.234791819331694, 103.07379867950841, -47.65774932442241, 120.4363623682433, 78.81759601498568, 160.71373033829036, 223.8066630316335, -37.996544720443346, -116.36550040127783, -63.428812322347426, -142.42520023901713, -61.68260809487445, -111.72233679440944, -85.67322641464312, -138.63195148956177, -43.25973667511036, -113.11189398863547, 133.5698103456222, -210.30003870352095, -12.085445311614219, -16.529007510523755, -124.0379374856234, 152.53757379121157, -143.03842411717935, 191.2493886678435, 141.06253121448933, -2.0823954935381788]}, "sampler_perf": {"mean_env_wait_ms": 52.93811088341077, "mean_raw_obs_processing_ms": 2.34871060690737, "mean_inference_ms": 2.3792009871031157, "mean_action_processing_ms": 0.14222032356328104}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 84000, "timers": {"sample_time_ms": 86809.724, "sample_throughput": 48.382, "load_time_ms": 14.498, "load_throughput": 289699.51, "learn_time_ms": 8073.167, "learn_throughput": 520.242, "update_time_ms": 8.175}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 19.76688003540039, "policy_loss": -0.04046960175037384, "vf_loss": 19.801958084106445, "vf_explained_var": 0.9704223871231079, "kl": 0.011991526931524277, "entropy": 1.1702778339385986, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 15.711050033569336, "policy_loss": -0.039362963289022446, "vf_loss": 15.745694160461426, "vf_explained_var": 0.9725969433784485, "kl": 0.015737995505332947, "entropy": 1.1327043771743774, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 23.096176147460938, "policy_loss": -0.043689459562301636, "vf_loss": 23.13406753540039, "vf_explained_var": 0.9518908262252808, "kl": 0.012887981720268726, "entropy": 1.142356038093567, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 25.4805965423584, "policy_loss": -0.036874011158943176, "vf_loss": 25.51226043701172, "vf_explained_var": 0.9603243470191956, "kl": 0.017373977228999138, "entropy": 1.1509367227554321, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 84000, "num_steps_trained": 84000}, "done": false, "episodes_total": 687, "training_iteration": 20, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-47-04", "timestamp": 1624218424, "time_this_iter_s": 93.89740371704102, "time_total_s": 1963.9307577610016, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c8554560>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c8554680>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85548c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85549e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554b00>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554c20>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85548c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85549e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554b00>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554c20>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85548c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85549e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554b00>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554c20>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85548c0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c85549e0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554b00>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554c20>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8647170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 1963.9307577610016, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 56.60223880597015, "ram_util_percent": 94.72985074626867}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1092.6873839386183, "episode_reward_min": -937.9056112652848, "episode_reward_mean": -23.58739996167097, "episode_len_mean": 134.48, "episodes_this_iter": 28, "policy_reward_min": {"AGENT-2": -164.70158468921298, "AGENT-1": -427.24290989376, "AGENT-0": -445.18917439768296, "AGENT-3": -231.49913210860547}, "policy_reward_max": {"AGENT-2": 309.75647913722656, "AGENT-1": 310.21464269643945, "AGENT-0": 264.3921487851612, "AGENT-3": 373.6457591404354}, "policy_reward_mean": {"AGENT-2": 7.734068943756986, "AGENT-1": -21.871599371650078, "AGENT-0": -1.8603356548220042, "AGENT-3": -7.589533878955879}, "custom_metrics": {"mean_ego_speed_mean": 41.994125, "mean_ego_speed_min": 32.231750000000005, "mean_ego_speed_max": 45.662000000000006, "distance_travelled_mean": 86.68693249999998, "distance_travelled_min": 28.3675, "distance_travelled_max": 124.862}, "hist_stats": {"episode_reward": [1092.6873839386183, 176.22014172383015, -937.9056112652848, 697.8097571735036, 939.1665635040032, -319.78770301605255, 1018.5866457737153, 8.418167829186062, -356.12394432281354, -14.356995766559079, -475.6788138854952, -99.66817331910327, -188.06068737879968, 235.86972680336441, 8.889363886482641, 158.01795199323917, -22.31817269355908, -283.1133028869647, -507.3402278209731, -211.25366204051613, 472.9253642097653, 854.4047180944852, -472.9413463897698, -375.4781766175104, -494.4099561655311, 296.3694802667904, 480.3723397220689, 160.97106513907443, 617.0701492415864, -462.33973930481454, -531.9264778359878, -267.3983559697931, -340.3852006432527, 945.9090521014892, -625.3646523070015, 837.7852751941094, -277.18979173180185, 868.11283635818, -43.16810381513511, 580.8476760299131, 93.18179016769778, 653.0527239954503, -88.00478340044825, 681.6961451086839, 986.2083849700139, 255.6236658162204, -345.8530490983888, -84.24786856046354, -473.1952844969986, -51.478856324366575, -443.9236301376318, -88.57488236588088, -511.3503405099593, -45.675216268451656, -582.7923056612789, 426.3358082890508, -499.54140138615213, -56.81897760563705, -178.83938687770413, -326.41747211878953, 199.98469578304204, -415.6202784158596, 374.6428511858307, 378.7202844906946, -324.7184361825337, 505.06949445889234, -245.40021568119073, -59.081609540826605, -545.7057553887313, 107.19660284935051, -344.0333864161374, 178.44475669516873, -36.193204772980586, 553.9490443077012, -344.88369858790134, -852.036659109806, -349.2776754562645, -96.36987357697636, -175.21491132415872, -74.96340725221502, -318.9527480423273, -152.35072368019502, -427.88723786082494, -133.50936383864905, -272.87666424576776, -65.54597816753608, -493.031457500863, -96.4473830683564, -413.4099189990901, -709.9170360045662, -5.050293693492328, 328.6504348382733, -321.9141421789134, -512.8459000303535, 270.4416261855688, -550.9572814804092, 801.9665916994662, -564.795223545505, 24.438224350812597, 357.13623368888125], "episode_lengths": [108, 250, 181, 415, 129, 116, 152, 115, 115, 114, 113, 116, 130, 115, 387, 90, 130, 81, 123, 212, 113, 145, 130, 130, 126, 129, 128, 116, 121, 133, 125, 119, 120, 136, 130, 140, 104, 137, 116, 147, 122, 149, 122, 189, 135, 127, 116, 114, 109, 118, 135, 119, 392, 109, 121, 103, 123, 199, 117, 120, 156, 111, 134, 113, 132, 152, 30, 61, 133, 141, 108, 143, 113, 123, 94, 173, 98, 120, 119, 114, 128, 100, 139, 73, 129, 107, 116, 117, 142, 135, 254, 112, 124, 122, 129, 145, 110, 114, 94, 114], "policy_AGENT-2_reward": [309.75647913722656, -108.4086275962311, -32.638068993799195, 275.2316795531159, 238.04581972417114, -44.073542817834934, 276.39444506989406, 29.018644607315014, -61.32853314395985, 27.235313681849977, -62.66163991214957, 19.927818354851915, -126.15361917902874, 45.215286770628126, 97.95664899849382, 29.77369444945794, -33.223608833893245, -14.5734109285714, -84.2533073029482, -46.659451445784974, 22.614335486691544, 222.64096775883493, -131.32074803406098, -12.133140039656094, -61.67025384712608, -14.205934619665147, 228.929525815589, 48.357322433198455, 83.68108116412964, -150.18032475692377, -64.65912443303878, -13.985339573167977, -61.236986290283156, 235.88431414098986, -71.32969663763971, 212.77670319106633, -46.74918949702279, 220.96029862098757, -1.6287985621754988, 177.47323142346738, -47.372494573288, 196.08217768310217, -102.20880787968991, 171.51004101476173, 251.07319972480198, -37.873643624163975, -59.13204413109171, 16.454520348891485, -73.8163886571448, 30.041464766818404, -120.81264277754377, 35.50466212400608, -164.70158468921298, 19.474211876510584, -159.59291118353872, 66.92875296202902, -53.85005232315103, -21.634446426990383, -16.505267423260896, -52.70024252028282, 183.5564876156223, -76.25382323435697, -19.64751931726029, 43.61956259441489, -2.050376793972757, 182.48104716406058, -33.44860075032633, -50.893925034705184, -157.73238272088687, -27.764691085488824, -40.31541597188328, -31.881762069757468, -100.68639348940596, 186.5161572283023, -50.473148004194016, -20.909000678294795, -93.51672681152111, 32.06235251748104, -109.20798177285056, 19.71318179699071, -77.37186056051509, 18.47169016885291, -83.74633101569528, 14.996559674996643, -95.59980230226238, 17.323913086564215, -111.240353586601, 24.402191872668862, -90.71070178058935, -129.9431467566178, -33.92462073310092, 47.7098161416057, -11.471460537934322, -62.47115324458072, 53.07476890758958, -95.27179138717308, 193.25891804491164, -63.66604178016519, -34.85835248425343, 25.608843237469696], "policy_AGENT-1_reward": [310.21464269643945, -107.85218270023297, -427.24290989376, 248.44850318195935, 243.86082704254167, -113.26035607047265, 275.49791519853756, -23.02276374378664, -112.52305666947431, -29.989844654652842, -197.90786043763703, -66.14590606045539, -125.65908765403631, 45.62521413233848, -105.07722691459733, 30.158505319733056, 43.51718417966357, -126.98620204894004, -163.21073065733822, -46.22072023679477, 23.075872983563553, 260.1076391543922, -129.38721640311417, -155.43968261168246, -180.16831735030914, 33.88488058636566, 25.496807196368387, 39.53886438755894, 229.82559283122046, -6.883079597139677, -197.57986409568528, -119.71180456916771, -60.80887959201845, 257.2586830466264, -70.60936690902606, 215.7461552830982, -91.7219604214623, 250.60904618888296, -15.258830563708836, 122.14974207307617, 82.33432361361722, 139.87915390286472, -101.76828617108171, 177.3965366913541, 257.0157485995059, 151.29295306318792, -111.77347687126063, -54.29557111087469, -183.68796420777383, -50.336215166509135, -120.19842974220572, -74.34204367120803, -103.9488647580063, -41.9269671834143, -159.09526811901702, 158.33783809437261, -53.107217192917666, -21.20248385723347, -84.92417027187355, -52.154574785926634, -68.03903673854997, -120.67372691065466, -19.100401340825847, 149.85195221287424, -139.06533850447644, 79.61017091296806, -89.26913742942548, 21.332416830562206, -94.54616507848299, 101.89812987882382, -120.54894876845317, 141.87547993549362, -100.23342407570692, 92.60966660039624, -141.5841677555984, -395.9454925492917, -92.82040656182794, -76.60923648916229, -108.77115775804, -55.12510545481256, -73.22120853929641, -94.64961473236608, -74.21950765729774, -81.75496988900159, -20.780374398560056, -37.252586571499485, -132.23020862618634, -67.64013929577273, -85.5843362250639, -129.35773989872538, -33.495175743019935, 94.9025743486909, -126.62565319472291, -187.44834248535827, 94.39638509612796, -94.83839818372847, 246.08681810151873, -206.42100289732645, -34.42660332311323, 156.7108295114103], "policy_AGENT-0_reward": [99.07050296451732, 163.86889669854426, -445.18917439768296, 40.94061908756489, 240.1171694781744, -43.518557548780244, 261.90594449724756, 29.464245486883552, -60.77415426412453, 27.693796680878737, -62.2127638441454, 20.499458420821753, 12.536123886381581, 90.418201589326, -104.99233155589441, 30.205111216374213, 0.531547725388549, -126.9786679719447, -83.70924946200985, -87.89497310868477, 227.18781935292174, 251.7141435030739, -101.46370597012205, -195.7474715241757, -61.12113851986931, 153.57081127082577, 25.66093466210862, 48.945872304871166, 84.27068088882545, -191.55668225011163, -64.22469090720246, -119.5825875736307, -131.36342252431723, 264.3921487851612, -261.5309173200837, 213.37001523617488, -46.28467613513603, 229.86585297775932, -1.04568286991887, 178.15090385386077, 105.8777104517907, 196.65503004124017, 37.15471463533777, 172.07583706427764, 254.31277361407257, 180.2009010976398, -58.582027694758544, 17.02199452386707, -73.26573139306308, 30.498502170198567, -91.19022082347267, 35.93572559596423, -104.06793957317824, 20.037275713562412, -150.99223237008738, 67.49940688702705, -182.28409316656249, -1.8966020097989755, -60.88094167204565, -97.52471732695668, -68.07032888524175, -75.65430415366922, 222.1413831760734, 44.18623846891621, -181.5203253905462, 183.05214714150594, -89.34613950745288, 21.323648402955723, -135.44054871924786, 60.77789757672265, -39.74206681287394, 100.48492431028495, 95.63280826704553, 144.77105269866064, -50.03729285325021, -414.1814635729316, -92.94855043887657, 32.61779307918476, 1.0928134891461525, 20.285323732083715, -52.38487904006679, 19.036496426912827, -127.61284863624628, 15.570492187399344, -60.676739210412116, 17.890870763374032, -110.68399251077768, 24.838149002066846, -124.90134495393657, -243.465458814846, -4.4186927960141205, 48.28100177329617, -172.37600586077355, -62.04003443996547, 76.47428084915032, -196.4593466685152, 193.83662627966413, -63.209046759407755, 28.88423142660109, 26.182346906901596], "policy_AGENT-3_reward": [373.6457591404354, 228.61205532175035, -32.83545798004304, 133.1889553508629, 217.14274725911565, -118.93524657896454, 204.78834100803692, -27.041958521225855, -121.49820024525476, -39.296261474634946, -152.89654969156268, -73.94954403432156, 51.21589556788341, 54.61102431107181, 121.00227335848061, 67.88064100767389, -33.14329576471808, -14.575021937508737, -176.16694039867681, -30.47851724925156, 200.04733638658854, 119.94196767818406, -110.76967598247292, -12.157882441996186, -191.45024644822695, 123.11972302926421, 200.2850720480028, 24.129006013445746, 219.2927943574108, -113.7196527006394, -205.46279840006142, -14.118624253826706, -86.97591223663426, 188.37390612871184, -221.89467144025176, 195.89240148376976, -92.43396567818095, 166.6776385705502, -25.234791819331694, 103.07379867950841, -47.65774932442241, 120.4363623682433, 78.81759601498568, 160.71373033829036, 223.8066630316335, -37.996544720443346, -116.36550040127783, -63.428812322347426, -142.42520023901713, -61.68260809487445, -111.72233679440944, -85.67322641464312, -138.63195148956177, -43.25973667511036, -113.11189398863547, 133.5698103456222, -210.30003870352095, -12.085445311614219, -16.529007510523755, -124.0379374856234, 152.53757379121157, -143.03842411717935, 191.2493886678435, 141.06253121448933, -2.0823954935381788, 59.92612924035741, -33.33633799398599, -50.84374973963938, -157.98665887011256, -27.71473352070704, -143.42695486292712, -32.03388548085232, 69.0938045250869, 130.0521677803418, -102.7890899748586, -21.000702309288044, -69.99199164403898, -84.44078268447993, 41.67141471758589, -59.83680732647692, -115.97479990244908, -95.20929554359468, -142.30855055158608, -82.32144581204344, -95.81974833453275, -63.508175445974835, -138.87690277729837, -78.04758464731935, -112.21353603950062, -207.15069053437725, 66.78819557864261, 137.7570425746808, -11.441022585482857, -200.8863698604491, 46.49619133270101, -164.38774524099264, 168.7842292733717, -231.49913210860547, 64.8389487315782, 148.63421403309954]}, "sampler_perf": {"mean_env_wait_ms": 52.90338320685991, "mean_raw_obs_processing_ms": 2.352638893016508, "mean_inference_ms": 2.3752825320116546, "mean_action_processing_ms": 0.14247207256955285}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 88200, "timers": {"sample_time_ms": 86936.429, "sample_throughput": 48.311, "load_time_ms": 14.387, "load_throughput": 291929.013, "learn_time_ms": 8025.757, "learn_throughput": 523.315, "update_time_ms": 8.384}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 28.430294036865234, "policy_loss": -0.0393700934946537, "vf_loss": 28.4638729095459, "vf_explained_var": 0.9601606726646423, "kl": 0.012886933982372284, "entropy": 1.158610463142395, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 13.836732864379883, "policy_loss": -0.04600917547941208, "vf_loss": 13.877508163452148, "vf_explained_var": 0.9766842722892761, "kl": 0.01744401454925537, "entropy": 1.1721895933151245, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 22.549814224243164, "policy_loss": -0.03462916612625122, "vf_loss": 22.577457427978516, "vf_explained_var": 0.9604691863059998, "kl": 0.015527538023889065, "entropy": 1.0752556324005127, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 26.35881233215332, "policy_loss": -0.04185444116592407, "vf_loss": 26.395517349243164, "vf_explained_var": 0.9701932072639465, "kl": 0.01716325618326664, "entropy": 1.0831363201141357, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 88200, "num_steps_trained": 88200}, "done": false, "episodes_total": 715, "training_iteration": 21, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-48-32", "timestamp": 1624218512, "time_this_iter_s": 87.68741011619568, "time_total_s": 2051.6181678771973, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c84aee60>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c85d3d40>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554440>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554320>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85543b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688b90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554440>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554320>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85543b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688b90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554440>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554320>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85543b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688b90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554440>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554320>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85543b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688b90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8554e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2051.6181678771973, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 54.069047619047616, "ram_util_percent": 95.0452380952381}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1299.4841652249033, "episode_reward_min": -937.9056112652848, "episode_reward_mean": 12.823303971548905, "episode_len_mean": 134.1, "episodes_this_iter": 30, "policy_reward_min": {"AGENT-0": -445.18917439768296, "AGENT-3": -231.49913210860547, "AGENT-2": -165.52887495572583, "AGENT-1": -427.24290989376}, "policy_reward_max": {"AGENT-0": 368.859626108929, "AGENT-3": 373.6457591404354, "AGENT-2": 365.8262119967253, "AGENT-1": 366.26545884920114}, "policy_reward_mean": {"AGENT-0": 17.0406083767361, "AGENT-3": 2.6109792840014614, "AGENT-2": 10.844700131329303, "AGENT-1": -17.67298382051799}, "custom_metrics": {"mean_ego_speed_mean": 42.055452499999994, "mean_ego_speed_min": 32.231750000000005, "mean_ego_speed_max": 45.662000000000006, "distance_travelled_mean": 86.45618250000001, "distance_travelled_min": 28.3675, "distance_travelled_max": 124.862}, "hist_stats": {"episode_reward": [-145.48049233307736, 515.6769650715478, -207.12350560100586, 939.2961121800274, -58.119066407005946, 511.37591035693254, -239.45831442880336, 1299.4841652249033, 1247.2215238210042, -139.26048925547985, -460.3027526863563, -146.48913239175408, 228.83482321855902, -38.125492456176524, -223.8073306767309, -96.13351136776741, 203.9877042669672, -44.92295171845157, -96.96651426162887, -12.891217395854405, 68.08206962698237, -361.4010495760113, -69.30134010724747, 445.81620601796334, 362.9569307607799, -582.7130172983187, 434.61230467899424, 603.2200560315237, 304.6451782552406, 524.9512116211822, -178.83938687770413, -326.41747211878953, 199.98469578304204, -415.6202784158596, 374.6428511858307, 378.7202844906946, -324.7184361825337, 505.06949445889234, -245.40021568119073, -59.081609540826605, -545.7057553887313, 107.19660284935051, -344.0333864161374, 178.44475669516873, -36.193204772980586, 553.9490443077012, -344.88369858790134, -852.036659109806, -349.2776754562645, -96.36987357697636, -175.21491132415872, -74.96340725221502, -318.9527480423273, -152.35072368019502, -427.88723786082494, -133.50936383864905, -272.87666424576776, -65.54597816753608, -493.031457500863, -96.4473830683564, -413.4099189990901, -709.9170360045662, -5.050293693492328, 328.6504348382733, -321.9141421789134, -512.8459000303535, 270.4416261855688, -550.9572814804092, 801.9665916994662, -564.795223545505, 24.438224350812597, 357.13623368888125, 1092.6873839386183, 176.22014172383015, -937.9056112652848, 697.8097571735036, 939.1665635040032, -319.78770301605255, 1018.5866457737153, 8.418167829186062, -356.12394432281354, -14.356995766559079, -475.6788138854952, -99.66817331910327, -188.06068737879968, 235.86972680336441, 8.889363886482641, 158.01795199323917, -22.31817269355908, -283.1133028869647, -507.3402278209731, -211.25366204051613, 472.9253642097653, 854.4047180944852, -472.9413463897698, -375.4781766175104, -494.4099561655311, 296.3694802667904, 480.3723397220689, 160.97106513907443], "episode_lengths": [119, 175, 117, 132, 119, 136, 107, 129, 174, 115, 121, 120, 126, 116, 165, 115, 130, 111, 140, 106, 128, 109, 83, 107, 114, 121, 164, 444, 132, 117, 117, 120, 156, 111, 134, 113, 132, 152, 30, 61, 133, 141, 108, 143, 113, 123, 94, 173, 98, 120, 119, 114, 128, 100, 139, 73, 129, 107, 116, 117, 142, 135, 254, 112, 124, 122, 129, 145, 110, 114, 94, 114, 108, 250, 181, 415, 129, 116, 152, 115, 115, 114, 113, 116, 130, 115, 387, 90, 130, 81, 123, 212, 113, 145, 130, 130, 126, 129, 128, 116], "policy_AGENT-0_reward": [-20.067772519946672, 186.35647581585556, -33.89289869116647, 256.8359667045303, 40.905924635474626, 155.03478679793966, -41.8242579827728, 368.859626108929, 348.4946837993983, -13.509035889188464, -51.699625154355914, 22.95839751572854, 160.80862937256032, 32.72111817476467, -3.938969764439314, 28.260123099996644, 148.3959969081993, 24.107202520409786, 63.20555899668559, 24.39517238142184, 155.95714783355132, -96.17112469298513, 38.03377318412862, 32.61791189960851, 53.95305254765346, -104.9154228924292, 241.87028162357373, 238.08078827491013, 176.22077685018326, 67.49208262302828, -60.88094167204565, -97.52471732695668, -68.07032888524175, -75.65430415366922, 222.1413831760734, 44.18623846891621, -181.5203253905462, 183.05214714150594, -89.34613950745288, 21.323648402955723, -135.44054871924786, 60.77789757672265, -39.74206681287394, 100.48492431028495, 95.63280826704553, 144.77105269866064, -50.03729285325021, -414.1814635729316, -92.94855043887657, 32.61779307918476, 1.0928134891461525, 20.285323732083715, -52.38487904006679, 19.036496426912827, -127.61284863624628, 15.570492187399344, -60.676739210412116, 17.890870763374032, -110.68399251077768, 24.838149002066846, -124.90134495393657, -243.465458814846, -4.4186927960141205, 48.28100177329617, -172.37600586077355, -62.04003443996547, 76.47428084915032, -196.4593466685152, 193.83662627966413, -63.209046759407755, 28.88423142660109, 26.182346906901596, 99.07050296451732, 163.86889669854426, -445.18917439768296, 40.94061908756489, 240.1171694781744, -43.518557548780244, 261.90594449724756, 29.464245486883552, -60.77415426412453, 27.693796680878737, -62.2127638441454, 20.499458420821753, 12.536123886381581, 90.418201589326, -104.99233155589441, 30.205111216374213, 0.531547725388549, -126.9786679719447, -83.70924946200985, -87.89497310868477, 227.18781935292174, 251.7141435030739, -101.46370597012205, -195.7474715241757, -61.12113851986931, 153.57081127082577, 25.66093466210862, 48.945872304871166], "policy_AGENT-3_reward": [-56.03416348506359, 63.57660542087092, -74.18119798929462, 151.3917917789087, 81.92143867361378, 92.25527095427323, -92.08669568242878, 198.53286827004735, 244.11277187412014, -60.79315041554467, -78.22015015763266, -99.50500835685848, -31.98347447101758, -56.80484172046802, -139.29491575733064, -56.13979742734987, -32.624488244812795, -57.46341086461759, -96.76849129442479, -44.24801786374813, 126.25313503745133, -84.97981218240636, -1.8095502238785528, 178.18319230187385, 123.68578543468901, -164.86175875459284, 282.35122498941587, 16.16400289772846, 144.56608690727407, 191.32930695685963, -16.529007510523755, -124.0379374856234, 152.53757379121157, -143.03842411717935, 191.2493886678435, 141.06253121448933, -2.0823954935381788, 59.92612924035741, -33.33633799398599, -50.84374973963938, -157.98665887011256, -27.71473352070704, -143.42695486292712, -32.03388548085232, 69.0938045250869, 130.0521677803418, -102.7890899748586, -21.000702309288044, -69.99199164403898, -84.44078268447993, 41.67141471758589, -59.83680732647692, -115.97479990244908, -95.20929554359468, -142.30855055158608, -82.32144581204344, -95.81974833453275, -63.508175445974835, -138.87690277729837, -78.04758464731935, -112.21353603950062, -207.15069053437725, 66.78819557864261, 137.7570425746808, -11.441022585482857, -200.8863698604491, 46.49619133270101, -164.38774524099264, 168.7842292733717, -231.49913210860547, 64.8389487315782, 148.63421403309954, 373.6457591404354, 228.61205532175035, -32.83545798004304, 133.1889553508629, 217.14274725911565, -118.93524657896454, 204.78834100803692, -27.041958521225855, -121.49820024525476, -39.296261474634946, -152.89654969156268, -73.94954403432156, 51.21589556788341, 54.61102431107181, 121.00227335848061, 67.88064100767389, -33.14329576471808, -14.575021937508737, -176.16694039867681, -30.47851724925156, 200.04733638658854, 119.94196767818406, -110.76967598247292, -12.157882441996186, -191.45024644822695, 123.11972302926421, 200.2850720480028, 24.129006013445746], "policy_AGENT-2_reward": [-20.64582895662991, 185.78102605130027, -34.451066624303195, 252.7110936415819, -90.70508573673345, 154.4268055653225, -42.407053793691375, 365.8262119967253, 318.50400332125224, -14.103583092717214, -165.52887495572583, 22.37441233105036, -32.0057981265627, 32.27023650428548, -44.96299773923207, 27.701897873137504, -32.66579625325559, 23.519792900142498, -96.46487446018855, 23.976595560742624, -107.2780994576197, -96.72293657753383, -52.980135658873245, 32.190405054210785, 53.351410946392356, -105.47912805956022, -45.02434002174698, 208.30131813879046, -8.290660298135222, 66.92435171030203, -16.505267423260896, -52.70024252028282, 183.5564876156223, -76.25382323435697, -19.64751931726029, 43.61956259441489, -2.050376793972757, 182.48104716406058, -33.44860075032633, -50.893925034705184, -157.73238272088687, -27.764691085488824, -40.31541597188328, -31.881762069757468, -100.68639348940596, 186.5161572283023, -50.473148004194016, -20.909000678294795, -93.51672681152111, 32.06235251748104, -109.20798177285056, 19.71318179699071, -77.37186056051509, 18.47169016885291, -83.74633101569528, 14.996559674996643, -95.59980230226238, 17.323913086564215, -111.240353586601, 24.402191872668862, -90.71070178058935, -129.9431467566178, -33.92462073310092, 47.7098161416057, -11.471460537934322, -62.47115324458072, 53.07476890758958, -95.27179138717308, 193.25891804491164, -63.66604178016519, -34.85835248425343, 25.608843237469696, 309.75647913722656, -108.4086275962311, -32.638068993799195, 275.2316795531159, 238.04581972417114, -44.073542817834934, 276.39444506989406, 29.018644607315014, -61.32853314395985, 27.235313681849977, -62.66163991214957, 19.927818354851915, -126.15361917902874, 45.215286770628126, 97.95664899849382, 29.77369444945794, -33.223608833893245, -14.5734109285714, -84.2533073029482, -46.659451445784974, 22.614335486691544, 222.64096775883493, -131.32074803406098, -12.133140039656094, -61.67025384712608, -14.205934619665147, 228.929525815589, 48.357322433198455], "policy_AGENT-1_reward": [-48.73272737143719, 79.96285778352137, -64.59834229624154, 278.3572600550064, -90.24134397936083, 109.65904703939667, -63.14030696991054, 366.26545884920114, 336.1100648262344, -50.85471985802958, -164.85410241864213, -92.3169338816745, 132.01546644357893, -46.31200541475862, -35.61044741572934, -95.95573491355167, 120.88199185683624, -35.086536274386226, 33.06129249629833, -17.01496747427069, -106.85011378640067, -83.52717612308618, -52.54542740862428, 202.82469676227015, 131.96668183204508, -207.45670759173677, -44.58486191224825, 140.6739467200944, -7.851025204081658, 199.2054703309923, -84.92417027187355, -52.154574785926634, -68.03903673854997, -120.67372691065466, -19.100401340825847, 149.85195221287424, -139.06533850447644, 79.61017091296806, -89.26913742942548, 21.332416830562206, -94.54616507848299, 101.89812987882382, -120.54894876845317, 141.87547993549362, -100.23342407570692, 92.60966660039624, -141.5841677555984, -395.9454925492917, -92.82040656182794, -76.60923648916229, -108.77115775804, -55.12510545481256, -73.22120853929641, -94.64961473236608, -74.21950765729774, -81.75496988900159, -20.780374398560056, -37.252586571499485, -132.23020862618634, -67.64013929577273, -85.5843362250639, -129.35773989872538, -33.495175743019935, 94.9025743486909, -126.62565319472291, -187.44834248535827, 94.39638509612796, -94.83839818372847, 246.08681810151873, -206.42100289732645, -34.42660332311323, 156.7108295114103, 310.21464269643945, -107.85218270023297, -427.24290989376, 248.44850318195935, 243.86082704254167, -113.26035607047265, 275.49791519853756, -23.02276374378664, -112.52305666947431, -29.989844654652842, -197.90786043763703, -66.14590606045539, -125.65908765403631, 45.62521413233848, -105.07722691459733, 30.158505319733056, 43.51718417966357, -126.98620204894004, -163.21073065733822, -46.22072023679477, 23.075872983563553, 260.1076391543922, -129.38721640311417, -155.43968261168246, -180.16831735030914, 33.88488058636566, 25.496807196368387, 39.53886438755894]}, "sampler_perf": {"mean_env_wait_ms": 52.75245619855096, "mean_raw_obs_processing_ms": 2.3490506964284013, "mean_inference_ms": 2.370663420226937, "mean_action_processing_ms": 0.14255103972888294}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 92400, "timers": {"sample_time_ms": 88028.434, "sample_throughput": 47.712, "load_time_ms": 15.151, "load_throughput": 277207.244, "learn_time_ms": 8204.208, "learn_throughput": 511.932, "update_time_ms": 8.482}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 24.64507484436035, "policy_loss": -0.04349169880151749, "vf_loss": 24.682802200317383, "vf_explained_var": 0.9620612263679504, "kl": 0.01280823815613985, "entropy": 1.1132731437683105, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 24.667938232421875, "policy_loss": -0.040319234132766724, "vf_loss": 24.70330047607422, "vf_explained_var": 0.9641804695129395, "kl": 0.016528528183698654, "entropy": 1.1097782850265503, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 21.213966369628906, "policy_loss": -0.03641701117157936, "vf_loss": 21.244138717651367, "vf_explained_var": 0.9648035764694214, "kl": 0.013877460733056068, "entropy": 1.0230733156204224, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 30.341869354248047, "policy_loss": -0.037831373512744904, "vf_loss": 30.374826431274414, "vf_explained_var": 0.9652571678161621, "kl": 0.016248716041445732, "entropy": 1.057335376739502, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 92400, "num_steps_trained": 92400}, "done": false, "episodes_total": 745, "training_iteration": 22, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-50-14", "timestamp": 1624218614, "time_this_iter_s": 101.90344786643982, "time_total_s": 2153.521615743637, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c84b64d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c84b6f80>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6c20>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397170>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397290>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6c20>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397170>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397290>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6c20>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397170>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397290>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84b6c20>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397170>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397290>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8647560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2153.521615743637, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 54.39310344827586, "ram_util_percent": 95.10000000000001}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1299.4841652249033, "episode_reward_min": -1041.7649174680428, "episode_reward_mean": 48.669124678996376, "episode_len_mean": 136.36, "episodes_this_iter": 33, "policy_reward_min": {"AGENT-2": -365.33398950613974, "AGENT-1": -427.24290989376, "AGENT-0": -445.18917439768296, "AGENT-3": -231.49913210860547}, "policy_reward_max": {"AGENT-2": 365.8262119967253, "AGENT-1": 366.26545884920114, "AGENT-0": 368.859626108929, "AGENT-3": 373.6457591404354}, "policy_reward_mean": {"AGENT-2": 18.62008490392304, "AGENT-1": -5.4819053785083875, "AGENT-0": 29.670208088051403, "AGENT-3": 5.860737065530318}, "custom_metrics": {"mean_ego_speed_mean": 42.13782249999999, "mean_ego_speed_min": 32.231750000000005, "mean_ego_speed_max": 46.5685, "distance_travelled_mean": 88.13296250000002, "distance_travelled_min": 27.7395, "distance_travelled_max": 124.72425000000001}, "hist_stats": {"episode_reward": [325.38557124626453, -319.9910828056149, 1180.9898231459251, 111.38301507582193, 412.0594613697715, 223.70285290189355, 202.56486306102232, -371.17009933120556, -881.7661843132956, -243.41764929316736, -217.76581750188788, -381.4531383583153, -17.63250339908042, -461.06422210362825, -159.56481401084704, 260.61672858516096, 39.271728685751164, -367.2077775616535, -49.13609194821222, -1041.7649174680428, -151.8239643418256, -704.7750135603537, 398.3070031792575, 99.06905379068853, 1013.3970776322053, -531.7512739108032, 332.34780426446486, -104.39098310239291, -744.2632229021691, -419.9017090167241, 1120.2303441128233, -371.0023782006385, 245.37254079049342, 328.6504348382733, -321.9141421789134, -512.8459000303535, 270.4416261855688, -550.9572814804092, 801.9665916994662, -564.795223545505, 24.438224350812597, 357.13623368888125, 1092.6873839386183, 176.22014172383015, -937.9056112652848, 697.8097571735036, 939.1665635040032, -319.78770301605255, 1018.5866457737153, 8.418167829186062, -356.12394432281354, -14.356995766559079, -475.6788138854952, -99.66817331910327, -188.06068737879968, 235.86972680336441, 8.889363886482641, 158.01795199323917, -22.31817269355908, -283.1133028869647, -507.3402278209731, -211.25366204051613, 472.9253642097653, 854.4047180944852, -472.9413463897698, -375.4781766175104, -494.4099561655311, 296.3694802667904, 480.3723397220689, 160.97106513907443, -145.48049233307736, 515.6769650715478, -207.12350560100586, 939.2961121800274, -58.119066407005946, 511.37591035693254, -239.45831442880336, 1299.4841652249033, 1247.2215238210042, -139.26048925547985, -460.3027526863563, -146.48913239175408, 228.83482321855902, -38.125492456176524, -223.8073306767309, -96.13351136776741, 203.9877042669672, -44.92295171845157, -96.96651426162887, -12.891217395854405, 68.08206962698237, -361.4010495760113, -69.30134010724747, 445.81620601796334, 362.9569307607799, -582.7130172983187, 434.61230467899424, 603.2200560315237, 304.6451782552406, 524.9512116211822], "episode_lengths": [185, 116, 171, 136, 190, 134, 180, 119, 174, 31, 114, 142, 105, 119, 117, 135, 114, 115, 115, 154, 117, 93, 163, 105, 160, 134, 104, 114, 151, 133, 164, 61, 106, 112, 124, 122, 129, 145, 110, 114, 94, 114, 108, 250, 181, 415, 129, 116, 152, 115, 115, 114, 113, 116, 130, 115, 387, 90, 130, 81, 123, 212, 113, 145, 130, 130, 126, 129, 128, 116, 119, 175, 117, 132, 119, 136, 107, 129, 174, 115, 121, 120, 126, 116, 165, 115, 130, 111, 140, 106, 128, 109, 83, 107, 114, 121, 164, 444, 132, 117], "policy_AGENT-2_reward": [174.10781945103867, -46.231917984132664, 273.88193340071695, -106.66780426567156, 196.31830529667985, -65.80526646246247, 151.12713027304423, -52.066051442330625, -14.426360006750464, -33.149012069657736, 26.222108069733718, -79.68326013344728, 24.4557315395796, -109.97465695534845, 19.07138890462048, -30.74254423437683, 43.150295102788036, -70.45983225166283, 27.75393449356574, -365.33398950613974, 22.898736978278297, -210.73595464261467, 7.279627578789743, 33.06578583035877, 345.7605686507491, -122.81013975092809, 43.11261255032556, 33.574342727226494, -251.5005600621012, -120.40716906056025, 356.8644230059134, -120.48562785960286, 15.992949399876842, 47.7098161416057, -11.471460537934322, -62.47115324458072, 53.07476890758958, -95.27179138717308, 193.25891804491164, -63.66604178016519, -34.85835248425343, 25.608843237469696, 309.75647913722656, -108.4086275962311, -32.638068993799195, 275.2316795531159, 238.04581972417114, -44.073542817834934, 276.39444506989406, 29.018644607315014, -61.32853314395985, 27.235313681849977, -62.66163991214957, 19.927818354851915, -126.15361917902874, 45.215286770628126, 97.95664899849382, 29.77369444945794, -33.223608833893245, -14.5734109285714, -84.2533073029482, -46.659451445784974, 22.614335486691544, 222.64096775883493, -131.32074803406098, -12.133140039656094, -61.67025384712608, -14.205934619665147, 228.929525815589, 48.357322433198455, -20.64582895662991, 185.78102605130027, -34.451066624303195, 252.7110936415819, -90.70508573673345, 154.4268055653225, -42.407053793691375, 365.8262119967253, 318.50400332125224, -14.103583092717214, -165.52887495572583, 22.37441233105036, -32.0057981265627, 32.27023650428548, -44.96299773923207, 27.701897873137504, -32.66579625325559, 23.519792900142498, -96.46487446018855, 23.976595560742624, -107.2780994576197, -96.72293657753383, -52.980135658873245, 32.190405054210785, 53.351410946392356, -105.47912805956022, -45.02434002174698, 208.30131813879046, -8.290660298135222, 66.92435171030203], "policy_AGENT-1_reward": [1.7615759708308438, -109.36474694322467, 304.620154088984, -106.1135755901976, 14.61089295247034, 163.04417037437062, -42.3559909334606, -130.77596005481064, -408.93225094174215, -88.51850377381709, -122.59753562737902, -77.06223524307252, -21.52143322556327, -108.43327606577985, -95.41640520102705, 147.45163851160956, -20.747289182158557, -111.34438158630742, -47.42516487188467, -138.7837690658747, -118.8521302260099, -141.6539774327921, 7.703921425781708, 34.55982206972497, 260.36090141459715, -126.67361311079438, 134.935248243408, -73.55215068793787, -3.9561075686406895, -71.48187228754938, 259.5519741857393, -64.91277289481106, 118.5641517994991, 94.9025743486909, -126.62565319472291, -187.44834248535827, 94.39638509612796, -94.83839818372847, 246.08681810151873, -206.42100289732645, -34.42660332311323, 156.7108295114103, 310.21464269643945, -107.85218270023297, -427.24290989376, 248.44850318195935, 243.86082704254167, -113.26035607047265, 275.49791519853756, -23.02276374378664, -112.52305666947431, -29.989844654652842, -197.90786043763703, -66.14590606045539, -125.65908765403631, 45.62521413233848, -105.07722691459733, 30.158505319733056, 43.51718417966357, -126.98620204894004, -163.21073065733822, -46.22072023679477, 23.075872983563553, 260.1076391543922, -129.38721640311417, -155.43968261168246, -180.16831735030914, 33.88488058636566, 25.496807196368387, 39.53886438755894, -48.73272737143719, 79.96285778352137, -64.59834229624154, 278.3572600550064, -90.24134397936083, 109.65904703939667, -63.14030696991054, 366.26545884920114, 336.1100648262344, -50.85471985802958, -164.85410241864213, -92.3169338816745, 132.01546644357893, -46.31200541475862, -35.61044741572934, -95.95573491355167, 120.88199185683624, -35.086536274386226, 33.06129249629833, -17.01496747427069, -106.85011378640067, -83.52717612308618, -52.54542740862428, 202.82469676227015, 131.96668183204508, -207.45670759173677, -44.58486191224825, 140.6739467200944, -7.851025204081658, 199.2054703309923], "policy_AGENT-0_reward": [174.6812279687315, -45.65939097077932, 365.69427204079216, 178.12182150897945, 196.90158149086247, 192.29488615541638, 151.71011785203655, -51.48595263306534, -443.9728770674952, -88.66422569395242, 26.79895153923849, -116.59738534223503, 25.037972808014096, -109.41783378462213, 19.648648203125425, 174.6241388266905, 43.714249758786195, -69.87218983207083, 28.336338452205673, -398.29904779782856, 23.46500177636101, -210.16853734213478, 171.58029768291806, 33.639129481593926, 319.1812398483138, -166.2122627500853, 43.710668854639465, -73.39550540140314, -283.9040091106642, -155.9518330226827, 330.029482165026, -64.96154700714378, 16.56394590090328, 48.28100177329617, -172.37600586077355, -62.04003443996547, 76.47428084915032, -196.4593466685152, 193.83662627966413, -63.209046759407755, 28.88423142660109, 26.182346906901596, 99.07050296451732, 163.86889669854426, -445.18917439768296, 40.94061908756489, 240.1171694781744, -43.518557548780244, 261.90594449724756, 29.464245486883552, -60.77415426412453, 27.693796680878737, -62.2127638441454, 20.499458420821753, 12.536123886381581, 90.418201589326, -104.99233155589441, 30.205111216374213, 0.531547725388549, -126.9786679719447, -83.70924946200985, -87.89497310868477, 227.18781935292174, 251.7141435030739, -101.46370597012205, -195.7474715241757, -61.12113851986931, 153.57081127082577, 25.66093466210862, 48.945872304871166, -20.067772519946672, 186.35647581585556, -33.89289869116647, 256.8359667045303, 40.905924635474626, 155.03478679793966, -41.8242579827728, 368.859626108929, 348.4946837993983, -13.509035889188464, -51.699625154355914, 22.95839751572854, 160.80862937256032, 32.72111817476467, -3.938969764439314, 28.260123099996644, 148.3959969081993, 24.107202520409786, 63.20555899668559, 24.39517238142184, 155.95714783355132, -96.17112469298513, 38.03377318412862, 32.61791189960851, 53.95305254765346, -104.9154228924292, 241.87028162357373, 238.08078827491013, 176.22077685018326, 67.49208262302828], "policy_AGENT-3_reward": [-25.165052144335988, -118.73502690747809, 236.79346361543116, 146.04257342271177, 4.228681629759375, -65.83093716543087, -57.91639413059829, -136.84213520099914, -14.434696297306957, -33.085907755740095, -148.18934148348103, -108.11025763956044, -45.60477452111086, -133.23845529787684, -102.86844591756592, -30.716504518762395, -26.845526993664592, -115.53137389161212, -57.80120002209887, -139.34811109820072, -79.33557287045494, -142.21654414281187, 211.74315649176788, -2.1956835909892547, 88.09436771854521, -116.05525829899513, 110.58927461609179, 8.982330259721545, -204.90254616076328, -72.06083464593192, 173.78446475614447, -120.64243043908087, 94.25149369021413, 137.7570425746808, -11.441022585482857, -200.8863698604491, 46.49619133270101, -164.38774524099264, 168.7842292733717, -231.49913210860547, 64.8389487315782, 148.63421403309954, 373.6457591404354, 228.61205532175035, -32.83545798004304, 133.1889553508629, 217.14274725911565, -118.93524657896454, 204.78834100803692, -27.041958521225855, -121.49820024525476, -39.296261474634946, -152.89654969156268, -73.94954403432156, 51.21589556788341, 54.61102431107181, 121.00227335848061, 67.88064100767389, -33.14329576471808, -14.575021937508737, -176.16694039867681, -30.47851724925156, 200.04733638658854, 119.94196767818406, -110.76967598247292, -12.157882441996186, -191.45024644822695, 123.11972302926421, 200.2850720480028, 24.129006013445746, -56.03416348506359, 63.57660542087092, -74.18119798929462, 151.3917917789087, 81.92143867361378, 92.25527095427323, -92.08669568242878, 198.53286827004735, 244.11277187412014, -60.79315041554467, -78.22015015763266, -99.50500835685848, -31.98347447101758, -56.80484172046802, -139.29491575733064, -56.13979742734987, -32.624488244812795, -57.46341086461759, -96.76849129442479, -44.24801786374813, 126.25313503745133, -84.97981218240636, -1.8095502238785528, 178.18319230187385, 123.68578543468901, -164.86175875459284, 282.35122498941587, 16.16400289772846, 144.56608690727407, 191.32930695685963]}, "sampler_perf": {"mean_env_wait_ms": 52.607041190325035, "mean_raw_obs_processing_ms": 2.3468189497163525, "mean_inference_ms": 2.3632880971737626, "mean_action_processing_ms": 0.14256646354729646}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 96600, "timers": {"sample_time_ms": 88993.26, "sample_throughput": 47.195, "load_time_ms": 15.333, "load_throughput": 273916.712, "learn_time_ms": 8341.461, "learn_throughput": 503.509, "update_time_ms": 8.506}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 21.691585540771484, "policy_loss": -0.04635687544941902, "vf_loss": 21.731529235839844, "vf_explained_var": 0.9742397665977478, "kl": 0.014254511334002018, "entropy": 1.1415058374404907, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 21.680362701416016, "policy_loss": -0.04048680514097214, "vf_loss": 21.71505355834961, "vf_explained_var": 0.9709146022796631, "kl": 0.019316939637064934, "entropy": 1.1022921800613403, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 25.387187957763672, "policy_loss": -0.045435354113578796, "vf_loss": 25.426050186157227, "vf_explained_var": 0.9618337750434875, "kl": 0.014605370350182056, "entropy": 1.1207751035690308, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 24.378957748413086, "policy_loss": -0.03685423731803894, "vf_loss": 24.411176681518555, "vf_explained_var": 0.9710297584533691, "kl": 0.015454860404133797, "entropy": 1.1016498804092407, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 96600, "num_steps_trained": 96600}, "done": false, "episodes_total": 778, "training_iteration": 23, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-51-53", "timestamp": 1624218713, "time_this_iter_s": 97.92993640899658, "time_total_s": 2251.4515521526337, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c85413b0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c8541e60>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85543b0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc22cb78320>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647f80>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85543b0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc22cb78320>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647f80>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85543b0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc22cb78320>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647f80>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85543b0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc22cb78320>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647f80>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8397e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2251.4515521526337, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 55.75142857142857, "ram_util_percent": 95.07714285714287}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1710.4946327585817, "episode_reward_min": -1041.7649174680428, "episode_reward_mean": 29.500144587888723, "episode_len_mean": 132.42, "episodes_this_iter": 32, "policy_reward_min": {"AGENT-2": -365.33398950613974, "AGENT-1": -408.93225094174215, "AGENT-0": -443.9728770674952, "AGENT-3": -223.8738703723822}, "policy_reward_max": {"AGENT-2": 435.8524206335904, "AGENT-1": 462.4031506614871, "AGENT-0": 520.7673662048653, "AGENT-3": 298.3965556939721}, "policy_reward_mean": {"AGENT-2": 9.594281375622664, "AGENT-1": -12.602484767592827, "AGENT-0": 34.405529368704975, "AGENT-3": -1.8971813888460827}, "custom_metrics": {"mean_ego_speed_mean": 42.30547249999999, "mean_ego_speed_min": 32.08325, "mean_ego_speed_max": 46.5685, "distance_travelled_mean": 89.30145, "distance_travelled_min": 27.7395, "distance_travelled_max": 124.78925}, "hist_stats": {"episode_reward": [1710.4946327585817, 40.46523137466634, -879.2302465698328, 18.72471069642337, 236.68221213983378, 120.14549521242955, 1156.7901418857264, -684.6099657998574, 1427.3026150001133, 42.54452393139782, -75.15224356988969, -113.94402662259132, -373.4963127683262, -120.15011977424571, -516.4917505658502, -128.6807550549489, -1016.2948329873337, -161.8298922743447, 129.89165508344723, -5.441831521351861, -856.8755089699267, 401.950404919439, 427.1272939425165, -372.0276803293152, -410.5036446715924, -398.78467338849464, -530.7456617251413, 471.732313214334, 527.5904445050917, -275.94479598430945, -480.75928151374546, 379.1912479884519, -375.4781766175104, -494.4099561655311, 296.3694802667904, 480.3723397220689, 160.97106513907443, -145.48049233307736, 515.6769650715478, -207.12350560100586, 939.2961121800274, -58.119066407005946, 511.37591035693254, -239.45831442880336, 1299.4841652249033, 1247.2215238210042, -139.26048925547985, -460.3027526863563, -146.48913239175408, 228.83482321855902, -38.125492456176524, -223.8073306767309, -96.13351136776741, 203.9877042669672, -44.92295171845157, -96.96651426162887, -12.891217395854405, 68.08206962698237, -361.4010495760113, -69.30134010724747, 445.81620601796334, 362.9569307607799, -582.7130172983187, 434.61230467899424, 603.2200560315237, 304.6451782552406, 524.9512116211822, 325.38557124626453, -319.9910828056149, 1180.9898231459251, 111.38301507582193, 412.0594613697715, 223.70285290189355, 202.56486306102232, -371.17009933120556, -881.7661843132956, -243.41764929316736, -217.76581750188788, -381.4531383583153, -17.63250339908042, -461.06422210362825, -159.56481401084704, 260.61672858516096, 39.271728685751164, -367.2077775616535, -49.13609194821222, -1041.7649174680428, -151.8239643418256, -704.7750135603537, 398.3070031792575, 99.06905379068853, 1013.3970776322053, -531.7512739108032, 332.34780426446486, -104.39098310239291, -744.2632229021691, -419.9017090167241, 1120.2303441128233, -371.0023782006385, 245.37254079049342], "episode_lengths": [176, 123, 208, 116, 179, 139, 134, 201, 188, 105, 124, 120, 149, 118, 136, 122, 111, 121, 128, 125, 147, 170, 108, 39, 122, 128, 117, 134, 115, 121, 113, 113, 130, 126, 129, 128, 116, 119, 175, 117, 132, 119, 136, 107, 129, 174, 115, 121, 120, 126, 116, 165, 115, 130, 111, 140, 106, 128, 109, 83, 107, 114, 121, 164, 444, 132, 117, 185, 116, 171, 136, 190, 134, 180, 119, 174, 31, 114, 142, 105, 119, 117, 135, 114, 115, 115, 154, 117, 93, 163, 105, 160, 134, 104, 114, 151, 133, 164, 61, 106], "policy_AGENT-2_reward": [435.8524206335904, -100.08807606741405, -30.455476261960456, -99.31738892122893, 164.06641755691797, -88.11067104932354, 299.4649272058021, -188.0960319953009, 347.78743926498913, 44.756106353349615, 84.13183205569219, 31.7041640382748, -75.95976794923057, 23.49599623291148, -132.26324949620837, 28.284988845939925, -249.38019653397677, 29.438367456032733, -39.88927830121546, 67.22811778185476, -213.94009514526292, -47.11488195130136, 27.89369622516902, -118.2438344041523, -23.116877796281067, -13.495600026217925, -119.41823579530755, -51.866955477122715, 21.360777923180905, -15.951816682289419, -68.88219326253767, 67.97514501432788, -12.133140039656094, -61.67025384712608, -14.205934619665147, 228.929525815589, 48.357322433198455, -20.64582895662991, 185.78102605130027, -34.451066624303195, 252.7110936415819, -90.70508573673345, 154.4268055653225, -42.407053793691375, 365.8262119967253, 318.50400332125224, -14.103583092717214, -165.52887495572583, 22.37441233105036, -32.0057981265627, 32.27023650428548, -44.96299773923207, 27.701897873137504, -32.66579625325559, 23.519792900142498, -96.46487446018855, 23.976595560742624, -107.2780994576197, -96.72293657753383, -52.980135658873245, 32.190405054210785, 53.351410946392356, -105.47912805956022, -45.02434002174698, 208.30131813879046, -8.290660298135222, 66.92435171030203, 174.10781945103867, -46.231917984132664, 273.88193340071695, -106.66780426567156, 196.31830529667985, -65.80526646246247, 151.12713027304423, -52.066051442330625, -14.426360006750464, -33.149012069657736, 26.222108069733718, -79.68326013344728, 24.4557315395796, -109.97465695534845, 19.07138890462048, -30.74254423437683, 43.150295102788036, -70.45983225166283, 27.75393449356574, -365.33398950613974, 22.898736978278297, -210.73595464261467, 7.279627578789743, 33.06578583035877, 345.7605686507491, -122.81013975092809, 43.11261255032556, 33.574342727226494, -251.5005600621012, -120.40716906056025, 356.8644230059134, -120.48562785960286, 15.992949399876842], "policy_AGENT-1_reward": [462.4031506614871, -99.37897806024762, -386.9236984627451, -98.80942394361483, -38.611101941834896, 133.5904517640024, 322.0655444513763, -139.71772189423828, 363.4446598192478, -11.974005811664874, -106.97373057368807, -82.6832921659308, -69.28667309752817, -79.99983327035872, -107.90464359447346, -89.45308440044695, -271.6257512836415, -106.69108621223424, 124.73148415469932, -64.39032287888948, -213.36728896209735, -46.33910562058769, 198.08042965648315, -67.67359876935421, -22.48503889792765, -199.10314912629113, -141.30891289634235, -51.31858338903581, 21.922727999157146, -100.32540668357969, -193.83045627051163, 100.23534750974191, -155.43968261168246, -180.16831735030914, 33.88488058636566, 25.496807196368387, 39.53886438755894, -48.73272737143719, 79.96285778352137, -64.59834229624154, 278.3572600550064, -90.24134397936083, 109.65904703939667, -63.14030696991054, 366.26545884920114, 336.1100648262344, -50.85471985802958, -164.85410241864213, -92.3169338816745, 132.01546644357893, -46.31200541475862, -35.61044741572934, -95.95573491355167, 120.88199185683624, -35.086536274386226, 33.06129249629833, -17.01496747427069, -106.85011378640067, -83.52717612308618, -52.54542740862428, 202.82469676227015, 131.96668183204508, -207.45670759173677, -44.58486191224825, 140.6739467200944, -7.851025204081658, 199.2054703309923, 1.7615759708308438, -109.36474694322467, 304.620154088984, -106.1135755901976, 14.61089295247034, 163.04417037437062, -42.3559909334606, -130.77596005481064, -408.93225094174215, -88.51850377381709, -122.59753562737902, -77.06223524307252, -21.52143322556327, -108.43327606577985, -95.41640520102705, 147.45163851160956, -20.747289182158557, -111.34438158630742, -47.42516487188467, -138.7837690658747, -118.8521302260099, -141.6539774327921, 7.703921425781708, 34.55982206972497, 260.36090141459715, -126.67361311079438, 134.935248243408, -73.55215068793787, -3.9561075686406895, -71.48187228754938, 259.5519741857393, -64.91277289481106, 118.5641517994991], "policy_AGENT-0_reward": [520.7673662048653, 134.464750174171, -431.3482113635445, 120.05451243175023, 164.64671659374645, 163.08875037290176, 272.75224621278414, -168.54952137306802, 417.67396022190405, 45.316379122734375, -106.94086866069466, 32.27375420673837, -106.74597931510888, 24.048305102721702, -148.9479580108604, 28.751343572174253, -271.41501479733245, 29.876802398574455, 84.8993350742153, 67.76860324417096, -247.09681588986433, 227.2541828082242, 28.46447410199253, -67.79013653928115, -202.76047294323993, -172.67408630789558, -118.85535824299728, 301.04207630278097, 256.0770384511303, -143.69096419036956, -68.43721904258945, 68.55819411628374, -195.7474715241757, -61.12113851986931, 153.57081127082577, 25.66093466210862, 48.945872304871166, -20.067772519946672, 186.35647581585556, -33.89289869116647, 256.8359667045303, 40.905924635474626, 155.03478679793966, -41.8242579827728, 368.859626108929, 348.4946837993983, -13.509035889188464, -51.699625154355914, 22.95839751572854, 160.80862937256032, 32.72111817476467, -3.938969764439314, 28.260123099996644, 148.3959969081993, 24.107202520409786, 63.20555899668559, 24.39517238142184, 155.95714783355132, -96.17112469298513, 38.03377318412862, 32.61791189960851, 53.95305254765346, -104.9154228924292, 241.87028162357373, 238.08078827491013, 176.22077685018326, 67.49208262302828, 174.6812279687315, -45.65939097077932, 365.69427204079216, 178.12182150897945, 196.90158149086247, 192.29488615541638, 151.71011785203655, -51.48595263306534, -443.9728770674952, -88.66422569395242, 26.79895153923849, -116.59738534223503, 25.037972808014096, -109.41783378462213, 19.648648203125425, 174.6241388266905, 43.714249758786195, -69.87218983207083, 28.336338452205673, -398.29904779782856, 23.46500177636101, -210.16853734213478, 171.58029768291806, 33.639129481593926, 319.1812398483138, -166.2122627500853, 43.710668854639465, -73.39550540140314, -283.9040091106642, -155.9518330226827, 330.029482165026, -64.96154700714378, 16.56394590090328], "policy_AGENT-3_reward": [291.47169525864024, 105.46753532815723, -30.50286048158285, 96.79701112951689, -53.41982006899511, -88.4230358751507, 262.50742401576315, -188.24669053725074, 298.3965556939721, -35.55395573302138, 54.63052360880067, -95.23865270167379, -121.50389240645845, -87.69458783952014, -127.37589946430674, -96.26400307261609, -223.8738703723822, -114.45397591671761, -39.849885844251894, -76.04822966848803, -182.47130897270267, 268.1502096831039, 172.68869395887165, -118.32011061652753, -162.1412550341439, -13.511837928090348, -151.16315479049382, 273.87577577771174, 228.22990013162348, -15.976608428070556, -149.60941293810635, 142.42256134809872, -12.157882441996186, -191.45024644822695, 123.11972302926421, 200.2850720480028, 24.129006013445746, -56.03416348506359, 63.57660542087092, -74.18119798929462, 151.3917917789087, 81.92143867361378, 92.25527095427323, -92.08669568242878, 198.53286827004735, 244.11277187412014, -60.79315041554467, -78.22015015763266, -99.50500835685848, -31.98347447101758, -56.80484172046802, -139.29491575733064, -56.13979742734987, -32.624488244812795, -57.46341086461759, -96.76849129442479, -44.24801786374813, 126.25313503745133, -84.97981218240636, -1.8095502238785528, 178.18319230187385, 123.68578543468901, -164.86175875459284, 282.35122498941587, 16.16400289772846, 144.56608690727407, 191.32930695685963, -25.165052144335988, -118.73502690747809, 236.79346361543116, 146.04257342271177, 4.228681629759375, -65.83093716543087, -57.91639413059829, -136.84213520099914, -14.434696297306957, -33.085907755740095, -148.18934148348103, -108.11025763956044, -45.60477452111086, -133.23845529787684, -102.86844591756592, -30.716504518762395, -26.845526993664592, -115.53137389161212, -57.80120002209887, -139.34811109820072, -79.33557287045494, -142.21654414281187, 211.74315649176788, -2.1956835909892547, 88.09436771854521, -116.05525829899513, 110.58927461609179, 8.982330259721545, -204.90254616076328, -72.06083464593192, 173.78446475614447, -120.64243043908087, 94.25149369021413]}, "sampler_perf": {"mean_env_wait_ms": 52.5333499757606, "mean_raw_obs_processing_ms": 2.3442591988116397, "mean_inference_ms": 2.361236680705093, "mean_action_processing_ms": 0.14263029659308665}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 100800, "timers": {"sample_time_ms": 88911.644, "sample_throughput": 47.238, "load_time_ms": 15.656, "load_throughput": 268260.908, "learn_time_ms": 8408.635, "learn_throughput": 499.487, "update_time_ms": 8.668}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 19.453306198120117, "policy_loss": -0.04672443866729736, "vf_loss": 19.493255615234375, "vf_explained_var": 0.9804776310920715, "kl": 0.015058779157698154, "entropy": 1.1071206331253052, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 20.26649284362793, "policy_loss": -0.04113422706723213, "vf_loss": 20.3031005859375, "vf_explained_var": 0.9751389026641846, "kl": 0.015091768465936184, "entropy": 1.1062861680984497, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 26.791913986206055, "policy_loss": -0.042226485908031464, "vf_loss": 26.8287296295166, "vf_explained_var": 0.9614342451095581, "kl": 0.012022354640066624, "entropy": 1.138089656829834, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 24.309232711791992, "policy_loss": -0.04115094617009163, "vf_loss": 24.3453369140625, "vf_explained_var": 0.9795392155647278, "kl": 0.01682613417506218, "entropy": 1.0979204177856445, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 100800, "num_steps_trained": 100800}, "done": false, "episodes_total": 810, "training_iteration": 24, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-53-27", "timestamp": 1624218807, "time_this_iter_s": 94.15225601196289, "time_total_s": 2345.6038081645966, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c8397950>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c8397830>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c83975f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c83973b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397ef0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e050>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c83975f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c83973b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397ef0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e050>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c83975f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c83973b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397ef0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e050>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c83975f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c83973b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397ef0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e050>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8688b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2345.6038081645966, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 57.56222222222222, "ram_util_percent": 95.10000000000002}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1710.4946327585817, "episode_reward_min": -1041.7649174680428, "episode_reward_mean": -4.955892904994281, "episode_len_mean": 135.22, "episodes_this_iter": 31, "policy_reward_min": {"AGENT-0": -443.9728770674952, "AGENT-3": -223.8738703723822, "AGENT-2": -365.33398950613974, "AGENT-1": -408.93225094174215}, "policy_reward_max": {"AGENT-0": 520.7673662048653, "AGENT-3": 350.51241374876986, "AGENT-2": 435.8524206335904, "AGENT-1": 462.4031506614871}, "policy_reward_mean": {"AGENT-0": 27.43313171940398, "AGENT-3": -7.169107647975238, "AGENT-2": 0.1324649197277111, "AGENT-1": -25.352381896150685}, "custom_metrics": {"mean_ego_speed_mean": 42.30320749999999, "mean_ego_speed_min": 32.08325, "mean_ego_speed_max": 46.5685, "distance_travelled_mean": 90.53219999999997, "distance_travelled_min": 27.7395, "distance_travelled_max": 124.81450000000001}, "hist_stats": {"episode_reward": [76.45771624421593, 486.12718891236796, -272.0097172689492, -46.66570884785039, -208.97559688740466, 450.5469639258061, -180.13178166375374, 1434.1211750835635, -193.26271350601618, -270.3893666419009, 214.14200845884199, 37.33336002590396, -14.065222925945243, -167.20937538261055, -128.40128969206268, -662.8339097187013, -105.59483293396941, -547.9808569043404, -116.31371526028454, -468.4763925458341, -120.40810972094563, -484.50159622112875, 335.84482562493963, -499.48739633913306, 267.7465982368061, -707.4175586472142, 651.3941870889881, 397.935639562564, 1045.5143293012923, -350.7599263398468, -329.821689376807, 434.61230467899424, 603.2200560315237, 304.6451782552406, 524.9512116211822, 325.38557124626453, -319.9910828056149, 1180.9898231459251, 111.38301507582193, 412.0594613697715, 223.70285290189355, 202.56486306102232, -371.17009933120556, -881.7661843132956, -243.41764929316736, -217.76581750188788, -381.4531383583153, -17.63250339908042, -461.06422210362825, -159.56481401084704, 260.61672858516096, 39.271728685751164, -367.2077775616535, -49.13609194821222, -1041.7649174680428, -151.8239643418256, -704.7750135603537, 398.3070031792575, 99.06905379068853, 1013.3970776322053, -531.7512739108032, 332.34780426446486, -104.39098310239291, -744.2632229021691, -419.9017090167241, 1120.2303441128233, -371.0023782006385, 245.37254079049342, 1710.4946327585817, 40.46523137466634, -879.2302465698328, 18.72471069642337, 236.68221213983378, 120.14549521242955, 1156.7901418857264, -684.6099657998574, 1427.3026150001133, 42.54452393139782, -75.15224356988969, -113.94402662259132, -373.4963127683262, -120.15011977424571, -516.4917505658502, -128.6807550549489, -1016.2948329873337, -161.8298922743447, 129.89165508344723, -5.441831521351861, -856.8755089699267, 401.950404919439, 427.1272939425165, -372.0276803293152, -410.5036446715924, -398.78467338849464, -530.7456617251413, 471.732313214334, 527.5904445050917, -275.94479598430945, -480.75928151374546, 379.1912479884519], "episode_lengths": [132, 204, 113, 177, 141, 197, 104, 176, 116, 130, 128, 128, 117, 131, 112, 127, 110, 119, 107, 95, 112, 123, 103, 130, 114, 138, 246, 105, 153, 125, 131, 164, 444, 132, 117, 185, 116, 171, 136, 190, 134, 180, 119, 174, 31, 114, 142, 105, 119, 117, 135, 114, 115, 115, 154, 117, 93, 163, 105, 160, 134, 104, 114, 151, 133, 164, 61, 106, 176, 123, 208, 116, 179, 139, 134, 201, 188, 105, 124, 120, 149, 118, 136, 122, 111, 121, 128, 125, 147, 170, 108, 39, 122, 128, 117, 134, 115, 121, 113, 113], "policy_AGENT-0_reward": [80.20450565869012, 218.63171878768773, -40.58956282834365, 129.1402340148894, -86.27054875232999, 200.65169813352523, -31.49889822160264, 455.0102794954399, -40.469152014761846, 26.154268212363057, 153.76105140807897, 148.70628555580117, 40.11896505385192, 10.727207777358942, 31.06925183179108, -152.65741039978337, 24.41647839455772, -135.06161119180365, 19.98028943857777, -45.96742247818961, 25.666859726034698, -157.96744329903876, 34.72358924577098, -105.82074190263356, 38.76543875799156, -214.57613078279064, 359.0859641357952, 37.88472778629281, 291.90753047290417, -92.18325139302767, -173.59248664988374, 241.87028162357373, 238.08078827491013, 176.22077685018326, 67.49208262302828, 174.6812279687315, -45.65939097077932, 365.69427204079216, 178.12182150897945, 196.90158149086247, 192.29488615541638, 151.71011785203655, -51.48595263306534, -443.9728770674952, -88.66422569395242, 26.79895153923849, -116.59738534223503, 25.037972808014096, -109.41783378462213, 19.648648203125425, 174.6241388266905, 43.714249758786195, -69.87218983207083, 28.336338452205673, -398.29904779782856, 23.46500177636101, -210.16853734213478, 171.58029768291806, 33.639129481593926, 319.1812398483138, -166.2122627500853, 43.710668854639465, -73.39550540140314, -283.9040091106642, -155.9518330226827, 330.029482165026, -64.96154700714378, 16.56394590090328, 520.7673662048653, 134.464750174171, -431.3482113635445, 120.05451243175023, 164.64671659374645, 163.08875037290176, 272.75224621278414, -168.54952137306802, 417.67396022190405, 45.316379122734375, -106.94086866069466, 32.27375420673837, -106.74597931510888, 24.048305102721702, -148.9479580108604, 28.751343572174253, -271.41501479733245, 29.876802398574455, 84.8993350742153, 67.76860324417096, -247.09681588986433, 227.2541828082242, 28.46447410199253, -67.79013653928115, -202.76047294323993, -172.67408630789558, -118.85535824299728, 301.04207630278097, 256.0770384511303, -143.69096419036956, -68.43721904258945, 68.55819411628374], "policy_AGENT-3_reward": [-62.38223392564246, 49.480912810365, -99.18666788161157, -160.25438045147047, -35.15942107784711, 21.22867612597915, -71.59485165711746, 260.5709249659998, -57.43891892058105, -4.4687245063137695, -33.2938074753593, 118.82374166701628, -49.702775717400186, 49.9742505631674, -74.4658740435991, -140.09871780559865, -55.856240774037566, -138.27997702020005, -89.34758994459057, -116.61565670332732, -65.06803064438898, -115.64015646857978, 121.17605642434519, -127.65792058941227, 116.5833266922515, -157.20994836223335, 350.51241374876986, 148.68016391799392, 203.60891807735229, -125.32119572999694, -12.749314151979812, 282.35122498941587, 16.16400289772846, 144.56608690727407, 191.32930695685963, -25.165052144335988, -118.73502690747809, 236.79346361543116, 146.04257342271177, 4.228681629759375, -65.83093716543087, -57.91639413059829, -136.84213520099914, -14.434696297306957, -33.085907755740095, -148.18934148348103, -108.11025763956044, -45.60477452111086, -133.23845529787684, -102.86844591756592, -30.716504518762395, -26.845526993664592, -115.53137389161212, -57.80120002209887, -139.34811109820072, -79.33557287045494, -142.21654414281187, 211.74315649176788, -2.1956835909892547, 88.09436771854521, -116.05525829899513, 110.58927461609179, 8.982330259721545, -204.90254616076328, -72.06083464593192, 173.78446475614447, -120.64243043908087, 94.25149369021413, 291.47169525864024, 105.46753532815723, -30.50286048158285, 96.79701112951689, -53.41982006899511, -88.4230358751507, 262.50742401576315, -188.24669053725074, 298.3965556939721, -35.55395573302138, 54.63052360880067, -95.23865270167379, -121.50389240645845, -87.69458783952014, -127.37589946430674, -96.26400307261609, -223.8738703723822, -114.45397591671761, -39.849885844251894, -76.04822966848803, -182.47130897270267, 268.1502096831039, 172.68869395887165, -118.32011061652753, -162.1412550341439, -13.511837928090348, -151.16315479049382, 273.87577577771174, 228.22990013162348, -15.976608428070556, -149.60941293810635, 142.42256134809872], "policy_AGENT-2_reward": [-62.25390211301582, 218.058824406836, -41.03578599991122, 128.48614095649216, -35.0861140477373, 200.06584164075576, -32.06758287925055, 342.16033583533687, -41.04031735737042, -146.29430307299896, -33.43724126038035, -115.42171272850354, 39.551073571561275, -114.24839600999252, 30.616252334611683, -185.42897048266275, 23.82397594107451, -140.5234258111617, 19.42535518644418, -153.24161512759855, 25.090231436689113, -105.82851160017373, 34.16458402676752, -131.87061486549405, 38.18176109068367, -157.0815506965935, -29.32186131643791, 37.304022187369874, 266.22305575358394, -66.84147048726355, -12.799572105298068, -45.02434002174698, 208.30131813879046, -8.290660298135222, 66.92435171030203, 174.10781945103867, -46.231917984132664, 273.88193340071695, -106.66780426567156, 196.31830529667985, -65.80526646246247, 151.12713027304423, -52.066051442330625, -14.426360006750464, -33.149012069657736, 26.222108069733718, -79.68326013344728, 24.4557315395796, -109.97465695534845, 19.07138890462048, -30.74254423437683, 43.150295102788036, -70.45983225166283, 27.75393449356574, -365.33398950613974, 22.898736978278297, -210.73595464261467, 7.279627578789743, 33.06578583035877, 345.7605686507491, -122.81013975092809, 43.11261255032556, 33.574342727226494, -251.5005600621012, -120.40716906056025, 356.8644230059134, -120.48562785960286, 15.992949399876842, 435.8524206335904, -100.08807606741405, -30.455476261960456, -99.31738892122893, 164.06641755691797, -88.11067104932354, 299.4649272058021, -188.0960319953009, 347.78743926498913, 44.756106353349615, 84.13183205569219, 31.7041640382748, -75.95976794923057, 23.49599623291148, -132.26324949620837, 28.284988845939925, -249.38019653397677, 29.438367456032733, -39.88927830121546, 67.22811778185476, -213.94009514526292, -47.11488195130136, 27.89369622516902, -118.2438344041523, -23.116877796281067, -13.495600026217925, -119.41823579530755, -51.866955477122715, 21.360777923180905, -15.951816682289419, -68.88219326253767, 67.97514501432788], "policy_AGENT-1_reward": [120.88934662418411, -0.04426709252123118, -91.19770055908266, -144.03770336776134, -52.459513009490415, 28.600748025545396, -44.97044890578323, 376.3796347867883, -54.31432521330295, -145.78060727495108, 127.11200578650252, -114.77495446841002, -44.03248583395831, -113.66243771314481, -115.62091981486631, -184.6488110306563, -97.97904649556412, -134.11584288117538, -66.3717699407159, -152.65169823671846, -106.09717023928036, -105.06548485333613, 145.78059592805602, -134.1381189815931, 74.21607169587926, -178.54992880559666, -28.882329479138377, 174.0667256709074, 283.7748249974515, -66.41400872955866, -130.68031646964553, -44.58486191224825, 140.6739467200944, -7.851025204081658, 199.2054703309923, 1.7615759708308438, -109.36474694322467, 304.620154088984, -106.1135755901976, 14.61089295247034, 163.04417037437062, -42.3559909334606, -130.77596005481064, -408.93225094174215, -88.51850377381709, -122.59753562737902, -77.06223524307252, -21.52143322556327, -108.43327606577985, -95.41640520102705, 147.45163851160956, -20.747289182158557, -111.34438158630742, -47.42516487188467, -138.7837690658747, -118.8521302260099, -141.6539774327921, 7.703921425781708, 34.55982206972497, 260.36090141459715, -126.67361311079438, 134.935248243408, -73.55215068793787, -3.9561075686406895, -71.48187228754938, 259.5519741857393, -64.91277289481106, 118.5641517994991, 462.4031506614871, -99.37897806024762, -386.9236984627451, -98.80942394361483, -38.611101941834896, 133.5904517640024, 322.0655444513763, -139.71772189423828, 363.4446598192478, -11.974005811664874, -106.97373057368807, -82.6832921659308, -69.28667309752817, -79.99983327035872, -107.90464359447346, -89.45308440044695, -271.6257512836415, -106.69108621223424, 124.73148415469932, -64.39032287888948, -213.36728896209735, -46.33910562058769, 198.08042965648315, -67.67359876935421, -22.48503889792765, -199.10314912629113, -141.30891289634235, -51.31858338903581, 21.922727999157146, -100.32540668357969, -193.83045627051163, 100.23534750974191]}, "sampler_perf": {"mean_env_wait_ms": 52.51859084823192, "mean_raw_obs_processing_ms": 2.3470366126954647, "mean_inference_ms": 2.3592241336154656, "mean_action_processing_ms": 0.14279230597306894}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 105000, "timers": {"sample_time_ms": 90813.148, "sample_throughput": 46.249, "load_time_ms": 15.714, "load_throughput": 267279.181, "learn_time_ms": 8366.648, "learn_throughput": 501.993, "update_time_ms": 8.496}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 22.911767959594727, "policy_loss": -0.03845756873488426, "vf_loss": 22.943206787109375, "vf_explained_var": 0.9751209020614624, "kl": 0.015596069395542145, "entropy": 1.1249853372573853, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 25.495121002197266, "policy_loss": -0.0394994355738163, "vf_loss": 25.528833389282227, "vf_explained_var": 0.968015193939209, "kl": 0.01929572783410549, "entropy": 1.0526361465454102, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 21.983049392700195, "policy_loss": -0.041092533618211746, "vf_loss": 22.017736434936523, "vf_explained_var": 0.9727807641029358, "kl": 0.014231124892830849, "entropy": 1.0968717336654663, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 31.973796844482422, "policy_loss": -0.035831697285175323, "vf_loss": 32.00504684448242, "vf_explained_var": 0.9734606146812439, "kl": 0.015276176854968071, "entropy": 1.0851423740386963, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 105000, "num_steps_trained": 105000}, "done": false, "episodes_total": 841, "training_iteration": 25, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-55-08", "timestamp": 1624218908, "time_this_iter_s": 100.7631893157959, "time_total_s": 2446.3669974803925, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c84aedd0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c84aee60>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554440>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85543b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554d40>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554440>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85543b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554d40>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554440>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85543b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554d40>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554440>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85543b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554d40>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c833ec20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2446.3669974803925, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 54.94444444444444, "ram_util_percent": 95.26180555555555}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1830.527628472451, "episode_reward_min": -1087.5321608205188, "episode_reward_mean": 6.548245171522963, "episode_len_mean": 136.18, "episodes_this_iter": 29, "policy_reward_min": {"AGENT-2": -397.368561279572, "AGENT-1": -386.9236984627451, "AGENT-0": -455.08029198603185, "AGENT-3": -223.8738703723822}, "policy_reward_max": {"AGENT-2": 459.97624763270596, "AGENT-1": 489.24761595244246, "AGENT-0": 587.868279685496, "AGENT-3": 350.51241374876986}, "policy_reward_mean": {"AGENT-2": -4.503490226998899, "AGENT-1": -22.13054587179218, "AGENT-0": 28.85666647241534, "AGENT-3": 4.3256147978987345}, "custom_metrics": {"mean_ego_speed_mean": 42.0347925, "mean_ego_speed_min": 32.08325, "mean_ego_speed_max": 47.40675, "distance_travelled_mean": 89.79736000000001, "distance_travelled_min": 42.34975, "distance_travelled_max": 124.81450000000001}, "hist_stats": {"episode_reward": [1021.1920069719802, 1830.527628472451, 46.27670569669392, 37.08473344080052, -300.30008863228704, 300.10839472714673, 178.8598467814474, 65.49785891538679, -238.20982312943872, -337.35391437255197, -160.5334667281797, -1087.5321608205188, -16.19964235193522, -386.1181303394521, -106.26686931453494, -936.9511342597336, 203.7904587676389, -758.4963227720771, 129.38669105349643, -89.63040356990541, 435.97987938274025, 382.33714775378655, 184.24327009654596, 402.0429364231702, 284.65412016894123, 458.63984871337846, 564.459772699202, 381.2315825125137, -572.6644653714083, -531.7512739108032, 332.34780426446486, -104.39098310239291, -744.2632229021691, -419.9017090167241, 1120.2303441128233, -371.0023782006385, 245.37254079049342, 1710.4946327585817, 40.46523137466634, -879.2302465698328, 18.72471069642337, 236.68221213983378, 120.14549521242955, 1156.7901418857264, -684.6099657998574, 1427.3026150001133, 42.54452393139782, -75.15224356988969, -113.94402662259132, -373.4963127683262, -120.15011977424571, -516.4917505658502, -128.6807550549489, -1016.2948329873337, -161.8298922743447, 129.89165508344723, -5.441831521351861, -856.8755089699267, 401.950404919439, 427.1272939425165, -372.0276803293152, -410.5036446715924, -398.78467338849464, -530.7456617251413, 471.732313214334, 527.5904445050917, -275.94479598430945, -480.75928151374546, 379.1912479884519, 76.45771624421593, 486.12718891236796, -272.0097172689492, -46.66570884785039, -208.97559688740466, 450.5469639258061, -180.13178166375374, 1434.1211750835635, -193.26271350601618, -270.3893666419009, 214.14200845884199, 37.33336002590396, -14.065222925945243, -167.20937538261055, -128.40128969206268, -662.8339097187013, -105.59483293396941, -547.9808569043404, -116.31371526028454, -468.4763925458341, -120.40810972094563, -484.50159622112875, 335.84482562493963, -499.48739633913306, 267.7465982368061, -707.4175586472142, 651.3941870889881, 397.935639562564, 1045.5143293012923, -350.7599263398468, -329.821689376807], "episode_lengths": [151, 203, 150, 190, 109, 165, 128, 235, 159, 115, 110, 250, 108, 113, 62, 143, 168, 145, 123, 140, 230, 107, 127, 93, 130, 107, 223, 115, 158, 134, 104, 114, 151, 133, 164, 61, 106, 176, 123, 208, 116, 179, 139, 134, 201, 188, 105, 124, 120, 149, 118, 136, 122, 111, 121, 128, 125, 147, 170, 108, 39, 122, 128, 117, 134, 115, 121, 113, 113, 132, 204, 113, 177, 141, 197, 104, 176, 116, 130, 128, 128, 117, 131, 112, 127, 110, 119, 107, 95, 112, 123, 103, 130, 114, 138, 246, 105, 153, 125, 131], "policy_AGENT-2_reward": [251.53439500231696, 459.97624763270596, -92.11535524550624, 123.21045581548255, -43.322092322329716, 79.62362141446377, 165.90954488167017, -96.22832610143737, 92.6894707521153, -54.93797004282142, 21.486490199093005, -397.368561279572, 21.597842036529897, -53.21391174566608, 23.213664388722115, -355.00239648021716, -33.73145287022963, -215.53088627243756, 75.69590696399814, -9.398323222770918, -29.26437995328333, 23.436171472505855, -58.544049108223376, 27.76632421919284, -41.19964439688669, 42.983291746921104, -42.485727136783865, 30.22047539301762, 1.1310447313271146, -122.81013975092809, 43.11261255032556, 33.574342727226494, -251.5005600621012, -120.40716906056025, 356.8644230059134, -120.48562785960286, 15.992949399876842, 435.8524206335904, -100.08807606741405, -30.455476261960456, -99.31738892122893, 164.06641755691797, -88.11067104932354, 299.4649272058021, -188.0960319953009, 347.78743926498913, 44.756106353349615, 84.13183205569219, 31.7041640382748, -75.95976794923057, 23.49599623291148, -132.26324949620837, 28.284988845939925, -249.38019653397677, 29.438367456032733, -39.88927830121546, 67.22811778185476, -213.94009514526292, -47.11488195130136, 27.89369622516902, -118.2438344041523, -23.116877796281067, -13.495600026217925, -119.41823579530755, -51.866955477122715, 21.360777923180905, -15.951816682289419, -68.88219326253767, 67.97514501432788, -62.25390211301582, 218.058824406836, -41.03578599991122, 128.48614095649216, -35.0861140477373, 200.06584164075576, -32.06758287925055, 342.16033583533687, -41.04031735737042, -146.29430307299896, -33.43724126038035, -115.42171272850354, 39.551073571561275, -114.24839600999252, 30.616252334611683, -185.42897048266275, 23.82397594107451, -140.5234258111617, 19.42535518644418, -153.24161512759855, 25.090231436689113, -105.82851160017373, 34.16458402676752, -131.87061486549405, 38.18176109068367, -157.0815506965935, -29.32186131643791, 37.304022187369874, 266.22305575358394, -66.84147048726355, -12.799572105298068], "policy_AGENT-1_reward": [266.3078671685286, 489.24761595244246, 108.31945609746737, -100.0305414173532, -129.2508725841435, 92.1342763880289, -106.60568695733865, -95.5701515716703, -202.45993633924664, -110.39434268080497, -125.8957505965048, -117.2603722648904, -29.25388124952744, -161.07205091363744, -76.35510669161607, -130.95939086554247, 120.36854221504588, -148.17244858735936, -4.231388548803737, -12.789724785053739, -28.824709971170485, 178.70701390472163, -58.01131929905185, 28.19853330608201, -40.76665375439494, 198.35396127753077, -41.987516142601876, 164.59539650459243, -272.4992343798531, -126.67361311079438, 134.935248243408, -73.55215068793787, -3.9561075686406895, -71.48187228754938, 259.5519741857393, -64.91277289481106, 118.5641517994991, 462.4031506614871, -99.37897806024762, -386.9236984627451, -98.80942394361483, -38.611101941834896, 133.5904517640024, 322.0655444513763, -139.71772189423828, 363.4446598192478, -11.974005811664874, -106.97373057368807, -82.6832921659308, -69.28667309752817, -79.99983327035872, -107.90464359447346, -89.45308440044695, -271.6257512836415, -106.69108621223424, 124.73148415469932, -64.39032287888948, -213.36728896209735, -46.33910562058769, 198.08042965648315, -67.67359876935421, -22.48503889792765, -199.10314912629113, -141.30891289634235, -51.31858338903581, 21.922727999157146, -100.32540668357969, -193.83045627051163, 100.23534750974191, 120.88934662418411, -0.04426709252123118, -91.19770055908266, -144.03770336776134, -52.459513009490415, 28.600748025545396, -44.97044890578323, 376.3796347867883, -54.31432521330295, -145.78060727495108, 127.11200578650252, -114.77495446841002, -44.03248583395831, -113.66243771314481, -115.62091981486631, -184.6488110306563, -97.97904649556412, -134.11584288117538, -66.3717699407159, -152.65169823671846, -106.09717023928036, -105.06548485333613, 145.78059592805602, -134.1381189815931, 74.21607169587926, -178.54992880559666, -28.882329479138377, 174.0667256709074, 283.7748249974515, -66.41400872955866, -130.68031646964553], "policy_AGENT-0_reward": [252.39213069200213, 587.868279685496, 122.24843539306367, 123.77527441252319, -42.89675813805395, 80.1916958552386, 166.47670424570367, 134.5195297724622, 93.26032459097232, -54.38472155407203, 22.049402723767624, -455.08029198603185, 22.159313826149024, -52.77562963507315, 23.79734814951317, -319.4636830916486, 150.7432144244316, -246.0556025186779, 76.25555555128557, -58.06461838908881, 220.6475050034192, 24.018209638355053, 131.19214626352323, 156.31436370150007, 195.4917824009051, 43.56514973589839, 330.90316353364267, 30.62036154241094, -302.45874622690417, -166.2122627500853, 43.710668854639465, -73.39550540140314, -283.9040091106642, -155.9518330226827, 330.029482165026, -64.96154700714378, 16.56394590090328, 520.7673662048653, 134.464750174171, -431.3482113635445, 120.05451243175023, 164.64671659374645, 163.08875037290176, 272.75224621278414, -168.54952137306802, 417.67396022190405, 45.316379122734375, -106.94086866069466, 32.27375420673837, -106.74597931510888, 24.048305102721702, -148.9479580108604, 28.751343572174253, -271.41501479733245, 29.876802398574455, 84.8993350742153, 67.76860324417096, -247.09681588986433, 227.2541828082242, 28.46447410199253, -67.79013653928115, -202.76047294323993, -172.67408630789558, -118.85535824299728, 301.04207630278097, 256.0770384511303, -143.69096419036956, -68.43721904258945, 68.55819411628374, 80.20450565869012, 218.63171878768773, -40.58956282834365, 129.1402340148894, -86.27054875232999, 200.65169813352523, -31.49889822160264, 455.0102794954399, -40.469152014761846, 26.154268212363057, 153.76105140807897, 148.70628555580117, 40.11896505385192, 10.727207777358942, 31.06925183179108, -152.65741039978337, 24.41647839455772, -135.06161119180365, 19.98028943857777, -45.96742247818961, 25.666859726034698, -157.96744329903876, 34.72358924577098, -105.82074190263356, 38.76543875799156, -214.57613078279064, 359.0859641357952, 37.88472778629281, 291.90753047290417, -92.18325139302767, -173.59248664988374], "policy_AGENT-3_reward": [250.9576141091319, 293.4354852018064, -92.17583054833094, -109.87045536985183, -84.83036558775973, 48.1588010694153, -46.92071538858807, 122.77680681603226, -221.69968213327957, -117.63688009485382, -78.17360905453555, -117.82293529002396, -30.702916965086658, -119.05653804507533, -76.9227751611541, -131.52566382232573, -33.58984500160915, -148.73738539360207, -18.33338291298348, -9.377737172991939, 273.42146430377477, 156.17575273820384, 169.60649224029788, 189.76371519639514, 171.1286359193177, 173.73744595302833, 318.0298524449451, 155.79534907249283, 1.1624705040217451, -116.05525829899513, 110.58927461609179, 8.982330259721545, -204.90254616076328, -72.06083464593192, 173.78446475614447, -120.64243043908087, 94.25149369021413, 291.47169525864024, 105.46753532815723, -30.50286048158285, 96.79701112951689, -53.41982006899511, -88.4230358751507, 262.50742401576315, -188.24669053725074, 298.3965556939721, -35.55395573302138, 54.63052360880067, -95.23865270167379, -121.50389240645845, -87.69458783952014, -127.37589946430674, -96.26400307261609, -223.8738703723822, -114.45397591671761, -39.849885844251894, -76.04822966848803, -182.47130897270267, 268.1502096831039, 172.68869395887165, -118.32011061652753, -162.1412550341439, -13.511837928090348, -151.16315479049382, 273.87577577771174, 228.22990013162348, -15.976608428070556, -149.60941293810635, 142.42256134809872, -62.38223392564246, 49.480912810365, -99.18666788161157, -160.25438045147047, -35.15942107784711, 21.22867612597915, -71.59485165711746, 260.5709249659998, -57.43891892058105, -4.4687245063137695, -33.2938074753593, 118.82374166701628, -49.702775717400186, 49.9742505631674, -74.4658740435991, -140.09871780559865, -55.856240774037566, -138.27997702020005, -89.34758994459057, -116.61565670332732, -65.06803064438898, -115.64015646857978, 121.17605642434519, -127.65792058941227, 116.5833266922515, -157.20994836223335, 350.51241374876986, 148.68016391799392, 203.60891807735229, -125.32119572999694, -12.749314151979812]}, "sampler_perf": {"mean_env_wait_ms": 52.5189716494981, "mean_raw_obs_processing_ms": 2.3477411345265056, "mean_inference_ms": 2.3563087758092096, "mean_action_processing_ms": 0.1430009118566379}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 109200, "timers": {"sample_time_ms": 89248.426, "sample_throughput": 47.06, "load_time_ms": 15.424, "load_throughput": 272294.675, "learn_time_ms": 8120.411, "learn_throughput": 517.215, "update_time_ms": 8.545}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 30.688331604003906, "policy_loss": -0.03801620751619339, "vf_loss": 30.7210693359375, "vf_explained_var": 0.9706704020500183, "kl": 0.01172239612787962, "entropy": 1.1212979555130005, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 33.83346176147461, "policy_loss": -0.03904326260089874, "vf_loss": 33.86770248413086, "vf_explained_var": 0.9626918435096741, "kl": 0.015989718958735466, "entropy": 1.0465574264526367, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 33.32044982910156, "policy_loss": -0.045485615730285645, "vf_loss": 33.35987091064453, "vf_explained_var": 0.9618039727210999, "kl": 0.013473164290189743, "entropy": 1.0761626958847046, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 33.59634017944336, "policy_loss": -0.04469519481062889, "vf_loss": 33.63664245605469, "vf_explained_var": 0.9757441282272339, "kl": 0.014646138995885849, "entropy": 1.0571798086166382, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 109200, "num_steps_trained": 109200}, "done": false, "episodes_total": 870, "training_iteration": 26, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-56-40", "timestamp": 1624219000, "time_this_iter_s": 92.16462659835815, "time_total_s": 2538.5316240787506, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c833e710>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c833e5f0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e3b0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e170>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c833ed40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833edd0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e3b0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e170>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c833ed40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833edd0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e3b0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e170>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c833ed40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833edd0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e3b0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e170>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c833ed40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833edd0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8688050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2538.5316240787506, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 56.70916030534351, "ram_util_percent": 95.29847328244274}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1830.527628472451, "episode_reward_min": -1087.5321608205188, "episode_reward_mean": -54.5584053985958, "episode_len_mean": 137.05, "episodes_this_iter": 31, "policy_reward_min": {"AGENT-0": -479.095818058065, "AGENT-3": -221.69968213327957, "AGENT-2": -397.368561279572, "AGENT-1": -462.27265626446336}, "policy_reward_max": {"AGENT-0": 587.868279685496, "AGENT-3": 350.51241374876986, "AGENT-2": 459.97624763270596, "AGENT-1": 489.24761595244246}, "policy_reward_mean": {"AGENT-0": 10.056920083903378, "AGENT-3": -3.342414819938804, "AGENT-2": -16.13031432290703, "AGENT-1": -45.14259633965334}, "custom_metrics": {"mean_ego_speed_mean": 41.850372499999985, "mean_ego_speed_min": 18.212, "mean_ego_speed_max": 47.40675, "distance_travelled_mean": 87.42417249999997, "distance_travelled_min": 42.34975, "distance_travelled_max": 124.81450000000001}, "hist_stats": {"episode_reward": [-98.94926596923959, 22.238470223874025, -43.84388443847535, 279.0590544859971, 314.2490789759478, -220.0611008049297, -811.492942052125, -211.48914537973042, -994.7656108334185, 258.60772241227164, -938.9719461683468, -200.26829266430866, 16.270132679716088, -115.51147111478062, -958.843239441292, 29.070395318443076, 115.22991167605785, -104.81645879805508, -249.46168428182295, -44.44025154038117, -549.2686377819858, -68.20146247790622, -1051.0626040874217, 454.20757669169416, 575.8062989515395, -450.90176735448085, -545.7564945689251, 154.11208125992096, 168.36888847994857, -361.3955804014528, -171.82027550708057, -372.0276803293152, -410.5036446715924, -398.78467338849464, -530.7456617251413, 471.732313214334, 527.5904445050917, -275.94479598430945, -480.75928151374546, 379.1912479884519, 76.45771624421593, 486.12718891236796, -272.0097172689492, -46.66570884785039, -208.97559688740466, 450.5469639258061, -180.13178166375374, 1434.1211750835635, -193.26271350601618, -270.3893666419009, 214.14200845884199, 37.33336002590396, -14.065222925945243, -167.20937538261055, -128.40128969206268, -662.8339097187013, -105.59483293396941, -547.9808569043404, -116.31371526028454, -468.4763925458341, -120.40810972094563, -484.50159622112875, 335.84482562493963, -499.48739633913306, 267.7465982368061, -707.4175586472142, 651.3941870889881, 397.935639562564, 1045.5143293012923, -350.7599263398468, -329.821689376807, 1021.1920069719802, 1830.527628472451, 46.27670569669392, 37.08473344080052, -300.30008863228704, 300.10839472714673, 178.8598467814474, 65.49785891538679, -238.20982312943872, -337.35391437255197, -160.5334667281797, -1087.5321608205188, -16.19964235193522, -386.1181303394521, -106.26686931453494, -936.9511342597336, 203.7904587676389, -758.4963227720771, 129.38669105349643, -89.63040356990541, 435.97987938274025, 382.33714775378655, 184.24327009654596, 402.0429364231702, 284.65412016894123, 458.63984871337846, 564.459772699202, 381.2315825125137, -572.6644653714083], "episode_lengths": [114, 178, 118, 163, 180, 105, 173, 102, 171, 105, 167, 116, 129, 114, 176, 118, 157, 107, 111, 104, 117, 118, 215, 229, 118, 131, 134, 136, 108, 171, 117, 39, 122, 128, 117, 134, 115, 121, 113, 113, 132, 204, 113, 177, 141, 197, 104, 176, 116, 130, 128, 128, 117, 131, 112, 127, 110, 119, 107, 95, 112, 123, 103, 130, 114, 138, 246, 105, 153, 125, 131, 151, 203, 150, 190, 109, 165, 128, 235, 159, 115, 110, 250, 108, 113, 62, 143, 168, 145, 123, 140, 230, 107, 127, 93, 130, 107, 223, 115, 158], "policy_AGENT-0_reward": [-10.316598309557376, 146.44992992629412, 100.11925559024618, 60.069013866111675, 177.2949422190813, -37.14723547792861, -416.7863705430955, -38.271131851833886, -479.095818058065, 59.027663073450086, -349.43869719309555, 27.01550359485352, 101.14014518834212, 19.405356800962362, -321.53777108704685, 41.41738893574831, 169.1330739694726, 23.38205458880325, -55.96431164459791, 31.367323862256413, -175.5639232708989, 23.885829937513716, -355.497910590255, 238.84747303084913, 266.06266208448363, -232.4988509927975, -220.15026300829638, 99.33626521180092, 28.691370095269846, -186.59552791132228, -86.81942882615881, -67.79013653928115, -202.76047294323993, -172.67408630789558, -118.85535824299728, 301.04207630278097, 256.0770384511303, -143.69096419036956, -68.43721904258945, 68.55819411628374, 80.20450565869012, 218.63171878768773, -40.58956282834365, 129.1402340148894, -86.27054875232999, 200.65169813352523, -31.49889822160264, 455.0102794954399, -40.469152014761846, 26.154268212363057, 153.76105140807897, 148.70628555580117, 40.11896505385192, 10.727207777358942, 31.06925183179108, -152.65741039978337, 24.41647839455772, -135.06161119180365, 19.98028943857777, -45.96742247818961, 25.666859726034698, -157.96744329903876, 34.72358924577098, -105.82074190263356, 38.76543875799156, -214.57613078279064, 359.0859641357952, 37.88472778629281, 291.90753047290417, -92.18325139302767, -173.59248664988374, 252.39213069200213, 587.868279685496, 122.24843539306367, 123.77527441252319, -42.89675813805395, 80.1916958552386, 166.47670424570367, 134.5195297724622, 93.26032459097232, -54.38472155407203, 22.049402723767624, -455.08029198603185, 22.159313826149024, -52.77562963507315, 23.79734814951317, -319.4636830916486, 150.7432144244316, -246.0556025186779, 76.25555555128557, -58.06461838908881, 220.6475050034192, 24.018209638355053, 131.19214626352323, 156.31436370150007, 195.4917824009051, 43.56514973589839, 330.90316353364267, 30.62036154241094, -302.45874622690417], "policy_AGENT-3_reward": [-43.662721892217746, -116.93417478127196, 74.20666210949798, 77.8075484352261, -26.417339222310815, -84.42755331111788, 2.1348418815665156, -79.51365024705908, -26.669987359071918, 57.67499729972111, -132.92196941246, -107.31008055341735, -79.31301144057262, -80.3364432219921, -145.6435848179969, -29.451730113787796, -95.17960686923749, -86.41008914903175, -83.93222765251848, -66.40667635688185, -85.32543144757987, -59.121766034373145, -188.9121045212121, 292.77199521868795, 237.76737938389607, -14.633338026568033, -73.8633025609417, 66.95300193509033, 37.87491267414263, -4.44350930775772, -40.02852892309625, -118.32011061652753, -162.1412550341439, -13.511837928090348, -151.16315479049382, 273.87577577771174, 228.22990013162348, -15.976608428070556, -149.60941293810635, 142.42256134809872, -62.38223392564246, 49.480912810365, -99.18666788161157, -160.25438045147047, -35.15942107784711, 21.22867612597915, -71.59485165711746, 260.5709249659998, -57.43891892058105, -4.4687245063137695, -33.2938074753593, 118.82374166701628, -49.702775717400186, 49.9742505631674, -74.4658740435991, -140.09871780559865, -55.856240774037566, -138.27997702020005, -89.34758994459057, -116.61565670332732, -65.06803064438898, -115.64015646857978, 121.17605642434519, -127.65792058941227, 116.5833266922515, -157.20994836223335, 350.51241374876986, 148.68016391799392, 203.60891807735229, -125.32119572999694, -12.749314151979812, 250.9576141091319, 293.4354852018064, -92.17583054833094, -109.87045536985183, -84.83036558775973, 48.1588010694153, -46.92071538858807, 122.77680681603226, -221.69968213327957, -117.63688009485382, -78.17360905453555, -117.82293529002396, -30.702916965086658, -119.05653804507533, -76.9227751611541, -131.52566382232573, -33.58984500160915, -148.73738539360207, -18.33338291298348, -9.377737172991939, 273.42146430377477, 156.17575273820384, 169.60649224029788, 189.76371519639514, 171.1286359193177, 173.73744595302833, 318.0298524449451, 155.79534907249283, 1.1624705040217451], "policy_AGENT-2_reward": [-10.898978638422365, 145.88532563398698, -109.34459636519031, 59.458746718821956, 176.69233799229977, -37.70295650424276, 2.178709885401304, -38.83394652359957, -26.727149151817798, 58.44050102341297, -324.25561388539785, 26.45331183107394, -79.34012665894238, 18.820224617523618, -346.58396031435666, 40.853291869948386, -94.9597814208434, 22.813534905086023, -56.52872458746135, 30.784855923683903, -203.6156018156991, 23.3152114855568, -188.96090235575747, -38.9290916100982, 35.760204406861696, -14.663111862072743, -73.87207271752582, -6.371268755049357, 28.267861702086083, -4.279437898137337, -22.70901559369167, -118.2438344041523, -23.116877796281067, -13.495600026217925, -119.41823579530755, -51.866955477122715, 21.360777923180905, -15.951816682289419, -68.88219326253767, 67.97514501432788, -62.25390211301582, 218.058824406836, -41.03578599991122, 128.48614095649216, -35.0861140477373, 200.06584164075576, -32.06758287925055, 342.16033583533687, -41.04031735737042, -146.29430307299896, -33.43724126038035, -115.42171272850354, 39.551073571561275, -114.24839600999252, 30.616252334611683, -185.42897048266275, 23.82397594107451, -140.5234258111617, 19.42535518644418, -153.24161512759855, 25.090231436689113, -105.82851160017373, 34.16458402676752, -131.87061486549405, 38.18176109068367, -157.0815506965935, -29.32186131643791, 37.304022187369874, 266.22305575358394, -66.84147048726355, -12.799572105298068, 251.53439500231696, 459.97624763270596, -92.11535524550624, 123.21045581548255, -43.322092322329716, 79.62362141446377, 165.90954488167017, -96.22832610143737, 92.6894707521153, -54.93797004282142, 21.486490199093005, -397.368561279572, 21.597842036529897, -53.21391174566608, 23.213664388722115, -355.00239648021716, -33.73145287022963, -215.53088627243756, 75.69590696399814, -9.398323222770918, -29.26437995328333, 23.436171472505855, -58.544049108223376, 27.76632421919284, -41.19964439688669, 42.983291746921104, -42.485727136783865, 30.22047539301762, 1.1310447313271146], "policy_AGENT-1_reward": [-34.07096712904206, -153.1626105551346, -108.82520577302925, 81.72374546583737, -13.320862013122726, -60.78335551164069, -399.0201232759979, -54.870416757237834, -462.27265626446336, 83.46456101568756, -132.3556656773947, -146.4270275368188, 73.78312559088903, -73.40060931127447, -145.0779232218909, -23.7485553734658, 136.23622599666572, -64.60195914291258, -53.03642039724527, -40.185754969439685, -84.76368124780797, -56.280737866603566, -317.6916866201973, -38.48279994774479, 36.216053076298095, -189.1064664730428, -177.87085628216082, -5.8059171319208716, 73.5347440084499, -166.07710528423547, -22.263302164133922, -67.67359876935421, -22.48503889792765, -199.10314912629113, -141.30891289634235, -51.31858338903581, 21.922727999157146, -100.32540668357969, -193.83045627051163, 100.23534750974191, 120.88934662418411, -0.04426709252123118, -91.19770055908266, -144.03770336776134, -52.459513009490415, 28.600748025545396, -44.97044890578323, 376.3796347867883, -54.31432521330295, -145.78060727495108, 127.11200578650252, -114.77495446841002, -44.03248583395831, -113.66243771314481, -115.62091981486631, -184.6488110306563, -97.97904649556412, -134.11584288117538, -66.3717699407159, -152.65169823671846, -106.09717023928036, -105.06548485333613, 145.78059592805602, -134.1381189815931, 74.21607169587926, -178.54992880559666, -28.882329479138377, 174.0667256709074, 283.7748249974515, -66.41400872955866, -130.68031646964553, 266.3078671685286, 489.24761595244246, 108.31945609746737, -100.0305414173532, -129.2508725841435, 92.1342763880289, -106.60568695733865, -95.5701515716703, -202.45993633924664, -110.39434268080497, -125.8957505965048, -117.2603722648904, -29.25388124952744, -161.07205091363744, -76.35510669161607, -130.95939086554247, 120.36854221504588, -148.17244858735936, -4.231388548803737, -12.789724785053739, -28.824709971170485, 178.70701390472163, -58.01131929905185, 28.19853330608201, -40.76665375439494, 198.35396127753077, -41.987516142601876, 164.59539650459243, -272.4992343798531]}, "sampler_perf": {"mean_env_wait_ms": 52.394521622943465, "mean_raw_obs_processing_ms": 2.343387648270072, "mean_inference_ms": 2.3514593223623517, "mean_action_processing_ms": 0.14297714490189345}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 113400, "timers": {"sample_time_ms": 87620.617, "sample_throughput": 47.934, "load_time_ms": 15.409, "load_throughput": 272565.999, "learn_time_ms": 8242.881, "learn_throughput": 509.531, "update_time_ms": 8.453}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 23.493804931640625, "policy_loss": -0.04320177063345909, "vf_loss": 23.53101348876953, "vf_explained_var": 0.9781611561775208, "kl": 0.013316242024302483, "entropy": 1.1676181554794312, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 27.62982749938965, "policy_loss": -0.036626581102609634, "vf_loss": 27.661588668823242, "vf_explained_var": 0.9726436734199524, "kl": 0.016219431534409523, "entropy": 1.0452806949615479, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 29.31399154663086, "policy_loss": -0.039421871304512024, "vf_loss": 29.346708297729492, "vf_explained_var": 0.9630141854286194, "kl": 0.014900357462465763, "entropy": 1.0781058073043823, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 42.83046340942383, "policy_loss": -0.032817866653203964, "vf_loss": 42.85905075073242, "vf_explained_var": 0.9688485860824585, "kl": 0.01409439742565155, "entropy": 1.0668950080871582, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 113400, "num_steps_trained": 113400}, "done": false, "episodes_total": 901, "training_iteration": 27, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-58-06", "timestamp": 1624219086, "time_this_iter_s": 85.44572734832764, "time_total_s": 2623.9773514270782, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c83974d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc22cb78320>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84aedd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541e60>, info_adapter=<function AgentSpec.<lambda> at 0x7fc22ce93560>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84aedd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541e60>, info_adapter=<function AgentSpec.<lambda> at 0x7fc22ce93560>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84aedd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541e60>, info_adapter=<function AgentSpec.<lambda> at 0x7fc22ce93560>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c84aedd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8541e60>, info_adapter=<function AgentSpec.<lambda> at 0x7fc22ce93560>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c833eef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2623.9773514270782, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 56.84308943089431, "ram_util_percent": 95.36341463414631}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1830.527628472451, "episode_reward_min": -1087.5321608205188, "episode_reward_mean": -63.56710864666395, "episode_len_mean": 143.48, "episodes_this_iter": 28, "policy_reward_min": {"AGENT-2": -397.368561279572, "AGENT-1": -462.27265626446336, "AGENT-0": -479.095818058065, "AGENT-3": -221.69968213327957}, "policy_reward_max": {"AGENT-2": 459.97624763270596, "AGENT-1": 489.24761595244246, "AGENT-0": 587.868279685496, "AGENT-3": 350.51241374876986}, "policy_reward_mean": {"AGENT-2": -17.045139273495803, "AGENT-1": -45.104328229151946, "AGENT-0": 0.29340740790329206, "AGENT-3": -1.7110485519194685}, "custom_metrics": {"mean_ego_speed_mean": 41.57966, "mean_ego_speed_min": 18.212, "mean_ego_speed_max": 48.67450000000001, "distance_travelled_mean": 86.74212500000002, "distance_travelled_min": 46.55825, "distance_travelled_max": 124.60025}, "hist_stats": {"episode_reward": [543.6474663255144, -297.77306154966124, -729.0212885412686, 282.1459757879034, -32.353193146895485, -11.6441669092115, -791.1471767690551, -292.8531909227914, 56.16388083257155, 180.9077815682128, -131.59096675039763, -982.8346428831105, -12.572007063226629, 237.29258696649887, -104.12289718604524, -113.80539134418417, -24.14699955539126, 127.38130959167059, -213.35186612634809, -1017.3994494542346, 890.208503757213, -399.596438673607, -363.2759250563643, -140.55009736284504, 444.28140296579426, 342.41564259315965, 247.91755115035687, 99.44892606111995, -468.4763925458341, -120.40810972094563, -484.50159622112875, 335.84482562493963, -499.48739633913306, 267.7465982368061, -707.4175586472142, 651.3941870889881, 397.935639562564, 1045.5143293012923, -350.7599263398468, -329.821689376807, 1021.1920069719802, 1830.527628472451, 46.27670569669392, 37.08473344080052, -300.30008863228704, 300.10839472714673, 178.8598467814474, 65.49785891538679, -238.20982312943872, -337.35391437255197, -160.5334667281797, -1087.5321608205188, -16.19964235193522, -386.1181303394521, -106.26686931453494, -936.9511342597336, 203.7904587676389, -758.4963227720771, 129.38669105349643, -89.63040356990541, 435.97987938274025, 382.33714775378655, 184.24327009654596, 402.0429364231702, 284.65412016894123, 458.63984871337846, 564.459772699202, 381.2315825125137, -572.6644653714083, -98.94926596923959, 22.238470223874025, -43.84388443847535, 279.0590544859971, 314.2490789759478, -220.0611008049297, -811.492942052125, -211.48914537973042, -994.7656108334185, 258.60772241227164, -938.9719461683468, -200.26829266430866, 16.270132679716088, -115.51147111478062, -958.843239441292, 29.070395318443076, 115.22991167605785, -104.81645879805508, -249.46168428182295, -44.44025154038117, -549.2686377819858, -68.20146247790622, -1051.0626040874217, 454.20757669169416, 575.8062989515395, -450.90176735448085, -545.7564945689251, 154.11208125992096, 168.36888847994857, -361.3955804014528, -171.82027550708057], "episode_lengths": [192, 115, 157, 131, 178, 125, 174, 122, 187, 134, 118, 152, 114, 128, 104, 125, 109, 147, 122, 153, 105, 132, 118, 114, 161, 526, 140, 131, 95, 112, 123, 103, 130, 114, 138, 246, 105, 153, 125, 131, 151, 203, 150, 190, 109, 165, 128, 235, 159, 115, 110, 250, 108, 113, 62, 143, 168, 145, 123, 140, 230, 107, 127, 93, 130, 107, 223, 115, 158, 114, 178, 118, 163, 180, 105, 173, 102, 171, 105, 167, 116, 129, 114, 176, 118, 157, 107, 111, 104, 117, 118, 215, 229, 118, 131, 134, 136, 108, 171, 117], "policy_AGENT-2_reward": [221.15802943721388, -46.19454654091339, -19.692941439100338, -36.02022359547532, 116.95223548080138, -97.98812677076492, -10.270445227038067, -103.63371926539436, 159.9986863617964, -38.66712496403905, 37.274473928958976, -367.8975185311837, 30.046967376064497, -30.547578123132382, 14.07714828958803, 24.779020853488433, 20.242551449198256, -81.47245163409995, 28.38876900332577, -364.96508879256834, 201.04342382201878, -92.18503603190216, -16.008935099104267, -12.643561270747512, -32.293012851207116, 160.39230770650886, -43.05629752044746, 21.410956493005962, -153.24161512759855, 25.090231436689113, -105.82851160017373, 34.16458402676752, -131.87061486549405, 38.18176109068367, -157.0815506965935, -29.32186131643791, 37.304022187369874, 266.22305575358394, -66.84147048726355, -12.799572105298068, 251.53439500231696, 459.97624763270596, -92.11535524550624, 123.21045581548255, -43.322092322329716, 79.62362141446377, 165.90954488167017, -96.22832610143737, 92.6894707521153, -54.93797004282142, 21.486490199093005, -397.368561279572, 21.597842036529897, -53.21391174566608, 23.213664388722115, -355.00239648021716, -33.73145287022963, -215.53088627243756, 75.69590696399814, -9.398323222770918, -29.26437995328333, 23.436171472505855, -58.544049108223376, 27.76632421919284, -41.19964439688669, 42.983291746921104, -42.485727136783865, 30.22047539301762, 1.1310447313271146, -10.898978638422365, 145.88532563398698, -109.34459636519031, 59.458746718821956, 176.69233799229977, -37.70295650424276, 2.178709885401304, -38.83394652359957, -26.727149151817798, 58.44050102341297, -324.25561388539785, 26.45331183107394, -79.34012665894238, 18.820224617523618, -346.58396031435666, 40.853291869948386, -94.9597814208434, 22.813534905086023, -56.52872458746135, 30.784855923683903, -203.6156018156991, 23.3152114855568, -188.96090235575747, -38.9290916100982, 35.760204406861696, -14.663111862072743, -73.87207271752582, -6.371268755049357, 28.267861702086083, -4.279437898137337, -22.70901559369167], "policy_AGENT-1_reward": [55.95827865968439, -101.35592381103947, -363.7882297470455, 162.5054107247667, -126.16415371979578, -97.4494208281661, -378.181723990042, -103.13567778937346, -124.68500623162245, 148.15663634515218, -97.56563136656615, -106.32511019691668, -32.86118794515792, 169.4155729396797, -53.83119548056356, -103.48341817511198, -32.081125137086225, 129.1924744328284, -128.57295068704917, -127.86874762466275, 255.90273332830245, -91.75494540198359, -161.9088016459759, -69.89532380849394, -31.85820978240191, 30.93908992017315, -42.42989143937373, 22.03712060547526, -152.65169823671846, -106.09717023928036, -105.06548485333613, 145.78059592805602, -134.1381189815931, 74.21607169587926, -178.54992880559666, -28.882329479138377, 174.0667256709074, 283.7748249974515, -66.41400872955866, -130.68031646964553, 266.3078671685286, 489.24761595244246, 108.31945609746737, -100.0305414173532, -129.2508725841435, 92.1342763880289, -106.60568695733865, -95.5701515716703, -202.45993633924664, -110.39434268080497, -125.8957505965048, -117.2603722648904, -29.25388124952744, -161.07205091363744, -76.35510669161607, -130.95939086554247, 120.36854221504588, -148.17244858735936, -4.231388548803737, -12.789724785053739, -28.824709971170485, 178.70701390472163, -58.01131929905185, 28.19853330608201, -40.76665375439494, 198.35396127753077, -41.987516142601876, 164.59539650459243, -272.4992343798531, -34.07096712904206, -153.1626105551346, -108.82520577302925, 81.72374546583737, -13.320862013122726, -60.78335551164069, -399.0201232759979, -54.870416757237834, -462.27265626446336, 83.46456101568756, -132.3556656773947, -146.4270275368188, 73.78312559088903, -73.40060931127447, -145.0779232218909, -23.7485553734658, 136.23622599666572, -64.60195914291258, -53.03642039724527, -40.185754969439685, -84.76368124780797, -56.280737866603566, -317.6916866201973, -38.48279994774479, 36.216053076298095, -189.1064664730428, -177.87085628216082, -5.8059171319208716, 73.5347440084499, -166.07710528423547, -22.263302164133922], "policy_AGENT-0_reward": [221.71444312295614, -45.643400408675, -325.90099383174237, 191.5584459281891, 117.52340371338477, 72.80769215576683, -392.4377725068089, -25.530101637450947, 160.5631189226614, 110.09242747779089, 37.72636894977235, -401.72154868765443, 30.485883224570948, 128.90427878392853, 14.640426715132586, -103.61668837842902, 20.792343709847074, 161.2247258934412, 28.836805706586837, -396.1317817941682, 201.6038184179166, -125.38904467613418, -169.32404663918663, -45.40418241668036, 267.753355256089, 30.869760703147968, 147.88785732377846, 13.25725932977079, -45.96742247818961, 25.666859726034698, -157.96744329903876, 34.72358924577098, -105.82074190263356, 38.76543875799156, -214.57613078279064, 359.0859641357952, 37.88472778629281, 291.90753047290417, -92.18325139302767, -173.59248664988374, 252.39213069200213, 587.868279685496, 122.24843539306367, 123.77527441252319, -42.89675813805395, 80.1916958552386, 166.47670424570367, 134.5195297724622, 93.26032459097232, -54.38472155407203, 22.049402723767624, -455.08029198603185, 22.159313826149024, -52.77562963507315, 23.79734814951317, -319.4636830916486, 150.7432144244316, -246.0556025186779, 76.25555555128557, -58.06461838908881, 220.6475050034192, 24.018209638355053, 131.19214626352323, 156.31436370150007, 195.4917824009051, 43.56514973589839, 330.90316353364267, 30.62036154241094, -302.45874622690417, -10.316598309557376, 146.44992992629412, 100.11925559024618, 60.069013866111675, 177.2949422190813, -37.14723547792861, -416.7863705430955, -38.271131851833886, -479.095818058065, 59.027663073450086, -349.43869719309555, 27.01550359485352, 101.14014518834212, 19.405356800962362, -321.53777108704685, 41.41738893574831, 169.1330739694726, 23.38205458880325, -55.96431164459791, 31.367323862256413, -175.5639232708989, 23.885829937513716, -355.497910590255, 238.84747303084913, 266.06266208448363, -232.4988509927975, -220.15026300829638, 99.33626521180092, 28.691370095269846, -186.59552791132228, -86.81942882615881], "policy_AGENT-3_reward": [44.81671510566057, -104.5791907890332, -19.639123523379936, -35.89765726957719, -140.66467862128616, 110.98568853395277, -10.257235045167114, -60.55369223057247, -139.71291822026308, -38.67415729069133, -109.0261782625628, -106.8904654673552, -40.24366971870419, -30.479686633976648, -79.00927671020233, 68.51569435586875, -33.10076957735038, -81.56343910049885, -142.00449014921148, -128.4338312428352, 231.65852818897505, -90.26741256358697, -16.034141672097345, -12.607029866923122, 240.67927034331404, 120.21448426332987, 185.51588278639952, 42.743589632867966, -116.61565670332732, -65.06803064438898, -115.64015646857978, 121.17605642434519, -127.65792058941227, 116.5833266922515, -157.20994836223335, 350.51241374876986, 148.68016391799392, 203.60891807735229, -125.32119572999694, -12.749314151979812, 250.9576141091319, 293.4354852018064, -92.17583054833094, -109.87045536985183, -84.83036558775973, 48.1588010694153, -46.92071538858807, 122.77680681603226, -221.69968213327957, -117.63688009485382, -78.17360905453555, -117.82293529002396, -30.702916965086658, -119.05653804507533, -76.9227751611541, -131.52566382232573, -33.58984500160915, -148.73738539360207, -18.33338291298348, -9.377737172991939, 273.42146430377477, 156.17575273820384, 169.60649224029788, 189.76371519639514, 171.1286359193177, 173.73744595302833, 318.0298524449451, 155.79534907249283, 1.1624705040217451, -43.662721892217746, -116.93417478127196, 74.20666210949798, 77.8075484352261, -26.417339222310815, -84.42755331111788, 2.1348418815665156, -79.51365024705908, -26.669987359071918, 57.67499729972111, -132.92196941246, -107.31008055341735, -79.31301144057262, -80.3364432219921, -145.6435848179969, -29.451730113787796, -95.17960686923749, -86.41008914903175, -83.93222765251848, -66.40667635688185, -85.32543144757987, -59.121766034373145, -188.9121045212121, 292.77199521868795, 237.76737938389607, -14.633338026568033, -73.8633025609417, 66.95300193509033, 37.87491267414263, -4.44350930775772, -40.02852892309625]}, "sampler_perf": {"mean_env_wait_ms": 52.2290806905178, "mean_raw_obs_processing_ms": 2.33905356152037, "mean_inference_ms": 2.3454564020904325, "mean_action_processing_ms": 0.14287582930713477}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 117600, "timers": {"sample_time_ms": 86788.186, "sample_throughput": 48.394, "load_time_ms": 15.04, "load_throughput": 279248.379, "learn_time_ms": 7987.935, "learn_throughput": 525.793, "update_time_ms": 8.426}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 21.476619720458984, "policy_loss": -0.04144449532032013, "vf_loss": 21.510343551635742, "vf_explained_var": 0.9814061522483826, "kl": 0.017164859920740128, "entropy": 1.1216611862182617, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 26.3007869720459, "policy_loss": -0.03598425164818764, "vf_loss": 26.331789016723633, "vf_explained_var": 0.9768853187561035, "kl": 0.01659563183784485, "entropy": 1.0330638885498047, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 24.02890968322754, "policy_loss": -0.03686003014445305, "vf_loss": 24.060468673706055, "vf_explained_var": 0.9679698944091797, "kl": 0.011780254542827606, "entropy": 0.9587100148200989, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 60.27067565917969, "policy_loss": -0.03689783066511154, "vf_loss": 60.30339813232422, "vf_explained_var": 0.962106466293335, "kl": 0.01392717007547617, "entropy": 1.047661542892456, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 117600, "num_steps_trained": 117600}, "done": false, "episodes_total": 929, "training_iteration": 28, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_19-59-30", "timestamp": 1624219170, "time_this_iter_s": 84.02460384368896, "time_total_s": 2708.001955270767, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c83cb4d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c83cb5f0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb830>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb950>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cba70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cbb90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb830>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb950>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cba70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cbb90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb830>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb950>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cba70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cbb90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb830>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb950>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cba70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cbb90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c86470e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2708.001955270767, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 55.6975, "ram_util_percent": 95.28333333333332}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 924.9926399244257, "episode_reward_min": -1051.0626040874217, "episode_reward_mean": -86.3127365217932, "episode_len_mean": 135.07, "episodes_this_iter": 34, "policy_reward_min": {"AGENT-0": -479.095818058065, "AGENT-3": -307.8629809475186, "AGENT-2": -367.8975185311837, "AGENT-1": -462.27265626446336}, "policy_reward_max": {"AGENT-0": 330.90316353364267, "AGENT-3": 406.3640257395491, "AGENT-2": 221.15802943721388, "AGENT-1": 255.90273332830245}, "policy_reward_mean": {"AGENT-0": -0.45731707760921464, "AGENT-3": -7.3760075100997655, "AGENT-2": -18.01225568436194, "AGENT-1": -60.46715624972226}, "custom_metrics": {"mean_ego_speed_mean": 41.510724999999994, "mean_ego_speed_min": 18.212, "mean_ego_speed_max": 48.67450000000001, "distance_travelled_mean": 82.43385749999999, "distance_travelled_min": 26.241, "distance_travelled_max": 118.14750000000001}, "hist_stats": {"episode_reward": [-326.96267017186165, -438.21577885383886, 37.07500687578977, -437.9745373328184, -191.4398023585851, -471.7578689306166, -236.92676741134818, 924.9926399244257, 223.91017320880005, -202.49136756603136, -165.7328971399367, -379.87703870926873, 360.82926260550704, -319.3253824643374, -565.2898070380046, -119.3233227873549, -236.92666549638034, -406.6121902960825, -464.5625885644392, -347.7350538440613, 1.1425956280611596, 765.1832062575668, -24.091271594932838, 231.3126237314631, 434.2712780585583, -68.96474636378667, 363.440134089186, 246.59892288923058, 71.2733999921607, -205.92181394034955, -826.276511237668, 330.87428644177646, 472.3962196435686, -350.4421484606841, 184.24327009654596, 402.0429364231702, 284.65412016894123, 458.63984871337846, 564.459772699202, 381.2315825125137, -572.6644653714083, -98.94926596923959, 22.238470223874025, -43.84388443847535, 279.0590544859971, 314.2490789759478, -220.0611008049297, -811.492942052125, -211.48914537973042, -994.7656108334185, 258.60772241227164, -938.9719461683468, -200.26829266430866, 16.270132679716088, -115.51147111478062, -958.843239441292, 29.070395318443076, 115.22991167605785, -104.81645879805508, -249.46168428182295, -44.44025154038117, -549.2686377819858, -68.20146247790622, -1051.0626040874217, 454.20757669169416, 575.8062989515395, -450.90176735448085, -545.7564945689251, 154.11208125992096, 168.36888847994857, -361.3955804014528, -171.82027550708057, 543.6474663255144, -297.77306154966124, -729.0212885412686, 282.1459757879034, -32.353193146895485, -11.6441669092115, -791.1471767690551, -292.8531909227914, 56.16388083257155, 180.9077815682128, -131.59096675039763, -982.8346428831105, -12.572007063226629, 237.29258696649887, -104.12289718604524, -113.80539134418417, -24.14699955539126, 127.38130959167059, -213.35186612634809, -1017.3994494542346, 890.208503757213, -399.596438673607, -363.2759250563643, -140.55009736284504, 444.28140296579426, 342.41564259315965, 247.91755115035687, 99.44892606111995], "episode_lengths": [126, 89, 106, 124, 113, 91, 105, 181, 133, 189, 103, 128, 136, 127, 56, 125, 27, 137, 125, 126, 114, 124, 114, 140, 111, 135, 103, 123, 104, 121, 117, 141, 110, 134, 127, 93, 130, 107, 223, 115, 158, 114, 178, 118, 163, 180, 105, 173, 102, 171, 105, 167, 116, 129, 114, 176, 118, 157, 107, 111, 104, 117, 118, 215, 229, 118, 131, 134, 136, 108, 171, 117, 192, 115, 157, 131, 178, 125, 174, 122, 187, 134, 118, 152, 114, 128, 104, 125, 109, 147, 122, 153, 105, 132, 118, 114, 161, 526, 140, 131], "policy_AGENT-0_reward": [-105.22334381219886, -191.9176018529728, 11.377815282527198, 118.9151611550512, -67.70352921530517, -207.93007298582444, -44.03488183880506, 125.42067938054124, 176.09350460510234, 87.1765429396657, -29.84039622793836, 20.083708934419263, 228.44667903572406, 23.123290354463535, -118.16862417627698, 46.61470371696468, -87.71219004400268, 37.47359795701267, -154.577232465355, 23.839892827267338, 25.65079481302424, 300.31432144992294, 95.99447689914508, 133.68194074231687, 208.55945651353068, -22.284895989976814, 31.85192399811236, 176.86275870370926, 17.79201080054145, -110.393909437796, -199.25543594592065, 204.29470447391128, 223.84837568667228, -183.83842255754166, 131.19214626352323, 156.31436370150007, 195.4917824009051, 43.56514973589839, 330.90316353364267, 30.62036154241094, -302.45874622690417, -10.316598309557376, 146.44992992629412, 100.11925559024618, 60.069013866111675, 177.2949422190813, -37.14723547792861, -416.7863705430955, -38.271131851833886, -479.095818058065, 59.027663073450086, -349.43869719309555, 27.01550359485352, 101.14014518834212, 19.405356800962362, -321.53777108704685, 41.41738893574831, 169.1330739694726, 23.38205458880325, -55.96431164459791, 31.367323862256413, -175.5639232708989, 23.885829937513716, -355.497910590255, 238.84747303084913, 266.06266208448363, -232.4988509927975, -220.15026300829638, 99.33626521180092, 28.691370095269846, -186.59552791132228, -86.81942882615881, 221.71444312295614, -45.643400408675, -325.90099383174237, 191.5584459281891, 117.52340371338477, 72.80769215576683, -392.4377725068089, -25.530101637450947, 160.5631189226614, 110.09242747779089, 37.72636894977235, -401.72154868765443, 30.485883224570948, 128.90427878392853, 14.640426715132586, -103.61668837842902, 20.792343709847074, 161.2247258934412, 28.836805706586837, -396.1317817941682, 201.6038184179166, -125.38904467613418, -169.32404663918663, -45.40418241668036, 267.753355256089, 30.869760703147968, 147.88785732377846, 13.25725932977079], "policy_AGENT-3_reward": [-75.04425905387113, -26.993166629124964, -5.680705144078162, -307.8629809475186, -28.022151949283245, -27.77178601670175, -85.72601446941056, 406.3640257395491, -50.154720023446906, -193.75201747058284, -65.36993993945204, -216.59668728933815, -32.645157400221315, -187.88180712202674, -164.40061146336706, -113.2715999603232, -30.711957339307823, -247.77576419779865, -101.68704894934895, -179.81963454835287, -35.60392853711748, 271.1890758246264, 70.7954333767332, 176.76067838903376, 184.87320338808385, 9.649889861818792, 137.62490040627168, 153.36030545797146, -0.6061742256339144, -14.001116703806918, -216.40395860781888, 170.31431743041824, 198.6125404859393, -10.409215683436416, 169.60649224029788, 189.76371519639514, 171.1286359193177, 173.73744595302833, 318.0298524449451, 155.79534907249283, 1.1624705040217451, -43.662721892217746, -116.93417478127196, 74.20666210949798, 77.8075484352261, -26.417339222310815, -84.42755331111788, 2.1348418815665156, -79.51365024705908, -26.669987359071918, 57.67499729972111, -132.92196941246, -107.31008055341735, -79.31301144057262, -80.3364432219921, -145.6435848179969, -29.451730113787796, -95.17960686923749, -86.41008914903175, -83.93222765251848, -66.40667635688185, -85.32543144757987, -59.121766034373145, -188.9121045212121, 292.77199521868795, 237.76737938389607, -14.633338026568033, -73.8633025609417, 66.95300193509033, 37.87491267414263, -4.44350930775772, -40.02852892309625, 44.81671510566057, -104.5791907890332, -19.639123523379936, -35.89765726957719, -140.66467862128616, 110.98568853395277, -10.257235045167114, -60.55369223057247, -139.71291822026308, -38.67415729069133, -109.0261782625628, -106.8904654673552, -40.24366971870419, -30.479686633976648, -79.00927671020233, 68.51569435586875, -33.10076957735038, -81.56343910049885, -142.00449014921148, -128.4338312428352, 231.65852818897505, -90.26741256358697, -16.034141672097345, -12.607029866923122, 240.67927034331404, 120.21448426332987, 185.51588278639952, 42.743589632867966], "policy_AGENT-2_reward": [-75.0161869921628, -27.05361065526048, 10.844705338069879, 118.32432776479256, -68.27574810160998, -27.804968032361174, -44.459034249963985, 191.74165648105705, -50.17600361981577, 86.60667330047775, -30.418573511060117, 19.522873750784, -32.76492982715668, 22.534987953926358, -164.44726036322567, 46.05895539741705, -30.753771816115954, 37.043199294650385, -101.62843020853354, 23.30179732631232, -35.60952705690619, 96.55581442616949, -95.65148813904378, -39.78503944716973, 20.1223392001422, -28.382629018911103, 31.289854922914188, -42.032543011157244, 17.217209974165147, -13.78401903955429, -199.8289146660976, -22.086743205143172, 24.708061525972518, -10.386063462648742, -58.544049108223376, 27.76632421919284, -41.19964439688669, 42.983291746921104, -42.485727136783865, 30.22047539301762, 1.1310447313271146, -10.898978638422365, 145.88532563398698, -109.34459636519031, 59.458746718821956, 176.69233799229977, -37.70295650424276, 2.178709885401304, -38.83394652359957, -26.727149151817798, 58.44050102341297, -324.25561388539785, 26.45331183107394, -79.34012665894238, 18.820224617523618, -346.58396031435666, 40.853291869948386, -94.9597814208434, 22.813534905086023, -56.52872458746135, 30.784855923683903, -203.6156018156991, 23.3152114855568, -188.96090235575747, -38.9290916100982, 35.760204406861696, -14.663111862072743, -73.87207271752582, -6.371268755049357, 28.267861702086083, -4.279437898137337, -22.70901559369167, 221.15802943721388, -46.19454654091339, -19.692941439100338, -36.02022359547532, 116.95223548080138, -97.98812677076492, -10.270445227038067, -103.63371926539436, 159.9986863617964, -38.66712496403905, 37.274473928958976, -367.8975185311837, 30.046967376064497, -30.547578123132382, 14.07714828958803, 24.779020853488433, 20.242551449198256, -81.47245163409995, 28.38876900332577, -364.96508879256834, 201.04342382201878, -92.18503603190216, -16.008935099104267, -12.643561270747512, -32.293012851207116, 160.39230770650886, -43.05629752044746, 21.410956493005962], "policy_AGENT-1_reward": [-71.67888031362861, -192.25139971648082, 20.533191399270937, -367.3510453051437, -27.438373092386712, -208.2510418957294, -62.70683685316865, 201.46627832327883, 148.1473922469605, -182.52256633559182, -40.10398746148623, -202.88693410513406, 197.79267079716087, -177.10185365070055, -118.27331103513501, -98.72538194141342, -87.74874629695383, -233.3532233499469, -106.66987694120141, -215.05710944928813, 46.70525640906056, 97.12399455684849, -95.22969373176721, -39.344955952717655, 20.716278956801705, -27.947111216717598, 162.67345476188785, -41.591598261292994, 36.87035344308801, -67.74276875919219, -210.78820201783108, -21.647992257410202, 25.227241944985025, -145.80844675705728, -58.01131929905185, 28.19853330608201, -40.76665375439494, 198.35396127753077, -41.987516142601876, 164.59539650459243, -272.4992343798531, -34.07096712904206, -153.1626105551346, -108.82520577302925, 81.72374546583737, -13.320862013122726, -60.78335551164069, -399.0201232759979, -54.870416757237834, -462.27265626446336, 83.46456101568756, -132.3556656773947, -146.4270275368188, 73.78312559088903, -73.40060931127447, -145.0779232218909, -23.7485553734658, 136.23622599666572, -64.60195914291258, -53.03642039724527, -40.185754969439685, -84.76368124780797, -56.280737866603566, -317.6916866201973, -38.48279994774479, 36.216053076298095, -189.1064664730428, -177.87085628216082, -5.8059171319208716, 73.5347440084499, -166.07710528423547, -22.263302164133922, 55.95827865968439, -101.35592381103947, -363.7882297470455, 162.5054107247667, -126.16415371979578, -97.4494208281661, -378.181723990042, -103.13567778937346, -124.68500623162245, 148.15663634515218, -97.56563136656615, -106.32511019691668, -32.86118794515792, 169.4155729396797, -53.83119548056356, -103.48341817511198, -32.081125137086225, 129.1924744328284, -128.57295068704917, -127.86874762466275, 255.90273332830245, -91.75494540198359, -161.9088016459759, -69.89532380849394, -31.85820978240191, 30.93908992017315, -42.42989143937373, 22.03712060547526]}, "sampler_perf": {"mean_env_wait_ms": 51.92562571475364, "mean_raw_obs_processing_ms": 2.3312499353928406, "mean_inference_ms": 2.3381086400497533, "mean_action_processing_ms": 0.14242518616744643}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 121800, "timers": {"sample_time_ms": 84325.453, "sample_throughput": 49.807, "load_time_ms": 14.248, "load_throughput": 294773.989, "learn_time_ms": 7788.313, "learn_throughput": 539.27, "update_time_ms": 8.342}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 18.60761260986328, "policy_loss": -0.045985642820596695, "vf_loss": 18.646915435791016, "vf_explained_var": 0.9825369715690613, "kl": 0.014852735213935375, "entropy": 1.0927425622940063, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 30.74654197692871, "policy_loss": -0.038001760840415955, "vf_loss": 30.779727935791016, "vf_explained_var": 0.971563994884491, "kl": 0.016059836372733116, "entropy": 1.0319476127624512, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 36.98531723022461, "policy_loss": -0.0337085947394371, "vf_loss": 37.01183319091797, "vf_explained_var": 0.9603751301765442, "kl": 0.015981610864400864, "entropy": 1.0286451578140259, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 41.91886520385742, "policy_loss": -0.03961829096078873, "vf_loss": 41.95295715332031, "vf_explained_var": 0.973732054233551, "kl": 0.018427342176437378, "entropy": 1.0080456733703613, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 121800, "num_steps_trained": 121800}, "done": false, "episodes_total": 963, "training_iteration": 29, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-00-54", "timestamp": 1624219254, "time_this_iter_s": 83.6285765171051, "time_total_s": 2791.6305317878723, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c833ec20>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c833e8c0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3d40>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84abcb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85543b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554f80>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3d40>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84abcb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85543b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554f80>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3d40>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84abcb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85543b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554f80>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3d40>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84abcb0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c85543b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554f80>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c83cbdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2791.6305317878723, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 55.445, "ram_util_percent": 95.29499999999999}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1481.8276954408043, "episode_reward_min": -1017.3994494542346, "episode_reward_mean": -31.220391008353367, "episode_len_mean": 136.54, "episodes_this_iter": 30, "policy_reward_min": {"AGENT-2": -367.8975185311837, "AGENT-1": -378.181723990042, "AGENT-0": -401.72154868765443, "AGENT-3": -307.8629809475186}, "policy_reward_max": {"AGENT-2": 382.3544009587423, "AGENT-1": 401.154195176617, "AGENT-0": 446.5503537478472, "AGENT-3": 406.3640257395491}, "policy_reward_mean": {"AGENT-2": 0.5971772080952144, "AGENT-1": -46.939678350614834, "AGENT-0": 16.0522681615722, "AGENT-3": -0.9301580274059138}, "custom_metrics": {"mean_ego_speed_mean": 41.34824750000001, "mean_ego_speed_min": 27.989, "mean_ego_speed_max": 48.67450000000001, "distance_travelled_mean": 82.75352500000001, "distance_travelled_min": 26.241, "distance_travelled_max": 124.23100000000001}, "hist_stats": {"episode_reward": [1481.8276954408043, -43.83558360683905, 840.9816895245523, -326.94933889880684, 383.42706058408345, -97.58310471682796, 1285.845857582189, -603.3830131295192, 150.02166824716227, 172.1116743164583, 549.3330296708863, -199.3073603835902, 45.917719581355065, 294.8443568708309, -85.59596854138185, 175.28394884731887, -150.59012670537203, 145.91214450232584, -33.187484726314764, -843.1901631817669, 742.9429575528136, -502.5815502259616, -214.9194957438585, -345.1690967995832, -481.323848597354, -800.5669030267435, 515.3059154322315, 182.13299966118592, -565.0634110851527, -87.52388392071131, 454.20757669169416, 575.8062989515395, -450.90176735448085, -545.7564945689251, 154.11208125992096, 168.36888847994857, -361.3955804014528, -171.82027550708057, 543.6474663255144, -297.77306154966124, -729.0212885412686, 282.1459757879034, -32.353193146895485, -11.6441669092115, -791.1471767690551, -292.8531909227914, 56.16388083257155, 180.9077815682128, -131.59096675039763, -982.8346428831105, -12.572007063226629, 237.29258696649887, -104.12289718604524, -113.80539134418417, -24.14699955539126, 127.38130959167059, -213.35186612634809, -1017.3994494542346, 890.208503757213, -399.596438673607, -363.2759250563643, -140.55009736284504, 444.28140296579426, 342.41564259315965, 247.91755115035687, 99.44892606111995, -326.96267017186165, -438.21577885383886, 37.07500687578977, -437.9745373328184, -191.4398023585851, -471.7578689306166, -236.92676741134818, 924.9926399244257, 223.91017320880005, -202.49136756603136, -165.7328971399367, -379.87703870926873, 360.82926260550704, -319.3253824643374, -565.2898070380046, -119.3233227873549, -236.92666549638034, -406.6121902960825, -464.5625885644392, -347.7350538440613, 1.1425956280611596, 765.1832062575668, -24.091271594932838, 231.3126237314631, 434.2712780585583, -68.96474636378667, 363.440134089186, 246.59892288923058, 71.2733999921607, -205.92181394034955, -826.276511237668, 330.87428644177646, 472.3962196435686, -350.4421484606841], "episode_lengths": [189, 105, 178, 110, 189, 101, 182, 119, 118, 132, 116, 125, 119, 449, 114, 131, 118, 124, 106, 167, 113, 121, 122, 121, 131, 136, 190, 89, 138, 105, 229, 118, 131, 134, 136, 108, 171, 117, 192, 115, 157, 131, 178, 125, 174, 122, 187, 134, 118, 152, 114, 128, 104, 125, 109, 147, 122, 153, 105, 132, 118, 114, 161, 526, 140, 131, 126, 89, 106, 124, 113, 91, 105, 181, 133, 189, 103, 128, 136, 127, 56, 125, 27, 137, 125, 126, 114, 124, 114, 140, 111, 135, 103, 123, 104, 121, 117, 141, 110, 134], "policy_AGENT-2_reward": [382.3544009587423, -7.84903516765143, 298.15865087000725, -45.734581873164714, 192.44000414281822, -18.475539303438445, 326.17526029297466, -224.23813368561963, 158.39234985598554, -38.661658212429614, 27.441526483961407, -120.50683721897511, 58.18492631435927, 247.08118063784408, 21.3255839392531, -88.05632767321993, 28.521555976874744, -36.88330738870317, 19.313320239014107, -207.73339761738575, 173.67307258994705, -65.9429207677334, -16.48590909978353, -20.3911102368088, -15.781577459129917, -151.47728612710526, -29.680244944673365, 35.645896966004116, -4.988736669973115, 32.93759253735462, -38.9290916100982, 35.760204406861696, -14.663111862072743, -73.87207271752582, -6.371268755049357, 28.267861702086083, -4.279437898137337, -22.70901559369167, 221.15802943721388, -46.19454654091339, -19.692941439100338, -36.02022359547532, 116.95223548080138, -97.98812677076492, -10.270445227038067, -103.63371926539436, 159.9986863617964, -38.66712496403905, 37.274473928958976, -367.8975185311837, 30.046967376064497, -30.547578123132382, 14.07714828958803, 24.779020853488433, 20.242551449198256, -81.47245163409995, 28.38876900332577, -364.96508879256834, 201.04342382201878, -92.18503603190216, -16.008935099104267, -12.643561270747512, -32.293012851207116, 160.39230770650886, -43.05629752044746, 21.410956493005962, -75.0161869921628, -27.05361065526048, 10.844705338069879, 118.32432776479256, -68.27574810160998, -27.804968032361174, -44.459034249963985, 191.74165648105705, -50.17600361981577, 86.60667330047775, -30.418573511060117, 19.522873750784, -32.76492982715668, 22.534987953926358, -164.44726036322567, 46.05895539741705, -30.753771816115954, 37.043199294650385, -101.62843020853354, 23.30179732631232, -35.60952705690619, 96.55581442616949, -95.65148813904378, -39.78503944716973, 20.1223392001422, -28.382629018911103, 31.289854922914188, -42.032543011157244, 17.217209974165147, -13.78401903955429, -199.8289146660976, -22.086743205143172, 24.708061525972518, -10.386063462648742], "policy_AGENT-1_reward": [401.154195176617, -2.0074516448490627, 127.33845199427363, -139.60790305863958, 4.301333030053771, -18.286685463939673, 345.29033225442225, -101.45146866688236, -114.16430248971898, 144.95605606911906, 27.917735434718754, -119.9353266009665, -29.142091447031245, -101.6062139533648, -60.17294766260331, -87.3736376901735, -98.40533182068387, 130.41063392448774, -24.383346907897153, -219.09349615563013, 227.30670912265742, -179.27537588967164, -105.09054421474534, -19.846020578873024, -240.33582056162268, -151.04699820562658, -29.24047145762261, 36.077375338519815, -258.0252582459303, -64.31973278099049, -38.48279994774479, 36.216053076298095, -189.1064664730428, -177.87085628216082, -5.8059171319208716, 73.5347440084499, -166.07710528423547, -22.263302164133922, 55.95827865968439, -101.35592381103947, -363.7882297470455, 162.5054107247667, -126.16415371979578, -97.4494208281661, -378.181723990042, -103.13567778937346, -124.68500623162245, 148.15663634515218, -97.56563136656615, -106.32511019691668, -32.86118794515792, 169.4155729396797, -53.83119548056356, -103.48341817511198, -32.081125137086225, 129.1924744328284, -128.57295068704917, -127.86874762466275, 255.90273332830245, -91.75494540198359, -161.9088016459759, -69.89532380849394, -31.85820978240191, 30.93908992017315, -42.42989143937373, 22.03712060547526, -71.67888031362861, -192.25139971648082, 20.533191399270937, -367.3510453051437, -27.438373092386712, -208.2510418957294, -62.70683685316865, 201.46627832327883, 148.1473922469605, -182.52256633559182, -40.10398746148623, -202.88693410513406, 197.79267079716087, -177.10185365070055, -118.27331103513501, -98.72538194141342, -87.74874629695383, -233.3532233499469, -106.66987694120141, -215.05710944928813, 46.70525640906056, 97.12399455684849, -95.22969373176721, -39.344955952717655, 20.716278956801705, -27.947111216717598, 162.67345476188785, -41.591598261292994, 36.87035344308801, -67.74276875919219, -210.78820201783108, -21.647992257410202, 25.227241944985025, -145.80844675705728], "policy_AGENT-0_reward": [446.5503537478472, -7.305244489943283, 159.88874035241318, -45.31398647203804, 193.00874004195273, -17.874750269810495, 378.4711565475884, -101.38227040639279, 158.96387914726267, 104.51357101819258, 260.06321825222835, -0.8945684172073314, 58.747046972003865, -101.69027583678135, 21.888492115326635, 188.6966129243749, 29.079198839784258, 89.25936542111646, 19.880455747602923, -247.7008122404723, 174.35520233211997, -65.37169662725381, -76.85446982723772, -136.05690511301248, -209.3924848980431, -266.85765270409007, 295.45395360658705, 35.985916886227834, -296.98900894079793, -64.44731931366894, 238.84747303084913, 266.06266208448363, -232.4988509927975, -220.15026300829638, 99.33626521180092, 28.691370095269846, -186.59552791132228, -86.81942882615881, 221.71444312295614, -45.643400408675, -325.90099383174237, 191.5584459281891, 117.52340371338477, 72.80769215576683, -392.4377725068089, -25.530101637450947, 160.5631189226614, 110.09242747779089, 37.72636894977235, -401.72154868765443, 30.485883224570948, 128.90427878392853, 14.640426715132586, -103.61668837842902, 20.792343709847074, 161.2247258934412, 28.836805706586837, -396.1317817941682, 201.6038184179166, -125.38904467613418, -169.32404663918663, -45.40418241668036, 267.753355256089, 30.869760703147968, 147.88785732377846, 13.25725932977079, -105.22334381219886, -191.9176018529728, 11.377815282527198, 118.9151611550512, -67.70352921530517, -207.93007298582444, -44.03488183880506, 125.42067938054124, 176.09350460510234, 87.1765429396657, -29.84039622793836, 20.083708934419263, 228.44667903572406, 23.123290354463535, -118.16862417627698, 46.61470371696468, -87.71219004400268, 37.47359795701267, -154.577232465355, 23.839892827267338, 25.65079481302424, 300.31432144992294, 95.99447689914508, 133.68194074231687, 208.55945651353068, -22.284895989976814, 31.85192399811236, 176.86275870370926, 17.79201080054145, -110.393909437796, -199.25543594592065, 204.29470447391128, 223.84837568667228, -183.83842255754166], "policy_AGENT-3_reward": [251.76874555759846, -26.67385230439523, 255.5958463078583, -96.29286749496471, -6.32301663074035, -42.9461296796393, 235.90910848720353, -176.3111403706243, -53.170258266366986, -38.696294558423624, 233.91054949997783, 42.02937185355883, -41.87216225797685, 251.05966602313367, -68.63709693335825, 162.01730128633767, -109.78554970134708, -36.874547454575136, -47.997913805034685, -168.66245716827834, 167.60797350808892, -191.99155694130272, -16.488572602091928, -168.87506087088894, -15.813965678558535, -231.18496598992218, 278.77267822794033, 74.42381047043419, -5.060407228451496, 8.305575636593465, 292.77199521868795, 237.76737938389607, -14.633338026568033, -73.8633025609417, 66.95300193509033, 37.87491267414263, -4.44350930775772, -40.02852892309625, 44.81671510566057, -104.5791907890332, -19.639123523379936, -35.89765726957719, -140.66467862128616, 110.98568853395277, -10.257235045167114, -60.55369223057247, -139.71291822026308, -38.67415729069133, -109.0261782625628, -106.8904654673552, -40.24366971870419, -30.479686633976648, -79.00927671020233, 68.51569435586875, -33.10076957735038, -81.56343910049885, -142.00449014921148, -128.4338312428352, 231.65852818897505, -90.26741256358697, -16.034141672097345, -12.607029866923122, 240.67927034331404, 120.21448426332987, 185.51588278639952, 42.743589632867966, -75.04425905387113, -26.993166629124964, -5.680705144078162, -307.8629809475186, -28.022151949283245, -27.77178601670175, -85.72601446941056, 406.3640257395491, -50.154720023446906, -193.75201747058284, -65.36993993945204, -216.59668728933815, -32.645157400221315, -187.88180712202674, -164.40061146336706, -113.2715999603232, -30.711957339307823, -247.77576419779865, -101.68704894934895, -179.81963454835287, -35.60392853711748, 271.1890758246264, 70.7954333767332, 176.76067838903376, 184.87320338808385, 9.649889861818792, 137.62490040627168, 153.36030545797146, -0.6061742256339144, -14.001116703806918, -216.40395860781888, 170.31431743041824, 198.6125404859393, -10.409215683436416]}, "sampler_perf": {"mean_env_wait_ms": 51.66795812801645, "mean_raw_obs_processing_ms": 2.3237421017404665, "mean_inference_ms": 2.3299139827424686, "mean_action_processing_ms": 0.1419903834471563}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 126000, "timers": {"sample_time_ms": 83094.811, "sample_throughput": 50.545, "load_time_ms": 13.99, "load_throughput": 300213.994, "learn_time_ms": 7605.026, "learn_throughput": 552.266, "update_time_ms": 8.443}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 26.736263275146484, "policy_loss": -0.03887266665697098, "vf_loss": 26.768878936767578, "vf_explained_var": 0.9791058897972107, "kl": 0.013899149373173714, "entropy": 1.0946085453033447, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 38.859352111816406, "policy_loss": -0.0351576954126358, "vf_loss": 38.89029312133789, "vf_explained_var": 0.9682998061180115, "kl": 0.014055144041776657, "entropy": 1.0168360471725464, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 33.052452087402344, "policy_loss": -0.03383074328303337, "vf_loss": 33.079917907714844, "vf_explained_var": 0.9685378074645996, "kl": 0.014134932309389114, "entropy": 0.9449957609176636, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 36.99003601074219, "policy_loss": -0.031095728278160095, "vf_loss": 37.01627731323242, "vf_explained_var": 0.9781468510627747, "kl": 0.01619856245815754, "entropy": 1.018865704536438, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 126000, "num_steps_trained": 126000}, "done": false, "episodes_total": 993, "training_iteration": 30, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-02-14", "timestamp": 1624219334, "time_this_iter_s": 79.75437521934509, "time_total_s": 2871.3849070072174, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c824a4d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c824a3b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c824a170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c824a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c824aa70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c824ab90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c824a170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c824a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c824aa70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c824ab90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c824a170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c824a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c824aa70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c824ab90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c824a170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c824a050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c824aa70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c824ab90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c824a830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2871.3849070072174, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 54.81504424778761, "ram_util_percent": 95.32477876106194}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 2005.3303985008338, "episode_reward_min": -843.1901631817669, "episode_reward_mean": 35.093879253207525, "episode_len_mean": 133.55, "episodes_this_iter": 32, "policy_reward_min": {"AGENT-2": -297.7712873258563, "AGENT-1": -367.3510453051437, "AGENT-0": -296.98900894079793, "AGENT-3": -307.8629809475186}, "policy_reward_max": {"AGENT-2": 554.9182040781637, "AGENT-1": 516.7705219114175, "AGENT-0": 625.2630144593237, "AGENT-3": 406.3640257395491}, "policy_reward_mean": {"AGENT-2": 10.027334332647316, "AGENT-1": -27.421288328836212, "AGENT-0": 43.24240305528332, "AGENT-3": 9.24543019411315}, "custom_metrics": {"mean_ego_speed_mean": 41.47978, "mean_ego_speed_min": 27.989, "mean_ego_speed_max": 47.8695, "distance_travelled_mean": 82.4046875, "distance_travelled_min": 26.241, "distance_travelled_max": 124.418}, "hist_stats": {"episode_reward": [1478.7539848707415, -250.42259354599997, -183.90503962712108, -396.6596565200682, 220.75154749639617, -82.25000430754565, 2005.3303985008338, -316.03374662246887, 433.3104685766423, 461.3654403781104, -799.9970010087621, 80.0030324127869, 305.77664580889126, 60.89655337435511, -397.0548886103347, -85.17634932035439, -439.14065707435026, -19.752176488666006, -789.1719672401777, -238.97516833834408, 391.29723610824084, 302.3073589566702, 460.40836017761166, 337.2695176265685, 173.15772690592928, 544.1492487847282, 297.2096783678487, -373.1095330487921, -701.085101415676, 592.047067124778, 349.2368268800691, -306.7807099403411, 444.28140296579426, 342.41564259315965, 247.91755115035687, 99.44892606111995, -326.96267017186165, -438.21577885383886, 37.07500687578977, -437.9745373328184, -191.4398023585851, -471.7578689306166, -236.92676741134818, 924.9926399244257, 223.91017320880005, -202.49136756603136, -165.7328971399367, -379.87703870926873, 360.82926260550704, -319.3253824643374, -565.2898070380046, -119.3233227873549, -236.92666549638034, -406.6121902960825, -464.5625885644392, -347.7350538440613, 1.1425956280611596, 765.1832062575668, -24.091271594932838, 231.3126237314631, 434.2712780585583, -68.96474636378667, 363.440134089186, 246.59892288923058, 71.2733999921607, -205.92181394034955, -826.276511237668, 330.87428644177646, 472.3962196435686, -350.4421484606841, 1481.8276954408043, -43.83558360683905, 840.9816895245523, -326.94933889880684, 383.42706058408345, -97.58310471682796, 1285.845857582189, -603.3830131295192, 150.02166824716227, 172.1116743164583, 549.3330296708863, -199.3073603835902, 45.917719581355065, 294.8443568708309, -85.59596854138185, 175.28394884731887, -150.59012670537203, 145.91214450232584, -33.187484726314764, -843.1901631817669, 742.9429575528136, -502.5815502259616, -214.9194957438585, -345.1690967995832, -481.323848597354, -800.5669030267435, 515.3059154322315, 182.13299966118592, -565.0634110851527, -87.52388392071131], "episode_lengths": [181, 107, 127, 150, 192, 115, 187, 53, 176, 107, 150, 118, 162, 104, 114, 112, 129, 102, 129, 117, 137, 115, 113, 128, 105, 194, 104, 31, 134, 182, 101, 125, 161, 526, 140, 131, 126, 89, 106, 124, 113, 91, 105, 181, 133, 189, 103, 128, 136, 127, 56, 125, 27, 137, 125, 126, 114, 124, 114, 140, 111, 135, 103, 123, 104, 121, 117, 141, 110, 134, 189, 105, 178, 110, 189, 101, 182, 119, 118, 132, 116, 125, 119, 449, 114, 131, 118, 124, 106, 167, 113, 121, 122, 121, 131, 136, 190, 89, 138, 105], "policy_AGENT-2_reward": [423.94389268316553, -39.01226867204326, 119.16627360718337, -115.46924203167939, 169.36583157468678, -10.314858658437949, 554.9182040781637, -42.68465458335935, 179.86833743685395, 108.27640043498741, -258.6905008713743, 41.216852615645955, -33.294091053578335, 41.03083070057351, -88.59357072416711, 19.821138767150885, -78.68612681825523, 31.435293322199268, -297.7712873258563, 24.224211869618763, -27.909707220694465, -47.98426256593715, 18.138689936564912, -24.565506552618185, 22.77919417216896, -35.17782387179436, 14.683721436056025, -118.3548469119106, -168.9335106245681, -15.170574613317378, 28.422396404817967, -12.684647095672535, -32.293012851207116, 160.39230770650886, -43.05629752044746, 21.410956493005962, -75.0161869921628, -27.05361065526048, 10.844705338069879, 118.32432776479256, -68.27574810160998, -27.804968032361174, -44.459034249963985, 191.74165648105705, -50.17600361981577, 86.60667330047775, -30.418573511060117, 19.522873750784, -32.76492982715668, 22.534987953926358, -164.44726036322567, 46.05895539741705, -30.753771816115954, 37.043199294650385, -101.62843020853354, 23.30179732631232, -35.60952705690619, 96.55581442616949, -95.65148813904378, -39.78503944716973, 20.1223392001422, -28.382629018911103, 31.289854922914188, -42.032543011157244, 17.217209974165147, -13.78401903955429, -199.8289146660976, -22.086743205143172, 24.708061525972518, -10.386063462648742, 382.3544009587423, -7.84903516765143, 298.15865087000725, -45.734581873164714, 192.44000414281822, -18.475539303438445, 326.17526029297466, -224.23813368561963, 158.39234985598554, -38.661658212429614, 27.441526483961407, -120.50683721897511, 58.18492631435927, 247.08118063784408, 21.3255839392531, -88.05632767321993, 28.521555976874744, -36.88330738870317, 19.313320239014107, -207.73339761738575, 173.67307258994705, -65.9429207677334, -16.48590909978353, -20.3911102368088, -15.781577459129917, -151.47728612710526, -29.680244944673365, 35.645896966004116, -4.988736669973115, 32.93759253735462], "policy_AGENT-1_reward": [419.76827048180894, -72.89991718737777, -241.32279823567416, -115.03083266880525, -54.67160000287547, -26.106221514958136, 516.7705219114175, -115.27298396156242, 44.84958844366435, 138.35828175850773, -126.05976137228134, -15.605171599254817, 175.59780822316526, 1.9931121381977803, -105.99369328872349, -58.42499217241019, -103.6144350559769, -28.42151664470273, -112.42983776546782, -163.1785765146352, 208.41948996913337, -47.539043906112866, 18.670373879180296, -23.93555330987027, 79.22129139683577, -34.742230810552186, 146.32100409553698, -68.19335213391228, -177.07294388972326, -14.73152148803564, 158.06169800065416, -120.57857195205833, -31.85820978240191, 30.93908992017315, -42.42989143937373, 22.03712060547526, -71.67888031362861, -192.25139971648082, 20.533191399270937, -367.3510453051437, -27.438373092386712, -208.2510418957294, -62.70683685316865, 201.46627832327883, 148.1473922469605, -182.52256633559182, -40.10398746148623, -202.88693410513406, 197.79267079716087, -177.10185365070055, -118.27331103513501, -98.72538194141342, -87.74874629695383, -233.3532233499469, -106.66987694120141, -215.05710944928813, 46.70525640906056, 97.12399455684849, -95.22969373176721, -39.344955952717655, 20.716278956801705, -27.947111216717598, 162.67345476188785, -41.591598261292994, 36.87035344308801, -67.74276875919219, -210.78820201783108, -21.647992257410202, 25.227241944985025, -145.80844675705728, 401.154195176617, -2.0074516448490627, 127.33845199427363, -139.60790305863958, 4.301333030053771, -18.286685463939673, 345.29033225442225, -101.45146866688236, -114.16430248971898, 144.95605606911906, 27.917735434718754, -119.9353266009665, -29.142091447031245, -101.6062139533648, -60.17294766260331, -87.3736376901735, -98.40533182068387, 130.41063392448774, -24.383346907897153, -219.09349615563013, 227.30670912265742, -179.27537588967164, -105.09054421474534, -19.846020578873024, -240.33582056162268, -151.04699820562658, -29.24047145762261, 36.077375338519815, -258.0252582459303, -64.31973278099049], "policy_AGENT-0_reward": [401.8568275473353, -38.44039124060446, 119.75333586238348, -97.5395537064476, 170.04140587140557, -9.717572526377188, 625.2630144593237, -42.23626686738178, 180.44384604100003, 109.07374956739014, -288.62088402591553, 41.768373068691915, 196.68302520301964, 41.58345727175616, -88.03193683872038, 20.37735268728306, -145.50453449738927, 31.875022009165143, -265.9801848982604, 24.805241565518784, 238.67129811967052, 173.57960857398916, 224.88400039021036, 207.43979909198427, 23.21309311703749, 318.2604032622495, 15.245323371342938, -68.25446223327225, -218.40264103132012, 323.10402189561523, 28.879429199830064, -160.81138951055698, 267.753355256089, 30.869760703147968, 147.88785732377846, 13.25725932977079, -105.22334381219886, -191.9176018529728, 11.377815282527198, 118.9151611550512, -67.70352921530517, -207.93007298582444, -44.03488183880506, 125.42067938054124, 176.09350460510234, 87.1765429396657, -29.84039622793836, 20.083708934419263, 228.44667903572406, 23.123290354463535, -118.16862417627698, 46.61470371696468, -87.71219004400268, 37.47359795701267, -154.577232465355, 23.839892827267338, 25.65079481302424, 300.31432144992294, 95.99447689914508, 133.68194074231687, 208.55945651353068, -22.284895989976814, 31.85192399811236, 176.86275870370926, 17.79201080054145, -110.393909437796, -199.25543594592065, 204.29470447391128, 223.84837568667228, -183.83842255754166, 446.5503537478472, -7.305244489943283, 159.88874035241318, -45.31398647203804, 193.00874004195273, -17.874750269810495, 378.4711565475884, -101.38227040639279, 158.96387914726267, 104.51357101819258, 260.06321825222835, -0.8945684172073314, 58.747046972003865, -101.69027583678135, 21.888492115326635, 188.6966129243749, 29.079198839784258, 89.25936542111646, 19.880455747602923, -247.7008122404723, 174.35520233211997, -65.37169662725381, -76.85446982723772, -136.05690511301248, -209.3924848980431, -266.85765270409007, 295.45395360658705, 35.985916886227834, -296.98900894079793, -64.44731931366894], "policy_AGENT-3_reward": [233.1849941584323, -100.07001644597453, -181.5018508610135, -68.620028113136, -63.984089946821065, -36.11135160777244, 308.3786580519305, -115.83984121016515, 28.14869665512426, 105.65700861722512, -126.62585473919076, 12.62297832770396, -33.210096563715254, -23.710846736172456, -114.43568775872339, -66.94984860237825, -111.33556070272911, -54.64097517532773, -112.99065725059266, -124.8260452588464, -27.88384475986891, 224.25105685473108, 198.71529597165576, 178.33077839707266, 47.94414821988706, 295.8089002048257, 120.95962946491285, -118.3068717696969, -136.67600587006413, 298.84514133051573, 133.87330327476676, -12.706101382053168, 240.67927034331404, 120.21448426332987, 185.51588278639952, 42.743589632867966, -75.04425905387113, -26.993166629124964, -5.680705144078162, -307.8629809475186, -28.022151949283245, -27.77178601670175, -85.72601446941056, 406.3640257395491, -50.154720023446906, -193.75201747058284, -65.36993993945204, -216.59668728933815, -32.645157400221315, -187.88180712202674, -164.40061146336706, -113.2715999603232, -30.711957339307823, -247.77576419779865, -101.68704894934895, -179.81963454835287, -35.60392853711748, 271.1890758246264, 70.7954333767332, 176.76067838903376, 184.87320338808385, 9.649889861818792, 137.62490040627168, 153.36030545797146, -0.6061742256339144, -14.001116703806918, -216.40395860781888, 170.31431743041824, 198.6125404859393, -10.409215683436416, 251.76874555759846, -26.67385230439523, 255.5958463078583, -96.29286749496471, -6.32301663074035, -42.9461296796393, 235.90910848720353, -176.3111403706243, -53.170258266366986, -38.696294558423624, 233.91054949997783, 42.02937185355883, -41.87216225797685, 251.05966602313367, -68.63709693335825, 162.01730128633767, -109.78554970134708, -36.874547454575136, -47.997913805034685, -168.66245716827834, 167.60797350808892, -191.99155694130272, -16.488572602091928, -168.87506087088894, -15.813965678558535, -231.18496598992218, 278.77267822794033, 74.42381047043419, -5.060407228451496, 8.305575636593465]}, "sampler_perf": {"mean_env_wait_ms": 51.396001173942494, "mean_raw_obs_processing_ms": 2.31661448106663, "mean_inference_ms": 2.323689624206583, "mean_action_processing_ms": 0.14156500711273412}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 130200, "timers": {"sample_time_ms": 83254.828, "sample_throughput": 50.448, "load_time_ms": 14.263, "load_throughput": 294460.614, "learn_time_ms": 7708.298, "learn_throughput": 544.867, "update_time_ms": 8.551}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 21.82362174987793, "policy_loss": -0.04324588552117348, "vf_loss": 21.8608341217041, "vf_explained_var": 0.9835373163223267, "kl": 0.013404343277215958, "entropy": 1.0617337226867676, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 34.40561294555664, "policy_loss": -0.035538315773010254, "vf_loss": 34.43727111816406, "vf_explained_var": 0.9689679145812988, "kl": 0.012919801287353039, "entropy": 0.98404860496521, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 23.734310150146484, "policy_loss": -0.0439494363963604, "vf_loss": 23.772178649902344, "vf_explained_var": 0.9790259599685669, "kl": 0.013511277735233307, "entropy": 1.0100594758987427, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 48.09724426269531, "policy_loss": -0.0331428162753582, "vf_loss": 48.12574005126953, "vf_explained_var": 0.9720703959465027, "kl": 0.015503013506531715, "entropy": 0.9917742609977722, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 130200, "num_steps_trained": 130200}, "done": false, "episodes_total": 1025, "training_iteration": 31, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-03-45", "timestamp": 1624219425, "time_this_iter_s": 90.32676649093628, "time_total_s": 2961.7116734981537, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c8397a70>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c8397e60>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c833ef80>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cbd40>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c833ef80>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cbd40>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c833ef80>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cbd40>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c833ef80>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8554d40>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb3b0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cbd40>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c824add0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 2961.7116734981537, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 55.72769230769231, "ram_util_percent": 95.38230769230768}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 2005.3303985008338, "episode_reward_min": -1250.527816648757, "episode_reward_mean": 94.43698389851224, "episode_len_mean": 135.53, "episodes_this_iter": 31, "policy_reward_min": {"AGENT-2": -297.7712873258563, "AGENT-1": -594.4466793890631, "AGENT-0": -611.6289215310821, "AGENT-3": -246.6559065643985}, "policy_reward_max": {"AGENT-2": 554.9182040781637, "AGENT-1": 516.7705219114175, "AGENT-0": 625.2630144593237, "AGENT-3": 308.3786580519305}, "policy_reward_mean": {"AGENT-2": 19.709936521707082, "AGENT-1": -9.95669685496555, "AGENT-0": 59.739557828299866, "AGENT-3": 24.944186403470884}, "custom_metrics": {"mean_ego_speed_mean": 42.1043375, "mean_ego_speed_min": 27.989, "mean_ego_speed_max": 49.925, "distance_travelled_mean": 85.08216499999999, "distance_travelled_min": 35.62875, "distance_travelled_max": 124.418}, "hist_stats": {"episode_reward": [-319.025674317401, -50.79636115309091, -217.9099016519311, 107.34264519875654, 1621.4263333619842, 329.9668753518438, 840.7656495649857, 43.261237415665036, -1250.527816648757, -77.88289519397226, -185.10378371763554, 140.20064105265385, 556.7215924291053, -358.1428610505838, -76.4149739482945, 198.45998747956, -149.23892271393032, -106.23742816642515, 7.904680377141908, -237.7450821271536, 435.91803045910154, 611.3930336066583, 530.0640589889081, 121.05520676228222, 349.65210097184354, 214.76977182227532, 441.05428446362407, 204.38910741626398, 440.44483541148264, 497.8934850163617, 342.6632942952537, 246.59892288923058, 71.2733999921607, -205.92181394034955, -826.276511237668, 330.87428644177646, 472.3962196435686, -350.4421484606841, 1481.8276954408043, -43.83558360683905, 840.9816895245523, -326.94933889880684, 383.42706058408345, -97.58310471682796, 1285.845857582189, -603.3830131295192, 150.02166824716227, 172.1116743164583, 549.3330296708863, -199.3073603835902, 45.917719581355065, 294.8443568708309, -85.59596854138185, 175.28394884731887, -150.59012670537203, 145.91214450232584, -33.187484726314764, -843.1901631817669, 742.9429575528136, -502.5815502259616, -214.9194957438585, -345.1690967995832, -481.323848597354, -800.5669030267435, 515.3059154322315, 182.13299966118592, -565.0634110851527, -87.52388392071131, 1478.7539848707415, -250.42259354599997, -183.90503962712108, -396.6596565200682, 220.75154749639617, -82.25000430754565, 2005.3303985008338, -316.03374662246887, 433.3104685766423, 461.3654403781104, -799.9970010087621, 80.0030324127869, 305.77664580889126, 60.89655337435511, -397.0548886103347, -85.17634932035439, -439.14065707435026, -19.752176488666006, -789.1719672401777, -238.97516833834408, 391.29723610824084, 302.3073589566702, 460.40836017761166, 337.2695176265685, 173.15772690592928, 544.1492487847282, 297.2096783678487, -373.1095330487921, -701.085101415676, 592.047067124778, 349.2368268800691, -306.7807099403411], "episode_lengths": [180, 102, 164, 103, 151, 137, 194, 106, 200, 102, 122, 125, 448, 124, 114, 126, 110, 132, 120, 138, 106, 193, 115, 95, 102, 121, 109, 119, 114, 170, 102, 123, 104, 121, 117, 141, 110, 134, 189, 105, 178, 110, 189, 101, 182, 119, 118, 132, 116, 125, 119, 449, 114, 131, 118, 124, 106, 167, 113, 121, 122, 121, 131, 136, 190, 89, 138, 105, 181, 107, 127, 150, 192, 115, 187, 53, 176, 107, 150, 118, 162, 104, 114, 112, 129, 102, 129, 117, 137, 115, 113, 128, 105, 194, 104, 31, 134, 182, 101, 125], "policy_AGENT-2_reward": [79.64725731781856, -7.45479209531729, 82.16124186565114, 28.25831617916725, 407.64975823539294, -40.71943060677374, 246.4016297362415, 8.223717338092236, -22.228716319113417, -71.64129447166052, 32.554537605153065, -56.233672659826524, 275.731972237051, -118.33197247573656, 24.320479579045358, -30.766530355992344, 28.056619878366128, -92.51715794232167, 53.878192682239614, -25.739517704228707, 115.91811028484564, -1.8178255872737665, 17.668421015768242, -37.403589708800645, 26.167878338038296, -40.621450660632014, 27.099706444728472, -42.10303896884673, 13.190224985090643, 26.344952350970914, 20.74013033411606, -42.032543011157244, 17.217209974165147, -13.78401903955429, -199.8289146660976, -22.086743205143172, 24.708061525972518, -10.386063462648742, 382.3544009587423, -7.84903516765143, 298.15865087000725, -45.734581873164714, 192.44000414281822, -18.475539303438445, 326.17526029297466, -224.23813368561963, 158.39234985598554, -38.661658212429614, 27.441526483961407, -120.50683721897511, 58.18492631435927, 247.08118063784408, 21.3255839392531, -88.05632767321993, 28.521555976874744, -36.88330738870317, 19.313320239014107, -207.73339761738575, 173.67307258994705, -65.9429207677334, -16.48590909978353, -20.3911102368088, -15.781577459129917, -151.47728612710526, -29.680244944673365, 35.645896966004116, -4.988736669973115, 32.93759253735462, 423.94389268316553, -39.01226867204326, 119.16627360718337, -115.46924203167939, 169.36583157468678, -10.314858658437949, 554.9182040781637, -42.68465458335935, 179.86833743685395, 108.27640043498741, -258.6905008713743, 41.216852615645955, -33.294091053578335, 41.03083070057351, -88.59357072416711, 19.821138767150885, -78.68612681825523, 31.435293322199268, -297.7712873258563, 24.224211869618763, -27.909707220694465, -47.98426256593715, 18.138689936564912, -24.565506552618185, 22.77919417216896, -35.17782387179436, 14.683721436056025, -118.3548469119106, -168.9335106245681, -15.170574613317378, 28.422396404817967, -12.684647095672535], "policy_AGENT-1_reward": [-232.23435959430606, -5.358555134772253, -182.3473009621666, 38.0032940776688, 408.07980454455793, 189.79169185591837, 177.6180490581093, 48.23217666469378, -594.4466793890631, 49.13793622519265, -119.01899520945057, 111.88236325515695, 28.68073306808605, -117.76889231572278, -58.04553649457439, 114.70929496005988, -90.9197677377464, 24.02127614824543, -69.06688125139345, -97.8748274258651, 151.82370415413928, -1.3829993399235434, 18.21347958057097, -36.74454977645315, 160.93458695580696, -39.97165074280224, 27.709735062966857, -41.41443764898381, 13.704018889193408, 26.826815421147685, 162.8899185993264, -41.591598261292994, 36.87035344308801, -67.74276875919219, -210.78820201783108, -21.647992257410202, 25.227241944985025, -145.80844675705728, 401.154195176617, -2.0074516448490627, 127.33845199427363, -139.60790305863958, 4.301333030053771, -18.286685463939673, 345.29033225442225, -101.45146866688236, -114.16430248971898, 144.95605606911906, 27.917735434718754, -119.9353266009665, -29.142091447031245, -101.6062139533648, -60.17294766260331, -87.3736376901735, -98.40533182068387, 130.41063392448774, -24.383346907897153, -219.09349615563013, 227.30670912265742, -179.27537588967164, -105.09054421474534, -19.846020578873024, -240.33582056162268, -151.04699820562658, -29.24047145762261, 36.077375338519815, -258.0252582459303, -64.31973278099049, 419.76827048180894, -72.89991718737777, -241.32279823567416, -115.03083266880525, -54.67160000287547, -26.106221514958136, 516.7705219114175, -115.27298396156242, 44.84958844366435, 138.35828175850773, -126.05976137228134, -15.605171599254817, 175.59780822316526, 1.9931121381977803, -105.99369328872349, -58.42499217241019, -103.6144350559769, -28.42151664470273, -112.42983776546782, -163.1785765146352, 208.41948996913337, -47.539043906112866, 18.670373879180296, -23.93555330987027, 79.22129139683577, -34.742230810552186, 146.32100409553698, -68.19335213391228, -177.07294388972326, -14.73152148803564, 158.06169800065416, -120.57857195205833], "policy_AGENT-0_reward": [80.21733452348455, -6.875367026908218, 82.72194330417828, 28.829414089783022, 521.8709790548235, 221.59216730628438, 246.96740963362646, 8.795990521763649, -611.6289215310821, 16.376689313919485, 32.99295305770097, 140.7732052768205, 28.722079687709613, -44.77997822703128, 24.746499834450383, 145.17829684069886, 28.620456341494194, 54.723861863598714, 54.44281377895889, -88.09460729685136, 116.4854201326079, 318.65111902505305, 260.1525022455505, 80.25088784826407, 26.601600795615894, 161.6868943546176, 206.0127834823879, 157.88492101121648, 219.56864127711836, 240.05318199030697, 21.168259400413035, 176.86275870370926, 17.79201080054145, -110.393909437796, -199.25543594592065, 204.29470447391128, 223.84837568667228, -183.83842255754166, 446.5503537478472, -7.305244489943283, 159.88874035241318, -45.31398647203804, 193.00874004195273, -17.874750269810495, 378.4711565475884, -101.38227040639279, 158.96387914726267, 104.51357101819258, 260.06321825222835, -0.8945684172073314, 58.747046972003865, -101.69027583678135, 21.888492115326635, 188.6966129243749, 29.079198839784258, 89.25936542111646, 19.880455747602923, -247.7008122404723, 174.35520233211997, -65.37169662725381, -76.85446982723772, -136.05690511301248, -209.3924848980431, -266.85765270409007, 295.45395360658705, 35.985916886227834, -296.98900894079793, -64.44731931366894, 401.8568275473353, -38.44039124060446, 119.75333586238348, -97.5395537064476, 170.04140587140557, -9.717572526377188, 625.2630144593237, -42.23626686738178, 180.44384604100003, 109.07374956739014, -288.62088402591553, 41.768373068691915, 196.68302520301964, 41.58345727175616, -88.03193683872038, 20.37735268728306, -145.50453449738927, 31.875022009165143, -265.9801848982604, 24.805241565518784, 238.67129811967052, 173.57960857398916, 224.88400039021036, 207.43979909198427, 23.21309311703749, 318.2604032622495, 15.245323371342938, -68.25446223327225, -218.40264103132012, 323.10402189561523, 28.879429199830064, -160.81138951055698], "policy_AGENT-3_reward": [-246.6559065643985, -31.107646896093005, -200.44578585959394, 12.251620852137464, 283.82579152721064, -40.69755320358529, 169.7785611370084, -21.99064710888461, -22.223499409499325, -71.75622626142396, -131.6322791710389, -56.221254819497204, 223.58680743625806, -77.26201803209271, -67.43641686721585, -30.661073965206302, -114.99623119604429, -92.46540823594752, -31.349444832663085, -26.036129700208622, 51.69079588750828, 295.94273950880176, 234.02965614701827, 114.95245839927195, 135.94803488238222, 133.675978871092, 180.2320594735408, 130.02166302287802, 193.98195026008017, 204.66853525393591, 137.86498596139816, 153.36030545797146, -0.6061742256339144, -14.001116703806918, -216.40395860781888, 170.31431743041824, 198.6125404859393, -10.409215683436416, 251.76874555759846, -26.67385230439523, 255.5958463078583, -96.29286749496471, -6.32301663074035, -42.9461296796393, 235.90910848720353, -176.3111403706243, -53.170258266366986, -38.696294558423624, 233.91054949997783, 42.02937185355883, -41.87216225797685, 251.05966602313367, -68.63709693335825, 162.01730128633767, -109.78554970134708, -36.874547454575136, -47.997913805034685, -168.66245716827834, 167.60797350808892, -191.99155694130272, -16.488572602091928, -168.87506087088894, -15.813965678558535, -231.18496598992218, 278.77267822794033, 74.42381047043419, -5.060407228451496, 8.305575636593465, 233.1849941584323, -100.07001644597453, -181.5018508610135, -68.620028113136, -63.984089946821065, -36.11135160777244, 308.3786580519305, -115.83984121016515, 28.14869665512426, 105.65700861722512, -126.62585473919076, 12.62297832770396, -33.210096563715254, -23.710846736172456, -114.43568775872339, -66.94984860237825, -111.33556070272911, -54.64097517532773, -112.99065725059266, -124.8260452588464, -27.88384475986891, 224.25105685473108, 198.71529597165576, 178.33077839707266, 47.94414821988706, 295.8089002048257, 120.95962946491285, -118.3068717696969, -136.67600587006413, 298.84514133051573, 133.87330327476676, -12.706101382053168]}, "sampler_perf": {"mean_env_wait_ms": 51.18742586139186, "mean_raw_obs_processing_ms": 2.30876702479258, "mean_inference_ms": 2.313639870860776, "mean_action_processing_ms": 0.1412294002823863}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 134400, "timers": {"sample_time_ms": 81539.494, "sample_throughput": 51.509, "load_time_ms": 13.555, "load_throughput": 309853.619, "learn_time_ms": 7419.236, "learn_throughput": 566.096, "update_time_ms": 8.369}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 28.696123123168945, "policy_loss": -0.04208068922162056, "vf_loss": 28.731840133666992, "vf_explained_var": 0.9750087261199951, "kl": 0.014138789847493172, "entropy": 1.022540807723999, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 39.477840423583984, "policy_loss": -0.04144210368394852, "vf_loss": 39.51490783691406, "vf_explained_var": 0.9694233536720276, "kl": 0.014577454887330532, "entropy": 0.9291790723800659, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 24.839784622192383, "policy_loss": -0.043534837663173676, "vf_loss": 24.878297805786133, "vf_explained_var": 0.9702318906784058, "kl": 0.01116124913096428, "entropy": 0.945141613483429, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 55.93877029418945, "policy_loss": -0.03096865676343441, "vf_loss": 55.96535873413086, "vf_explained_var": 0.9660898447036743, "kl": 0.014625263400375843, "entropy": 0.9102595448493958, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 134400, "num_steps_trained": 134400}, "done": false, "episodes_total": 1056, "training_iteration": 32, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-05-06", "timestamp": 1624219506, "time_this_iter_s": 81.84473848342896, "time_total_s": 3043.5564119815826, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c820e4d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c820e3b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c820e170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c820e050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c820ea70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c820eb90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c820e170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c820e050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c820ea70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c820eb90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c820e170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c820e050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c820ea70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c820eb90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c820e170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c820e050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c820ea70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c820eb90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c820e830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3043.5564119815826, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 54.30598290598291, "ram_util_percent": 95.40769230769232}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 2005.3303985008338, "episode_reward_min": -1250.527816648757, "episode_reward_mean": 142.70259957378576, "episode_len_mean": 136.26, "episodes_this_iter": 29, "policy_reward_min": {"AGENT-2": -297.7712873258563, "AGENT-1": -594.4466793890631, "AGENT-0": -611.6289215310821, "AGENT-3": -246.6559065643985}, "policy_reward_max": {"AGENT-2": 554.9182040781637, "AGENT-1": 516.7705219114175, "AGENT-0": 625.2630144593237, "AGENT-3": 452.8190940329631}, "policy_reward_mean": {"AGENT-2": 22.143890343598233, "AGENT-1": 6.079652857928466, "AGENT-0": 73.88182097311051, "AGENT-3": 40.59723539914855}, "custom_metrics": {"mean_ego_speed_mean": 42.57518500000001, "mean_ego_speed_min": 33.297250000000005, "mean_ego_speed_max": 49.925, "distance_travelled_mean": 85.882975, "distance_travelled_min": 35.62875, "distance_travelled_max": 124.418}, "hist_stats": {"episode_reward": [-270.56022105533145, -48.86688850218598, 1847.4836852837975, 225.48762076601594, 216.11417305838083, -246.24805026072767, 1357.5457755297762, -168.7915348504866, 1191.9018043301376, -203.24778912600343, 38.39063240951647, -557.8905023698501, 95.59363751433531, -252.86224611813822, 1063.9084978019855, -471.6444431731694, 65.99784973147388, 227.86240358336397, -68.79315781258823, 175.25843382311757, 504.425866153318, 101.19183951608264, 402.8154365601704, 584.4862241520965, 297.6202076951512, 536.8097222090414, 299.09122651276846, 445.9178469466856, 558.3119811510513, -214.9194957438585, -345.1690967995832, -481.323848597354, -800.5669030267435, 515.3059154322315, 182.13299966118592, -565.0634110851527, -87.52388392071131, 1478.7539848707415, -250.42259354599997, -183.90503962712108, -396.6596565200682, 220.75154749639617, -82.25000430754565, 2005.3303985008338, -316.03374662246887, 433.3104685766423, 461.3654403781104, -799.9970010087621, 80.0030324127869, 305.77664580889126, 60.89655337435511, -397.0548886103347, -85.17634932035439, -439.14065707435026, -19.752176488666006, -789.1719672401777, -238.97516833834408, 391.29723610824084, 302.3073589566702, 460.40836017761166, 337.2695176265685, 173.15772690592928, 544.1492487847282, 297.2096783678487, -373.1095330487921, -701.085101415676, 592.047067124778, 349.2368268800691, -306.7807099403411, -319.025674317401, -50.79636115309091, -217.9099016519311, 107.34264519875654, 1621.4263333619842, 329.9668753518438, 840.7656495649857, 43.261237415665036, -1250.527816648757, -77.88289519397226, -185.10378371763554, 140.20064105265385, 556.7215924291053, -358.1428610505838, -76.4149739482945, 198.45998747956, -149.23892271393032, -106.23742816642515, 7.904680377141908, -237.7450821271536, 435.91803045910154, 611.3930336066583, 530.0640589889081, 121.05520676228222, 349.65210097184354, 214.76977182227532, 441.05428446362407, 204.38910741626398, 440.44483541148264, 497.8934850163617, 342.6632942952537], "episode_lengths": [166, 112, 188, 106, 168, 118, 182, 112, 173, 131, 104, 107, 110, 149, 347, 143, 111, 125, 112, 100, 114, 154, 119, 194, 100, 190, 101, 198, 115, 122, 121, 131, 136, 190, 89, 138, 105, 181, 107, 127, 150, 192, 115, 187, 53, 176, 107, 150, 118, 162, 104, 114, 112, 129, 102, 129, 117, 137, 115, 113, 128, 105, 194, 104, 31, 134, 182, 101, 125, 180, 102, 164, 103, 151, 137, 194, 106, 200, 102, 122, 125, 448, 124, 114, 126, 110, 132, 120, 138, 106, 193, 115, 95, 102, 121, 109, 119, 114, 170, 102], "policy_AGENT-2_reward": [80.42211591596983, -0.20587640607042168, 477.19280078416864, 53.07652537631813, -5.487538718364966, -99.90849335504791, 329.6723963359414, -28.271465563574672, 312.0494172590679, -112.66478929051169, 35.45167952146876, -175.34861021128847, 62.76781332433895, -50.50945924263082, 336.8151991324412, -183.73145646009732, 36.35505571445905, -41.02712856109101, 25.29875949226097, -38.46636469071399, 20.84092587482293, -16.337310389962155, 47.35366640298254, -5.8219117818916715, 22.08605281466429, -14.166026998417664, 18.863934927949973, -33.92250429513782, 23.805056786058383, -16.48590909978353, -20.3911102368088, -15.781577459129917, -151.47728612710526, -29.680244944673365, 35.645896966004116, -4.988736669973115, 32.93759253735462, 423.94389268316553, -39.01226867204326, 119.16627360718337, -115.46924203167939, 169.36583157468678, -10.314858658437949, 554.9182040781637, -42.68465458335935, 179.86833743685395, 108.27640043498741, -258.6905008713743, 41.216852615645955, -33.294091053578335, 41.03083070057351, -88.59357072416711, 19.821138767150885, -78.68612681825523, 31.435293322199268, -297.7712873258563, 24.224211869618763, -27.909707220694465, -47.98426256593715, 18.138689936564912, -24.565506552618185, 22.77919417216896, -35.17782387179436, 14.683721436056025, -118.3548469119106, -168.9335106245681, -15.170574613317378, 28.422396404817967, -12.684647095672535, 79.64725731781856, -7.45479209531729, 82.16124186565114, 28.25831617916725, 407.64975823539294, -40.71943060677374, 246.4016297362415, 8.223717338092236, -22.228716319113417, -71.64129447166052, 32.554537605153065, -56.233672659826524, 275.731972237051, -118.33197247573656, 24.320479579045358, -30.766530355992344, 28.056619878366128, -92.51715794232167, 53.878192682239614, -25.739517704228707, 115.91811028484564, -1.8178255872737665, 17.668421015768242, -37.403589708800645, 26.167878338038296, -40.621450660632014, 27.099706444728472, -42.10303896884673, 13.190224985090643, 26.344952350970914, 20.74013033411606], "policy_AGENT-1_reward": [-206.7894830209682, -20.29117481045264, 492.46306160412195, 79.57433086355142, 99.39090743479754, -99.47440293224415, 340.9983007791887, -52.977478890290534, 323.6328769842007, -3.1039399611745537, -3.4798105674075295, -88.00493116156177, -35.993627612758196, -77.3508782628408, 263.55884491071805, -183.30944638893874, 0.08022625711866671, 140.5396106010029, -55.95096589162711, -38.04055185563021, 21.43607906588425, -15.819417425401475, 157.6900189885579, -5.389902899759647, 138.71730152722475, -13.551786328776537, 142.53016268651396, -33.49020116250879, 24.329703648449183, -105.09054421474534, -19.846020578873024, -240.33582056162268, -151.04699820562658, -29.24047145762261, 36.077375338519815, -258.0252582459303, -64.31973278099049, 419.76827048180894, -72.89991718737777, -241.32279823567416, -115.03083266880525, -54.67160000287547, -26.106221514958136, 516.7705219114175, -115.27298396156242, 44.84958844366435, 138.35828175850773, -126.05976137228134, -15.605171599254817, 175.59780822316526, 1.9931121381977803, -105.99369328872349, -58.42499217241019, -103.6144350559769, -28.42151664470273, -112.42983776546782, -163.1785765146352, 208.41948996913337, -47.539043906112866, 18.670373879180296, -23.93555330987027, 79.22129139683577, -34.742230810552186, 146.32100409553698, -68.19335213391228, -177.07294388972326, -14.73152148803564, 158.06169800065416, -120.57857195205833, -232.23435959430606, -5.358555134772253, -182.3473009621666, 38.0032940776688, 408.07980454455793, 189.79169185591837, 177.6180490581093, 48.23217666469378, -594.4466793890631, 49.13793622519265, -119.01899520945057, 111.88236325515695, 28.68073306808605, -117.76889231572278, -58.04553649457439, 114.70929496005988, -90.9197677377464, 24.02127614824543, -69.06688125139345, -97.8748274258651, 151.82370415413928, -1.3829993399235434, 18.21347958057097, -36.74454977645315, 160.93458695580696, -39.97165074280224, 27.709735062966857, -41.41443764898381, 13.704018889193408, 26.826815421147685, 162.8899185993264], "policy_AGENT-0_reward": [80.98884017091966, 0.37117997821355253, 563.39822340137, 53.68347360535692, 127.74368659544558, -5.932125812580708, 410.14516964478884, -27.818544620662887, 103.40041605390583, 25.393767924653538, 35.993942336071164, -205.9714335750117, 63.34029918395571, -46.921811174680954, 259.2756664359962, -34.105118612059925, 36.90218693554016, 169.37252024969686, 25.86449086941578, 108.76028030025317, 243.29965112147536, 51.772033772628944, 47.92537787186371, 311.34874178915555, 22.50989181877852, 294.90363446527476, 19.41737511737083, 235.4216323266145, 268.8853767308054, -76.85446982723772, -136.05690511301248, -209.3924848980431, -266.85765270409007, 295.45395360658705, 35.985916886227834, -296.98900894079793, -64.44731931366894, 401.8568275473353, -38.44039124060446, 119.75333586238348, -97.5395537064476, 170.04140587140557, -9.717572526377188, 625.2630144593237, -42.23626686738178, 180.44384604100003, 109.07374956739014, -288.62088402591553, 41.768373068691915, 196.68302520301964, 41.58345727175616, -88.03193683872038, 20.37735268728306, -145.50453449738927, 31.875022009165143, -265.9801848982604, 24.805241565518784, 238.67129811967052, 173.57960857398916, 224.88400039021036, 207.43979909198427, 23.21309311703749, 318.2604032622495, 15.245323371342938, -68.25446223327225, -218.40264103132012, 323.10402189561523, 28.879429199830064, -160.81138951055698, 80.21733452348455, -6.875367026908218, 82.72194330417828, 28.829414089783022, 521.8709790548235, 221.59216730628438, 246.96740963362646, 8.795990521763649, -611.6289215310821, 16.376689313919485, 32.99295305770097, 140.7732052768205, 28.722079687709613, -44.77997822703128, 24.746499834450383, 145.17829684069886, 28.620456341494194, 54.723861863598714, 54.44281377895889, -88.09460729685136, 116.4854201326079, 318.65111902505305, 260.1525022455505, 80.25088784826407, 26.601600795615894, 161.6868943546176, 206.0127834823879, 157.88492101121648, 219.56864127711836, 240.05318199030697, 21.168259400413035], "policy_AGENT-3_reward": [-225.1816941212529, -28.7410172638766, 314.42959949413495, 39.153290920789495, -5.532882253497462, -40.93302816085485, 276.7299087698585, -59.72404577595842, 452.8190940329631, -112.87282779897014, -29.57517888061594, -88.56552742198794, 5.479152618798864, -78.08009743798529, 204.25878732283053, -70.49842171207344, -7.3396191756439695, -41.02259870624494, -64.00544228263787, 143.00507006920867, 218.84921009113526, 81.57653355881725, 149.8463732967663, 284.34929704459176, 114.3069615344836, 269.62390107096064, 118.27975378093367, 277.90892007771754, 241.29184398573827, -16.488572602091928, -168.87506087088894, -15.813965678558535, -231.18496598992218, 278.77267822794033, 74.42381047043419, -5.060407228451496, 8.305575636593465, 233.1849941584323, -100.07001644597453, -181.5018508610135, -68.620028113136, -63.984089946821065, -36.11135160777244, 308.3786580519305, -115.83984121016515, 28.14869665512426, 105.65700861722512, -126.62585473919076, 12.62297832770396, -33.210096563715254, -23.710846736172456, -114.43568775872339, -66.94984860237825, -111.33556070272911, -54.64097517532773, -112.99065725059266, -124.8260452588464, -27.88384475986891, 224.25105685473108, 198.71529597165576, 178.33077839707266, 47.94414821988706, 295.8089002048257, 120.95962946491285, -118.3068717696969, -136.67600587006413, 298.84514133051573, 133.87330327476676, -12.706101382053168, -246.6559065643985, -31.107646896093005, -200.44578585959394, 12.251620852137464, 283.82579152721064, -40.69755320358529, 169.7785611370084, -21.99064710888461, -22.223499409499325, -71.75622626142396, -131.6322791710389, -56.221254819497204, 223.58680743625806, -77.26201803209271, -67.43641686721585, -30.661073965206302, -114.99623119604429, -92.46540823594752, -31.349444832663085, -26.036129700208622, 51.69079588750828, 295.94273950880176, 234.02965614701827, 114.95245839927195, 135.94803488238222, 133.675978871092, 180.2320594735408, 130.02166302287802, 193.98195026008017, 204.66853525393591, 137.86498596139816]}, "sampler_perf": {"mean_env_wait_ms": 50.963136671680104, "mean_raw_obs_processing_ms": 2.3033295820403143, "mean_inference_ms": 2.305945103731164, "mean_action_processing_ms": 0.14091478141358368}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 138600, "timers": {"sample_time_ms": 79825.657, "sample_throughput": 52.615, "load_time_ms": 13.472, "load_throughput": 311752.001, "learn_time_ms": 7289.335, "learn_throughput": 576.184, "update_time_ms": 8.687}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 31.04279327392578, "policy_loss": -0.040256988257169724, "vf_loss": 31.076684951782227, "vf_explained_var": 0.9721683859825134, "kl": 0.014148109592497349, "entropy": 1.0206061601638794, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 34.81849670410156, "policy_loss": -0.04003008082509041, "vf_loss": 34.853580474853516, "vf_explained_var": 0.9681559205055237, "kl": 0.016504622995853424, "entropy": 0.9460254311561584, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 33.942501068115234, "policy_loss": -0.03866899386048317, "vf_loss": 33.97449493408203, "vf_explained_var": 0.9659740924835205, "kl": 0.014841333031654358, "entropy": 0.9586463570594788, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 45.34590530395508, "policy_loss": -0.03352935612201691, "vf_loss": 45.3751106262207, "vf_explained_var": 0.973218560218811, "kl": 0.014412247575819492, "entropy": 0.879072904586792, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 138600, "num_steps_trained": 138600}, "done": false, "episodes_total": 1085, "training_iteration": 33, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-06-26", "timestamp": 1624219586, "time_this_iter_s": 79.49391102790833, "time_total_s": 3123.050323009491, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c833ea70>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c833e830>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c824a5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cbdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb170>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3d40>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c824a5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cbdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb170>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3d40>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c824a5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cbdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb170>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3d40>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c824a5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cbdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb170>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c85d3d40>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c820edd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3123.050323009491, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 55.44649122807018, "ram_util_percent": 95.37192982456136}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1863.7629001919554, "episode_reward_min": -1323.2552894946614, "episode_reward_mean": 186.6674593804885, "episode_len_mean": 140.7, "episodes_this_iter": 29, "policy_reward_min": {"AGENT-0": -611.6289215310821, "AGENT-3": -246.6559065643985, "AGENT-2": -365.8959838468643, "AGENT-1": -594.4466793890631}, "policy_reward_max": {"AGENT-0": 563.39822340137, "AGENT-3": 452.8190940329631, "AGENT-2": 554.3179095436204, "AGENT-1": 522.6466621463655}, "policy_reward_mean": {"AGENT-0": 82.98418021598879, "AGENT-3": 61.42301718905885, "AGENT-2": 27.370881196482173, "AGENT-1": 14.889380778958685}, "custom_metrics": {"mean_ego_speed_mean": 42.53036749999999, "mean_ego_speed_min": 23.554250000000003, "mean_ego_speed_max": 49.925, "distance_travelled_mean": 87.55705749999998, "distance_travelled_min": 35.62875, "distance_travelled_max": 124.418}, "hist_stats": {"episode_reward": [370.1699134239982, 1863.7629001919554, 64.7375905536418, -505.62869916464035, 930.8765663260353, 1585.384350167459, 133.25068627908976, -101.50263224510147, 168.9828517897533, 222.53196196329185, -295.7359474153403, 540.3010483147368, -536.2688336358702, 702.5147870121652, -765.6769294339811, 272.5710486895823, -390.2825624985064, -43.561867316310405, -249.79803323367133, -396.95576593089845, -500.9934010835258, 616.0314176236776, 510.93448328171064, 1092.8429092176518, -346.49645507136364, -1323.2552894946614, 894.9215095234523, -40.81233879299894, -434.54095362823733, 302.3073589566702, 460.40836017761166, 337.2695176265685, 173.15772690592928, 544.1492487847282, 297.2096783678487, -373.1095330487921, -701.085101415676, 592.047067124778, 349.2368268800691, -306.7807099403411, -319.025674317401, -50.79636115309091, -217.9099016519311, 107.34264519875654, 1621.4263333619842, 329.9668753518438, 840.7656495649857, 43.261237415665036, -1250.527816648757, -77.88289519397226, -185.10378371763554, 140.20064105265385, 556.7215924291053, -358.1428610505838, -76.4149739482945, 198.45998747956, -149.23892271393032, -106.23742816642515, 7.904680377141908, -237.7450821271536, 435.91803045910154, 611.3930336066583, 530.0640589889081, 121.05520676228222, 349.65210097184354, 214.76977182227532, 441.05428446362407, 204.38910741626398, 440.44483541148264, 497.8934850163617, 342.6632942952537, -270.56022105533145, -48.86688850218598, 1847.4836852837975, 225.48762076601594, 216.11417305838083, -246.24805026072767, 1357.5457755297762, -168.7915348504866, 1191.9018043301376, -203.24778912600343, 38.39063240951647, -557.8905023698501, 95.59363751433531, -252.86224611813822, 1063.9084978019855, -471.6444431731694, 65.99784973147388, 227.86240358336397, -68.79315781258823, 175.25843382311757, 504.425866153318, 101.19183951608264, 402.8154365601704, 584.4862241520965, 297.6202076951512, 536.8097222090414, 299.09122651276846, 445.9178469466856, 558.3119811510513], "episode_lengths": [470, 191, 127, 88, 105, 182, 105, 183, 125, 116, 137, 117, 124, 129, 132, 128, 111, 110, 154, 146, 136, 172, 116, 158, 129, 182, 121, 120, 131, 115, 113, 128, 105, 194, 104, 31, 134, 182, 101, 125, 180, 102, 164, 103, 151, 137, 194, 106, 200, 102, 122, 125, 448, 124, 114, 126, 110, 132, 120, 138, 106, 193, 115, 95, 102, 121, 109, 119, 114, 170, 102, 166, 112, 188, 106, 168, 118, 182, 112, 173, 131, 104, 107, 110, 149, 347, 143, 111, 125, 112, 100, 114, 154, 119, 194, 100, 190, 101, 198, 115], "policy_AGENT-0_reward": [-13.577696497501748, 505.2664943261292, 139.51910565192156, -222.59659747475297, 241.97779740751974, 494.33795925071695, 34.26674854978453, 113.7870367347774, 145.5313991582181, 53.293288891884174, -49.49427661163995, 208.16382788004844, -170.92965344173427, 260.88862562685284, -271.55905265090325, 80.88474670153795, -62.03441556466234, 28.15354846277963, 26.662692080089904, -177.96000591916675, -223.2455623592371, 324.62239768264374, 198.54521779011634, 320.3610181511537, -144.09328276869772, -384.79903637711664, 210.52334194875922, -58.68969803406281, -190.60338993881788, 173.57960857398916, 224.88400039021036, 207.43979909198427, 23.21309311703749, 318.2604032622495, 15.245323371342938, -68.25446223327225, -218.40264103132012, 323.10402189561523, 28.879429199830064, -160.81138951055698, 80.21733452348455, -6.875367026908218, 82.72194330417828, 28.829414089783022, 521.8709790548235, 221.59216730628438, 246.96740963362646, 8.795990521763649, -611.6289215310821, 16.376689313919485, 32.99295305770097, 140.7732052768205, 28.722079687709613, -44.77997822703128, 24.746499834450383, 145.17829684069886, 28.620456341494194, 54.723861863598714, 54.44281377895889, -88.09460729685136, 116.4854201326079, 318.65111902505305, 260.1525022455505, 80.25088784826407, 26.601600795615894, 161.6868943546176, 206.0127834823879, 157.88492101121648, 219.56864127711836, 240.05318199030697, 21.168259400413035, 80.98884017091966, 0.37117997821355253, 563.39822340137, 53.68347360535692, 127.74368659544558, -5.932125812580708, 410.14516964478884, -27.818544620662887, 103.40041605390583, 25.393767924653538, 35.993942336071164, -205.9714335750117, 63.34029918395571, -46.921811174680954, 259.2756664359962, -34.105118612059925, 36.90218693554016, 169.37252024969686, 25.86449086941578, 108.76028030025317, 243.29965112147536, 51.772033772628944, 47.92537787186371, 311.34874178915555, 22.50989181877852, 294.90363446527476, 19.41737511737083, 235.4216323266145, 268.8853767308054], "policy_AGENT-3_reward": [53.45507524685223, 281.5318341758408, 106.74500011869509, -30.07019575582964, 180.74606137764977, 251.00057694111933, 19.071830484103412, -170.543128616367, -46.94414526304401, 47.379040908767394, -67.10094597427461, 181.13017941611807, -83.69781200778033, 229.10028361859742, -95.08499123069205, 44.041384385712306, -111.72551055124839, -53.72360494355588, -11.19871404332919, -2.1368123449813767, -190.52893764933194, 303.0937008836846, 242.76124878318132, 204.89758983716027, -13.092612514300242, -147.67151310308785, 199.1112699394511, 23.46680460549804, -12.09994569053474, 224.25105685473108, 198.71529597165576, 178.33077839707266, 47.94414821988706, 295.8089002048257, 120.95962946491285, -118.3068717696969, -136.67600587006413, 298.84514133051573, 133.87330327476676, -12.706101382053168, -246.6559065643985, -31.107646896093005, -200.44578585959394, 12.251620852137464, 283.82579152721064, -40.69755320358529, 169.7785611370084, -21.99064710888461, -22.223499409499325, -71.75622626142396, -131.6322791710389, -56.221254819497204, 223.58680743625806, -77.26201803209271, -67.43641686721585, -30.661073965206302, -114.99623119604429, -92.46540823594752, -31.349444832663085, -26.036129700208622, 51.69079588750828, 295.94273950880176, 234.02965614701827, 114.95245839927195, 135.94803488238222, 133.675978871092, 180.2320594735408, 130.02166302287802, 193.98195026008017, 204.66853525393591, 137.86498596139816, -225.1816941212529, -28.7410172638766, 314.42959949413495, 39.153290920789495, -5.532882253497462, -40.93302816085485, 276.7299087698585, -59.72404577595842, 452.8190940329631, -112.87282779897014, -29.57517888061594, -88.56552742198794, 5.479152618798864, -78.08009743798529, 204.25878732283053, -70.49842171207344, -7.3396191756439695, -41.02259870624494, -64.00544228263787, 143.00507006920867, 218.84921009113526, 81.57653355881725, 149.8463732967663, 284.34929704459176, 114.3069615344836, 269.62390107096064, 118.27975378093367, 277.90892007771754, 241.29184398573827], "policy_AGENT-2_reward": [174.89305922526415, 554.3179095436204, -91.0846603992433, -30.058614373918964, 241.442508970091, 438.5608381198514, 33.671752073343384, 113.21747389909335, -46.93056554452591, 52.74151951822448, -89.85405440426011, 75.23240577088657, -198.50536897215179, 106.02590319010116, -304.5120712235654, 73.61091259348453, -62.61821540336322, 27.712604715319937, -132.96730692560703, -2.0532239641048924, -43.82221844495594, -6.059763668590477, 34.59797582243059, 283.4868894903085, -13.01298420317658, -365.8959838468643, 209.95477768593784, 53.384688650016614, -12.157518508583472, -47.98426256593715, 18.138689936564912, -24.565506552618185, 22.77919417216896, -35.17782387179436, 14.683721436056025, -118.3548469119106, -168.9335106245681, -15.170574613317378, 28.422396404817967, -12.684647095672535, 79.64725731781856, -7.45479209531729, 82.16124186565114, 28.25831617916725, 407.64975823539294, -40.71943060677374, 246.4016297362415, 8.223717338092236, -22.228716319113417, -71.64129447166052, 32.554537605153065, -56.233672659826524, 275.731972237051, -118.33197247573656, 24.320479579045358, -30.766530355992344, 28.056619878366128, -92.51715794232167, 53.878192682239614, -25.739517704228707, 115.91811028484564, -1.8178255872737665, 17.668421015768242, -37.403589708800645, 26.167878338038296, -40.621450660632014, 27.099706444728472, -42.10303896884673, 13.190224985090643, 26.344952350970914, 20.74013033411606, 80.42211591596983, -0.20587640607042168, 477.19280078416864, 53.07652537631813, -5.487538718364966, -99.90849335504791, 329.6723963359414, -28.271465563574672, 312.0494172590679, -112.66478929051169, 35.45167952146876, -175.34861021128847, 62.76781332433895, -50.50945924263082, 336.8151991324412, -183.73145646009732, 36.35505571445905, -41.02712856109101, 25.29875949226097, -38.46636469071399, 20.84092587482293, -16.337310389962155, 47.35366640298254, -5.8219117818916715, 22.08605281466429, -14.166026998417664, 18.863934927949973, -33.92250429513782, 23.805056786058383], "policy_AGENT-1_reward": [155.39947544938417, 522.6466621463655, -90.4418548177317, -222.90329156013885, 266.7101985707752, 401.4849758557731, 46.240355171858546, -157.96401426260536, 117.32616343910503, 69.11811264441583, -89.28667042516574, 75.7746352476836, -83.13599921420428, 106.49997457661368, -94.52081432882036, 74.03400500884754, -153.90442097923244, -45.704415550854065, -132.2947043448247, -214.80572370264528, -43.39668263000063, -5.624917274060053, 35.03004088598264, 284.0974117390291, -176.29757558518935, -424.88875616759344, 275.3321199493042, -58.974134014450755, -219.68009949030136, -47.539043906112866, 18.670373879180296, -23.93555330987027, 79.22129139683577, -34.742230810552186, 146.32100409553698, -68.19335213391228, -177.07294388972326, -14.73152148803564, 158.06169800065416, -120.57857195205833, -232.23435959430606, -5.358555134772253, -182.3473009621666, 38.0032940776688, 408.07980454455793, 189.79169185591837, 177.6180490581093, 48.23217666469378, -594.4466793890631, 49.13793622519265, -119.01899520945057, 111.88236325515695, 28.68073306808605, -117.76889231572278, -58.04553649457439, 114.70929496005988, -90.9197677377464, 24.02127614824543, -69.06688125139345, -97.8748274258651, 151.82370415413928, -1.3829993399235434, 18.21347958057097, -36.74454977645315, 160.93458695580696, -39.97165074280224, 27.709735062966857, -41.41443764898381, 13.704018889193408, 26.826815421147685, 162.8899185993264, -206.7894830209682, -20.29117481045264, 492.46306160412195, 79.57433086355142, 99.39090743479754, -99.47440293224415, 340.9983007791887, -52.977478890290534, 323.6328769842007, -3.1039399611745537, -3.4798105674075295, -88.00493116156177, -35.993627612758196, -77.3508782628408, 263.55884491071805, -183.30944638893874, 0.08022625711866671, 140.5396106010029, -55.95096589162711, -38.04055185563021, 21.43607906588425, -15.819417425401475, 157.6900189885579, -5.389902899759647, 138.71730152722475, -13.551786328776537, 142.53016268651396, -33.49020116250879, 24.329703648449183]}, "sampler_perf": {"mean_env_wait_ms": 50.71320457956325, "mean_raw_obs_processing_ms": 2.2959660589198068, "mean_inference_ms": 2.295745733347956, "mean_action_processing_ms": 0.1405066413181625}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 142800, "timers": {"sample_time_ms": 78463.54, "sample_throughput": 53.528, "load_time_ms": 13.556, "load_throughput": 309817.107, "learn_time_ms": 7206.49, "learn_throughput": 582.808, "update_time_ms": 8.483}, "info": {"learner": {"AGENT-1": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 39.78797912597656, "policy_loss": -0.04444582015275955, "vf_loss": 39.826171875, "vf_explained_var": 0.9730556607246399, "kl": 0.020840847864747047, "entropy": 0.9765509366989136, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 25.365070343017578, "policy_loss": -0.050182368606328964, "vf_loss": 25.408782958984375, "vf_explained_var": 0.9768628478050232, "kl": 0.014384828507900238, "entropy": 0.957794725894928, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 47.740684509277344, "policy_loss": -0.03922639787197113, "vf_loss": 47.77485656738281, "vf_explained_var": 0.9725425243377686, "kl": 0.016846222802996635, "entropy": 0.9206429123878479, "entropy_coeff": 0.0, "model": {}}, "AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 30.104061126708984, "policy_loss": -0.0400717668235302, "vf_loss": 30.137516021728516, "vf_explained_var": 0.9798076152801514, "kl": 0.01470813900232315, "entropy": 1.0648149251937866, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 142800, "num_steps_trained": 142800}, "done": false, "episodes_total": 1114, "training_iteration": 34, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-07-46", "timestamp": 1624219666, "time_this_iter_s": 79.69523692131042, "time_total_s": 3202.7455599308014, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c81d54d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c81d53b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5b90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5b90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5b90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5b90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c81d5830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3202.7455599308014, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 54.592035398230095, "ram_util_percent": 95.39734513274338}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1863.7629001919554, "episode_reward_min": -1323.2552894946614, "episode_reward_mean": 209.55768411937734, "episode_len_mean": 142.05, "episodes_this_iter": 28, "policy_reward_min": {"AGENT-0": -384.79903637711664, "AGENT-3": -225.1816941212529, "AGENT-2": -365.8959838468643, "AGENT-1": -424.88875616759344}, "policy_reward_max": {"AGENT-0": 563.39822340137, "AGENT-3": 452.8190940329631, "AGENT-2": 554.3179095436204, "AGENT-1": 522.6466621463655}, "policy_reward_mean": {"AGENT-0": 91.38777169132015, "AGENT-3": 69.21015674565297, "AGENT-2": 28.623561046138462, "AGENT-1": 20.336194636265688}, "custom_metrics": {"mean_ego_speed_mean": 42.331815, "mean_ego_speed_min": 17.643, "mean_ego_speed_max": 48.07449999999999, "distance_travelled_mean": 88.58433250000003, "distance_travelled_min": 35.772, "distance_travelled_max": 124.27199999999999}, "hist_stats": {"episode_reward": [268.9601763154934, 1140.771062314238, -215.04655297585643, 122.56375065317918, 179.98545017290843, -85.58027219072194, 336.5450029426764, 410.13301872087357, -192.67595275201845, 185.63510474031975, -293.684104056672, 410.79229818898693, -74.5877888013995, 605.9908454912209, 21.751554125037778, -60.05159679470344, -257.9524080459505, 271.4991085455348, -612.390545702571, -340.65193586831145, -220.55408305988215, 247.48137463371955, 377.7543739207046, 644.222932653611, 503.9693960896536, 602.1093981870556, 377.08676902820685, 762.8583092918988, -106.23742816642515, 7.904680377141908, -237.7450821271536, 435.91803045910154, 611.3930336066583, 530.0640589889081, 121.05520676228222, 349.65210097184354, 214.76977182227532, 441.05428446362407, 204.38910741626398, 440.44483541148264, 497.8934850163617, 342.6632942952537, -270.56022105533145, -48.86688850218598, 1847.4836852837975, 225.48762076601594, 216.11417305838083, -246.24805026072767, 1357.5457755297762, -168.7915348504866, 1191.9018043301376, -203.24778912600343, 38.39063240951647, -557.8905023698501, 95.59363751433531, -252.86224611813822, 1063.9084978019855, -471.6444431731694, 65.99784973147388, 227.86240358336397, -68.79315781258823, 175.25843382311757, 504.425866153318, 101.19183951608264, 402.8154365601704, 584.4862241520965, 297.6202076951512, 536.8097222090414, 299.09122651276846, 445.9178469466856, 558.3119811510513, 370.1699134239982, 1863.7629001919554, 64.7375905536418, -505.62869916464035, 930.8765663260353, 1585.384350167459, 133.25068627908976, -101.50263224510147, 168.9828517897533, 222.53196196329185, -295.7359474153403, 540.3010483147368, -536.2688336358702, 702.5147870121652, -765.6769294339811, 272.5710486895823, -390.2825624985064, -43.561867316310405, -249.79803323367133, -396.95576593089845, -500.9934010835258, 616.0314176236776, 510.93448328171064, 1092.8429092176518, -346.49645507136364, -1323.2552894946614, 894.9215095234523, -40.81233879299894, -434.54095362823733], "episode_lengths": [106, 194, 104, 177, 142, 158, 141, 179, 94, 118, 98, 121, 103, 546, 122, 102, 100, 131, 179, 128, 121, 136, 100, 158, 116, 186, 104, 111, 132, 120, 138, 106, 193, 115, 95, 102, 121, 109, 119, 114, 170, 102, 166, 112, 188, 106, 168, 118, 182, 112, 173, 131, 104, 107, 110, 149, 347, 143, 111, 125, 112, 100, 114, 154, 119, 194, 100, 190, 101, 198, 115, 470, 191, 127, 88, 105, 182, 105, 183, 125, 116, 137, 117, 124, 129, 132, 128, 111, 110, 154, 146, 136, 172, 116, 158, 129, 182, 121, 120, 131], "policy_AGENT-0_reward": [59.76565571034707, 401.5274462251758, -42.983666721212394, 153.40129809234742, 208.78945665611815, 95.74194552554984, 240.33179540383634, 190.79982147311617, -20.166791629545813, 66.96642622792733, -40.27861456564882, 124.78608752077875, 4.724932286346304, 27.84276913954127, 139.88388722750065, 21.99152510408785, -60.051312553504104, 148.39136504539545, -149.25363501219945, -140.413734682319, -103.49013251250832, 152.1192925471783, 157.64786403580894, 242.29912498583263, 249.2865638580354, 319.41311867307473, 22.57487411638659, 180.97012348451526, 54.723861863598714, 54.44281377895889, -88.09460729685136, 116.4854201326079, 318.65111902505305, 260.1525022455505, 80.25088784826407, 26.601600795615894, 161.6868943546176, 206.0127834823879, 157.88492101121648, 219.56864127711836, 240.05318199030697, 21.168259400413035, 80.98884017091966, 0.37117997821355253, 563.39822340137, 53.68347360535692, 127.74368659544558, -5.932125812580708, 410.14516964478884, -27.818544620662887, 103.40041605390583, 25.393767924653538, 35.993942336071164, -205.9714335750117, 63.34029918395571, -46.921811174680954, 259.2756664359962, -34.105118612059925, 36.90218693554016, 169.37252024969686, 25.86449086941578, 108.76028030025317, 243.29965112147536, 51.772033772628944, 47.92537787186371, 311.34874178915555, 22.50989181877852, 294.90363446527476, 19.41737511737083, 235.4216323266145, 268.8853767308054, -13.577696497501748, 505.2664943261292, 139.51910565192156, -222.59659747475297, 241.97779740751974, 494.33795925071695, 34.26674854978453, 113.7870367347774, 145.5313991582181, 53.293288891884174, -49.49427661163995, 208.16382788004844, -170.92965344173427, 260.88862562685284, -271.55905265090325, 80.88474670153795, -62.03441556466234, 28.15354846277963, 26.662692080089904, -177.96000591916675, -223.2455623592371, 324.62239768264374, 198.54521779011634, 320.3610181511537, -144.09328276869772, -384.79903637711664, 210.52334194875922, -58.68969803406281, -190.60338993881788], "policy_AGENT-3_reward": [61.446300042057125, 245.7770035675065, -64.63964380231874, -99.70441681398741, 173.55704835257296, -147.97811793998198, -56.42336547802475, 6.995863783583355, 18.058308335487784, 20.439199694215997, -6.46356158708841, 74.34085512006465, -60.22649157375212, 263.2541672363589, 112.95178518086846, -64.06728692334677, -79.8781042172754, -33.82586004102893, -100.9109586012779, -13.922569893432414, -12.905539349093148, 120.51514323797065, 185.62719321753005, 207.85514884088857, 223.4168122989322, 291.8448217931456, 153.58045216494082, 167.3952853084907, -92.46540823594752, -31.349444832663085, -26.036129700208622, 51.69079588750828, 295.94273950880176, 234.02965614701827, 114.95245839927195, 135.94803488238222, 133.675978871092, 180.2320594735408, 130.02166302287802, 193.98195026008017, 204.66853525393591, 137.86498596139816, -225.1816941212529, -28.7410172638766, 314.42959949413495, 39.153290920789495, -5.532882253497462, -40.93302816085485, 276.7299087698585, -59.72404577595842, 452.8190940329631, -112.87282779897014, -29.57517888061594, -88.56552742198794, 5.479152618798864, -78.08009743798529, 204.25878732283053, -70.49842171207344, -7.3396191756439695, -41.02259870624494, -64.00544228263787, 143.00507006920867, 218.84921009113526, 81.57653355881725, 149.8463732967663, 284.34929704459176, 114.3069615344836, 269.62390107096064, 118.27975378093367, 277.90892007771754, 241.29184398573827, 53.45507524685223, 281.5318341758408, 106.74500011869509, -30.07019575582964, 180.74606137764977, 251.00057694111933, 19.071830484103412, -170.543128616367, -46.94414526304401, 47.379040908767394, -67.10094597427461, 181.13017941611807, -83.69781200778033, 229.10028361859742, -95.08499123069205, 44.041384385712306, -111.72551055124839, -53.72360494355588, -11.19871404332919, -2.1368123449813767, -190.52893764933194, 303.0937008836846, 242.76124878318132, 204.89758983716027, -13.092612514300242, -147.67151310308785, 199.1112699394511, 23.46680460549804, -12.09994569053474], "policy_AGENT-2_reward": [59.198314733032795, 238.2965002370992, -43.5330122222374, 152.83243584927914, -101.40833721072158, 95.17587075241279, -56.38284489293197, 190.2456219753322, -95.59101161667311, 66.40816571874512, -123.83786209109041, 124.20803074915662, -60.28350880038151, 286.9958080676597, -115.86202423412641, 21.434570485690884, -60.618564142494606, -33.82955142687926, -178.49166789299466, -13.814095977523264, -12.859845743711341, -12.79856453114568, 16.812273008467194, 96.81721838792318, 15.30596843930017, -4.789154808679029, 22.014523810610864, 180.40467904385787, -92.51715794232167, 53.878192682239614, -25.739517704228707, 115.91811028484564, -1.8178255872737665, 17.668421015768242, -37.403589708800645, 26.167878338038296, -40.621450660632014, 27.099706444728472, -42.10303896884673, 13.190224985090643, 26.344952350970914, 20.74013033411606, 80.42211591596983, -0.20587640607042168, 477.19280078416864, 53.07652537631813, -5.487538718364966, -99.90849335504791, 329.6723963359414, -28.271465563574672, 312.0494172590679, -112.66478929051169, 35.45167952146876, -175.34861021128847, 62.76781332433895, -50.50945924263082, 336.8151991324412, -183.73145646009732, 36.35505571445905, -41.02712856109101, 25.29875949226097, -38.46636469071399, 20.84092587482293, -16.337310389962155, 47.35366640298254, -5.8219117818916715, 22.08605281466429, -14.166026998417664, 18.863934927949973, -33.92250429513782, 23.805056786058383, 174.89305922526415, 554.3179095436204, -91.0846603992433, -30.058614373918964, 241.442508970091, 438.5608381198514, 33.671752073343384, 113.21747389909335, -46.93056554452591, 52.74151951822448, -89.85405440426011, 75.23240577088657, -198.50536897215179, 106.02590319010116, -304.5120712235654, 73.61091259348453, -62.61821540336322, 27.712604715319937, -132.96730692560703, -2.0532239641048924, -43.82221844495594, -6.059763668590477, 34.59797582243059, 283.4868894903085, -13.01298420317658, -365.8959838468643, 209.95477768593784, 53.384688650016614, -12.157518508583472], "policy_AGENT-1_reward": [88.54990583005598, 255.17011228445563, -63.890230230087994, -83.96556647446015, -100.95271762506113, -128.51997052870266, 209.0194179097964, 22.09171148884143, -94.97645784128736, 31.821313099431258, -123.10406581284471, 87.45732479898709, 41.19727928638787, 27.898101047660273, -115.22209404920511, -39.410405461135426, -57.40442713267614, 190.76315496804744, -183.73428419609857, -172.50153531503653, -91.2985654545693, -12.354496620283697, 17.667043658898248, 97.25144043896685, 15.960051493386157, -4.3593874704856646, 178.91691893626862, 234.08822145503504, 24.02127614824543, -69.06688125139345, -97.8748274258651, 151.82370415413928, -1.3829993399235434, 18.21347958057097, -36.74454977645315, 160.93458695580696, -39.97165074280224, 27.709735062966857, -41.41443764898381, 13.704018889193408, 26.826815421147685, 162.8899185993264, -206.7894830209682, -20.29117481045264, 492.46306160412195, 79.57433086355142, 99.39090743479754, -99.47440293224415, 340.9983007791887, -52.977478890290534, 323.6328769842007, -3.1039399611745537, -3.4798105674075295, -88.00493116156177, -35.993627612758196, -77.3508782628408, 263.55884491071805, -183.30944638893874, 0.08022625711866671, 140.5396106010029, -55.95096589162711, -38.04055185563021, 21.43607906588425, -15.819417425401475, 157.6900189885579, -5.389902899759647, 138.71730152722475, -13.551786328776537, 142.53016268651396, -33.49020116250879, 24.329703648449183, 155.39947544938417, 522.6466621463655, -90.4418548177317, -222.90329156013885, 266.7101985707752, 401.4849758557731, 46.240355171858546, -157.96401426260536, 117.32616343910503, 69.11811264441583, -89.28667042516574, 75.7746352476836, -83.13599921420428, 106.49997457661368, -94.52081432882036, 74.03400500884754, -153.90442097923244, -45.704415550854065, -132.2947043448247, -214.80572370264528, -43.39668263000063, -5.624917274060053, 35.03004088598264, 284.0974117390291, -176.29757558518935, -424.88875616759344, 275.3321199493042, -58.974134014450755, -219.68009949030136]}, "sampler_perf": {"mean_env_wait_ms": 50.4350974254219, "mean_raw_obs_processing_ms": 2.2869385623776375, "mean_inference_ms": 2.286052736761864, "mean_action_processing_ms": 0.14003033329618989}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 147000, "timers": {"sample_time_ms": 76118.466, "sample_throughput": 55.177, "load_time_ms": 13.309, "load_throughput": 315587.753, "learn_time_ms": 7123.311, "learn_throughput": 589.613, "update_time_ms": 8.462}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 35.93608856201172, "policy_loss": -0.04675783962011337, "vf_loss": 35.97657012939453, "vf_explained_var": 0.9736073613166809, "kl": 0.013952854089438915, "entropy": 1.0126253366470337, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 41.87471389770508, "policy_loss": -0.045594606548547745, "vf_loss": 41.91461944580078, "vf_explained_var": 0.9711532592773438, "kl": 0.012641658075153828, "entropy": 0.9478234648704529, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 31.531108856201172, "policy_loss": -0.03590468317270279, "vf_loss": 31.560897827148438, "vf_explained_var": 0.9737531542778015, "kl": 0.013589197769761086, "entropy": 0.9064796566963196, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 66.10652160644531, "policy_loss": -0.030279304832220078, "vf_loss": 66.13265991210938, "vf_explained_var": 0.9646531939506531, "kl": 0.01377955637872219, "entropy": 0.8876024484634399, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 147000, "num_steps_trained": 147000}, "done": false, "episodes_total": 1142, "training_iteration": 35, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-09-03", "timestamp": 1624219743, "time_this_iter_s": 76.47444939613342, "time_total_s": 3279.220009326935, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c824ac20>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c8541f80>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c820e8c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c820ed40>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c820e8c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c820ed40>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c820e8c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c820ed40>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c83cb3b0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c820e8c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c820ed40>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c81d5dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3279.220009326935, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 54.67909090909091, "ram_util_percent": 95.54181818181819}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 1863.7629001919554, "episode_reward_min": -1323.2552894946614, "episode_reward_mean": 178.60422647905753, "episode_len_mean": 142.04, "episodes_this_iter": 31, "policy_reward_min": {"AGENT-2": -387.10359533195776, "AGENT-1": -424.88875616759344, "AGENT-0": -384.79903637711664, "AGENT-3": -218.5729209868116}, "policy_reward_max": {"AGENT-2": 554.3179095436204, "AGENT-1": 522.6466621463655, "AGENT-0": 505.2664943261292, "AGENT-3": 303.0937008836846}, "policy_reward_mean": {"AGENT-2": 20.76176877832339, "AGENT-1": 18.69246490227912, "AGENT-0": 82.08076993199782, "AGENT-3": 57.069222866457174}, "custom_metrics": {"mean_ego_speed_mean": 41.9597575, "mean_ego_speed_min": 17.643, "mean_ego_speed_max": 48.93125, "distance_travelled_mean": 89.33980499999998, "distance_travelled_min": 35.772, "distance_travelled_max": 124.30125}, "hist_stats": {"episode_reward": [1402.6705678520912, 148.42739270878081, 1665.0473082353974, -215.6603570296466, 101.22103806744622, 177.22449095992346, 1359.3746146547949, 26.323925511307742, 1338.6821651133328, 473.27488355718697, -968.3384142194388, -28.819647384045986, 328.49720174529386, -85.0646589579555, -530.6536471584387, 698.6233334877601, 136.92045662589177, 851.9721444984497, -71.88762588951845, 76.85797486401921, -202.23982352002267, -564.0683863405839, -519.0883616638985, -227.43334827617622, -536.4630632891276, -457.8761320917614, 231.49010023151322, 261.4126285833107, 957.5918780470026, -661.1753834336183, -526.657639254104, 227.86240358336397, -68.79315781258823, 175.25843382311757, 504.425866153318, 101.19183951608264, 402.8154365601704, 584.4862241520965, 297.6202076951512, 536.8097222090414, 299.09122651276846, 445.9178469466856, 558.3119811510513, 370.1699134239982, 1863.7629001919554, 64.7375905536418, -505.62869916464035, 930.8765663260353, 1585.384350167459, 133.25068627908976, -101.50263224510147, 168.9828517897533, 222.53196196329185, -295.7359474153403, 540.3010483147368, -536.2688336358702, 702.5147870121652, -765.6769294339811, 272.5710486895823, -390.2825624985064, -43.561867316310405, -249.79803323367133, -396.95576593089845, -500.9934010835258, 616.0314176236776, 510.93448328171064, 1092.8429092176518, -346.49645507136364, -1323.2552894946614, 894.9215095234523, -40.81233879299894, -434.54095362823733, 268.9601763154934, 1140.771062314238, -215.04655297585643, 122.56375065317918, 179.98545017290843, -85.58027219072194, 336.5450029426764, 410.13301872087357, -192.67595275201845, 185.63510474031975, -293.684104056672, 410.79229818898693, -74.5877888013995, 605.9908454912209, 21.751554125037778, -60.05159679470344, -257.9524080459505, 271.4991085455348, -612.390545702571, -340.65193586831145, -220.55408305988215, 247.48137463371955, 377.7543739207046, 644.222932653611, 503.9693960896536, 602.1093981870556, 377.08676902820685, 762.8583092918988], "episode_lengths": [175, 127, 175, 100, 181, 137, 171, 103, 171, 154, 169, 102, 133, 105, 42, 149, 131, 134, 116, 106, 128, 125, 169, 122, 158, 135, 219, 99, 134, 133, 159, 125, 112, 100, 114, 154, 119, 194, 100, 190, 101, 198, 115, 470, 191, 127, 88, 105, 182, 105, 183, 125, 116, 137, 117, 124, 129, 132, 128, 111, 110, 154, 146, 136, 172, 116, 158, 129, 182, 121, 120, 131, 106, 194, 104, 177, 142, 158, 141, 179, 94, 118, 98, 121, 103, 546, 122, 102, 100, 131, 179, 128, 121, 136, 100, 158, 116, 186, 104, 111], "policy_AGENT-2_reward": [341.8437904840417, -101.35442615393444, 437.678265375716, -37.72108195393476, -11.263335605502931, -105.29124493182445, 325.8163933123167, -51.71980037425885, 325.1531138609893, -54.74872520969073, -387.10359533195776, 18.073801464445353, -37.567834612153504, 21.766943259953877, -159.06121215743389, 62.48180864508601, -60.772320255068664, 139.3038985101008, -111.62180400945192, 51.577964304015595, -115.57105997942064, -139.76361539753665, -10.527563963570074, -64.4219407369568, -10.512285341533866, -28.667505967314696, 26.00035896979709, 18.704648954305178, 233.24660550528267, -165.6878067231779, -5.969310742553626, -41.02712856109101, 25.29875949226097, -38.46636469071399, 20.84092587482293, -16.337310389962155, 47.35366640298254, -5.8219117818916715, 22.08605281466429, -14.166026998417664, 18.863934927949973, -33.92250429513782, 23.805056786058383, 174.89305922526415, 554.3179095436204, -91.0846603992433, -30.058614373918964, 241.442508970091, 438.5608381198514, 33.671752073343384, 113.21747389909335, -46.93056554452591, 52.74151951822448, -89.85405440426011, 75.23240577088657, -198.50536897215179, 106.02590319010116, -304.5120712235654, 73.61091259348453, -62.61821540336322, 27.712604715319937, -132.96730692560703, -2.0532239641048924, -43.82221844495594, -6.059763668590477, 34.59797582243059, 283.4868894903085, -13.01298420317658, -365.8959838468643, 209.95477768593784, 53.384688650016614, -12.157518508583472, 59.198314733032795, 238.2965002370992, -43.5330122222374, 152.83243584927914, -101.40833721072158, 95.17587075241279, -56.38284489293197, 190.2456219753322, -95.59101161667311, 66.40816571874512, -123.83786209109041, 124.20803074915662, -60.28350880038151, 286.9958080676597, -115.86202423412641, 21.434570485690884, -60.618564142494606, -33.82955142687926, -178.49166789299466, -13.814095977523264, -12.859845743711341, -12.79856453114568, 16.812273008467194, 96.81721838792318, 15.30596843930017, -4.789154808679029, 22.014523810610864, 180.40467904385787], "policy_AGENT-1_reward": [374.82734594096166, -100.87592346669274, 471.95134912115435, -58.787204296210206, 48.07468186858589, -104.68456564386838, 360.4742902585675, 81.66002640793437, 359.34358217555126, 275.47898101763036, -116.93239912054712, -21.253741025519, 186.59840915356097, -51.40917093422803, -106.20377572836038, 62.95637472011004, 114.32876022403023, 139.72803176795216, -111.14314144428246, 0.41405693640434293, 0.2993227220256134, -156.75479957053312, -261.03007187056625, -68.56120524059247, -277.3372686414254, -28.18446171024431, 26.44881493134124, 123.27973184311708, 261.3223050129153, -186.61883759455296, -273.19090736184035, 140.5396106010029, -55.95096589162711, -38.04055185563021, 21.43607906588425, -15.819417425401475, 157.6900189885579, -5.389902899759647, 138.71730152722475, -13.551786328776537, 142.53016268651396, -33.49020116250879, 24.329703648449183, 155.39947544938417, 522.6466621463655, -90.4418548177317, -222.90329156013885, 266.7101985707752, 401.4849758557731, 46.240355171858546, -157.96401426260536, 117.32616343910503, 69.11811264441583, -89.28667042516574, 75.7746352476836, -83.13599921420428, 106.49997457661368, -94.52081432882036, 74.03400500884754, -153.90442097923244, -45.704415550854065, -132.2947043448247, -214.80572370264528, -43.39668263000063, -5.624917274060053, 35.03004088598264, 284.0974117390291, -176.29757558518935, -424.88875616759344, 275.3321199493042, -58.974134014450755, -219.68009949030136, 88.54990583005598, 255.17011228445563, -63.890230230087994, -83.96556647446015, -100.95271762506113, -128.51997052870266, 209.0194179097964, 22.09171148884143, -94.97645784128736, 31.821313099431258, -123.10406581284471, 87.45732479898709, 41.19727928638787, 27.898101047660273, -115.22209404920511, -39.410405461135426, -57.40442713267614, 190.76315496804744, -183.73428419609857, -172.50153531503653, -91.2985654545693, -12.354496620283697, 17.667043658898248, 97.25144043896685, 15.960051493386157, -4.3593874704856646, 178.91691893626862, 234.08822145503504], "policy_AGENT-0_reward": [424.1625014075662, 189.54075799108912, 471.43302880689237, -37.29416881478814, 75.62691783115773, 208.42909043854092, 410.2389028401885, 48.09962025524303, 388.9087405576517, 307.377063791867, -346.80692769837185, 18.627048606161726, 217.07379516489, 22.198611068938632, -106.15225393770385, 305.57653833159617, 144.144911680245, 302.38375013402253, 51.13728024726757, 52.14279292312311, 28.66968037105901, -127.65362362193412, -237.06314096210625, -41.18252402582477, -238.03097174061938, -182.45124342739078, 103.3968106294844, 19.133014450771423, 263.2019012105326, -154.55333381264592, -241.53864824905975, 169.37252024969686, 25.86449086941578, 108.76028030025317, 243.29965112147536, 51.772033772628944, 47.92537787186371, 311.34874178915555, 22.50989181877852, 294.90363446527476, 19.41737511737083, 235.4216323266145, 268.8853767308054, -13.577696497501748, 505.2664943261292, 139.51910565192156, -222.59659747475297, 241.97779740751974, 494.33795925071695, 34.26674854978453, 113.7870367347774, 145.5313991582181, 53.293288891884174, -49.49427661163995, 208.16382788004844, -170.92965344173427, 260.88862562685284, -271.55905265090325, 80.88474670153795, -62.03441556466234, 28.15354846277963, 26.662692080089904, -177.96000591916675, -223.2455623592371, 324.62239768264374, 198.54521779011634, 320.3610181511537, -144.09328276869772, -384.79903637711664, 210.52334194875922, -58.68969803406281, -190.60338993881788, 59.76565571034707, 401.5274462251758, -42.983666721212394, 153.40129809234742, 208.78945665611815, 95.74194552554984, 240.33179540383634, 190.79982147311617, -20.166791629545813, 66.96642622792733, -40.27861456564882, 124.78608752077875, 4.724932286346304, 27.84276913954127, 139.88388722750065, 21.99152510408785, -60.051312553504104, 148.39136504539545, -149.25363501219945, -140.413734682319, -103.49013251250832, 152.1192925471783, 157.64786403580894, 242.29912498583263, 249.2865638580354, 319.41311867307473, 22.57487411638659, 180.97012348451526], "policy_AGENT-3_reward": [261.8369300195204, 161.1169843383186, 283.98466493163426, -81.85790196471336, -11.2172260267945, 178.77121109707537, 262.8450282437233, -51.71592077761091, 265.2767285191404, -54.83243604261957, -117.49549206856237, -44.26675642913412, -37.60716796100374, -77.62104235261995, -159.23640533494046, 267.60861179096753, -60.78089502331474, 270.556464086375, 99.74003931694848, -27.27683929952375, -115.63776663368645, -139.89634775058013, -10.467584867656779, -53.26767827280221, -10.582537565549194, -218.5729209868116, 75.64411570089055, 100.295233335117, 199.82106631827267, -154.31540530324125, -5.95877290065061, -41.02259870624494, -64.00544228263787, 143.00507006920867, 218.84921009113526, 81.57653355881725, 149.8463732967663, 284.34929704459176, 114.3069615344836, 269.62390107096064, 118.27975378093367, 277.90892007771754, 241.29184398573827, 53.45507524685223, 281.5318341758408, 106.74500011869509, -30.07019575582964, 180.74606137764977, 251.00057694111933, 19.071830484103412, -170.543128616367, -46.94414526304401, 47.379040908767394, -67.10094597427461, 181.13017941611807, -83.69781200778033, 229.10028361859742, -95.08499123069205, 44.041384385712306, -111.72551055124839, -53.72360494355588, -11.19871404332919, -2.1368123449813767, -190.52893764933194, 303.0937008836846, 242.76124878318132, 204.89758983716027, -13.092612514300242, -147.67151310308785, 199.1112699394511, 23.46680460549804, -12.09994569053474, 61.446300042057125, 245.7770035675065, -64.63964380231874, -99.70441681398741, 173.55704835257296, -147.97811793998198, -56.42336547802475, 6.995863783583355, 18.058308335487784, 20.439199694215997, -6.46356158708841, 74.34085512006465, -60.22649157375212, 263.2541672363589, 112.95178518086846, -64.06728692334677, -79.8781042172754, -33.82586004102893, -100.9109586012779, -13.922569893432414, -12.905539349093148, 120.51514323797065, 185.62719321753005, 207.85514884088857, 223.4168122989322, 291.8448217931456, 153.58045216494082, 167.3952853084907]}, "sampler_perf": {"mean_env_wait_ms": 50.142815602935705, "mean_raw_obs_processing_ms": 2.272995756827045, "mean_inference_ms": 2.2760835106385424, "mean_action_processing_ms": 0.13946620449297864}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 151200, "timers": {"sample_time_ms": 75163.633, "sample_throughput": 55.878, "load_time_ms": 13.334, "load_throughput": 314987.346, "learn_time_ms": 7089.314, "learn_throughput": 592.441, "update_time_ms": 8.229}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 35.617862701416016, "policy_loss": -0.03844795003533363, "vf_loss": 35.64909744262695, "vf_explained_var": 0.9795273542404175, "kl": 0.016037732362747192, "entropy": 1.0103294849395752, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 32.20804977416992, "policy_loss": -0.04294285923242569, "vf_loss": 32.24409866333008, "vf_explained_var": 0.980092465877533, "kl": 0.015322051011025906, "entropy": 0.9252457022666931, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 36.72622299194336, "policy_loss": -0.03774480149149895, "vf_loss": 36.75766372680664, "vf_explained_var": 0.9734177589416504, "kl": 0.014007854275405407, "entropy": 0.9997695684432983, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 43.349449157714844, "policy_loss": -0.03262941166758537, "vf_loss": 43.37687301635742, "vf_explained_var": 0.9751285910606384, "kl": 0.017359163612127304, "entropy": 0.9518033266067505, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 151200, "num_steps_trained": 151200}, "done": false, "episodes_total": 1173, "training_iteration": 36, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-10-25", "timestamp": 1624219825, "time_this_iter_s": 82.276686668396, "time_total_s": 3361.496695995331, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c827f4d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c827f3b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c827f170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c827f050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c827fa70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c827fb90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c827f170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c827f050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c827fa70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c827fb90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c827f170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c827f050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c827fa70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c827fb90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c827f170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c827f050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c827fa70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c827fb90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c827f830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3361.496695995331, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 55.54017094017094, "ram_util_percent": 95.44444444444444}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 2144.9452224663437, "episode_reward_min": -1323.2552894946614, "episode_reward_mean": 160.95466428000387, "episode_len_mean": 141.73, "episodes_this_iter": 29, "policy_reward_min": {"AGENT-2": -387.10359533195776, "AGENT-1": -424.88875616759344, "AGENT-0": -384.79903637711664, "AGENT-3": -218.5729209868116}, "policy_reward_max": {"AGENT-2": 565.912458078286, "AGENT-1": 594.241668989083, "AGENT-0": 642.9665185091353, "AGENT-3": 341.8245768898356}, "policy_reward_mean": {"AGENT-2": 32.072159619628295, "AGENT-1": 12.376297975520274, "AGENT-0": 69.75559100002414, "AGENT-3": 46.750615684831125}, "custom_metrics": {"mean_ego_speed_mean": 41.369525, "mean_ego_speed_min": 17.643, "mean_ego_speed_max": 48.93125, "distance_travelled_mean": 92.94853750000001, "distance_travelled_min": 44.994, "distance_travelled_max": 124.30125}, "hist_stats": {"episode_reward": [1743.6800232318546, 688.8809738699172, 2144.9452224663437, -299.72014250355613, 1186.931029349931, -71.83346414094662, 1589.607840625354, 222.91791533081488, 688.6050638694495, 550.5701171842251, -500.7333945711425, 453.8773610510049, -51.883540421024115, 849.5001730981236, -144.36697871712042, -77.3281884443096, -647.5578228049761, 231.59903369578063, -173.06602821389365, -472.3534421643011, 1129.967655022348, -377.4207560733705, -358.13873712982155, -681.9435138858579, -378.422503348648, -616.2942647754003, 712.4819788451464, -468.6384992036389, -313.83320033911923, -43.561867316310405, -249.79803323367133, -396.95576593089845, -500.9934010835258, 616.0314176236776, 510.93448328171064, 1092.8429092176518, -346.49645507136364, -1323.2552894946614, 894.9215095234523, -40.81233879299894, -434.54095362823733, 268.9601763154934, 1140.771062314238, -215.04655297585643, 122.56375065317918, 179.98545017290843, -85.58027219072194, 336.5450029426764, 410.13301872087357, -192.67595275201845, 185.63510474031975, -293.684104056672, 410.79229818898693, -74.5877888013995, 605.9908454912209, 21.751554125037778, -60.05159679470344, -257.9524080459505, 271.4991085455348, -612.390545702571, -340.65193586831145, -220.55408305988215, 247.48137463371955, 377.7543739207046, 644.222932653611, 503.9693960896536, 602.1093981870556, 377.08676902820685, 762.8583092918988, 1402.6705678520912, 148.42739270878081, 1665.0473082353974, -215.6603570296466, 101.22103806744622, 177.22449095992346, 1359.3746146547949, 26.323925511307742, 1338.6821651133328, 473.27488355718697, -968.3384142194388, -28.819647384045986, 328.49720174529386, -85.0646589579555, -530.6536471584387, 698.6233334877601, 136.92045662589177, 851.9721444984497, -71.88762588951845, 76.85797486401921, -202.23982352002267, -564.0683863405839, -519.0883616638985, -227.43334827617622, -536.4630632891276, -457.8761320917614, 231.49010023151322, 261.4126285833107, 957.5918780470026, -661.1753834336183, -526.657639254104], "episode_lengths": [174, 150, 184, 98, 194, 102, 177, 105, 184, 114, 123, 113, 172, 139, 212, 114, 124, 123, 109, 155, 146, 127, 123, 178, 140, 161, 161, 121, 138, 110, 154, 146, 136, 172, 116, 158, 129, 182, 121, 120, 131, 106, 194, 104, 177, 142, 158, 141, 179, 94, 118, 98, 121, 103, 546, 122, 102, 100, 131, 179, 128, 121, 136, 100, 158, 116, 186, 104, 111, 175, 127, 175, 100, 181, 137, 171, 103, 171, 154, 169, 102, 133, 105, 42, 149, 131, 134, 116, 106, 128, 125, 169, 122, 158, 135, 219, 99, 134, 133, 159], "policy_AGENT-2_reward": [475.4181859190429, 400.6140461626332, 565.912458078286, -36.56522081737966, 450.49156742511263, -7.69689190983959, 500.0438601175541, 51.84168874176939, 284.6926744188151, 73.77127851574944, -177.7388864023736, 115.74211033629439, -128.40881480977066, 84.38558501005525, -153.7175561582392, 21.981388782947093, -246.02922616523355, 54.310266210176344, 25.72699267732388, -132.21147203519328, 276.0273515725371, -46.627880001179655, -14.199650451077463, -148.19881244227963, -10.225883602883354, -141.98885122582408, 90.45017891634261, -46.59245332206244, -1.5110672463568102, 27.712604715319937, -132.96730692560703, -2.0532239641048924, -43.82221844495594, -6.059763668590477, 34.59797582243059, 283.4868894903085, -13.01298420317658, -365.8959838468643, 209.95477768593784, 53.384688650016614, -12.157518508583472, 59.198314733032795, 238.2965002370992, -43.5330122222374, 152.83243584927914, -101.40833721072158, 95.17587075241279, -56.38284489293197, 190.2456219753322, -95.59101161667311, 66.40816571874512, -123.83786209109041, 124.20803074915662, -60.28350880038151, 286.9958080676597, -115.86202423412641, 21.434570485690884, -60.618564142494606, -33.82955142687926, -178.49166789299466, -13.814095977523264, -12.859845743711341, -12.79856453114568, 16.812273008467194, 96.81721838792318, 15.30596843930017, -4.789154808679029, 22.014523810610864, 180.40467904385787, 341.8437904840417, -101.35442615393444, 437.678265375716, -37.72108195393476, -11.263335605502931, -105.29124493182445, 325.8163933123167, -51.71980037425885, 325.1531138609893, -54.74872520969073, -387.10359533195776, 18.073801464445353, -37.567834612153504, 21.766943259953877, -159.06121215743389, 62.48180864508601, -60.772320255068664, 139.3038985101008, -111.62180400945192, 51.577964304015595, -115.57105997942064, -139.76361539753665, -10.527563963570074, -64.4219407369568, -10.512285341533866, -28.667505967314696, 26.00035896979709, 18.704648954305178, 233.24660550528267, -165.6878067231779, -5.969310742553626], "policy_AGENT-1_reward": [502.0821669591032, -6.799071004519355, 594.241668989083, -113.30991530803229, 235.45460339242652, -15.385753387712143, 438.5530160027746, 90.19129408889779, 74.90113638959733, 74.20605048974478, -85.31246038431883, 124.45496704330581, -127.9286781692127, 84.99864985626203, -153.10304472576627, -56.82128493799422, -91.96191099256069, 75.05830631411158, -133.4147509596953, -120.77169028567857, 310.14891905500036, -156.63786520243386, -177.79844102700883, -211.826708894211, -156.38763648755378, -185.8143354958955, 177.64222924566278, -45.97916185438408, -168.2194479080242, -45.704415550854065, -132.2947043448247, -214.80572370264528, -43.39668263000063, -5.624917274060053, 35.03004088598264, 284.0974117390291, -176.29757558518935, -424.88875616759344, 275.3321199493042, -58.974134014450755, -219.68009949030136, 88.54990583005598, 255.17011228445563, -63.890230230087994, -83.96556647446015, -100.95271762506113, -128.51997052870266, 209.0194179097964, 22.09171148884143, -94.97645784128736, 31.821313099431258, -123.10406581284471, 87.45732479898709, 41.19727928638787, 27.898101047660273, -115.22209404920511, -39.410405461135426, -57.40442713267614, 190.76315496804744, -183.73428419609857, -172.50153531503653, -91.2985654545693, -12.354496620283697, 17.667043658898248, 97.25144043896685, 15.960051493386157, -4.3593874704856646, 178.91691893626862, 234.08822145503504, 374.82734594096166, -100.87592346669274, 471.95134912115435, -58.787204296210206, 48.07468186858589, -104.68456564386838, 360.4742902585675, 81.66002640793437, 359.34358217555126, 275.47898101763036, -116.93239912054712, -21.253741025519, 186.59840915356097, -51.40917093422803, -106.20377572836038, 62.95637472011004, 114.32876022403023, 139.72803176795216, -111.14314144428246, 0.41405693640434293, 0.2993227220256134, -156.75479957053312, -261.03007187056625, -68.56120524059247, -277.3372686414254, -28.18446171024431, 26.44881493134124, 123.27973184311708, 261.3223050129153, -186.61883759455296, -273.19090736184035], "policy_AGENT-0_reward": [511.8468305792782, 337.6860513053083, 642.9665185091353, -35.972555198813936, 220.1248800976413, -7.1278644072478325, 390.0710836543283, 52.411648419597704, 56.81080390243436, 214.26565511083845, -151.8014179511369, 116.29201780081411, 76.60077943745934, 355.15078630697025, 99.58962907872535, 22.41619004122982, -217.03882564839517, 54.87260068131367, 26.28307593377285, -87.00802774130402, 310.22159827059085, -127.58829050637706, -151.87398252380365, -173.7703219909752, -201.56874769424255, -146.4723369506976, 219.6008339051171, -209.6529812946473, -142.6471799527512, 28.15354846277963, 26.662692080089904, -177.96000591916675, -223.2455623592371, 324.62239768264374, 198.54521779011634, 320.3610181511537, -144.09328276869772, -384.79903637711664, 210.52334194875922, -58.68969803406281, -190.60338993881788, 59.76565571034707, 401.5274462251758, -42.983666721212394, 153.40129809234742, 208.78945665611815, 95.74194552554984, 240.33179540383634, 190.79982147311617, -20.166791629545813, 66.96642622792733, -40.27861456564882, 124.78608752077875, 4.724932286346304, 27.84276913954127, 139.88388722750065, 21.99152510408785, -60.051312553504104, 148.39136504539545, -149.25363501219945, -140.413734682319, -103.49013251250832, 152.1192925471783, 157.64786403580894, 242.29912498583263, 249.2865638580354, 319.41311867307473, 22.57487411638659, 180.97012348451526, 424.1625014075662, 189.54075799108912, 471.43302880689237, -37.29416881478814, 75.62691783115773, 208.42909043854092, 410.2389028401885, 48.09962025524303, 388.9087405576517, 307.377063791867, -346.80692769837185, 18.627048606161726, 217.07379516489, 22.198611068938632, -106.15225393770385, 305.57653833159617, 144.144911680245, 302.38375013402253, 51.13728024726757, 52.14279292312311, 28.66968037105901, -127.65362362193412, -237.06314096210625, -41.18252402582477, -238.03097174061938, -182.45124342739078, 103.3968106294844, 19.133014450771423, 263.2019012105326, -154.55333381264592, -241.53864824905975], "policy_AGENT-3_reward": [254.33283977443102, -42.62005259350493, 341.8245768898356, -113.87245117933003, 280.8599784347501, -41.62295443614714, 260.93988085069583, 28.473284080550084, 272.2004491586024, 188.32713306789236, -85.88062983331312, 97.38826587059037, 127.85317312049975, 324.9651519248364, 62.863993088159475, -64.90448233049231, -92.52785999878688, 47.3578604901788, -91.66134586529502, -132.36225210212447, 233.56978612421992, -46.566720363379815, -14.266663127931771, -148.14767055839192, -10.240235563968682, -142.01874110298368, 224.788736778024, -166.41390273254507, -1.4555052319869222, -53.72360494355588, -11.19871404332919, -2.1368123449813767, -190.52893764933194, 303.0937008836846, 242.76124878318132, 204.89758983716027, -13.092612514300242, -147.67151310308785, 199.1112699394511, 23.46680460549804, -12.09994569053474, 61.446300042057125, 245.7770035675065, -64.63964380231874, -99.70441681398741, 173.55704835257296, -147.97811793998198, -56.42336547802475, 6.995863783583355, 18.058308335487784, 20.439199694215997, -6.46356158708841, 74.34085512006465, -60.22649157375212, 263.2541672363589, 112.95178518086846, -64.06728692334677, -79.8781042172754, -33.82586004102893, -100.9109586012779, -13.922569893432414, -12.905539349093148, 120.51514323797065, 185.62719321753005, 207.85514884088857, 223.4168122989322, 291.8448217931456, 153.58045216494082, 167.3952853084907, 261.8369300195204, 161.1169843383186, 283.98466493163426, -81.85790196471336, -11.2172260267945, 178.77121109707537, 262.8450282437233, -51.71592077761091, 265.2767285191404, -54.83243604261957, -117.49549206856237, -44.26675642913412, -37.60716796100374, -77.62104235261995, -159.23640533494046, 267.60861179096753, -60.78089502331474, 270.556464086375, 99.74003931694848, -27.27683929952375, -115.63776663368645, -139.89634775058013, -10.467584867656779, -53.26767827280221, -10.582537565549194, -218.5729209868116, 75.64411570089055, 100.295233335117, 199.82106631827267, -154.31540530324125, -5.95877290065061]}, "sampler_perf": {"mean_env_wait_ms": 49.94504635988918, "mean_raw_obs_processing_ms": 2.260218096933795, "mean_inference_ms": 2.267936090710293, "mean_action_processing_ms": 0.13902516388382444}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 155400, "timers": {"sample_time_ms": 74985.301, "sample_throughput": 56.011, "load_time_ms": 13.219, "load_throughput": 317735.402, "learn_time_ms": 6905.546, "learn_throughput": 608.207, "update_time_ms": 7.995}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 47.07899856567383, "policy_loss": -0.04212227091193199, "vf_loss": 47.11477279663086, "vf_explained_var": 0.9757596254348755, "kl": 0.014095352962613106, "entropy": 1.0248277187347412, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 40.89334487915039, "policy_loss": -0.0429687537252903, "vf_loss": 40.93011474609375, "vf_explained_var": 0.9743278622627258, "kl": 0.013767536729574203, "entropy": 0.9487056732177734, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 25.752281188964844, "policy_loss": -0.05155977979302406, "vf_loss": 25.796926498413086, "vf_explained_var": 0.9850503206253052, "kl": 0.015357887372374535, "entropy": 0.9811645746231079, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 46.086463928222656, "policy_loss": -0.034948501735925674, "vf_loss": 46.11588668823242, "vf_explained_var": 0.97535640001297, "kl": 0.018402548506855965, "entropy": 0.9594099521636963, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 155400, "num_steps_trained": 155400}, "done": false, "episodes_total": 1202, "training_iteration": 37, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-11-47", "timestamp": 1624219907, "time_this_iter_s": 81.82311773300171, "time_total_s": 3443.3198137283325, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c81d5680>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c81d58c0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e830>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e320>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c820ee60>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e830>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e320>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c820ee60>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e830>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e320>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c820ee60>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e830>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e8c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e320>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c820ee60>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c827fdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3443.3198137283325, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 56.36101694915253, "ram_util_percent": 95.5042372881356}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 2144.9452224663437, "episode_reward_min": -968.3384142194388, "episode_reward_mean": 228.63363159998732, "episode_len_mean": 150.08, "episodes_this_iter": 24, "policy_reward_min": {"AGENT-0": -353.1518899030562, "AGENT-3": -218.5729209868116, "AGENT-2": -399.1369713559961, "AGENT-1": -277.3372686414254}, "policy_reward_max": {"AGENT-0": 642.9665185091353, "AGENT-3": 341.8245768898356, "AGENT-2": 565.912458078286, "AGENT-1": 594.241668989083}, "policy_reward_mean": {"AGENT-0": 80.96675002105935, "AGENT-3": 63.16258942761218, "AGENT-2": 48.48437016109432, "AGENT-1": 36.01992199022145}, "custom_metrics": {"mean_ego_speed_mean": 41.131172500000005, "mean_ego_speed_min": 17.643, "mean_ego_speed_max": 48.93125, "distance_travelled_mean": 94.00317750000002, "distance_travelled_min": 44.994, "distance_travelled_max": 124.30125}, "hist_stats": {"episode_reward": [292.7082315328096, 899.7517308403199, -199.2203546781441, 1658.8755896090274, 2.3662576662843797, 1597.8156915131124, 932.3191206581921, 61.59180191589343, 1599.6671569000825, -187.8455218073214, 672.8089078008135, -929.1419102527917, 774.0862654110033, -481.3134447236774, 768.0700694822904, 204.6478548640685, -386.1473515821587, 576.0037257168628, -136.09225293032043, 560.2688706308802, 539.2443423374402, -485.96140599208934, -642.0321941663841, 1122.1407484203808, -74.5877888013995, 605.9908454912209, 21.751554125037778, -60.05159679470344, -257.9524080459505, 271.4991085455348, -612.390545702571, -340.65193586831145, -220.55408305988215, 247.48137463371955, 377.7543739207046, 644.222932653611, 503.9693960896536, 602.1093981870556, 377.08676902820685, 762.8583092918988, 1402.6705678520912, 148.42739270878081, 1665.0473082353974, -215.6603570296466, 101.22103806744622, 177.22449095992346, 1359.3746146547949, 26.323925511307742, 1338.6821651133328, 473.27488355718697, -968.3384142194388, -28.819647384045986, 328.49720174529386, -85.0646589579555, -530.6536471584387, 698.6233334877601, 136.92045662589177, 851.9721444984497, -71.88762588951845, 76.85797486401921, -202.23982352002267, -564.0683863405839, -519.0883616638985, -227.43334827617622, -536.4630632891276, -457.8761320917614, 231.49010023151322, 261.4126285833107, 957.5918780470026, -661.1753834336183, -526.657639254104, 1743.6800232318546, 688.8809738699172, 2144.9452224663437, -299.72014250355613, 1186.931029349931, -71.83346414094662, 1589.607840625354, 222.91791533081488, 688.6050638694495, 550.5701171842251, -500.7333945711425, 453.8773610510049, -51.883540421024115, 849.5001730981236, -144.36697871712042, -77.3281884443096, -647.5578228049761, 231.59903369578063, -173.06602821389365, -472.3534421643011, 1129.967655022348, -377.4207560733705, -358.13873712982155, -681.9435138858579, -378.422503348648, -616.2942647754003, 712.4819788451464, -468.6384992036389, -313.83320033911923], "episode_lengths": [212, 192, 104, 177, 103, 182, 162, 101, 171, 183, 260, 178, 128, 115, 535, 116, 117, 199, 64, 204, 119, 177, 158, 185, 103, 546, 122, 102, 100, 131, 179, 128, 121, 136, 100, 158, 116, 186, 104, 111, 175, 127, 175, 100, 181, 137, 171, 103, 171, 154, 169, 102, 133, 105, 42, 149, 131, 134, 116, 106, 128, 125, 169, 122, 158, 135, 219, 99, 134, 133, 159, 174, 150, 184, 98, 194, 102, 177, 105, 184, 114, 123, 113, 172, 139, 212, 114, 124, 123, 109, 155, 146, 127, 123, 178, 140, 161, 161, 121, 138], "policy_AGENT-0_reward": [254.8505637013893, 265.48227136569534, -35.017611636783194, 418.1106182309148, 10.052031982932345, 430.74412869792434, 253.9227738087297, 17.926703658085877, 404.85604905971684, 53.52195833682982, 179.53182613903525, -353.1518899030562, 227.99056554247227, -134.4410861371875, 77.00475364242277, 111.33650727957155, -120.29035756356153, 178.42932573413705, -59.114631821206174, 339.08269237620794, 28.71792959610929, -209.84541093095922, -180.3139573103909, 329.88824889172525, 4.724932286346304, 27.84276913954127, 139.88388722750065, 21.99152510408785, -60.051312553504104, 148.39136504539545, -149.25363501219945, -140.413734682319, -103.49013251250832, 152.1192925471783, 157.64786403580894, 242.29912498583263, 249.2865638580354, 319.41311867307473, 22.57487411638659, 180.97012348451526, 424.1625014075662, 189.54075799108912, 471.43302880689237, -37.29416881478814, 75.62691783115773, 208.42909043854092, 410.2389028401885, 48.09962025524303, 388.9087405576517, 307.377063791867, -346.80692769837185, 18.627048606161726, 217.07379516489, 22.198611068938632, -106.15225393770385, 305.57653833159617, 144.144911680245, 302.38375013402253, 51.13728024726757, 52.14279292312311, 28.66968037105901, -127.65362362193412, -237.06314096210625, -41.18252402582477, -238.03097174061938, -182.45124342739078, 103.3968106294844, 19.133014450771423, 263.2019012105326, -154.55333381264592, -241.53864824905975, 511.8468305792782, 337.6860513053083, 642.9665185091353, -35.972555198813936, 220.1248800976413, -7.1278644072478325, 390.0710836543283, 52.411648419597704, 56.81080390243436, 214.26565511083845, -151.8014179511369, 116.29201780081411, 76.60077943745934, 355.15078630697025, 99.58962907872535, 22.41619004122982, -217.03882564839517, 54.87260068131367, 26.28307593377285, -87.00802774130402, 310.22159827059085, -127.58829050637706, -151.87398252380365, -173.7703219909752, -201.56874769424255, -146.4723369506976, 219.6008339051171, -209.6529812946473, -142.6471799527512], "policy_AGENT-3_reward": [243.10660402057374, 179.97291283080997, -64.80331321130826, 308.8025354546745, -21.681700555489282, 292.5769581290467, 65.80402929095968, 1.0734497509806982, 297.1506793719865, 21.394823823087414, 151.75076003533457, -88.7091308657235, 171.40702455618137, -95.27383933010198, 313.9724507511812, -33.09015305694143, -146.46077800076964, 194.71524259057648, -8.741522985411759, 309.01095865971905, 226.64364582411915, -9.730271115766374, -120.39926571740655, 220.9892210617342, -60.22649157375212, 263.2541672363589, 112.95178518086846, -64.06728692334677, -79.8781042172754, -33.82586004102893, -100.9109586012779, -13.922569893432414, -12.905539349093148, 120.51514323797065, 185.62719321753005, 207.85514884088857, 223.4168122989322, 291.8448217931456, 153.58045216494082, 167.3952853084907, 261.8369300195204, 161.1169843383186, 283.98466493163426, -81.85790196471336, -11.2172260267945, 178.77121109707537, 262.8450282437233, -51.71592077761091, 265.2767285191404, -54.83243604261957, -117.49549206856237, -44.26675642913412, -37.60716796100374, -77.62104235261995, -159.23640533494046, 267.60861179096753, -60.78089502331474, 270.556464086375, 99.74003931694848, -27.27683929952375, -115.63776663368645, -139.89634775058013, -10.467584867656779, -53.26767827280221, -10.582537565549194, -218.5729209868116, 75.64411570089055, 100.295233335117, 199.82106631827267, -154.31540530324125, -5.95877290065061, 254.33283977443102, -42.62005259350493, 341.8245768898356, -113.87245117933003, 280.8599784347501, -41.62295443614714, 260.93988085069583, 28.473284080550084, 272.2004491586024, 188.32713306789236, -85.88062983331312, 97.38826587059037, 127.85317312049975, 324.9651519248364, 62.863993088159475, -64.90448233049231, -92.52785999878688, 47.3578604901788, -91.66134586529502, -132.36225210212447, 233.56978612421992, -46.566720363379815, -14.266663127931771, -148.14767055839192, -10.240235563968682, -142.01874110298368, 224.788736778024, -166.41390273254507, -1.4555052319869222], "policy_AGENT-2_reward": [-102.86963419788192, 264.9208593514649, -35.589901294793805, 514.0491083709926, 9.463753818334396, 430.0035584691856, 318.7228836155644, 17.35209379346381, 506.5105100864617, -131.75472368322093, 152.87006868036593, -399.1369713559961, 173.15947019478577, -156.89122722425725, 300.1827286934418, -32.96471789001549, -60.05674207966068, 60.45590229381651, -8.851167934264357, -44.123057750966396, 255.11791282974175, -9.784189620045119, -120.39113105102247, 279.60547681464243, -60.28350880038151, 286.9958080676597, -115.86202423412641, 21.434570485690884, -60.618564142494606, -33.82955142687926, -178.49166789299466, -13.814095977523264, -12.859845743711341, -12.79856453114568, 16.812273008467194, 96.81721838792318, 15.30596843930017, -4.789154808679029, 22.014523810610864, 180.40467904385787, 341.8437904840417, -101.35442615393444, 437.678265375716, -37.72108195393476, -11.263335605502931, -105.29124493182445, 325.8163933123167, -51.71980037425885, 325.1531138609893, -54.74872520969073, -387.10359533195776, 18.073801464445353, -37.567834612153504, 21.766943259953877, -159.06121215743389, 62.48180864508601, -60.772320255068664, 139.3038985101008, -111.62180400945192, 51.577964304015595, -115.57105997942064, -139.76361539753665, -10.527563963570074, -64.4219407369568, -10.512285341533866, -28.667505967314696, 26.00035896979709, 18.704648954305178, 233.24660550528267, -165.6878067231779, -5.969310742553626, 475.4181859190429, 400.6140461626332, 565.912458078286, -36.56522081737966, 450.49156742511263, -7.69689190983959, 500.0438601175541, 51.84168874176939, 284.6926744188151, 73.77127851574944, -177.7388864023736, 115.74211033629439, -128.40881480977066, 84.38558501005525, -153.7175561582392, 21.981388782947093, -246.02922616523355, 54.310266210176344, 25.72699267732388, -132.21147203519328, 276.0273515725371, -46.627880001179655, -14.199650451077463, -148.19881244227963, -10.225883602883354, -141.98885122582408, 90.45017891634261, -46.59245332206244, -1.5110672463568102], "policy_AGENT-1_reward": [-102.37930199127153, 189.37568729234943, -63.80952853525881, 417.91332755244696, 4.532172420506896, 444.4910462169556, 293.86943394293945, 25.23955471336295, 391.1499183819173, -131.00758028401748, 188.65625294607833, -88.14391812801583, 201.52920511756432, -94.70729203213094, 76.91013639524307, 159.36621853145385, -59.33947393816698, 142.40325509833326, -59.38493018943814, -43.70172265408015, 28.764854087470262, -256.6015343253189, -220.9278400875644, 291.65780165227864, 41.19727928638787, 27.898101047660273, -115.22209404920511, -39.410405461135426, -57.40442713267614, 190.76315496804744, -183.73428419609857, -172.50153531503653, -91.2985654545693, -12.354496620283697, 17.667043658898248, 97.25144043896685, 15.960051493386157, -4.3593874704856646, 178.91691893626862, 234.08822145503504, 374.82734594096166, -100.87592346669274, 471.95134912115435, -58.787204296210206, 48.07468186858589, -104.68456564386838, 360.4742902585675, 81.66002640793437, 359.34358217555126, 275.47898101763036, -116.93239912054712, -21.253741025519, 186.59840915356097, -51.40917093422803, -106.20377572836038, 62.95637472011004, 114.32876022403023, 139.72803176795216, -111.14314144428246, 0.41405693640434293, 0.2993227220256134, -156.75479957053312, -261.03007187056625, -68.56120524059247, -277.3372686414254, -28.18446171024431, 26.44881493134124, 123.27973184311708, 261.3223050129153, -186.61883759455296, -273.19090736184035, 502.0821669591032, -6.799071004519355, 594.241668989083, -113.30991530803229, 235.45460339242652, -15.385753387712143, 438.5530160027746, 90.19129408889779, 74.90113638959733, 74.20605048974478, -85.31246038431883, 124.45496704330581, -127.9286781692127, 84.99864985626203, -153.10304472576627, -56.82128493799422, -91.96191099256069, 75.05830631411158, -133.4147509596953, -120.77169028567857, 310.14891905500036, -156.63786520243386, -177.79844102700883, -211.826708894211, -156.38763648755378, -185.8143354958955, 177.64222924566278, -45.97916185438408, -168.2194479080242]}, "sampler_perf": {"mean_env_wait_ms": 49.74533293839955, "mean_raw_obs_processing_ms": 2.2502260954034456, "mean_inference_ms": 2.262092723811889, "mean_action_processing_ms": 0.1386557236022185}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 159600, "timers": {"sample_time_ms": 74217.611, "sample_throughput": 56.59, "load_time_ms": 13.462, "load_throughput": 311991.074, "learn_time_ms": 6923.629, "learn_throughput": 606.618, "update_time_ms": 7.959}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 30.26387596130371, "policy_loss": -0.04193633794784546, "vf_loss": 30.298219680786133, "vf_explained_var": 0.9834974408149719, "kl": 0.01686576008796692, "entropy": 1.0207937955856323, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 44.40633773803711, "policy_loss": -0.040130071341991425, "vf_loss": 44.44062423706055, "vf_explained_var": 0.9711411595344543, "kl": 0.012998171150684357, "entropy": 0.8961854577064514, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 28.37332534790039, "policy_loss": -0.04042179882526398, "vf_loss": 28.408140182495117, "vf_explained_var": 0.981773853302002, "kl": 0.012454362586140633, "entropy": 0.8375667929649353, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 45.0062255859375, "policy_loss": -0.03724884241819382, "vf_loss": 45.03942108154297, "vf_explained_var": 0.9768720865249634, "kl": 0.013522275723516941, "entropy": 0.8202580213546753, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 159600, "num_steps_trained": 159600}, "done": false, "episodes_total": 1226, "training_iteration": 38, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-13-04", "timestamp": 1624219984, "time_this_iter_s": 76.53496265411377, "time_total_s": 3519.8547763824463, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c82214d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c82213b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221b90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221b90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221b90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221b90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8221830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3519.8547763824463, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 51.29724770642201, "ram_util_percent": 95.51926605504588}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 2144.9452224663437, "episode_reward_min": -968.3384142194388, "episode_reward_mean": 227.87430932126557, "episode_len_mean": 156.38, "episodes_this_iter": 21, "policy_reward_min": {"AGENT-0": -353.1518899030562, "AGENT-3": -223.80045956630542, "AGENT-2": -399.1369713559961, "AGENT-1": -374.2052247351024}, "policy_reward_max": {"AGENT-0": 642.9665185091353, "AGENT-3": 358.65609964637673, "AGENT-2": 565.912458078286, "AGENT-1": 594.241668989083}, "policy_reward_mean": {"AGENT-0": 73.89277451057195, "AGENT-3": 54.71308128478315, "AGENT-2": 59.32639858557058, "AGENT-1": 39.9420549403398}, "custom_metrics": {"mean_ego_speed_mean": 41.061865, "mean_ego_speed_min": 17.933999999999997, "mean_ego_speed_max": 48.93125, "distance_travelled_mean": 96.1737225, "distance_travelled_min": 44.994, "distance_travelled_max": 124.30125}, "hist_stats": {"episode_reward": [-204.96594149749473, 1696.0616714695705, -290.410402226678, 134.40099589167147, -60.87821853662277, 952.1315233650989, 548.5315302637233, 785.1932921683988, -174.34268819249144, 453.85986361483725, 176.08958115020712, 883.6978803475117, -95.97973460391607, 243.57952095091082, 1082.5446106594252, -269.8741933270663, 1033.7697448371994, -955.2980110514737, -709.2186215566826, -149.21103306315896, 794.6280549927449, 177.22449095992346, 1359.3746146547949, 26.323925511307742, 1338.6821651133328, 473.27488355718697, -968.3384142194388, -28.819647384045986, 328.49720174529386, -85.0646589579555, -530.6536471584387, 698.6233334877601, 136.92045662589177, 851.9721444984497, -71.88762588951845, 76.85797486401921, -202.23982352002267, -564.0683863405839, -519.0883616638985, -227.43334827617622, -536.4630632891276, -457.8761320917614, 231.49010023151322, 261.4126285833107, 957.5918780470026, -661.1753834336183, -526.657639254104, 1743.6800232318546, 688.8809738699172, 2144.9452224663437, -299.72014250355613, 1186.931029349931, -71.83346414094662, 1589.607840625354, 222.91791533081488, 688.6050638694495, 550.5701171842251, -500.7333945711425, 453.8773610510049, -51.883540421024115, 849.5001730981236, -144.36697871712042, -77.3281884443096, -647.5578228049761, 231.59903369578063, -173.06602821389365, -472.3534421643011, 1129.967655022348, -377.4207560733705, -358.13873712982155, -681.9435138858579, -378.422503348648, -616.2942647754003, 712.4819788451464, -468.6384992036389, -313.83320033911923, 292.7082315328096, 899.7517308403199, -199.2203546781441, 1658.8755896090274, 2.3662576662843797, 1597.8156915131124, 932.3191206581921, 61.59180191589343, 1599.6671569000825, -187.8455218073214, 672.8089078008135, -929.1419102527917, 774.0862654110033, -481.3134447236774, 768.0700694822904, 204.6478548640685, -386.1473515821587, 576.0037257168628, -136.09225293032043, 560.2688706308802, 539.2443423374402, -485.96140599208934, -642.0321941663841, 1122.1407484203808], "episode_lengths": [104, 172, 102, 191, 102, 162, 477, 187, 121, 121, 224, 129, 183, 617, 153, 97, 118, 176, 163, 113, 119, 137, 171, 103, 171, 154, 169, 102, 133, 105, 42, 149, 131, 134, 116, 106, 128, 125, 169, 122, 158, 135, 219, 99, 134, 133, 159, 174, 150, 184, 98, 194, 102, 177, 105, 184, 114, 123, 113, 172, 139, 212, 114, 124, 123, 109, 155, 146, 127, 123, 178, 140, 161, 161, 121, 138, 212, 192, 104, 177, 103, 182, 162, 101, 171, 183, 260, 178, 128, 115, 535, 116, 117, 199, 64, 204, 119, 177, 158, 185], "policy_AGENT-0_reward": [-35.43922686719543, 487.5017231714546, -43.15562675928727, 183.6366203643738, -6.750365018159323, 221.26968937369827, 46.578129120449866, 247.11288232677379, 65.1322644377487, 62.04501865710067, 190.9403675587358, 262.348338384413, -1.9081582360460063, -62.31490396503538, 307.0482725443483, -77.44669389396597, 245.87727609757553, -255.16666282459522, -339.26330903041054, -52.286202922480655, 184.2486793968538, 208.42909043854092, 410.2389028401885, 48.09962025524303, 388.9087405576517, 307.377063791867, -346.80692769837185, 18.627048606161726, 217.07379516489, 22.198611068938632, -106.15225393770385, 305.57653833159617, 144.144911680245, 302.38375013402253, 51.13728024726757, 52.14279292312311, 28.66968037105901, -127.65362362193412, -237.06314096210625, -41.18252402582477, -238.03097174061938, -182.45124342739078, 103.3968106294844, 19.133014450771423, 263.2019012105326, -154.55333381264592, -241.53864824905975, 511.8468305792782, 337.6860513053083, 642.9665185091353, -35.972555198813936, 220.1248800976413, -7.1278644072478325, 390.0710836543283, 52.411648419597704, 56.81080390243436, 214.26565511083845, -151.8014179511369, 116.29201780081411, 76.60077943745934, 355.15078630697025, 99.58962907872535, 22.41619004122982, -217.03882564839517, 54.87260068131367, 26.28307593377285, -87.00802774130402, 310.22159827059085, -127.58829050637706, -151.87398252380365, -173.7703219909752, -201.56874769424255, -146.4723369506976, 219.6008339051171, -209.6529812946473, -142.6471799527512, 254.8505637013893, 265.48227136569534, -35.017611636783194, 418.1106182309148, 10.052031982932345, 430.74412869792434, 253.9227738087297, 17.926703658085877, 404.85604905971684, 53.52195833682982, 179.53182613903525, -353.1518899030562, 227.99056554247227, -134.4410861371875, 77.00475364242277, 111.33650727957155, -120.29035756356153, 178.42932573413705, -59.114631821206174, 339.08269237620794, 28.71792959610929, -209.84541093095922, -180.3139573103909, 329.88824889172525], "policy_AGENT-3_reward": [-91.69055287059257, 279.3316843770831, -114.16128420616089, -123.09581619680614, -36.25533114772497, 358.65609964637673, 110.11164205561192, 38.84342520695403, 39.25836489506712, 156.98467029273849, -85.44629157741534, 196.24136587053394, -29.47065817333525, 137.63060674643543, 148.5297314959168, -42.540994883159215, 238.11676290954773, -223.80045956630542, 2.1066872872319333, -10.79476409923577, 181.06174763222, 178.77121109707537, 262.8450282437233, -51.71592077761091, 265.2767285191404, -54.83243604261957, -117.49549206856237, -44.26675642913412, -37.60716796100374, -77.62104235261995, -159.23640533494046, 267.60861179096753, -60.78089502331474, 270.556464086375, 99.74003931694848, -27.27683929952375, -115.63776663368645, -139.89634775058013, -10.467584867656779, -53.26767827280221, -10.582537565549194, -218.5729209868116, 75.64411570089055, 100.295233335117, 199.82106631827267, -154.31540530324125, -5.95877290065061, 254.33283977443102, -42.62005259350493, 341.8245768898356, -113.87245117933003, 280.8599784347501, -41.62295443614714, 260.93988085069583, 28.473284080550084, 272.2004491586024, 188.32713306789236, -85.88062983331312, 97.38826587059037, 127.85317312049975, 324.9651519248364, 62.863993088159475, -64.90448233049231, -92.52785999878688, 47.3578604901788, -91.66134586529502, -132.36225210212447, 233.56978612421992, -46.566720363379815, -14.266663127931771, -148.14767055839192, -10.240235563968682, -142.01874110298368, 224.788736778024, -166.41390273254507, -1.4555052319869222, 243.10660402057374, 179.97291283080997, -64.80331321130826, 308.8025354546745, -21.681700555489282, 292.5769581290467, 65.80402929095968, 1.0734497509806982, 297.1506793719865, 21.394823823087414, 151.75076003533457, -88.7091308657235, 171.40702455618137, -95.27383933010198, 313.9724507511812, -33.09015305694143, -146.46077800076964, 194.71524259057648, -8.741522985411759, 309.01095865971905, 226.64364582411915, -9.730271115766374, -120.39926571740655, 220.9892210617342], "policy_AGENT-2_reward": [-35.86834720809317, 450.8360739350072, -43.60078522125928, 183.06571641516288, -7.330194592322016, 118.13264827137621, 206.54018399437015, 276.9511108049622, -139.58041331935488, 108.02994371333835, -85.50095223220903, 189.20878376126868, -29.4423305968285, 230.70169925943298, 276.01324273039194, -72.28798835432958, 245.26183701257094, -186.3022753075393, 2.1432249215983044, -10.811423475579907, 183.66436376762184, -105.29124493182445, 325.8163933123167, -51.71980037425885, 325.1531138609893, -54.74872520969073, -387.10359533195776, 18.073801464445353, -37.567834612153504, 21.766943259953877, -159.06121215743389, 62.48180864508601, -60.772320255068664, 139.3038985101008, -111.62180400945192, 51.577964304015595, -115.57105997942064, -139.76361539753665, -10.527563963570074, -64.4219407369568, -10.512285341533866, -28.667505967314696, 26.00035896979709, 18.704648954305178, 233.24660550528267, -165.6878067231779, -5.969310742553626, 475.4181859190429, 400.6140461626332, 565.912458078286, -36.56522081737966, 450.49156742511263, -7.69689190983959, 500.0438601175541, 51.84168874176939, 284.6926744188151, 73.77127851574944, -177.7388864023736, 115.74211033629439, -128.40881480977066, 84.38558501005525, -153.7175561582392, 21.981388782947093, -246.02922616523355, 54.310266210176344, 25.72699267732388, -132.21147203519328, 276.0273515725371, -46.627880001179655, -14.199650451077463, -148.19881244227963, -10.225883602883354, -141.98885122582408, 90.45017891634261, -46.59245332206244, -1.5110672463568102, -102.86963419788192, 264.9208593514649, -35.589901294793805, 514.0491083709926, 9.463753818334396, 430.0035584691856, 318.7228836155644, 17.35209379346381, 506.5105100864617, -131.75472368322093, 152.87006868036593, -399.1369713559961, 173.15947019478577, -156.89122722425725, 300.1827286934418, -32.96471789001549, -60.05674207966068, 60.45590229381651, -8.851167934264357, -44.123057750966396, 255.11791282974175, -9.784189620045119, -120.39113105102247, 279.60547681464243], "policy_AGENT-1_reward": [-41.967814551613586, 478.39218998602576, -89.49270603997061, -109.20552469105904, -10.542327778416357, 254.07308607364706, 185.30157509329158, 222.28587382970846, -139.15290420595264, 126.80023095165977, 156.09645740109596, 235.899392331296, -35.15858759770633, -62.437881089922236, 350.9533638887681, -77.59851619561164, 304.5138688175047, -290.0286133530346, -374.2052247351024, -75.31864256586262, 245.6532641960487, -104.68456564386838, 360.4742902585675, 81.66002640793437, 359.34358217555126, 275.47898101763036, -116.93239912054712, -21.253741025519, 186.59840915356097, -51.40917093422803, -106.20377572836038, 62.95637472011004, 114.32876022403023, 139.72803176795216, -111.14314144428246, 0.41405693640434293, 0.2993227220256134, -156.75479957053312, -261.03007187056625, -68.56120524059247, -277.3372686414254, -28.18446171024431, 26.44881493134124, 123.27973184311708, 261.3223050129153, -186.61883759455296, -273.19090736184035, 502.0821669591032, -6.799071004519355, 594.241668989083, -113.30991530803229, 235.45460339242652, -15.385753387712143, 438.5530160027746, 90.19129408889779, 74.90113638959733, 74.20605048974478, -85.31246038431883, 124.45496704330581, -127.9286781692127, 84.99864985626203, -153.10304472576627, -56.82128493799422, -91.96191099256069, 75.05830631411158, -133.4147509596953, -120.77169028567857, 310.14891905500036, -156.63786520243386, -177.79844102700883, -211.826708894211, -156.38763648755378, -185.8143354958955, 177.64222924566278, -45.97916185438408, -168.2194479080242, -102.37930199127153, 189.37568729234943, -63.80952853525881, 417.91332755244696, 4.532172420506896, 444.4910462169556, 293.86943394293945, 25.23955471336295, 391.1499183819173, -131.00758028401748, 188.65625294607833, -88.14391812801583, 201.52920511756432, -94.70729203213094, 76.91013639524307, 159.36621853145385, -59.33947393816698, 142.40325509833326, -59.38493018943814, -43.70172265408015, 28.764854087470262, -256.6015343253189, -220.9278400875644, 291.65780165227864]}, "sampler_perf": {"mean_env_wait_ms": 49.554512631032, "mean_raw_obs_processing_ms": 2.2352857084911704, "mean_inference_ms": 2.255995002420151, "mean_action_processing_ms": 0.13823687386042138}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 163800, "timers": {"sample_time_ms": 73758.916, "sample_throughput": 56.942, "load_time_ms": 13.43, "load_throughput": 312722.155, "learn_time_ms": 6841.38, "learn_throughput": 613.911, "update_time_ms": 7.96}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 42.25663375854492, "policy_loss": -0.04451586678624153, "vf_loss": 42.29427719116211, "vf_explained_var": 0.9782548546791077, "kl": 0.015266754664480686, "entropy": 0.984931468963623, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 33.18431091308594, "policy_loss": -0.048585228621959686, "vf_loss": 33.22532653808594, "vf_explained_var": 0.9836041331291199, "kl": 0.01681930385529995, "entropy": 0.8908222913742065, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 24.414960861206055, "policy_loss": -0.034294623881578445, "vf_loss": 24.44365119934082, "vf_explained_var": 0.9812166094779968, "kl": 0.012461641803383827, "entropy": 0.7632478475570679, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 40.93009948730469, "policy_loss": -0.04341498017311096, "vf_loss": 40.96836853027344, "vf_explained_var": 0.9807377457618713, "kl": 0.017141392454504967, "entropy": 0.8390883803367615, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 163800, "num_steps_trained": 163800}, "done": false, "episodes_total": 1247, "training_iteration": 39, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-14-23", "timestamp": 1624220063, "time_this_iter_s": 78.2176501750946, "time_total_s": 3598.072426557541, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c820ed40>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c84aec20>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c824ac20>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c824add0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c824ad40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5dd0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c824ac20>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c824add0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c824ad40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5dd0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c824ac20>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c824add0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c824ad40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5dd0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c824ac20>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c824add0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c824ad40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d5dd0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8221dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3598.072426557541, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 49.01875, "ram_util_percent": 95.53750000000001}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 2169.134935964628, "episode_reward_min": -1336.2080377365148, "episode_reward_mean": 290.87270590028265, "episode_len_mean": 165.99, "episodes_this_iter": 26, "policy_reward_min": {"AGENT-2": -401.0789641908, "AGENT-1": -410.5591093354327, "AGENT-0": -371.9088580120792, "AGENT-3": -295.15664999132866}, "policy_reward_max": {"AGENT-2": 638.0668449490066, "AGENT-1": 627.0663865518512, "AGENT-0": 642.9665185091353, "AGENT-3": 358.65609964637673}, "policy_reward_mean": {"AGENT-2": 80.57002517368612, "AGENT-1": 52.065768528199385, "AGENT-0": 86.54493172384745, "AGENT-3": 71.69198047454968}, "custom_metrics": {"mean_ego_speed_mean": 40.437115000000006, "mean_ego_speed_min": 17.933999999999997, "mean_ego_speed_max": 46.632000000000005, "distance_travelled_mean": 95.985535, "distance_travelled_min": 45.47175, "distance_travelled_max": 124.2115}, "hist_stats": {"episode_reward": [2169.134935964628, -177.5254363873429, 592.218320829597, 92.43684666279768, 800.0249233809168, 180.69709573962612, 1413.1869874961303, 583.1003136891909, 2000.7073886430953, -275.94647017676954, 756.2259448948749, 66.15749851269447, -173.54352270955448, -916.0669067126842, 51.85480693722695, 400.384796973735, 796.3667198225654, 297.9073021483962, -51.16253632569874, -448.2623735745014, 1137.3782826568797, -391.2214923711017, -529.4369070610445, -1336.2080377365148, 669.4909521864142, 130.41989081925195, 1743.6800232318546, 688.8809738699172, 2144.9452224663437, -299.72014250355613, 1186.931029349931, -71.83346414094662, 1589.607840625354, 222.91791533081488, 688.6050638694495, 550.5701171842251, -500.7333945711425, 453.8773610510049, -51.883540421024115, 849.5001730981236, -144.36697871712042, -77.3281884443096, -647.5578228049761, 231.59903369578063, -173.06602821389365, -472.3534421643011, 1129.967655022348, -377.4207560733705, -358.13873712982155, -681.9435138858579, -378.422503348648, -616.2942647754003, 712.4819788451464, -468.6384992036389, -313.83320033911923, 292.7082315328096, 899.7517308403199, -199.2203546781441, 1658.8755896090274, 2.3662576662843797, 1597.8156915131124, 932.3191206581921, 61.59180191589343, 1599.6671569000825, -187.8455218073214, 672.8089078008135, -929.1419102527917, 774.0862654110033, -481.3134447236774, 768.0700694822904, 204.6478548640685, -386.1473515821587, 576.0037257168628, -136.09225293032043, 560.2688706308802, 539.2443423374402, -485.96140599208934, -642.0321941663841, 1122.1407484203808, -204.96594149749473, 1696.0616714695705, -290.410402226678, 134.40099589167147, -60.87821853662277, 952.1315233650989, 548.5315302637233, 785.1932921683988, -174.34268819249144, 453.85986361483725, 176.08958115020712, 883.6978803475117, -95.97973460391607, 243.57952095091082, 1082.5446106594252, -269.8741933270663, 1033.7697448371994, -955.2980110514737, -709.2186215566826, -149.21103306315896, 794.6280549927449], "episode_lengths": [180, 111, 186, 82, 184, 124, 180, 105, 187, 111, 564, 134, 155, 234, 180, 130, 113, 135, 138, 257, 152, 115, 184, 190, 241, 93, 174, 150, 184, 98, 194, 102, 177, 105, 184, 114, 123, 113, 172, 139, 212, 114, 124, 123, 109, 155, 146, 127, 123, 178, 140, 161, 161, 121, 138, 212, 192, 104, 177, 103, 182, 162, 101, 171, 183, 260, 178, 128, 115, 535, 116, 117, 199, 64, 204, 119, 177, 158, 185, 104, 172, 102, 191, 102, 162, 477, 187, 121, 121, 224, 129, 183, 617, 153, 97, 118, 176, 163, 113, 119], "policy_AGENT-2_reward": [638.0668449490066, -27.22712364153838, 234.19504968243814, 21.617437786001958, 184.56053697376026, -90.52337289955089, 395.6848358732544, 137.6280144865472, 547.6031502260502, -41.05321824063986, 370.19163692616405, -109.26366953981434, -110.21328803757459, -401.0789641908, 44.27625611507938, -29.85439216658885, 171.75041597245877, -40.12361513265327, -33.57244961543064, -20.993056043974754, 287.4134758968494, -64.79360244836174, -5.429988477810267, -258.5834203976741, 14.5030803871202, 22.69999542162401, 475.4181859190429, 400.6140461626332, 565.912458078286, -36.56522081737966, 450.49156742511263, -7.69689190983959, 500.0438601175541, 51.84168874176939, 284.6926744188151, 73.77127851574944, -177.7388864023736, 115.74211033629439, -128.40881480977066, 84.38558501005525, -153.7175561582392, 21.981388782947093, -246.02922616523355, 54.310266210176344, 25.72699267732388, -132.21147203519328, 276.0273515725371, -46.627880001179655, -14.199650451077463, -148.19881244227963, -10.225883602883354, -141.98885122582408, 90.45017891634261, -46.59245332206244, -1.5110672463568102, -102.86963419788192, 264.9208593514649, -35.589901294793805, 514.0491083709926, 9.463753818334396, 430.0035584691856, 318.7228836155644, 17.35209379346381, 506.5105100864617, -131.75472368322093, 152.87006868036593, -399.1369713559961, 173.15947019478577, -156.89122722425725, 300.1827286934418, -32.96471789001549, -60.05674207966068, 60.45590229381651, -8.851167934264357, -44.123057750966396, 255.11791282974175, -9.784189620045119, -120.39113105102247, 279.60547681464243, -35.86834720809317, 450.8360739350072, -43.60078522125928, 183.06571641516288, -7.330194592322016, 118.13264827137621, 206.54018399437015, 276.9511108049622, -139.58041331935488, 108.02994371333835, -85.50095223220903, 189.20878376126868, -29.4423305968285, 230.70169925943298, 276.01324273039194, -72.28798835432958, 245.26183701257094, -186.3022753075393, 2.1432249215983044, -10.811423475579907, 183.66436376762184], "policy_AGENT-1_reward": [627.0663865518512, -57.80635777947397, 68.61425910041497, 24.6037528931586, 144.4739380689875, -89.88148045988449, 438.26149716054795, 166.77078322720376, 559.2742215491461, -93.14229144143653, 34.52391882016279, -108.82860041003653, -47.389840388337376, -88.92100002543856, -30.402998700201074, 252.7967010870585, 222.2517646688928, 173.42895413714638, -33.13338618955255, -239.35030323675133, 299.6040198738975, -126.90816874361903, -282.55118859730464, -410.5591093354327, 15.17607009140032, 23.428158148139282, 502.0821669591032, -6.799071004519355, 594.241668989083, -113.30991530803229, 235.45460339242652, -15.385753387712143, 438.5530160027746, 90.19129408889779, 74.90113638959733, 74.20605048974478, -85.31246038431883, 124.45496704330581, -127.9286781692127, 84.99864985626203, -153.10304472576627, -56.82128493799422, -91.96191099256069, 75.05830631411158, -133.4147509596953, -120.77169028567857, 310.14891905500036, -156.63786520243386, -177.79844102700883, -211.826708894211, -156.38763648755378, -185.8143354958955, 177.64222924566278, -45.97916185438408, -168.2194479080242, -102.37930199127153, 189.37568729234943, -63.80952853525881, 417.91332755244696, 4.532172420506896, 444.4910462169556, 293.86943394293945, 25.23955471336295, 391.1499183819173, -131.00758028401748, 188.65625294607833, -88.14391812801583, 201.52920511756432, -94.70729203213094, 76.91013639524307, 159.36621853145385, -59.33947393816698, 142.40325509833326, -59.38493018943814, -43.70172265408015, 28.764854087470262, -256.6015343253189, -220.9278400875644, 291.65780165227864, -41.967814551613586, 478.39218998602576, -89.49270603997061, -109.20552469105904, -10.542327778416357, 254.07308607364706, 185.30157509329158, 222.28587382970846, -139.15290420595264, 126.80023095165977, 156.09645740109596, 235.899392331296, -35.15858759770633, -62.437881089922236, 350.9533638887681, -77.59851619561164, 304.5138688175047, -290.0286133530346, -374.2052247351024, -75.31864256586262, 245.6532641960487], "policy_AGENT-0_reward": [597.8419465759716, -26.674821765414272, 234.7576697041618, 22.176311519896522, 126.25563741917419, 194.59723675901574, 362.86401604641827, 138.18662637563358, 575.5427243560717, -40.61533320699639, 34.49949721821386, 157.31781967837716, -20.462631145619795, -336.57743860538795, 23.55114364762779, 207.56421537537412, 198.44146069596843, 204.77522405960994, -2.6762410478995164, -166.9114924932896, 325.8254290390179, -64.2374932930799, -236.0793744201505, -371.9088580120792, 319.1826178541076, 23.28671421875184, 511.8468305792782, 337.6860513053083, 642.9665185091353, -35.972555198813936, 220.1248800976413, -7.1278644072478325, 390.0710836543283, 52.411648419597704, 56.81080390243436, 214.26565511083845, -151.8014179511369, 116.29201780081411, 76.60077943745934, 355.15078630697025, 99.58962907872535, 22.41619004122982, -217.03882564839517, 54.87260068131367, 26.28307593377285, -87.00802774130402, 310.22159827059085, -127.58829050637706, -151.87398252380365, -173.7703219909752, -201.56874769424255, -146.4723369506976, 219.6008339051171, -209.6529812946473, -142.6471799527512, 254.8505637013893, 265.48227136569534, -35.017611636783194, 418.1106182309148, 10.052031982932345, 430.74412869792434, 253.9227738087297, 17.926703658085877, 404.85604905971684, 53.52195833682982, 179.53182613903525, -353.1518899030562, 227.99056554247227, -134.4410861371875, 77.00475364242277, 111.33650727957155, -120.29035756356153, 178.42932573413705, -59.114631821206174, 339.08269237620794, 28.71792959610929, -209.84541093095922, -180.3139573103909, 329.88824889172525, -35.43922686719543, 487.5017231714546, -43.15562675928727, 183.6366203643738, -6.750365018159323, 221.26968937369827, 46.578129120449866, 247.11288232677379, 65.1322644377487, 62.04501865710067, 190.9403675587358, 262.348338384413, -1.9081582360460063, -62.31490396503538, 307.0482725443483, -77.44669389396597, 245.87727609757553, -255.16666282459522, -339.26330903041054, -52.286202922480655, 184.2486793968538], "policy_AGENT-3_reward": [306.1597578877974, -65.81713320091629, 54.65134234258258, 24.039344463740605, 344.7348109189958, 166.50471234004587, 216.37663841590998, 140.5148895998065, 318.2872925118298, -101.13562728769678, 317.0108919303348, 126.93194878416806, 4.522236861977113, -89.48950389105721, 14.430405874720968, -30.12172732210874, 203.92307848524553, -40.17326091570695, 18.219540527183987, -21.0075218004864, 224.53535784711522, -135.2822278860409, -5.376355565778818, -295.15664999132866, 320.6291838537856, 61.00502303073686, 254.33283977443102, -42.62005259350493, 341.8245768898356, -113.87245117933003, 280.8599784347501, -41.62295443614714, 260.93988085069583, 28.473284080550084, 272.2004491586024, 188.32713306789236, -85.88062983331312, 97.38826587059037, 127.85317312049975, 324.9651519248364, 62.863993088159475, -64.90448233049231, -92.52785999878688, 47.3578604901788, -91.66134586529502, -132.36225210212447, 233.56978612421992, -46.566720363379815, -14.266663127931771, -148.14767055839192, -10.240235563968682, -142.01874110298368, 224.788736778024, -166.41390273254507, -1.4555052319869222, 243.10660402057374, 179.97291283080997, -64.80331321130826, 308.8025354546745, -21.681700555489282, 292.5769581290467, 65.80402929095968, 1.0734497509806982, 297.1506793719865, 21.394823823087414, 151.75076003533457, -88.7091308657235, 171.40702455618137, -95.27383933010198, 313.9724507511812, -33.09015305694143, -146.46077800076964, 194.71524259057648, -8.741522985411759, 309.01095865971905, 226.64364582411915, -9.730271115766374, -120.39926571740655, 220.9892210617342, -91.69055287059257, 279.3316843770831, -114.16128420616089, -123.09581619680614, -36.25533114772497, 358.65609964637673, 110.11164205561192, 38.84342520695403, 39.25836489506712, 156.98467029273849, -85.44629157741534, 196.24136587053394, -29.47065817333525, 137.63060674643543, 148.5297314959168, -42.540994883159215, 238.11676290954773, -223.80045956630542, 2.1066872872319333, -10.79476409923577, 181.06174763222]}, "sampler_perf": {"mean_env_wait_ms": 49.31614059886375, "mean_raw_obs_processing_ms": 2.210936221588032, "mean_inference_ms": 2.2480369782348415, "mean_action_processing_ms": 0.1376442283995942}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 168000, "timers": {"sample_time_ms": 73581.788, "sample_throughput": 57.079, "load_time_ms": 13.53, "load_throughput": 310411.621, "learn_time_ms": 6795.86, "learn_throughput": 618.023, "update_time_ms": 7.794}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 46.98695373535156, "policy_loss": -0.04231121018528938, "vf_loss": 47.02286148071289, "vf_explained_var": 0.9742640256881714, "kl": 0.014219709672033787, "entropy": 0.9866786003112793, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 46.88847732543945, "policy_loss": -0.040214937180280685, "vf_loss": 46.92184066772461, "vf_explained_var": 0.9776633977890015, "kl": 0.015231668949127197, "entropy": 0.864586591720581, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 40.8973503112793, "policy_loss": -0.037935495376586914, "vf_loss": 40.92844009399414, "vf_explained_var": 0.9769679307937622, "kl": 0.015208926983177662, "entropy": 0.9138989448547363, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 62.53720474243164, "policy_loss": -0.03503081575036049, "vf_loss": 62.56790542602539, "vf_explained_var": 0.9752832651138306, "kl": 0.014424026943743229, "entropy": 0.820305347442627, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 168000, "num_steps_trained": 168000}, "done": false, "episodes_total": 1273, "training_iteration": 40, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-15-40", "timestamp": 1624220140, "time_this_iter_s": 77.52733826637268, "time_total_s": 3675.5997648239136, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c80f94d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c80f93b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f9170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f9050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f9a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f9b90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f9170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f9050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f9a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f9b90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f9170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f9050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f9a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f9b90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f9170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f9050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f9a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f9b90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c80f9830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3675.5997648239136, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 52.98378378378377, "ram_util_percent": 95.57567567567567}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 2169.134935964628, "episode_reward_min": -1615.4450582630618, "episode_reward_mean": 340.703671297153, "episode_len_mean": 171.34, "episodes_this_iter": 25, "policy_reward_min": {"AGENT-2": -479.24790320973545, "AGENT-1": -410.5591093354327, "AGENT-0": -521.2572281626196, "AGENT-3": -583.5129707476556}, "policy_reward_max": {"AGENT-2": 638.0668449490066, "AGENT-1": 627.0663865518512, "AGENT-0": 597.8419465759716, "AGENT-3": 549.1574183898261}, "policy_reward_mean": {"AGENT-2": 78.17590160483516, "AGENT-1": 71.33831985854141, "AGENT-0": 104.13737720316169, "AGENT-3": 87.05207263061482}, "custom_metrics": {"mean_ego_speed_mean": 40.2066125, "mean_ego_speed_min": 15.849249999999998, "mean_ego_speed_max": 49.214749999999995, "distance_travelled_mean": 93.00302749999999, "distance_travelled_min": 28.088250000000002, "distance_travelled_max": 124.2115}, "hist_stats": {"episode_reward": [1803.937369641626, 465.8146740700525, 1603.9253171605726, 606.4697317346601, 1585.1064494130594, 531.313890240034, 1691.6995883868458, 932.1202672205003, 2090.17681328835, -142.16822755215486, -1104.5110929577486, 487.21354027517776, 609.3843964060394, 33.30080205839741, 433.3770002907772, 396.09382038530345, 702.5829409932405, 287.6648536115021, 773.2268030402706, 90.00198885253012, -365.4801504264878, -1615.4450582630618, -264.4427157227848, -149.4457405048845, 747.4931744213969, -616.2942647754003, 712.4819788451464, -468.6384992036389, -313.83320033911923, 292.7082315328096, 899.7517308403199, -199.2203546781441, 1658.8755896090274, 2.3662576662843797, 1597.8156915131124, 932.3191206581921, 61.59180191589343, 1599.6671569000825, -187.8455218073214, 672.8089078008135, -929.1419102527917, 774.0862654110033, -481.3134447236774, 768.0700694822904, 204.6478548640685, -386.1473515821587, 576.0037257168628, -136.09225293032043, 560.2688706308802, 539.2443423374402, -485.96140599208934, -642.0321941663841, 1122.1407484203808, -204.96594149749473, 1696.0616714695705, -290.410402226678, 134.40099589167147, -60.87821853662277, 952.1315233650989, 548.5315302637233, 785.1932921683988, -174.34268819249144, 453.85986361483725, 176.08958115020712, 883.6978803475117, -95.97973460391607, 243.57952095091082, 1082.5446106594252, -269.8741933270663, 1033.7697448371994, -955.2980110514737, -709.2186215566826, -149.21103306315896, 794.6280549927449, 2169.134935964628, -177.5254363873429, 592.218320829597, 92.43684666279768, 800.0249233809168, 180.69709573962612, 1413.1869874961303, 583.1003136891909, 2000.7073886430953, -275.94647017676954, 756.2259448948749, 66.15749851269447, -173.54352270955448, -916.0669067126842, 51.85480693722695, 400.384796973735, 796.3667198225654, 297.9073021483962, -51.16253632569874, -448.2623735745014, 1137.3782826568797, -391.2214923711017, -529.4369070610445, -1336.2080377365148, 669.4909521864142, 130.41989081925195], "episode_lengths": [186, 264, 138, 103, 178, 136, 163, 136, 184, 118, 263, 130, 120, 112, 206, 136, 243, 100, 272, 114, 156, 255, 113, 33, 256, 161, 161, 121, 138, 212, 192, 104, 177, 103, 182, 162, 101, 171, 183, 260, 178, 128, 115, 535, 116, 117, 199, 64, 204, 119, 177, 158, 185, 104, 172, 102, 191, 102, 162, 477, 187, 121, 121, 224, 129, 183, 617, 153, 97, 118, 176, 163, 113, 119, 180, 111, 186, 82, 184, 124, 180, 105, 187, 111, 564, 134, 155, 234, 180, 130, 113, 135, 138, 257, 152, 115, 184, 190, 241, 93], "policy_AGENT-2_reward": [578.3738321650106, -93.96339975248843, 433.03501683781946, 146.54968636603869, 385.73582093284165, 144.08908404678178, 426.97093664254567, 235.6499299577972, 583.715536929746, 24.101829609418168, -479.24790320973545, 35.67029463484349, 52.130060710391405, -28.3740421913454, -30.483844084806623, -43.148822384977095, -29.52983636352951, 13.828916265790198, -31.546142080332363, 39.37606538953172, -11.852528913394243, -255.55405437677064, -10.87989688389856, -9.173855756005137, -35.54588220352303, -141.98885122582408, 90.45017891634261, -46.59245332206244, -1.5110672463568102, -102.86963419788192, 264.9208593514649, -35.589901294793805, 514.0491083709926, 9.463753818334396, 430.0035584691856, 318.7228836155644, 17.35209379346381, 506.5105100864617, -131.75472368322093, 152.87006868036593, -399.1369713559961, 173.15947019478577, -156.89122722425725, 300.1827286934418, -32.96471789001549, -60.05674207966068, 60.45590229381651, -8.851167934264357, -44.123057750966396, 255.11791282974175, -9.784189620045119, -120.39113105102247, 279.60547681464243, -35.86834720809317, 450.8360739350072, -43.60078522125928, 183.06571641516288, -7.330194592322016, 118.13264827137621, 206.54018399437015, 276.9511108049622, -139.58041331935488, 108.02994371333835, -85.50095223220903, 189.20878376126868, -29.4423305968285, 230.70169925943298, 276.01324273039194, -72.28798835432958, 245.26183701257094, -186.3022753075393, 2.1432249215983044, -10.811423475579907, 183.66436376762184, 638.0668449490066, -27.22712364153838, 234.19504968243814, 21.617437786001958, 184.56053697376026, -90.52337289955089, 395.6848358732544, 137.6280144865472, 547.6031502260502, -41.05321824063986, 370.19163692616405, -109.26366953981434, -110.21328803757459, -401.0789641908, 44.27625611507938, -29.85439216658885, 171.75041597245877, -40.12361513265327, -33.57244961543064, -20.993056043974754, 287.4134758968494, -64.79360244836174, -5.429988477810267, -258.5834203976741, 14.5030803871202, 22.69999542162401], "policy_AGENT-1_reward": [554.1023309468588, -93.43199060478582, 433.4861924117888, 176.06935684699465, 402.5561619145705, 163.8764608499265, 427.40999045713033, 277.5214111405447, 598.1024635015661, -93.77978973605374, -91.04970176863466, 157.7404319881252, 52.823540689672235, 56.448492457089884, 219.56818857371317, 226.52077114994998, -29.02288844110058, 141.88755134292995, -31.03515697908131, 15.32504155966576, -188.85625352570995, -255.1208049760161, -96.4045219109796, -65.53513825571827, -35.115439784633935, -185.8143354958955, 177.64222924566278, -45.97916185438408, -168.2194479080242, -102.37930199127153, 189.37568729234943, -63.80952853525881, 417.91332755244696, 4.532172420506896, 444.4910462169556, 293.86943394293945, 25.23955471336295, 391.1499183819173, -131.00758028401748, 188.65625294607833, -88.14391812801583, 201.52920511756432, -94.70729203213094, 76.91013639524307, 159.36621853145385, -59.33947393816698, 142.40325509833326, -59.38493018943814, -43.70172265408015, 28.764854087470262, -256.6015343253189, -220.9278400875644, 291.65780165227864, -41.967814551613586, 478.39218998602576, -89.49270603997061, -109.20552469105904, -10.542327778416357, 254.07308607364706, 185.30157509329158, 222.28587382970846, -139.15290420595264, 126.80023095165977, 156.09645740109596, 235.899392331296, -35.15858759770633, -62.437881089922236, 350.9533638887681, -77.59851619561164, 304.5138688175047, -290.0286133530346, -374.2052247351024, -75.31864256586262, 245.6532641960487, 627.0663865518512, -57.80635777947397, 68.61425910041497, 24.6037528931586, 144.4739380689875, -89.88148045988449, 438.26149716054795, 166.77078322720376, 559.2742215491461, -93.14229144143653, 34.52391882016279, -108.82860041003653, -47.389840388337376, -88.92100002543856, -30.402998700201074, 252.7967010870585, 222.2517646688928, 173.42895413714638, -33.13338618955255, -239.35030323675133, 299.6040198738975, -126.90816874361903, -282.55118859730464, -410.5591093354327, 15.17607009140032, 23.428158148139282], "policy_AGENT-0_reward": [520.4778465436485, 344.0971650613871, 188.24668952113808, 147.14051424784572, 450.31507089477236, 144.66090134711817, 515.144809823985, 236.21728717343765, 597.5052555591442, 24.530785952658082, -442.60256628629725, 146.29679133478544, 265.64621146904506, 33.599929707782685, 274.82133817060276, 256.00699674024094, 377.820262058066, 14.387707230552168, 423.3608946073275, 39.93727937513889, -152.7487724189843, -521.2572281626196, -146.3354369232993, -65.65861903894668, 421.49354941003963, -146.4723369506976, 219.6008339051171, -209.6529812946473, -142.6471799527512, 254.8505637013893, 265.48227136569534, -35.017611636783194, 418.1106182309148, 10.052031982932345, 430.74412869792434, 253.9227738087297, 17.926703658085877, 404.85604905971684, 53.52195833682982, 179.53182613903525, -353.1518899030562, 227.99056554247227, -134.4410861371875, 77.00475364242277, 111.33650727957155, -120.29035756356153, 178.42932573413705, -59.114631821206174, 339.08269237620794, 28.71792959610929, -209.84541093095922, -180.3139573103909, 329.88824889172525, -35.43922686719543, 487.5017231714546, -43.15562675928727, 183.6366203643738, -6.750365018159323, 221.26968937369827, 46.578129120449866, 247.11288232677379, 65.1322644377487, 62.04501865710067, 190.9403675587358, 262.348338384413, -1.9081582360460063, -62.31490396503538, 307.0482725443483, -77.44669389396597, 245.87727609757553, -255.16666282459522, -339.26330903041054, -52.286202922480655, 184.2486793968538, 597.8419465759716, -26.674821765414272, 234.7576697041618, 22.176311519896522, 126.25563741917419, 194.59723675901574, 362.86401604641827, 138.18662637563358, 575.5427243560717, -40.61533320699639, 34.49949721821386, 157.31781967837716, -20.462631145619795, -336.57743860538795, 23.55114364762779, 207.56421537537412, 198.44146069596843, 204.77522405960994, -2.6762410478995164, -166.9114924932896, 325.8254290390179, -64.2374932930799, -236.0793744201505, -371.9088580120792, 319.1826178541076, 23.28671421875184], "policy_AGENT-3_reward": [150.98335998611066, 309.11289936593954, 549.1574183898261, 136.71017427378115, 346.49939567087546, 78.68744399620718, 322.1738514631871, 182.73163894872, 310.85355729789353, -97.02105337817731, -91.61092169308012, 147.50602231742351, 238.78458353693094, -28.373577915129687, -30.52868236873222, -43.28512511991024, 383.3154037398058, 117.56067877222975, 412.447207492357, -4.636397471806333, -12.022595568399382, -583.5129707476556, -10.822860004607357, -9.078127454214385, 396.66094699951395, -142.01874110298368, 224.788736778024, -166.41390273254507, -1.4555052319869222, 243.10660402057374, 179.97291283080997, -64.80331321130826, 308.8025354546745, -21.681700555489282, 292.5769581290467, 65.80402929095968, 1.0734497509806982, 297.1506793719865, 21.394823823087414, 151.75076003533457, -88.7091308657235, 171.40702455618137, -95.27383933010198, 313.9724507511812, -33.09015305694143, -146.46077800076964, 194.71524259057648, -8.741522985411759, 309.01095865971905, 226.64364582411915, -9.730271115766374, -120.39926571740655, 220.9892210617342, -91.69055287059257, 279.3316843770831, -114.16128420616089, -123.09581619680614, -36.25533114772497, 358.65609964637673, 110.11164205561192, 38.84342520695403, 39.25836489506712, 156.98467029273849, -85.44629157741534, 196.24136587053394, -29.47065817333525, 137.63060674643543, 148.5297314959168, -42.540994883159215, 238.11676290954773, -223.80045956630542, 2.1066872872319333, -10.79476409923577, 181.06174763222, 306.1597578877974, -65.81713320091629, 54.65134234258258, 24.039344463740605, 344.7348109189958, 166.50471234004587, 216.37663841590998, 140.5148895998065, 318.2872925118298, -101.13562728769678, 317.0108919303348, 126.93194878416806, 4.522236861977113, -89.48950389105721, 14.430405874720968, -30.12172732210874, 203.92307848524553, -40.17326091570695, 18.219540527183987, -21.0075218004864, 224.53535784711522, -135.2822278860409, -5.376355565778818, -295.15664999132866, 320.6291838537856, 61.00502303073686]}, "sampler_perf": {"mean_env_wait_ms": 49.067428167653986, "mean_raw_obs_processing_ms": 2.1931176879662964, "mean_inference_ms": 2.2374023929126627, "mean_action_processing_ms": 0.13711428357457764}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 172200, "timers": {"sample_time_ms": 72554.188, "sample_throughput": 57.888, "load_time_ms": 13.635, "load_throughput": 308023.451, "learn_time_ms": 6590.941, "learn_throughput": 637.238, "update_time_ms": 7.444}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 31.91388702392578, "policy_loss": -0.04067974537611008, "vf_loss": 31.947481155395508, "vf_explained_var": 0.9845167398452759, "kl": 0.01575665920972824, "entropy": 0.9577459692955017, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 41.94576644897461, "policy_loss": -0.035910915583372116, "vf_loss": 41.974552154541016, "vf_explained_var": 0.9772563576698303, "kl": 0.01581973023712635, "entropy": 0.8590114116668701, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 48.454063415527344, "policy_loss": -0.041484907269477844, "vf_loss": 48.48963928222656, "vf_explained_var": 0.975937008857727, "kl": 0.013127749785780907, "entropy": 0.8238867521286011, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.30000001192092896, "cur_lr": 0.0003000000142492354, "total_loss": 31.508983612060547, "policy_loss": -0.04427791386842728, "vf_loss": 31.54671859741211, "vf_explained_var": 0.9881290793418884, "kl": 0.021817227825522423, "entropy": 0.8208691477775574, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 172200, "num_steps_trained": 172200}, "done": false, "episodes_total": 1298, "training_iteration": 41, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-16-59", "timestamp": 1624220219, "time_this_iter_s": 77.99580073356628, "time_total_s": 3753.59556555748, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c824a680>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c85d3b90>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c827fd40>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c827fdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e290>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833ea70>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c827fd40>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c827fdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e290>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833ea70>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c827fd40>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c827fdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e290>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833ea70>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c827fd40>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c827fdd0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e290>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833ea70>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c80f9dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3753.59556555748, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 49.05945945945947, "ram_util_percent": 95.60180180180183}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 2387.0105137954833, "episode_reward_min": -1615.4450582630618, "episode_reward_mean": 378.99772218427756, "episode_len_mean": 177.63, "episodes_this_iter": 23, "policy_reward_min": {"AGENT-0": -521.2572281626196, "AGENT-3": -583.5129707476556, "AGENT-2": -479.24790320973545, "AGENT-1": -504.6437903317104}, "policy_reward_max": {"AGENT-0": 720.8259221387045, "AGENT-3": 549.1574183898261, "AGENT-2": 638.0668449490066, "AGENT-1": 692.2836959576864}, "policy_reward_mean": {"AGENT-0": 112.69830214290221, "AGENT-3": 102.79908836198449, "AGENT-2": 89.26741720068087, "AGENT-1": 74.23291447871011}, "custom_metrics": {"mean_ego_speed_mean": 40.01661, "mean_ego_speed_min": 15.849249999999998, "mean_ego_speed_max": 49.214749999999995, "distance_travelled_mean": 91.5190125, "distance_travelled_min": 28.088250000000002, "distance_travelled_max": 124.34375}, "hist_stats": {"episode_reward": [103.1139501787716, 2250.450854672916, -3.4361672743219103, 2387.0105137954833, 110.85230664434481, 1792.1932501411575, 36.63586048510859, 2172.1090470861022, 353.14645456272723, 798.9411762742579, 275.0906270357679, 656.7257183355309, 432.82646244850497, 714.8205980414153, -848.0148087486057, 493.8050836429634, 199.7036848377559, -981.7732924826759, -734.733604038743, -900.0600195316732, 463.6586488670698, 806.4436547176642, 284.56267148426906, 560.2688706308802, 539.2443423374402, -485.96140599208934, -642.0321941663841, 1122.1407484203808, -204.96594149749473, 1696.0616714695705, -290.410402226678, 134.40099589167147, -60.87821853662277, 952.1315233650989, 548.5315302637233, 785.1932921683988, -174.34268819249144, 453.85986361483725, 176.08958115020712, 883.6978803475117, -95.97973460391607, 243.57952095091082, 1082.5446106594252, -269.8741933270663, 1033.7697448371994, -955.2980110514737, -709.2186215566826, -149.21103306315896, 794.6280549927449, 2169.134935964628, -177.5254363873429, 592.218320829597, 92.43684666279768, 800.0249233809168, 180.69709573962612, 1413.1869874961303, 583.1003136891909, 2000.7073886430953, -275.94647017676954, 756.2259448948749, 66.15749851269447, -173.54352270955448, -916.0669067126842, 51.85480693722695, 400.384796973735, 796.3667198225654, 297.9073021483962, -51.16253632569874, -448.2623735745014, 1137.3782826568797, -391.2214923711017, -529.4369070610445, -1336.2080377365148, 669.4909521864142, 130.41989081925195, 1803.937369641626, 465.8146740700525, 1603.9253171605726, 606.4697317346601, 1585.1064494130594, 531.313890240034, 1691.6995883868458, 932.1202672205003, 2090.17681328835, -142.16822755215486, -1104.5110929577486, 487.21354027517776, 609.3843964060394, 33.30080205839741, 433.3770002907772, 396.09382038530345, 702.5829409932405, 287.6648536115021, 773.2268030402706, 90.00198885253012, -365.4801504264878, -1615.4450582630618, -264.4427157227848, -149.4457405048845, 747.4931744213969], "episode_lengths": [94, 218, 101, 216, 101, 206, 103, 188, 98, 787, 128, 125, 186, 163, 292, 110, 107, 174, 236, 206, 262, 308, 100, 204, 119, 177, 158, 185, 104, 172, 102, 191, 102, 162, 477, 187, 121, 121, 224, 129, 183, 617, 153, 97, 118, 176, 163, 113, 119, 180, 111, 186, 82, 184, 124, 180, 105, 187, 111, 564, 134, 155, 234, 180, 130, 113, 135, 138, 257, 152, 115, 184, 190, 241, 93, 186, 264, 138, 103, 178, 136, 163, 136, 184, 118, 263, 130, 120, 112, 206, 136, 243, 100, 272, 114, 156, 255, 113, 33, 256], "policy_AGENT-0_reward": [49.71954008584678, 682.1047678009129, 7.165523028299671, 720.8259221387045, 30.959562905680308, 437.0170514147455, 17.651899875310384, 612.6216993520342, 106.59143552160225, 39.80481691282082, 188.3926070807363, 244.53278517778776, 271.1679123690864, 282.41834973636213, -305.6524133538473, 110.75620868464597, 42.069823904630525, -466.0546161542661, -237.60942927967386, -421.14560625597477, -68.61826925930134, 396.5392178134704, 17.406540299522604, 339.08269237620794, 28.71792959610929, -209.84541093095922, -180.3139573103909, 329.88824889172525, -35.43922686719543, 487.5017231714546, -43.15562675928727, 183.6366203643738, -6.750365018159323, 221.26968937369827, 46.578129120449866, 247.11288232677379, 65.1322644377487, 62.04501865710067, 190.9403675587358, 262.348338384413, -1.9081582360460063, -62.31490396503538, 307.0482725443483, -77.44669389396597, 245.87727609757553, -255.16666282459522, -339.26330903041054, -52.286202922480655, 184.2486793968538, 597.8419465759716, -26.674821765414272, 234.7576697041618, 22.176311519896522, 126.25563741917419, 194.59723675901574, 362.86401604641827, 138.18662637563358, 575.5427243560717, -40.61533320699639, 34.49949721821386, 157.31781967837716, -20.462631145619795, -336.57743860538795, 23.55114364762779, 207.56421537537412, 198.44146069596843, 204.77522405960994, -2.6762410478995164, -166.9114924932896, 325.8254290390179, -64.2374932930799, -236.0793744201505, -371.9088580120792, 319.1826178541076, 23.28671421875184, 520.4778465436485, 344.0971650613871, 188.24668952113808, 147.14051424784572, 450.31507089477236, 144.66090134711817, 515.144809823985, 236.21728717343765, 597.5052555591442, 24.530785952658082, -442.60256628629725, 146.29679133478544, 265.64621146904506, 33.599929707782685, 274.82133817060276, 256.00699674024094, 377.820262058066, 14.387707230552168, 423.3608946073275, 39.93727937513889, -152.7487724189843, -521.2572281626196, -146.3354369232993, -65.65861903894668, 421.49354941003963], "policy_AGENT-3_reward": [1.7901451237740815, 374.1887519235059, -21.216178644991242, 483.01819338849737, 12.36269782110985, 488.40970993950896, -12.487534481178114, 360.25532781945253, 93.76960602010708, 339.4639289190563, -36.80182823236373, 215.58499224547947, -28.824010491932857, 239.53509889182274, -85.59608692643423, 157.40253384515083, 40.97241607123092, -5.51652262389846, -98.49139758194015, -6.743532159473347, 297.0545886477372, 351.05553679947, 113.38275713343229, 309.01095865971905, 226.64364582411915, -9.730271115766374, -120.39926571740655, 220.9892210617342, -91.69055287059257, 279.3316843770831, -114.16128420616089, -123.09581619680614, -36.25533114772497, 358.65609964637673, 110.11164205561192, 38.84342520695403, 39.25836489506712, 156.98467029273849, -85.44629157741534, 196.24136587053394, -29.47065817333525, 137.63060674643543, 148.5297314959168, -42.540994883159215, 238.11676290954773, -223.80045956630542, 2.1066872872319333, -10.79476409923577, 181.06174763222, 306.1597578877974, -65.81713320091629, 54.65134234258258, 24.039344463740605, 344.7348109189958, 166.50471234004587, 216.37663841590998, 140.5148895998065, 318.2872925118298, -101.13562728769678, 317.0108919303348, 126.93194878416806, 4.522236861977113, -89.48950389105721, 14.430405874720968, -30.12172732210874, 203.92307848524553, -40.17326091570695, 18.219540527183987, -21.0075218004864, 224.53535784711522, -135.2822278860409, -5.376355565778818, -295.15664999132866, 320.6291838537856, 61.00502303073686, 150.98335998611066, 309.11289936593954, 549.1574183898261, 136.71017427378115, 346.49939567087546, 78.68744399620718, 322.1738514631871, 182.73163894872, 310.85355729789353, -97.02105337817731, -91.61092169308012, 147.50602231742351, 238.78458353693094, -28.373577915129687, -30.52868236873222, -43.28512511991024, 383.3154037398058, 117.56067877222975, 412.447207492357, -4.636397471806333, -12.022595568399382, -583.5129707476556, -10.822860004607357, -9.078127454214385, 396.66094699951395], "policy_AGENT-2_reward": [49.16942080372655, 590.9932526660098, 6.582290397286127, 490.88270231059664, 30.414470825503418, 411.0259375587325, 17.25104081573766, 596.1801050509576, 106.19318758435321, 380.1849695635954, -36.74753504502693, 98.0592627501508, -28.821796742549687, 96.15645789335868, -371.76766021147574, 112.51644505352648, 41.515880000302154, -5.558363372801265, -98.44199037793184, -6.640437129898701, 303.8009427568145, 29.155241522513855, 16.98139374097775, -44.123057750966396, 255.11791282974175, -9.784189620045119, -120.39113105102247, 279.60547681464243, -35.86834720809317, 450.8360739350072, -43.60078522125928, 183.06571641516288, -7.330194592322016, 118.13264827137621, 206.54018399437015, 276.9511108049622, -139.58041331935488, 108.02994371333835, -85.50095223220903, 189.20878376126868, -29.4423305968285, 230.70169925943298, 276.01324273039194, -72.28798835432958, 245.26183701257094, -186.3022753075393, 2.1432249215983044, -10.811423475579907, 183.66436376762184, 638.0668449490066, -27.22712364153838, 234.19504968243814, 21.617437786001958, 184.56053697376026, -90.52337289955089, 395.6848358732544, 137.6280144865472, 547.6031502260502, -41.05321824063986, 370.19163692616405, -109.26366953981434, -110.21328803757459, -401.0789641908, 44.27625611507938, -29.85439216658885, 171.75041597245877, -40.12361513265327, -33.57244961543064, -20.993056043974754, 287.4134758968494, -64.79360244836174, -5.429988477810267, -258.5834203976741, 14.5030803871202, 22.69999542162401, 578.3738321650106, -93.96339975248843, 433.03501683781946, 146.54968636603869, 385.73582093284165, 144.08908404678178, 426.97093664254567, 235.6499299577972, 583.715536929746, 24.101829609418168, -479.24790320973545, 35.67029463484349, 52.130060710391405, -28.3740421913454, -30.483844084806623, -43.148822384977095, -29.52983636352951, 13.828916265790198, -31.546142080332363, 39.37606538953172, -11.852528913394243, -255.55405437677064, -10.87989688389856, -9.173855756005137, -35.54588220352303], "policy_AGENT-1_reward": [2.4348441654242023, 603.1640822824922, 4.032197945083659, 692.2836959576864, 37.11557509205126, 455.74055122817157, 14.220454275238751, 603.0519148636585, 46.59222543666495, 39.48746087878493, 160.24738323242212, 98.54867816211332, 219.3043573139009, 96.71069151987152, -84.99864825684787, 113.1298960596397, 75.14556486159222, -504.6437903317104, -300.19078679919676, -465.5304439863261, -68.5786132781803, 29.69365858221019, 136.79198031033624, -43.70172265408015, 28.764854087470262, -256.6015343253189, -220.9278400875644, 291.65780165227864, -41.967814551613586, 478.39218998602576, -89.49270603997061, -109.20552469105904, -10.542327778416357, 254.07308607364706, 185.30157509329158, 222.28587382970846, -139.15290420595264, 126.80023095165977, 156.09645740109596, 235.899392331296, -35.15858759770633, -62.437881089922236, 350.9533638887681, -77.59851619561164, 304.5138688175047, -290.0286133530346, -374.2052247351024, -75.31864256586262, 245.6532641960487, 627.0663865518512, -57.80635777947397, 68.61425910041497, 24.6037528931586, 144.4739380689875, -89.88148045988449, 438.26149716054795, 166.77078322720376, 559.2742215491461, -93.14229144143653, 34.52391882016279, -108.82860041003653, -47.389840388337376, -88.92100002543856, -30.402998700201074, 252.7967010870585, 222.2517646688928, 173.42895413714638, -33.13338618955255, -239.35030323675133, 299.6040198738975, -126.90816874361903, -282.55118859730464, -410.5591093354327, 15.17607009140032, 23.428158148139282, 554.1023309468588, -93.43199060478582, 433.4861924117888, 176.06935684699465, 402.5561619145705, 163.8764608499265, 427.40999045713033, 277.5214111405447, 598.1024635015661, -93.77978973605374, -91.04970176863466, 157.7404319881252, 52.823540689672235, 56.448492457089884, 219.56818857371317, 226.52077114994998, -29.02288844110058, 141.88755134292995, -31.03515697908131, 15.32504155966576, -188.85625352570995, -255.1208049760161, -96.4045219109796, -65.53513825571827, -35.115439784633935]}, "sampler_perf": {"mean_env_wait_ms": 48.81309742797921, "mean_raw_obs_processing_ms": 2.1771489210215846, "mean_inference_ms": 2.228619711787999, "mean_action_processing_ms": 0.13662697174421193}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 176400, "timers": {"sample_time_ms": 72444.485, "sample_throughput": 57.975, "load_time_ms": 13.496, "load_throughput": 311211.164, "learn_time_ms": 6613.324, "learn_throughput": 635.082, "update_time_ms": 7.496}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 37.37235641479492, "policy_loss": -0.03444696590304375, "vf_loss": 37.39974594116211, "vf_explained_var": 0.9836366176605225, "kl": 0.01568012870848179, "entropy": 0.9334083199501038, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 44.379730224609375, "policy_loss": -0.03911040723323822, "vf_loss": 44.411685943603516, "vf_explained_var": 0.9820893406867981, "kl": 0.015906212851405144, "entropy": 0.8482539653778076, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 36.43279266357422, "policy_loss": -0.03473196551203728, "vf_loss": 36.46186065673828, "vf_explained_var": 0.9818049073219299, "kl": 0.012572933919727802, "entropy": 0.7964226007461548, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 49.63802719116211, "policy_loss": -0.03182296082377434, "vf_loss": 49.66537094116211, "vf_explained_var": 0.9756550192832947, "kl": 0.009939027950167656, "entropy": 0.7198609709739685, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 176400, "num_steps_trained": 176400}, "done": false, "episodes_total": 1321, "training_iteration": 42, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-18-20", "timestamp": 1624220300, "time_this_iter_s": 80.97393846511841, "time_total_s": 3834.5695040225983, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c80c94d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c80c93b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9b90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9b90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9b90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9b90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c80c9830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3834.5695040225983, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 48.39396551724138, "ram_util_percent": 95.60000000000001}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 2387.0105137954833, "episode_reward_min": -1707.0795730281836, "episode_reward_mean": 389.9397457770916, "episode_len_mean": 178.38, "episodes_this_iter": 19, "policy_reward_min": {"AGENT-2": -479.24790320973545, "AGENT-1": -504.6437903317104, "AGENT-0": -521.2572281626196, "AGENT-3": -583.5129707476556}, "policy_reward_max": {"AGENT-2": 638.0668449490066, "AGENT-1": 692.2836959576864, "AGENT-0": 720.8259221387045, "AGENT-3": 549.1574183898261}, "policy_reward_mean": {"AGENT-2": 83.11129957109786, "AGENT-1": 83.90968900069544, "AGENT-0": 111.46020045447862, "AGENT-3": 111.45855675081988}, "custom_metrics": {"mean_ego_speed_mean": 39.458585, "mean_ego_speed_min": 14.120250000000002, "mean_ego_speed_max": 49.214749999999995, "distance_travelled_mean": 90.87881499999999, "distance_travelled_min": 28.088250000000002, "distance_travelled_max": 124.36149999999999}, "hist_stats": {"episode_reward": [1627.285078993199, -63.511977682840524, 2034.1901388911244, 954.634284430543, 1402.3452454420744, 93.56482514902358, 2219.4834568903075, 484.75263689713506, 411.13211200409665, 15.695603202141921, -973.2602897224558, 613.3030787339109, -981.8756462877467, 398.7768224682812, -915.6185780853041, 1118.9977830103312, 839.8624521022473, -337.8458587315287, -1707.0795730281836, 1082.5446106594252, -269.8741933270663, 1033.7697448371994, -955.2980110514737, -709.2186215566826, -149.21103306315896, 794.6280549927449, 2169.134935964628, -177.5254363873429, 592.218320829597, 92.43684666279768, 800.0249233809168, 180.69709573962612, 1413.1869874961303, 583.1003136891909, 2000.7073886430953, -275.94647017676954, 756.2259448948749, 66.15749851269447, -173.54352270955448, -916.0669067126842, 51.85480693722695, 400.384796973735, 796.3667198225654, 297.9073021483962, -51.16253632569874, -448.2623735745014, 1137.3782826568797, -391.2214923711017, -529.4369070610445, -1336.2080377365148, 669.4909521864142, 130.41989081925195, 1803.937369641626, 465.8146740700525, 1603.9253171605726, 606.4697317346601, 1585.1064494130594, 531.313890240034, 1691.6995883868458, 932.1202672205003, 2090.17681328835, -142.16822755215486, -1104.5110929577486, 487.21354027517776, 609.3843964060394, 33.30080205839741, 433.3770002907772, 396.09382038530345, 702.5829409932405, 287.6648536115021, 773.2268030402706, 90.00198885253012, -365.4801504264878, -1615.4450582630618, -264.4427157227848, -149.4457405048845, 747.4931744213969, 103.1139501787716, 2250.450854672916, -3.4361672743219103, 2387.0105137954833, 110.85230664434481, 1792.1932501411575, 36.63586048510859, 2172.1090470861022, 353.14645456272723, 798.9411762742579, 275.0906270357679, 656.7257183355309, 432.82646244850497, 714.8205980414153, -848.0148087486057, 493.8050836429634, 199.7036848377559, -981.7732924826759, -734.733604038743, -900.0600195316732, 463.6586488670698, 806.4436547176642, 284.56267148426906], "episode_lengths": [180, 110, 170, 103, 171, 102, 189, 291, 137, 103, 277, 125, 226, 176, 239, 358, 538, 99, 216, 153, 97, 118, 176, 163, 113, 119, 180, 111, 186, 82, 184, 124, 180, 105, 187, 111, 564, 134, 155, 234, 180, 130, 113, 135, 138, 257, 152, 115, 184, 190, 241, 93, 186, 264, 138, 103, 178, 136, 163, 136, 184, 118, 263, 130, 120, 112, 206, 136, 243, 100, 272, 114, 156, 255, 113, 33, 256, 94, 218, 101, 216, 101, 206, 103, 188, 98, 787, 128, 125, 186, 163, 292, 110, 107, 174, 236, 206, 262, 308, 100], "policy_AGENT-2_reward": [412.4770232858582, -3.642379655047414, 576.6266526408756, 238.88417490378828, 365.83271131239525, 27.06351972967673, 603.4020067781445, -92.76912493180393, -33.467278189875294, 32.392108547283385, -440.99750478647843, 28.944425430996127, -397.11920088549454, 50.27346421938313, -404.3684015664357, 152.33848344114205, 522.0492588182492, -7.112763586432166, -463.8507902573257, 276.01324273039194, -72.28798835432958, 245.26183701257094, -186.3022753075393, 2.1432249215983044, -10.811423475579907, 183.66436376762184, 638.0668449490066, -27.22712364153838, 234.19504968243814, 21.617437786001958, 184.56053697376026, -90.52337289955089, 395.6848358732544, 137.6280144865472, 547.6031502260502, -41.05321824063986, 370.19163692616405, -109.26366953981434, -110.21328803757459, -401.0789641908, 44.27625611507938, -29.85439216658885, 171.75041597245877, -40.12361513265327, -33.57244961543064, -20.993056043974754, 287.4134758968494, -64.79360244836174, -5.429988477810267, -258.5834203976741, 14.5030803871202, 22.69999542162401, 578.3738321650106, -93.96339975248843, 433.03501683781946, 146.54968636603869, 385.73582093284165, 144.08908404678178, 426.97093664254567, 235.6499299577972, 583.715536929746, 24.101829609418168, -479.24790320973545, 35.67029463484349, 52.130060710391405, -28.3740421913454, -30.483844084806623, -43.148822384977095, -29.52983636352951, 13.828916265790198, -31.546142080332363, 39.37606538953172, -11.852528913394243, -255.55405437677064, -10.87989688389856, -9.173855756005137, -35.54588220352303, 49.16942080372655, 590.9932526660098, 6.582290397286127, 490.88270231059664, 30.414470825503418, 411.0259375587325, 17.25104081573766, 596.1801050509576, 106.19318758435321, 380.1849695635954, -36.74753504502693, 98.0592627501508, -28.821796742549687, 96.15645789335868, -371.76766021147574, 112.51644505352648, 41.515880000302154, -5.558363372801265, -98.44199037793184, -6.640437129898701, 303.8009427568145, 29.155241522513855, 16.98139374097775], "policy_AGENT-1_reward": [418.6782241341153, -24.413454153658627, 589.2534761026216, 266.7632881503131, 318.381580161715, 32.02456396356592, 614.6531139578844, -92.00379241273434, 223.25963936683652, -11.93745737988155, -85.55613416108999, 29.398525677977204, -92.25685546703602, 50.72378995586471, -86.4029397499162, 489.21717677434634, -54.897319423309234, -161.81382999814835, -485.31152491606434, 350.9533638887681, -77.59851619561164, 304.5138688175047, -290.0286133530346, -374.2052247351024, -75.31864256586262, 245.6532641960487, 627.0663865518512, -57.80635777947397, 68.61425910041497, 24.6037528931586, 144.4739380689875, -89.88148045988449, 438.26149716054795, 166.77078322720376, 559.2742215491461, -93.14229144143653, 34.52391882016279, -108.82860041003653, -47.389840388337376, -88.92100002543856, -30.402998700201074, 252.7967010870585, 222.2517646688928, 173.42895413714638, -33.13338618955255, -239.35030323675133, 299.6040198738975, -126.90816874361903, -282.55118859730464, -410.5591093354327, 15.17607009140032, 23.428158148139282, 554.1023309468588, -93.43199060478582, 433.4861924117888, 176.06935684699465, 402.5561619145705, 163.8764608499265, 427.40999045713033, 277.5214111405447, 598.1024635015661, -93.77978973605374, -91.04970176863466, 157.7404319881252, 52.823540689672235, 56.448492457089884, 219.56818857371317, 226.52077114994998, -29.02288844110058, 141.88755134292995, -31.03515697908131, 15.32504155966576, -188.85625352570995, -255.1208049760161, -96.4045219109796, -65.53513825571827, -35.115439784633935, 2.4348441654242023, 603.1640822824922, 4.032197945083659, 692.2836959576864, 37.11557509205126, 455.74055122817157, 14.220454275238751, 603.0519148636585, 46.59222543666495, 39.48746087878493, 160.24738323242212, 98.54867816211332, 219.3043573139009, 96.71069151987152, -84.99864825684787, 113.1298960596397, 75.14556486159222, -504.6437903317104, -300.19078679919676, -465.5304439863261, -68.5786132781803, 29.69365858221019, 136.79198031033624], "policy_AGENT-0_reward": [456.4662993404683, -3.0657717205517034, 561.6863858725417, 239.4624304968952, 410.3959567319939, 27.638350825881457, 628.0249334093069, 364.5878926666228, 255.0901385848968, 32.94525068236851, -360.58461510117087, 290.49796440679506, -399.6790652412191, 174.26539119224014, -337.8815616865564, 135.68206693142739, -54.58236096187838, -161.8441012537396, -458.38949884696393, 307.0482725443483, -77.44669389396597, 245.87727609757553, -255.16666282459522, -339.26330903041054, -52.286202922480655, 184.2486793968538, 597.8419465759716, -26.674821765414272, 234.7576697041618, 22.176311519896522, 126.25563741917419, 194.59723675901574, 362.86401604641827, 138.18662637563358, 575.5427243560717, -40.61533320699639, 34.49949721821386, 157.31781967837716, -20.462631145619795, -336.57743860538795, 23.55114364762779, 207.56421537537412, 198.44146069596843, 204.77522405960994, -2.6762410478995164, -166.9114924932896, 325.8254290390179, -64.2374932930799, -236.0793744201505, -371.9088580120792, 319.1826178541076, 23.28671421875184, 520.4778465436485, 344.0971650613871, 188.24668952113808, 147.14051424784572, 450.31507089477236, 144.66090134711817, 515.144809823985, 236.21728717343765, 597.5052555591442, 24.530785952658082, -442.60256628629725, 146.29679133478544, 265.64621146904506, 33.599929707782685, 274.82133817060276, 256.00699674024094, 377.820262058066, 14.387707230552168, 423.3608946073275, 39.93727937513889, -152.7487724189843, -521.2572281626196, -146.3354369232993, -65.65861903894668, 421.49354941003963, 49.71954008584678, 682.1047678009129, 7.165523028299671, 720.8259221387045, 30.959562905680308, 437.0170514147455, 17.651899875310384, 612.6216993520342, 106.59143552160225, 39.80481691282082, 188.3926070807363, 244.53278517778776, 271.1679123690864, 282.41834973636213, -305.6524133538473, 110.75620868464597, 42.069823904630525, -466.0546161542661, -237.60942927967386, -421.14560625597477, -68.61826925930134, 396.5392178134704, 17.406540299522604], "policy_AGENT-3_reward": [339.66353223275746, -32.390372153582504, 306.623624275084, 209.52439087954596, 307.73499723597223, 6.8383906298996395, 373.40340274497146, 304.9376615750506, -33.75038775776139, -37.704298647628434, -86.12203567371527, 264.4621632181428, -92.82052469399542, 123.51417710079315, -86.96567508239642, 341.76005586341523, 427.29287366918595, -7.075163893208477, -299.527759007829, 148.5297314959168, -42.540994883159215, 238.11676290954773, -223.80045956630542, 2.1066872872319333, -10.79476409923577, 181.06174763222, 306.1597578877974, -65.81713320091629, 54.65134234258258, 24.039344463740605, 344.7348109189958, 166.50471234004587, 216.37663841590998, 140.5148895998065, 318.2872925118298, -101.13562728769678, 317.0108919303348, 126.93194878416806, 4.522236861977113, -89.48950389105721, 14.430405874720968, -30.12172732210874, 203.92307848524553, -40.17326091570695, 18.219540527183987, -21.0075218004864, 224.53535784711522, -135.2822278860409, -5.376355565778818, -295.15664999132866, 320.6291838537856, 61.00502303073686, 150.98335998611066, 309.11289936593954, 549.1574183898261, 136.71017427378115, 346.49939567087546, 78.68744399620718, 322.1738514631871, 182.73163894872, 310.85355729789353, -97.02105337817731, -91.61092169308012, 147.50602231742351, 238.78458353693094, -28.373577915129687, -30.52868236873222, -43.28512511991024, 383.3154037398058, 117.56067877222975, 412.447207492357, -4.636397471806333, -12.022595568399382, -583.5129707476556, -10.822860004607357, -9.078127454214385, 396.66094699951395, 1.7901451237740815, 374.1887519235059, -21.216178644991242, 483.01819338849737, 12.36269782110985, 488.40970993950896, -12.487534481178114, 360.25532781945253, 93.76960602010708, 339.4639289190563, -36.80182823236373, 215.58499224547947, -28.824010491932857, 239.53509889182274, -85.59608692643423, 157.40253384515083, 40.97241607123092, -5.51652262389846, -98.49139758194015, -6.743532159473347, 297.0545886477372, 351.05553679947, 113.38275713343229]}, "sampler_perf": {"mean_env_wait_ms": 48.59990025467148, "mean_raw_obs_processing_ms": 2.162918395704395, "mean_inference_ms": 2.22258078660162, "mean_action_processing_ms": 0.1362309985884579}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 180600, "timers": {"sample_time_ms": 72164.821, "sample_throughput": 58.2, "load_time_ms": 13.247, "load_throughput": 317042.333, "learn_time_ms": 6480.042, "learn_throughput": 648.144, "update_time_ms": 7.216}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 37.964599609375, "policy_loss": -0.04211052507162094, "vf_loss": 37.998294830322266, "vf_explained_var": 0.9852704405784607, "kl": 0.018696241080760956, "entropy": 0.9465676546096802, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 39.871238708496094, "policy_loss": -0.050537388771772385, "vf_loss": 39.914493560791016, "vf_explained_var": 0.9888004064559937, "kl": 0.016189217567443848, "entropy": 0.8529297113418579, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 41.953369140625, "policy_loss": -0.0379524901509285, "vf_loss": 41.983333587646484, "vf_explained_var": 0.984603762626648, "kl": 0.017740707844495773, "entropy": 0.8115359544754028, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 50.787628173828125, "policy_loss": -0.0360817089676857, "vf_loss": 50.817413330078125, "vf_explained_var": 0.9803276062011719, "kl": 0.014004625380039215, "entropy": 0.8229174613952637, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 180600, "num_steps_trained": 180600}, "done": false, "episodes_total": 1340, "training_iteration": 43, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-19-35", "timestamp": 1624220375, "time_this_iter_s": 75.36074161529541, "time_total_s": 3909.9302456378937, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c827f8c0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c820ed40>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84aec20>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f98c0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84aec20>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f98c0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84aec20>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f98c0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8397a70>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c84aec20>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8221d40>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f98c0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c80c9dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3909.9302456378937, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 48.2425925925926, "ram_util_percent": 95.63611111111112}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 2698.7152796949463, "episode_reward_min": -1707.0795730281836, "episode_reward_mean": 342.6817329666821, "episode_len_mean": 179.25, "episodes_this_iter": 27, "policy_reward_min": {"AGENT-2": -479.24790320973545, "AGENT-1": -634.2395104357594, "AGENT-0": -646.5432439039848, "AGENT-3": -583.5129707476556}, "policy_reward_max": {"AGENT-2": 743.5373613672818, "AGENT-1": 766.982792527926, "AGENT-0": 763.1131016910435, "AGENT-3": 549.1574183898261}, "policy_reward_mean": {"AGENT-2": 71.82801602894706, "AGENT-1": 71.44975458957633, "AGENT-0": 92.14711169958095, "AGENT-3": 107.25685064857778}, "custom_metrics": {"mean_ego_speed_mean": 39.418434999999995, "mean_ego_speed_min": 14.120250000000002, "mean_ego_speed_max": 49.214749999999995, "distance_travelled_mean": 89.5127225, "distance_travelled_min": 28.088250000000002, "distance_travelled_max": 124.36149999999999}, "hist_stats": {"episode_reward": [-1008.8907553980087, -248.63839624052153, 790.1149802864128, 386.19553623768684, 1842.6270088559493, 36.04113207067768, 2698.7152796949463, 83.11427019189276, 1661.677339565968, -281.72088908860115, 645.9544663992681, -91.60607930790403, 204.94148050940592, -1057.3544342457878, 8.60821410744772, -794.234734221018, -248.06316157425186, -792.6707878223169, -750.0397894214956, -351.2819037119379, -1117.9311816723364, -340.34224875499785, 498.59879149737566, 425.53349485150636, 1154.9683731599978, -468.74615611841995, 1373.8660564080171, 1137.3782826568797, -391.2214923711017, -529.4369070610445, -1336.2080377365148, 669.4909521864142, 130.41989081925195, 1803.937369641626, 465.8146740700525, 1603.9253171605726, 606.4697317346601, 1585.1064494130594, 531.313890240034, 1691.6995883868458, 932.1202672205003, 2090.17681328835, -142.16822755215486, -1104.5110929577486, 487.21354027517776, 609.3843964060394, 33.30080205839741, 433.3770002907772, 396.09382038530345, 702.5829409932405, 287.6648536115021, 773.2268030402706, 90.00198885253012, -365.4801504264878, -1615.4450582630618, -264.4427157227848, -149.4457405048845, 747.4931744213969, 103.1139501787716, 2250.450854672916, -3.4361672743219103, 2387.0105137954833, 110.85230664434481, 1792.1932501411575, 36.63586048510859, 2172.1090470861022, 353.14645456272723, 798.9411762742579, 275.0906270357679, 656.7257183355309, 432.82646244850497, 714.8205980414153, -848.0148087486057, 493.8050836429634, 199.7036848377559, -981.7732924826759, -734.733604038743, -900.0600195316732, 463.6586488670698, 806.4436547176642, 284.56267148426906, 1627.285078993199, -63.511977682840524, 2034.1901388911244, 954.634284430543, 1402.3452454420744, 93.56482514902358, 2219.4834568903075, 484.75263689713506, 411.13211200409665, 15.695603202141921, -973.2602897224558, 613.3030787339109, -981.8756462877467, 398.7768224682812, -915.6185780853041, 1118.9977830103312, 839.8624521022473, -337.8458587315287, -1707.0795730281836], "episode_lengths": [274, 103, 184, 123, 171, 99, 196, 101, 160, 112, 137, 128, 245, 310, 111, 135, 33, 310, 287, 115, 322, 113, 142, 103, 231, 117, 154, 152, 115, 184, 190, 241, 93, 186, 264, 138, 103, 178, 136, 163, 136, 184, 118, 263, 130, 120, 112, 206, 136, 243, 100, 272, 114, 156, 255, 113, 33, 256, 94, 218, 101, 216, 101, 206, 103, 188, 98, 787, 128, 125, 186, 163, 292, 110, 107, 174, 236, 206, 262, 308, 100, 180, 110, 170, 103, 171, 102, 189, 291, 137, 103, 277, 125, 226, 176, 239, 358, 538, 99, 216], "policy_AGENT-2_reward": [131.76885599254607, -40.10323830160597, 195.4520056147595, -32.901891047488434, 511.3029122570736, 10.691561239687426, 743.5373613672818, 24.230705949464287, 431.22656865808005, -42.43815741463679, 155.21534245127793, -129.77775441608142, -36.56534770140717, -444.9784359700622, 26.737905578953487, -317.29917114563585, -35.482218976961164, -348.5384506887788, 0.5766631609398878, -77.61488519055268, 18.97823666733765, -79.58694729745669, 12.365149818916777, 43.01527000489381, 163.5064647045555, -66.14783673797335, 333.8529879847242, 287.4134758968494, -64.79360244836174, -5.429988477810267, -258.5834203976741, 14.5030803871202, 22.69999542162401, 578.3738321650106, -93.96339975248843, 433.03501683781946, 146.54968636603869, 385.73582093284165, 144.08908404678178, 426.97093664254567, 235.6499299577972, 583.715536929746, 24.101829609418168, -479.24790320973545, 35.67029463484349, 52.130060710391405, -28.3740421913454, -30.483844084806623, -43.148822384977095, -29.52983636352951, 13.828916265790198, -31.546142080332363, 39.37606538953172, -11.852528913394243, -255.55405437677064, -10.87989688389856, -9.173855756005137, -35.54588220352303, 49.16942080372655, 590.9932526660098, 6.582290397286127, 490.88270231059664, 30.414470825503418, 411.0259375587325, 17.25104081573766, 596.1801050509576, 106.19318758435321, 380.1849695635954, -36.74753504502693, 98.0592627501508, -28.821796742549687, 96.15645789335868, -371.76766021147574, 112.51644505352648, 41.515880000302154, -5.558363372801265, -98.44199037793184, -6.640437129898701, 303.8009427568145, 29.155241522513855, 16.98139374097775, 412.4770232858582, -3.642379655047414, 576.6266526408756, 238.88417490378828, 365.83271131239525, 27.06351972967673, 603.4020067781445, -92.76912493180393, -33.467278189875294, 32.392108547283385, -440.99750478647843, 28.944425430996127, -397.11920088549454, 50.27346421938313, -404.3684015664357, 152.33848344114205, 522.0492588182492, -7.112763586432166, -463.8507902573257], "policy_AGENT-1_reward": [-634.2395104357594, -71.77844658465611, 137.9888017718784, 250.26811168962166, 471.73575729533627, 18.94776413399628, 766.982792527926, 29.748533312532352, 455.2544922896236, -94.45003879851154, 174.54563020244652, -129.17368494486092, 103.84019613707675, -114.65243169988118, -18.80786121997169, -94.50223323144601, -88.61593889534984, -83.6931281379841, -406.5431033695925, -97.22481112634854, -612.4713041247352, -88.4958778625947, 12.798764750602416, 180.99798214309192, 462.87084774290656, -163.0437716567924, 392.8984456657028, 299.6040198738975, -126.90816874361903, -282.55118859730464, -410.5591093354327, 15.17607009140032, 23.428158148139282, 554.1023309468588, -93.43199060478582, 433.4861924117888, 176.06935684699465, 402.5561619145705, 163.8764608499265, 427.40999045713033, 277.5214111405447, 598.1024635015661, -93.77978973605374, -91.04970176863466, 157.7404319881252, 52.823540689672235, 56.448492457089884, 219.56818857371317, 226.52077114994998, -29.02288844110058, 141.88755134292995, -31.03515697908131, 15.32504155966576, -188.85625352570995, -255.1208049760161, -96.4045219109796, -65.53513825571827, -35.115439784633935, 2.4348441654242023, 603.1640822824922, 4.032197945083659, 692.2836959576864, 37.11557509205126, 455.74055122817157, 14.220454275238751, 603.0519148636585, 46.59222543666495, 39.48746087878493, 160.24738323242212, 98.54867816211332, 219.3043573139009, 96.71069151987152, -84.99864825684787, 113.1298960596397, 75.14556486159222, -504.6437903317104, -300.19078679919676, -465.5304439863261, -68.5786132781803, 29.69365858221019, 136.79198031033624, 418.6782241341153, -24.413454153658627, 589.2534761026216, 266.7632881503131, 318.381580161715, 32.02456396356592, 614.6531139578844, -92.00379241273434, 223.25963936683652, -11.93745737988155, -85.55613416108999, 29.398525677977204, -92.25685546703602, 50.72378995586471, -86.4029397499162, 489.21717677434634, -54.897319423309234, -161.81382999814835, -485.31152491606434], "policy_AGENT-0_reward": [-646.5432439039848, -39.674649416136035, 119.78544319479231, 201.6405417589432, 528.4253009969628, 11.119254312720464, 763.1131016910435, 24.656157554061384, 459.90732382045644, -42.01011690704298, 185.30489858954667, 96.54109189575703, 174.1135171775486, -382.50394261746686, 27.28491660706459, -287.3670646880025, -88.60698875039205, -276.1783483745206, -344.62986468669516, -77.06561069730154, -543.4776371692461, -79.02075715690654, 253.6685100959733, 43.56517815478948, 191.8040084283772, -65.57325124803286, 357.8782863821556, 325.8254290390179, -64.2374932930799, -236.0793744201505, -371.9088580120792, 319.1826178541076, 23.28671421875184, 520.4778465436485, 344.0971650613871, 188.24668952113808, 147.14051424784572, 450.31507089477236, 144.66090134711817, 515.144809823985, 236.21728717343765, 597.5052555591442, 24.530785952658082, -442.60256628629725, 146.29679133478544, 265.64621146904506, 33.599929707782685, 274.82133817060276, 256.00699674024094, 377.820262058066, 14.387707230552168, 423.3608946073275, 39.93727937513889, -152.7487724189843, -521.2572281626196, -146.3354369232993, -65.65861903894668, 421.49354941003963, 49.71954008584678, 682.1047678009129, 7.165523028299671, 720.8259221387045, 30.959562905680308, 437.0170514147455, 17.651899875310384, 612.6216993520342, 106.59143552160225, 39.80481691282082, 188.3926070807363, 244.53278517778776, 271.1679123690864, 282.41834973636213, -305.6524133538473, 110.75620868464597, 42.069823904630525, -466.0546161542661, -237.60942927967386, -421.14560625597477, -68.61826925930134, 396.5392178134704, 17.406540299522604, 456.4662993404683, -3.0657717205517034, 561.6863858725417, 239.4624304968952, 410.3959567319939, 27.638350825881457, 628.0249334093069, 364.5878926666228, 255.0901385848968, 32.94525068236851, -360.58461510117087, 290.49796440679506, -399.6790652412191, 174.26539119224014, -337.8815616865564, 135.68206693142739, -54.58236096187838, -161.8441012537396, -458.38949884696393], "policy_AGENT-3_reward": [140.12314294918872, -97.08206193812357, 336.88872970498295, -32.811226163389506, 331.163038306576, -4.717447615726483, 425.0820241086926, 4.478873375834706, 315.2889547978069, -102.82257596840984, 130.88859515599643, 70.80426815728114, -36.44688510381235, -115.21962395837743, -26.60674685859871, -95.0662651559331, -35.35801495154881, -84.26086062103452, 0.5565154738518086, -99.3765966977352, 19.039522954307373, -93.23866643804018, 219.76636683188315, 157.95506454873112, 336.78705228415936, -173.9812964756211, 289.23633637543423, 224.53535784711522, -135.2822278860409, -5.376355565778818, -295.15664999132866, 320.6291838537856, 61.00502303073686, 150.98335998611066, 309.11289936593954, 549.1574183898261, 136.71017427378115, 346.49939567087546, 78.68744399620718, 322.1738514631871, 182.73163894872, 310.85355729789353, -97.02105337817731, -91.61092169308012, 147.50602231742351, 238.78458353693094, -28.373577915129687, -30.52868236873222, -43.28512511991024, 383.3154037398058, 117.56067877222975, 412.447207492357, -4.636397471806333, -12.022595568399382, -583.5129707476556, -10.822860004607357, -9.078127454214385, 396.66094699951395, 1.7901451237740815, 374.1887519235059, -21.216178644991242, 483.01819338849737, 12.36269782110985, 488.40970993950896, -12.487534481178114, 360.25532781945253, 93.76960602010708, 339.4639289190563, -36.80182823236373, 215.58499224547947, -28.824010491932857, 239.53509889182274, -85.59608692643423, 157.40253384515083, 40.97241607123092, -5.51652262389846, -98.49139758194015, -6.743532159473347, 297.0545886477372, 351.05553679947, 113.38275713343229, 339.66353223275746, -32.390372153582504, 306.623624275084, 209.52439087954596, 307.73499723597223, 6.8383906298996395, 373.40340274497146, 304.9376615750506, -33.75038775776139, -37.704298647628434, -86.12203567371527, 264.4621632181428, -92.82052469399542, 123.51417710079315, -86.96567508239642, 341.76005586341523, 427.29287366918595, -7.075163893208477, -299.527759007829]}, "sampler_perf": {"mean_env_wait_ms": 48.3068083549692, "mean_raw_obs_processing_ms": 2.144700434097832, "mean_inference_ms": 2.2125734705052613, "mean_action_processing_ms": 0.1356859024261839}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 184800, "timers": {"sample_time_ms": 71944.072, "sample_throughput": 58.379, "load_time_ms": 12.876, "load_throughput": 326189.213, "learn_time_ms": 6393.627, "learn_throughput": 656.904, "update_time_ms": 7.205}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 44.597862243652344, "policy_loss": -0.03749686852097511, "vf_loss": 44.62698745727539, "vf_explained_var": 0.9808903932571411, "kl": 0.018600407987833023, "entropy": 0.9260575771331787, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 46.994327545166016, "policy_loss": -0.0356895849108696, "vf_loss": 47.023895263671875, "vf_explained_var": 0.9803825616836548, "kl": 0.013605145737528801, "entropy": 0.867577314376831, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 62.96717834472656, "policy_loss": -0.047718595713377, "vf_loss": 63.00953674316406, "vf_explained_var": 0.9769729375839233, "kl": 0.011907990090548992, "entropy": 0.8962639570236206, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 28.18855094909668, "policy_loss": -0.03766019642353058, "vf_loss": 28.220108032226562, "vf_explained_var": 0.9872745275497437, "kl": 0.013557292520999908, "entropy": 0.8571601510047913, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 184800, "num_steps_trained": 184800}, "done": false, "episodes_total": 1367, "training_iteration": 44, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-20-52", "timestamp": 1624220452, "time_this_iter_s": 76.62140345573425, "time_total_s": 3986.551649093628, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c814f4d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c814f3b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c814f170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c814f050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c814fa70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c814fb90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c814f170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c814f050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c814fa70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c814fb90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c814f170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c814f050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c814fa70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c814fb90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c814f170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c814f050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c814fa70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c814fb90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c814f830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 3986.551649093628, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 53.106363636363625, "ram_util_percent": 95.60181818181819}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 2732.6385457045917, "episode_reward_min": -1707.0795730281836, "episode_reward_mean": 357.3419743154414, "episode_len_mean": 185.88, "episodes_this_iter": 17, "policy_reward_min": {"AGENT-2": -463.8507902573257, "AGENT-1": -634.2395104357594, "AGENT-0": -646.5432439039848, "AGENT-3": -583.5129707476556}, "policy_reward_max": {"AGENT-2": 762.7025625367257, "AGENT-1": 787.3057928792331, "AGENT-0": 792.7929303415186, "AGENT-3": 488.40970993950896}, "policy_reward_mean": {"AGENT-2": 76.00196407884025, "AGENT-1": 79.00718188055126, "AGENT-0": 99.32741392474833, "AGENT-3": 103.00541443130162}, "custom_metrics": {"mean_ego_speed_mean": 39.805567499999995, "mean_ego_speed_min": 14.120250000000002, "mean_ego_speed_max": 51.197500000000005, "distance_travelled_mean": 90.03120000000001, "distance_travelled_min": 28.088250000000002, "distance_travelled_max": 124.37225000000001}, "hist_stats": {"episode_reward": [1959.7681565590228, 599.3332199413297, 2425.196912092104, 2247.121985213439, 539.2421581792954, 2732.6385457045917, 788.7168060495142, -558.0343448418064, 760.0425299626913, 328.2706272437229, 770.8360023846334, -237.60118153695484, 398.0124126541883, -582.2761712870802, -158.0604825035635, -454.4475394526482, -348.42803234686306, 487.21354027517776, 609.3843964060394, 33.30080205839741, 433.3770002907772, 396.09382038530345, 702.5829409932405, 287.6648536115021, 773.2268030402706, 90.00198885253012, -365.4801504264878, -1615.4450582630618, -264.4427157227848, -149.4457405048845, 747.4931744213969, 103.1139501787716, 2250.450854672916, -3.4361672743219103, 2387.0105137954833, 110.85230664434481, 1792.1932501411575, 36.63586048510859, 2172.1090470861022, 353.14645456272723, 798.9411762742579, 275.0906270357679, 656.7257183355309, 432.82646244850497, 714.8205980414153, -848.0148087486057, 493.8050836429634, 199.7036848377559, -981.7732924826759, -734.733604038743, -900.0600195316732, 463.6586488670698, 806.4436547176642, 284.56267148426906, 1627.285078993199, -63.511977682840524, 2034.1901388911244, 954.634284430543, 1402.3452454420744, 93.56482514902358, 2219.4834568903075, 484.75263689713506, 411.13211200409665, 15.695603202141921, -973.2602897224558, 613.3030787339109, -981.8756462877467, 398.7768224682812, -915.6185780853041, 1118.9977830103312, 839.8624521022473, -337.8458587315287, -1707.0795730281836, -1008.8907553980087, -248.63839624052153, 790.1149802864128, 386.19553623768684, 1842.6270088559493, 36.04113207067768, 2698.7152796949463, 83.11427019189276, 1661.677339565968, -281.72088908860115, 645.9544663992681, -91.60607930790403, 204.94148050940592, -1057.3544342457878, 8.60821410744772, -794.234734221018, -248.06316157425186, -792.6707878223169, -750.0397894214956, -351.2819037119379, -1117.9311816723364, -340.34224875499785, 498.59879149737566, 425.53349485150636, 1154.9683731599978, -468.74615611841995, 1373.8660564080171], "episode_lengths": [228, 134, 180, 187, 339, 195, 161, 130, 318, 129, 128, 96, 764, 146, 113, 134, 125, 130, 120, 112, 206, 136, 243, 100, 272, 114, 156, 255, 113, 33, 256, 94, 218, 101, 216, 101, 206, 103, 188, 98, 787, 128, 125, 186, 163, 292, 110, 107, 174, 236, 206, 262, 308, 100, 180, 110, 170, 103, 171, 102, 189, 291, 137, 103, 277, 125, 226, 176, 239, 358, 538, 99, 216, 274, 103, 184, 123, 171, 99, 196, 101, 160, 112, 137, 128, 245, 310, 111, 135, 33, 310, 287, 115, 322, 113, 142, 103, 231, 117, 154], "policy_AGENT-2_reward": [469.72647452368227, -44.57451613828511, 675.3943935890081, 634.7730067799527, -72.20010418590435, 762.7025625367257, 163.17510691322673, -142.36960263973924, 123.865753992026, -28.80690409351502, 139.2062787421312, -103.13917326077808, 279.85436942099466, 11.212962780048901, -64.78253091375586, 3.315132560281877, -9.13849470925966, 35.67029463484349, 52.130060710391405, -28.3740421913454, -30.483844084806623, -43.148822384977095, -29.52983636352951, 13.828916265790198, -31.546142080332363, 39.37606538953172, -11.852528913394243, -255.55405437677064, -10.87989688389856, -9.173855756005137, -35.54588220352303, 49.16942080372655, 590.9932526660098, 6.582290397286127, 490.88270231059664, 30.414470825503418, 411.0259375587325, 17.25104081573766, 596.1801050509576, 106.19318758435321, 380.1849695635954, -36.74753504502693, 98.0592627501508, -28.821796742549687, 96.15645789335868, -371.76766021147574, 112.51644505352648, 41.515880000302154, -5.558363372801265, -98.44199037793184, -6.640437129898701, 303.8009427568145, 29.155241522513855, 16.98139374097775, 412.4770232858582, -3.642379655047414, 576.6266526408756, 238.88417490378828, 365.83271131239525, 27.06351972967673, 603.4020067781445, -92.76912493180393, -33.467278189875294, 32.392108547283385, -440.99750478647843, 28.944425430996127, -397.11920088549454, 50.27346421938313, -404.3684015664357, 152.33848344114205, 522.0492588182492, -7.112763586432166, -463.8507902573257, 131.76885599254607, -40.10323830160597, 195.4520056147595, -32.901891047488434, 511.3029122570736, 10.691561239687426, 743.5373613672818, 24.230705949464287, 431.22656865808005, -42.43815741463679, 155.21534245127793, -129.77775441608142, -36.56534770140717, -444.9784359700622, 26.737905578953487, -317.29917114563585, -35.482218976961164, -348.5384506887788, 0.5766631609398878, -77.61488519055268, 18.97823666733765, -79.58694729745669, 12.365149818916777, 43.01527000489381, 163.5064647045555, -66.14783673797335, 333.8529879847242], "policy_AGENT-1_reward": [487.5688860255181, 381.6944160706911, 704.8335639820539, 640.990506164914, 318.4964278241539, 787.3057928792331, 209.9165478986937, -125.39891006009094, 124.67234429825841, 177.89229207084145, 219.55413018846292, -102.56068197002585, -64.62852090063195, -317.55494287838394, -26.065036240933956, -244.92858804242303, -142.99283081585065, 157.7404319881252, 52.823540689672235, 56.448492457089884, 219.56818857371317, 226.52077114994998, -29.02288844110058, 141.88755134292995, -31.03515697908131, 15.32504155966576, -188.85625352570995, -255.1208049760161, -96.4045219109796, -65.53513825571827, -35.115439784633935, 2.4348441654242023, 603.1640822824922, 4.032197945083659, 692.2836959576864, 37.11557509205126, 455.74055122817157, 14.220454275238751, 603.0519148636585, 46.59222543666495, 39.48746087878493, 160.24738323242212, 98.54867816211332, 219.3043573139009, 96.71069151987152, -84.99864825684787, 113.1298960596397, 75.14556486159222, -504.6437903317104, -300.19078679919676, -465.5304439863261, -68.5786132781803, 29.69365858221019, 136.79198031033624, 418.6782241341153, -24.413454153658627, 589.2534761026216, 266.7632881503131, 318.381580161715, 32.02456396356592, 614.6531139578844, -92.00379241273434, 223.25963936683652, -11.93745737988155, -85.55613416108999, 29.398525677977204, -92.25685546703602, 50.72378995586471, -86.4029397499162, 489.21717677434634, -54.897319423309234, -161.81382999814835, -485.31152491606434, -634.2395104357594, -71.77844658465611, 137.9888017718784, 250.26811168962166, 471.73575729533627, 18.94776413399628, 766.982792527926, 29.748533312532352, 455.2544922896236, -94.45003879851154, 174.54563020244652, -129.17368494486092, 103.84019613707675, -114.65243169988118, -18.80786121997169, -94.50223323144601, -88.61593889534984, -83.6931281379841, -406.5431033695925, -97.22481112634854, -612.4713041247352, -88.4958778625947, 12.798764750602416, 180.99798214309192, 462.87084774290656, -163.0437716567924, 392.8984456657028], "policy_AGENT-0_reward": [631.4296086762373, 306.7462240645979, 676.1603479543875, 642.1333745478968, 365.1418433766898, 792.7929303415186, 248.55613567495766, -140.13658730866626, 291.39829670894136, 208.0046779461289, 247.43984943706226, -34.77053649189189, -64.63937405293744, -286.86131092400484, -40.58288409511648, -216.048064439553, -186.93151367410516, 146.29679133478544, 265.64621146904506, 33.599929707782685, 274.82133817060276, 256.00699674024094, 377.820262058066, 14.387707230552168, 423.3608946073275, 39.93727937513889, -152.7487724189843, -521.2572281626196, -146.3354369232993, -65.65861903894668, 421.49354941003963, 49.71954008584678, 682.1047678009129, 7.165523028299671, 720.8259221387045, 30.959562905680308, 437.0170514147455, 17.651899875310384, 612.6216993520342, 106.59143552160225, 39.80481691282082, 188.3926070807363, 244.53278517778776, 271.1679123690864, 282.41834973636213, -305.6524133538473, 110.75620868464597, 42.069823904630525, -466.0546161542661, -237.60942927967386, -421.14560625597477, -68.61826925930134, 396.5392178134704, 17.406540299522604, 456.4662993404683, -3.0657717205517034, 561.6863858725417, 239.4624304968952, 410.3959567319939, 27.638350825881457, 628.0249334093069, 364.5878926666228, 255.0901385848968, 32.94525068236851, -360.58461510117087, 290.49796440679506, -399.6790652412191, 174.26539119224014, -337.8815616865564, 135.68206693142739, -54.58236096187838, -161.8441012537396, -458.38949884696393, -646.5432439039848, -39.674649416136035, 119.78544319479231, 201.6405417589432, 528.4253009969628, 11.119254312720464, 763.1131016910435, 24.656157554061384, 459.90732382045644, -42.01011690704298, 185.30489858954667, 96.54109189575703, 174.1135171775486, -382.50394261746686, 27.28491660706459, -287.3670646880025, -88.60698875039205, -276.1783483745206, -344.62986468669516, -77.06561069730154, -543.4776371692461, -79.02075715690654, 253.6685100959733, 43.56517815478948, 191.8040084283772, -65.57325124803286, 357.8782863821556], "policy_AGENT-3_reward": [371.043187333587, -44.53290405567467, 368.8086065666547, 329.22509772067684, -72.19600883564435, 389.837259947118, 167.06901556263517, -150.12924483330946, 220.10613496346585, -28.819438679732446, 164.63574401697633, 2.8692101857405703, 247.42593818676335, 10.92711973525917, -26.630031253757252, 3.2139804690460494, -9.365193147647542, 147.50602231742351, 238.78458353693094, -28.373577915129687, -30.52868236873222, -43.28512511991024, 383.3154037398058, 117.56067877222975, 412.447207492357, -4.636397471806333, -12.022595568399382, -583.5129707476556, -10.822860004607357, -9.078127454214385, 396.66094699951395, 1.7901451237740815, 374.1887519235059, -21.216178644991242, 483.01819338849737, 12.36269782110985, 488.40970993950896, -12.487534481178114, 360.25532781945253, 93.76960602010708, 339.4639289190563, -36.80182823236373, 215.58499224547947, -28.824010491932857, 239.53509889182274, -85.59608692643423, 157.40253384515083, 40.97241607123092, -5.51652262389846, -98.49139758194015, -6.743532159473347, 297.0545886477372, 351.05553679947, 113.38275713343229, 339.66353223275746, -32.390372153582504, 306.623624275084, 209.52439087954596, 307.73499723597223, 6.8383906298996395, 373.40340274497146, 304.9376615750506, -33.75038775776139, -37.704298647628434, -86.12203567371527, 264.4621632181428, -92.82052469399542, 123.51417710079315, -86.96567508239642, 341.76005586341523, 427.29287366918595, -7.075163893208477, -299.527759007829, 140.12314294918872, -97.08206193812357, 336.88872970498295, -32.811226163389506, 331.163038306576, -4.717447615726483, 425.0820241086926, 4.478873375834706, 315.2889547978069, -102.82257596840984, 130.88859515599643, 70.80426815728114, -36.44688510381235, -115.21962395837743, -26.60674685859871, -95.0662651559331, -35.35801495154881, -84.26086062103452, 0.5565154738518086, -99.3765966977352, 19.039522954307373, -93.23866643804018, 219.76636683188315, 157.95506454873112, 336.78705228415936, -173.9812964756211, 289.23633637543423]}, "sampler_perf": {"mean_env_wait_ms": 48.02838300981989, "mean_raw_obs_processing_ms": 2.135972629150977, "mean_inference_ms": 2.2049966570132558, "mean_action_processing_ms": 0.1353192686729939}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 189000, "timers": {"sample_time_ms": 71932.94, "sample_throughput": 58.388, "load_time_ms": 12.907, "load_throughput": 325409.518, "learn_time_ms": 6310.151, "learn_throughput": 665.594, "update_time_ms": 7.23}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 57.700992584228516, "policy_loss": -0.036473263055086136, "vf_loss": 57.73074722290039, "vf_explained_var": 0.9809643626213074, "kl": 0.014940053224563599, "entropy": 0.8958192467689514, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 48.40801239013672, "policy_loss": -0.04574203863739967, "vf_loss": 48.44702911376953, "vf_explained_var": 0.9850443601608276, "kl": 0.014929174445569515, "entropy": 0.8796332478523254, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 28.609434127807617, "policy_loss": -0.026439527049660683, "vf_loss": 28.630584716796875, "vf_explained_var": 0.9873539805412292, "kl": 0.011745963245630264, "entropy": 0.693349301815033, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 41.247657775878906, "policy_loss": -0.046465568244457245, "vf_loss": 41.2885856628418, "vf_explained_var": 0.9836469888687134, "kl": 0.012294207699596882, "entropy": 0.8106050491333008, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 189000, "num_steps_trained": 189000}, "done": false, "episodes_total": 1384, "training_iteration": 45, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-22-08", "timestamp": 1624220528, "time_this_iter_s": 75.52793550491333, "time_total_s": 4062.0795845985413, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c824a5f0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c80c98c0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647d40>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647ef0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647d40>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647ef0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647d40>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647ef0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647d40>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647f80>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647680>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647ef0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c814fdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4062.0795845985413, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 45.231481481481474, "ram_util_percent": 95.62314814814816}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 2732.6385457045917, "episode_reward_min": -1707.0795730281836, "episode_reward_mean": 348.03646475545895, "episode_len_mean": 198.19, "episodes_this_iter": 23, "policy_reward_min": {"AGENT-0": -646.5432439039848, "AGENT-3": -299.527759007829, "AGENT-2": -512.8532933025252, "AGENT-1": -634.2395104357594}, "policy_reward_max": {"AGENT-0": 793.2128566427535, "AGENT-3": 463.8977481094434, "AGENT-2": 762.7025625367257, "AGENT-1": 787.3057928792331}, "policy_reward_mean": {"AGENT-0": 91.92296384107091, "AGENT-3": 108.08836158521582, "AGENT-2": 68.77656837927302, "AGENT-1": 79.24857094989916}, "custom_metrics": {"mean_ego_speed_mean": 39.3188025, "mean_ego_speed_min": 14.120250000000002, "mean_ego_speed_max": 51.197500000000005, "distance_travelled_mean": 90.62146750000002, "distance_travelled_min": 31.826749999999997, "distance_travelled_max": 124.37225000000001}, "hist_stats": {"episode_reward": [305.9238622003582, 2494.7403840865754, -112.19553726928324, 1731.9600450521361, -10.19083236612854, 2699.094887797515, 263.5171891837223, 883.72199230763, -1183.9453701299528, 137.09421345261183, 738.0083767529077, -854.849277862673, -149.32133963838638, -791.6509366809539, -64.29856037026838, 437.51275218692683, 1022.5489573381094, -292.8538423088081, 857.9820797502776, -450.057403533269, 775.2104694137023, 526.8754672166356, 1472.2231931320712, 798.9411762742579, 275.0906270357679, 656.7257183355309, 432.82646244850497, 714.8205980414153, -848.0148087486057, 493.8050836429634, 199.7036848377559, -981.7732924826759, -734.733604038743, -900.0600195316732, 463.6586488670698, 806.4436547176642, 284.56267148426906, 1627.285078993199, -63.511977682840524, 2034.1901388911244, 954.634284430543, 1402.3452454420744, 93.56482514902358, 2219.4834568903075, 484.75263689713506, 411.13211200409665, 15.695603202141921, -973.2602897224558, 613.3030787339109, -981.8756462877467, 398.7768224682812, -915.6185780853041, 1118.9977830103312, 839.8624521022473, -337.8458587315287, -1707.0795730281836, -1008.8907553980087, -248.63839624052153, 790.1149802864128, 386.19553623768684, 1842.6270088559493, 36.04113207067768, 2698.7152796949463, 83.11427019189276, 1661.677339565968, -281.72088908860115, 645.9544663992681, -91.60607930790403, 204.94148050940592, -1057.3544342457878, 8.60821410744772, -794.234734221018, -248.06316157425186, -792.6707878223169, -750.0397894214956, -351.2819037119379, -1117.9311816723364, -340.34224875499785, 498.59879149737566, 425.53349485150636, 1154.9683731599978, -468.74615611841995, 1373.8660564080171, 1959.7681565590228, 599.3332199413297, 2425.196912092104, 2247.121985213439, 539.2421581792954, 2732.6385457045917, 788.7168060495142, -558.0343448418064, 760.0425299626913, 328.2706272437229, 770.8360023846334, -237.60118153695484, 398.0124126541883, -582.2761712870802, -158.0604825035635, -454.4475394526482, -348.42803234686306], "episode_lengths": [305, 203, 309, 176, 102, 186, 131, 672, 232, 123, 129, 279, 66, 99, 114, 134, 230, 114, 380, 73, 272, 123, 350, 787, 128, 125, 186, 163, 292, 110, 107, 174, 236, 206, 262, 308, 100, 180, 110, 170, 103, 171, 102, 189, 291, 137, 103, 277, 125, 226, 176, 239, 358, 538, 99, 216, 274, 103, 184, 123, 171, 99, 196, 101, 160, 112, 137, 128, 245, 310, 111, 135, 33, 310, 287, 115, 322, 113, 142, 103, 231, 117, 154, 228, 134, 180, 187, 339, 195, 161, 130, 318, 129, 128, 96, 764, 146, 113, 134, 125], "policy_AGENT-0_reward": [276.6757606637621, 706.6482505168299, 71.60579574916832, 512.2157500582477, -16.339299891853514, 793.2128566427535, 231.91243264989757, 26.41608244232287, -485.5474094213122, 53.785348484073346, 316.7418553415741, -302.78951315783934, 18.05802156639262, -313.30878372046277, 30.10127196559067, 267.0338739365438, 131.56290243562498, -77.42509323638157, 112.18227982951761, -69.53849041247715, 386.0083793451035, 259.45056726138466, 362.92045826666555, 39.80481691282082, 188.3926070807363, 244.53278517778776, 271.1679123690864, 282.41834973636213, -305.6524133538473, 110.75620868464597, 42.069823904630525, -466.0546161542661, -237.60942927967386, -421.14560625597477, -68.61826925930134, 396.5392178134704, 17.406540299522604, 456.4662993404683, -3.0657717205517034, 561.6863858725417, 239.4624304968952, 410.3959567319939, 27.638350825881457, 628.0249334093069, 364.5878926666228, 255.0901385848968, 32.94525068236851, -360.58461510117087, 290.49796440679506, -399.6790652412191, 174.26539119224014, -337.8815616865564, 135.68206693142739, -54.58236096187838, -161.8441012537396, -458.38949884696393, -646.5432439039848, -39.674649416136035, 119.78544319479231, 201.6405417589432, 528.4253009969628, 11.119254312720464, 763.1131016910435, 24.656157554061384, 459.90732382045644, -42.01011690704298, 185.30489858954667, 96.54109189575703, 174.1135171775486, -382.50394261746686, 27.28491660706459, -287.3670646880025, -88.60698875039205, -276.1783483745206, -344.62986468669516, -77.06561069730154, -543.4776371692461, -79.02075715690654, 253.6685100959733, 43.56517815478948, 191.8040084283772, -65.57325124803286, 357.8782863821556, 631.4296086762373, 306.7462240645979, 676.1603479543875, 642.1333745478968, 365.1418433766898, 792.7929303415186, 248.55613567495766, -140.13658730866626, 291.39829670894136, 208.0046779461289, 247.43984943706226, -34.77053649189189, -64.63937405293744, -286.86131092400484, -40.58288409511648, -216.048064439553, -186.93151367410516], "policy_AGENT-3_reward": [201.2750536505464, 383.876479267216, -10.068068168056968, 308.436645956977, 11.240927265056676, 448.17238340595725, 206.89736938918625, 463.8977481094434, -93.05585153579878, 8.065274751915858, 288.1338344379203, -83.16126986134616, -92.72186934771823, -101.66545421685814, -65.57510141289245, -33.49212175834965, 333.2340185695848, -69.83043477048903, 310.54879282811663, -155.48730388356992, 414.0148113349856, 235.13535158185425, 354.5287249153292, 339.4639289190563, -36.80182823236373, 215.58499224547947, -28.824010491932857, 239.53509889182274, -85.59608692643423, 157.40253384515083, 40.97241607123092, -5.51652262389846, -98.49139758194015, -6.743532159473347, 297.0545886477372, 351.05553679947, 113.38275713343229, 339.66353223275746, -32.390372153582504, 306.623624275084, 209.52439087954596, 307.73499723597223, 6.8383906298996395, 373.40340274497146, 304.9376615750506, -33.75038775776139, -37.704298647628434, -86.12203567371527, 264.4621632181428, -92.82052469399542, 123.51417710079315, -86.96567508239642, 341.76005586341523, 427.29287366918595, -7.075163893208477, -299.527759007829, 140.12314294918872, -97.08206193812357, 336.88872970498295, -32.811226163389506, 331.163038306576, -4.717447615726483, 425.0820241086926, 4.478873375834706, 315.2889547978069, -102.82257596840984, 130.88859515599643, 70.80426815728114, -36.44688510381235, -115.21962395837743, -26.60674685859871, -95.0662651559331, -35.35801495154881, -84.26086062103452, 0.5565154738518086, -99.3765966977352, 19.039522954307373, -93.23866643804018, 219.76636683188315, 157.95506454873112, 336.78705228415936, -173.9812964756211, 289.23633637543423, 371.043187333587, -44.53290405567467, 368.8086065666547, 329.22509772067684, -72.19600883564435, 389.837259947118, 167.06901556263517, -150.12924483330946, 220.10613496346585, -28.819438679732446, 164.63574401697633, 2.8692101857405703, 247.42593818676335, 10.92711973525917, -26.630031253757252, 3.2139804690460494, -9.365193147647542], "policy_AGENT-2_reward": [-86.35146611742825, 698.7690229005806, -87.078428768375, 442.5816597371404, -16.899085405617647, 728.5680239542118, -87.94674469654026, 366.93055669278505, -512.8532933025252, 53.19726164534763, 66.21226286769883, -386.3182520803843, 17.49893808580143, -275.59398443214025, 29.550633104178576, -33.55037705219338, 93.69875518978492, -77.97249431853325, 66.5454851921501, -70.10706813337505, -12.627399929757622, 15.794597248242201, 299.0206674371039, 380.1849695635954, -36.74753504502693, 98.0592627501508, -28.821796742549687, 96.15645789335868, -371.76766021147574, 112.51644505352648, 41.515880000302154, -5.558363372801265, -98.44199037793184, -6.640437129898701, 303.8009427568145, 29.155241522513855, 16.98139374097775, 412.4770232858582, -3.642379655047414, 576.6266526408756, 238.88417490378828, 365.83271131239525, 27.06351972967673, 603.4020067781445, -92.76912493180393, -33.467278189875294, 32.392108547283385, -440.99750478647843, 28.944425430996127, -397.11920088549454, 50.27346421938313, -404.3684015664357, 152.33848344114205, 522.0492588182492, -7.112763586432166, -463.8507902573257, 131.76885599254607, -40.10323830160597, 195.4520056147595, -32.901891047488434, 511.3029122570736, 10.691561239687426, 743.5373613672818, 24.230705949464287, 431.22656865808005, -42.43815741463679, 155.21534245127793, -129.77775441608142, -36.56534770140717, -444.9784359700622, 26.737905578953487, -317.29917114563585, -35.482218976961164, -348.5384506887788, 0.5766631609398878, -77.61488519055268, 18.97823666733765, -79.58694729745669, 12.365149818916777, 43.01527000489381, 163.5064647045555, -66.14783673797335, 333.8529879847242, 469.72647452368227, -44.57451613828511, 675.3943935890081, 634.7730067799527, -72.20010418590435, 762.7025625367257, 163.17510691322673, -142.36960263973924, 123.865753992026, -28.80690409351502, 139.2062787421312, -103.13917326077808, 279.85436942099466, 11.212962780048901, -64.78253091375586, 3.315132560281877, -9.13849470925966], "policy_AGENT-1_reward": [-85.6754859965219, 705.4466314019497, -86.65483608201967, 468.7259892997716, 11.806625666286031, 729.1416237945921, -87.34586815882133, 26.47760506307816, -92.48881587031664, 22.04632857127517, 66.92042410571375, -82.58024276310353, -92.15642994286222, -101.0827143114927, -58.3753640271452, 237.521377060926, 464.05328114311436, -67.62581998340421, 368.7055219004939, -154.92454110384682, -12.185321336629578, 16.49495112515474, 455.7533425129754, 39.48746087878493, 160.24738323242212, 98.54867816211332, 219.3043573139009, 96.71069151987152, -84.99864825684787, 113.1298960596397, 75.14556486159222, -504.6437903317104, -300.19078679919676, -465.5304439863261, -68.5786132781803, 29.69365858221019, 136.79198031033624, 418.6782241341153, -24.413454153658627, 589.2534761026216, 266.7632881503131, 318.381580161715, 32.02456396356592, 614.6531139578844, -92.00379241273434, 223.25963936683652, -11.93745737988155, -85.55613416108999, 29.398525677977204, -92.25685546703602, 50.72378995586471, -86.4029397499162, 489.21717677434634, -54.897319423309234, -161.81382999814835, -485.31152491606434, -634.2395104357594, -71.77844658465611, 137.9888017718784, 250.26811168962166, 471.73575729533627, 18.94776413399628, 766.982792527926, 29.748533312532352, 455.2544922896236, -94.45003879851154, 174.54563020244652, -129.17368494486092, 103.84019613707675, -114.65243169988118, -18.80786121997169, -94.50223323144601, -88.61593889534984, -83.6931281379841, -406.5431033695925, -97.22481112634854, -612.4713041247352, -88.4958778625947, 12.798764750602416, 180.99798214309192, 462.87084774290656, -163.0437716567924, 392.8984456657028, 487.5688860255181, 381.6944160706911, 704.8335639820539, 640.990506164914, 318.4964278241539, 787.3057928792331, 209.9165478986937, -125.39891006009094, 124.67234429825841, 177.89229207084145, 219.55413018846292, -102.56068197002585, -64.62852090063195, -317.55494287838394, -26.065036240933956, -244.92858804242303, -142.99283081585065]}, "sampler_perf": {"mean_env_wait_ms": 47.647507646199735, "mean_raw_obs_processing_ms": 2.1202199903933705, "mean_inference_ms": 2.1943621858639855, "mean_action_processing_ms": 0.13476743968705546}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 193200, "timers": {"sample_time_ms": 70983.374, "sample_throughput": 59.169, "load_time_ms": 12.731, "load_throughput": 329900.817, "learn_time_ms": 6188.601, "learn_throughput": 678.667, "update_time_ms": 7.276}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 51.03208541870117, "policy_loss": -0.03508268669247627, "vf_loss": 51.060760498046875, "vf_explained_var": 0.982555091381073, "kl": 0.01425265520811081, "entropy": 0.931915283203125, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 76.025634765625, "policy_loss": -0.03971623629331589, "vf_loss": 76.05979919433594, "vf_explained_var": 0.9723725914955139, "kl": 0.012366112321615219, "entropy": 0.8462595343589783, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 77.91033172607422, "policy_loss": -0.04104162007570267, "vf_loss": 77.94585418701172, "vf_explained_var": 0.9765794277191162, "kl": 0.012245653197169304, "entropy": 0.8536938428878784, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 60.37773132324219, "policy_loss": -0.030845101922750473, "vf_loss": 60.40290451049805, "vf_explained_var": 0.979860246181488, "kl": 0.012611228972673416, "entropy": 0.7789894938468933, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 193200, "num_steps_trained": 193200}, "done": false, "episodes_total": 1407, "training_iteration": 46, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-23-20", "timestamp": 1624220600, "time_this_iter_s": 71.56064295768738, "time_total_s": 4133.640227556229, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c81894d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c81893b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8189170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8189050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8189a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8189b90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8189170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8189050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8189a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8189b90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8189170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8189050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8189a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8189b90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8189170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8189050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8189a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8189b90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8189830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4133.640227556229, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 51.422549019607835, "ram_util_percent": 95.60000000000002}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 4004.778780163486, "episode_reward_min": -1724.4466945395336, "episode_reward_mean": 355.96567251806914, "episode_len_mean": 202.73, "episodes_this_iter": 19, "policy_reward_min": {"AGENT-2": -512.8532933025252, "AGENT-1": -892.131219293194, "AGENT-0": -828.596502001634, "AGENT-3": -380.9482319571125}, "policy_reward_max": {"AGENT-2": 1148.7187160235858, "AGENT-1": 1160.4603646560752, "AGENT-0": 1293.2231402736784, "AGENT-3": 744.7208816983477}, "policy_reward_mean": {"AGENT-2": 79.60841423144645, "AGENT-1": 85.62850270647773, "AGENT-0": 85.8394194598167, "AGENT-3": 104.8893361203285}, "custom_metrics": {"mean_ego_speed_mean": 39.060845, "mean_ego_speed_min": 14.120250000000002, "mean_ego_speed_max": 51.197500000000005, "distance_travelled_mean": 90.16273249999999, "distance_travelled_min": 31.826749999999997, "distance_travelled_max": 124.37225000000001}, "hist_stats": {"episode_reward": [573.0186639152306, 407.3882703940965, 4004.778780163486, 679.6241203788428, 123.31775910764368, 111.14819116885067, 1613.294627412224, -315.45803448813683, 2414.6592391924705, 1489.836127193601, 225.1728677880325, -58.58871146647207, -807.2824569261109, 104.136277603093, -847.816227113891, -1724.4466945395336, -394.3182124481871, 1286.3580366207943, -474.96247673740436, 93.56482514902358, 2219.4834568903075, 484.75263689713506, 411.13211200409665, 15.695603202141921, -973.2602897224558, 613.3030787339109, -981.8756462877467, 398.7768224682812, -915.6185780853041, 1118.9977830103312, 839.8624521022473, -337.8458587315287, -1707.0795730281836, -1008.8907553980087, -248.63839624052153, 790.1149802864128, 386.19553623768684, 1842.6270088559493, 36.04113207067768, 2698.7152796949463, 83.11427019189276, 1661.677339565968, -281.72088908860115, 645.9544663992681, -91.60607930790403, 204.94148050940592, -1057.3544342457878, 8.60821410744772, -794.234734221018, -248.06316157425186, -792.6707878223169, -750.0397894214956, -351.2819037119379, -1117.9311816723364, -340.34224875499785, 498.59879149737566, 425.53349485150636, 1154.9683731599978, -468.74615611841995, 1373.8660564080171, 1959.7681565590228, 599.3332199413297, 2425.196912092104, 2247.121985213439, 539.2421581792954, 2732.6385457045917, 788.7168060495142, -558.0343448418064, 760.0425299626913, 328.2706272437229, 770.8360023846334, -237.60118153695484, 398.0124126541883, -582.2761712870802, -158.0604825035635, -454.4475394526482, -348.42803234686306, 305.9238622003582, 2494.7403840865754, -112.19553726928324, 1731.9600450521361, -10.19083236612854, 2699.094887797515, 263.5171891837223, 883.72199230763, -1183.9453701299528, 137.09421345261183, 738.0083767529077, -854.849277862673, -149.32133963838638, -791.6509366809539, -64.29856037026838, 437.51275218692683, 1022.5489573381094, -292.8538423088081, 857.9820797502776, -450.057403533269, 775.2104694137023, 526.8754672166356, 1472.2231931320712], "episode_lengths": [205, 103, 310, 107, 330, 114, 165, 53, 196, 828, 112, 77, 348, 115, 322, 366, 136, 374, 111, 102, 189, 291, 137, 103, 277, 125, 226, 176, 239, 358, 538, 99, 216, 274, 103, 184, 123, 171, 99, 196, 101, 160, 112, 137, 128, 245, 310, 111, 135, 33, 310, 287, 115, 322, 113, 142, 103, 231, 117, 154, 228, 134, 180, 187, 339, 195, 161, 130, 318, 129, 128, 96, 764, 146, 113, 134, 125, 305, 203, 309, 176, 102, 186, 131, 672, 232, 123, 129, 279, 66, 99, 114, 134, 230, 114, 380, 73, 272, 123, 350], "policy_AGENT-2_reward": [152.09452664065984, 95.35138157080485, 1148.7187160235858, 157.66843498681004, 139.28355668799134, 19.242034867409473, 420.40044312894133, -43.40006219999505, 675.167862094265, 670.2456421301125, -35.1452039987631, 33.84245001917109, -347.6229931831117, 56.465221554419024, -51.636884004331925, -1.768193984624634, -20.684322651219002, 214.2268994376161, -78.69393101297423, 27.06351972967673, 603.4020067781445, -92.76912493180393, -33.467278189875294, 32.392108547283385, -440.99750478647843, 28.944425430996127, -397.11920088549454, 50.27346421938313, -404.3684015664357, 152.33848344114205, 522.0492588182492, -7.112763586432166, -463.8507902573257, 131.76885599254607, -40.10323830160597, 195.4520056147595, -32.901891047488434, 511.3029122570736, 10.691561239687426, 743.5373613672818, 24.230705949464287, 431.22656865808005, -42.43815741463679, 155.21534245127793, -129.77775441608142, -36.56534770140717, -444.9784359700622, 26.737905578953487, -317.29917114563585, -35.482218976961164, -348.5384506887788, 0.5766631609398878, -77.61488519055268, 18.97823666733765, -79.58694729745669, 12.365149818916777, 43.01527000489381, 163.5064647045555, -66.14783673797335, 333.8529879847242, 469.72647452368227, -44.57451613828511, 675.3943935890081, 634.7730067799527, -72.20010418590435, 762.7025625367257, 163.17510691322673, -142.36960263973924, 123.865753992026, -28.80690409351502, 139.2062787421312, -103.13917326077808, 279.85436942099466, 11.212962780048901, -64.78253091375586, 3.315132560281877, -9.13849470925966, -86.35146611742825, 698.7690229005806, -87.078428768375, 442.5816597371404, -16.899085405617647, 728.5680239542118, -87.94674469654026, 366.93055669278505, -512.8532933025252, 53.19726164534763, 66.21226286769883, -386.3182520803843, 17.49893808580143, -275.59398443214025, 29.550633104178576, -33.55037705219338, 93.69875518978492, -77.97249431853325, 66.5454851921501, -70.10706813337505, -12.627399929757622, 15.794597248242201, 299.0206674371039], "policy_AGENT-1_reward": [32.098572093169, 119.89682352659223, 1160.4603646560752, 210.84197917771198, -240.04319812018167, 36.328868433694225, 470.432784155037, -114.26491870352307, 683.4944799213612, 37.33178694095327, 171.80041280917473, -63.12683545536532, -98.00622611695316, 0.05654867468977143, -51.0334246370427, -892.131219293194, -20.15614527611536, 490.7057842734387, -182.91275873794987, 32.02456396356592, 614.6531139578844, -92.00379241273434, 223.25963936683652, -11.93745737988155, -85.55613416108999, 29.398525677977204, -92.25685546703602, 50.72378995586471, -86.4029397499162, 489.21717677434634, -54.897319423309234, -161.81382999814835, -485.31152491606434, -634.2395104357594, -71.77844658465611, 137.9888017718784, 250.26811168962166, 471.73575729533627, 18.94776413399628, 766.982792527926, 29.748533312532352, 455.2544922896236, -94.45003879851154, 174.54563020244652, -129.17368494486092, 103.84019613707675, -114.65243169988118, -18.80786121997169, -94.50223323144601, -88.61593889534984, -83.6931281379841, -406.5431033695925, -97.22481112634854, -612.4713041247352, -88.4958778625947, 12.798764750602416, 180.99798214309192, 462.87084774290656, -163.0437716567924, 392.8984456657028, 487.5688860255181, 381.6944160706911, 704.8335639820539, 640.990506164914, 318.4964278241539, 787.3057928792331, 209.9165478986937, -125.39891006009094, 124.67234429825841, 177.89229207084145, 219.55413018846292, -102.56068197002585, -64.62852090063195, -317.55494287838394, -26.065036240933956, -244.92858804242303, -142.99283081585065, -85.6754859965219, 705.4466314019497, -86.65483608201967, 468.7259892997716, 11.806625666286031, 729.1416237945921, -87.34586815882133, 26.47760506307816, -92.48881587031664, 22.04632857127517, 66.92042410571375, -82.58024276310353, -92.15642994286222, -101.0827143114927, -58.3753640271452, 237.521377060926, 464.05328114311436, -67.62581998340421, 368.7055219004939, -154.92454110384682, -12.185321336629578, 16.49495112515474, 455.7533425129754], "policy_AGENT-0_reward": [14.770509623665916, 95.91601692909933, 1293.2231402736784, 158.20708253770346, -257.2948222843183, 19.812345285960937, 390.8549828312475, -42.960930816952455, 695.2395644500832, 37.537816424187454, 123.90644760965426, 34.38785201515807, -263.0805916531408, 57.03052912421772, -364.197686515403, -828.596502001634, -179.96187722151618, 243.9364596517023, -78.13154599146827, 27.638350825881457, 628.0249334093069, 364.5878926666228, 255.0901385848968, 32.94525068236851, -360.58461510117087, 290.49796440679506, -399.6790652412191, 174.26539119224014, -337.8815616865564, 135.68206693142739, -54.58236096187838, -161.8441012537396, -458.38949884696393, -646.5432439039848, -39.674649416136035, 119.78544319479231, 201.6405417589432, 528.4253009969628, 11.119254312720464, 763.1131016910435, 24.656157554061384, 459.90732382045644, -42.01011690704298, 185.30489858954667, 96.54109189575703, 174.1135171775486, -382.50394261746686, 27.28491660706459, -287.3670646880025, -88.60698875039205, -276.1783483745206, -344.62986468669516, -77.06561069730154, -543.4776371692461, -79.02075715690654, 253.6685100959733, 43.56517815478948, 191.8040084283772, -65.57325124803286, 357.8782863821556, 631.4296086762373, 306.7462240645979, 676.1603479543875, 642.1333745478968, 365.1418433766898, 792.7929303415186, 248.55613567495766, -140.13658730866626, 291.39829670894136, 208.0046779461289, 247.43984943706226, -34.77053649189189, -64.63937405293744, -286.86131092400484, -40.58288409511648, -216.048064439553, -186.93151367410516, 276.6757606637621, 706.6482505168299, 71.60579574916832, 512.2157500582477, -16.339299891853514, 793.2128566427535, 231.91243264989757, 26.41608244232287, -485.5474094213122, 53.785348484073346, 316.7418553415741, -302.78951315783934, 18.05802156639262, -313.30878372046277, 30.10127196559067, 267.0338739365438, 131.56290243562498, -77.42509323638157, 112.18227982951761, -69.53849041247715, 386.0083793451035, 259.45056726138466, 362.92045826666555], "policy_AGENT-3_reward": [374.0550555577353, 96.22404836759985, 402.3765592101541, 152.90662367661724, 481.37222282415837, 35.764942581786094, 331.6064172969991, -114.83212276766628, 360.7573327267631, 744.7208816983477, -35.38878863203338, -63.692178045435874, -98.57264597290487, -9.41602175023369, -380.9482319571125, -1.9507792600805938, -173.51586729933646, 337.48889325803594, -135.22424099501222, 6.8383906298996395, 373.40340274497146, 304.9376615750506, -33.75038775776139, -37.704298647628434, -86.12203567371527, 264.4621632181428, -92.82052469399542, 123.51417710079315, -86.96567508239642, 341.76005586341523, 427.29287366918595, -7.075163893208477, -299.527759007829, 140.12314294918872, -97.08206193812357, 336.88872970498295, -32.811226163389506, 331.163038306576, -4.717447615726483, 425.0820241086926, 4.478873375834706, 315.2889547978069, -102.82257596840984, 130.88859515599643, 70.80426815728114, -36.44688510381235, -115.21962395837743, -26.60674685859871, -95.0662651559331, -35.35801495154881, -84.26086062103452, 0.5565154738518086, -99.3765966977352, 19.039522954307373, -93.23866643804018, 219.76636683188315, 157.95506454873112, 336.78705228415936, -173.9812964756211, 289.23633637543423, 371.043187333587, -44.53290405567467, 368.8086065666547, 329.22509772067684, -72.19600883564435, 389.837259947118, 167.06901556263517, -150.12924483330946, 220.10613496346585, -28.819438679732446, 164.63574401697633, 2.8692101857405703, 247.42593818676335, 10.92711973525917, -26.630031253757252, 3.2139804690460494, -9.365193147647542, 201.2750536505464, 383.876479267216, -10.068068168056968, 308.436645956977, 11.240927265056676, 448.17238340595725, 206.89736938918625, 463.8977481094434, -93.05585153579878, 8.065274751915858, 288.1338344379203, -83.16126986134616, -92.72186934771823, -101.66545421685814, -65.57510141289245, -33.49212175834965, 333.2340185695848, -69.83043477048903, 310.54879282811663, -155.48730388356992, 414.0148113349856, 235.13535158185425, 354.5287249153292]}, "sampler_perf": {"mean_env_wait_ms": 47.478647864184474, "mean_raw_obs_processing_ms": 2.1011122553567554, "mean_inference_ms": 2.18940926395009, "mean_action_processing_ms": 0.13436693641762298}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 197400, "timers": {"sample_time_ms": 70571.781, "sample_throughput": 59.514, "load_time_ms": 12.742, "load_throughput": 329631.053, "learn_time_ms": 6046.893, "learn_throughput": 694.572, "update_time_ms": 7.382}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 50.687496185302734, "policy_loss": -0.030446328222751617, "vf_loss": 50.711509704589844, "vf_explained_var": 0.9859830737113953, "kl": 0.014291208237409592, "entropy": 0.8682184219360352, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 59.83915328979492, "policy_loss": -0.0415322408080101, "vf_loss": 59.87391662597656, "vf_explained_var": 0.9862515926361084, "kl": 0.01504497230052948, "entropy": 0.8366972804069519, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 53.58530044555664, "policy_loss": -0.03346274048089981, "vf_loss": 53.61345291137695, "vf_explained_var": 0.982043445110321, "kl": 0.011800778098404408, "entropy": 0.6810019016265869, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 48.72641372680664, "policy_loss": -0.034118231385946274, "vf_loss": 48.75526809692383, "vf_explained_var": 0.9872021675109863, "kl": 0.011700495146214962, "entropy": 0.7866430282592773, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 197400, "num_steps_trained": 197400}, "done": false, "episodes_total": 1426, "training_iteration": 47, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-24-36", "timestamp": 1624220676, "time_this_iter_s": 76.28705072402954, "time_total_s": 4209.927278280258, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c820e680>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c820edd0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c814f5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c814f680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d58c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9dd0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c814f5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c814f680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d58c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9dd0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c814f5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c814f680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d58c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9dd0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c814f5f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c814f680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c81d58c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c80c9dd0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8189dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4209.927278280258, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 45.57981651376147, "ram_util_percent": 95.64128440366974}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 4004.778780163486, "episode_reward_min": -1724.4466945395336, "episode_reward_mean": 375.9673277761082, "episode_len_mean": 205.5, "episodes_this_iter": 16, "policy_reward_min": {"AGENT-0": -828.596502001634, "AGENT-3": -380.9482319571125, "AGENT-2": -512.8532933025252, "AGENT-1": -892.131219293194}, "policy_reward_max": {"AGENT-0": 1293.2231402736784, "AGENT-3": 744.7208816983477, "AGENT-2": 1148.7187160235858, "AGENT-1": 1160.4603646560752}, "policy_reward_mean": {"AGENT-0": 99.0594191048065, "AGENT-3": 104.38062148920905, "AGENT-2": 78.75099432691114, "AGENT-1": 93.77629285518175}, "custom_metrics": {"mean_ego_speed_mean": 39.81501, "mean_ego_speed_min": 15.514999999999999, "mean_ego_speed_max": 51.197500000000005, "distance_travelled_mean": 90.35194750000001, "distance_travelled_min": 31.826749999999997, "distance_travelled_max": 124.37225000000001}, "hist_stats": {"episode_reward": [584.9154376912319, 1754.218544753936, -978.5636341953289, 198.71661477682972, -976.2404521017891, 154.7140918522126, -645.8265959392535, -129.64031459770695, 175.24110223077386, 784.7884216134908, 721.495635583557, 214.036461929123, -507.98813090754743, -439.8901886792536, 872.73138537164, 239.81681938571867, 790.1149802864128, 386.19553623768684, 1842.6270088559493, 36.04113207067768, 2698.7152796949463, 83.11427019189276, 1661.677339565968, -281.72088908860115, 645.9544663992681, -91.60607930790403, 204.94148050940592, -1057.3544342457878, 8.60821410744772, -794.234734221018, -248.06316157425186, -792.6707878223169, -750.0397894214956, -351.2819037119379, -1117.9311816723364, -340.34224875499785, 498.59879149737566, 425.53349485150636, 1154.9683731599978, -468.74615611841995, 1373.8660564080171, 1959.7681565590228, 599.3332199413297, 2425.196912092104, 2247.121985213439, 539.2421581792954, 2732.6385457045917, 788.7168060495142, -558.0343448418064, 760.0425299626913, 328.2706272437229, 770.8360023846334, -237.60118153695484, 398.0124126541883, -582.2761712870802, -158.0604825035635, -454.4475394526482, -348.42803234686306, 305.9238622003582, 2494.7403840865754, -112.19553726928324, 1731.9600450521361, -10.19083236612854, 2699.094887797515, 263.5171891837223, 883.72199230763, -1183.9453701299528, 137.09421345261183, 738.0083767529077, -854.849277862673, -149.32133963838638, -791.6509366809539, -64.29856037026838, 437.51275218692683, 1022.5489573381094, -292.8538423088081, 857.9820797502776, -450.057403533269, 775.2104694137023, 526.8754672166356, 1472.2231931320712, 573.0186639152306, 407.3882703940965, 4004.778780163486, 679.6241203788428, 123.31775910764368, 111.14819116885067, 1613.294627412224, -315.45803448813683, 2414.6592391924705, 1489.836127193601, 225.1728677880325, -58.58871146647207, -807.2824569261109, 104.136277603093, -847.816227113891, -1724.4466945395336, -394.3182124481871, 1286.3580366207943, -474.96247673740436], "episode_lengths": [759, 243, 313, 102, 331, 108, 135, 116, 104, 145, 373, 111, 132, 128, 333, 297, 184, 123, 171, 99, 196, 101, 160, 112, 137, 128, 245, 310, 111, 135, 33, 310, 287, 115, 322, 113, 142, 103, 231, 117, 154, 228, 134, 180, 187, 339, 195, 161, 130, 318, 129, 128, 96, 764, 146, 113, 134, 125, 305, 203, 309, 176, 102, 186, 131, 672, 232, 123, 129, 279, 66, 99, 114, 134, 230, 114, 380, 73, 272, 123, 350, 205, 103, 310, 107, 330, 114, 165, 53, 196, 828, 112, 77, 348, 115, 322, 366, 136, 374, 111], "policy_AGENT-0_reward": [88.64990823956667, 576.9378265354843, -329.21266839579545, 62.5288628696824, -336.7192743449997, 39.510859018693566, -219.5054464048268, 29.96010731459556, 108.19484488327709, 243.55131857167413, 415.2220683595893, 45.42816812676054, -233.83334907314685, -229.44137691039123, 380.9558438395769, 129.32516415712738, 119.78544319479231, 201.6405417589432, 528.4253009969628, 11.119254312720464, 763.1131016910435, 24.656157554061384, 459.90732382045644, -42.01011690704298, 185.30489858954667, 96.54109189575703, 174.1135171775486, -382.50394261746686, 27.28491660706459, -287.3670646880025, -88.60698875039205, -276.1783483745206, -344.62986468669516, -77.06561069730154, -543.4776371692461, -79.02075715690654, 253.6685100959733, 43.56517815478948, 191.8040084283772, -65.57325124803286, 357.8782863821556, 631.4296086762373, 306.7462240645979, 676.1603479543875, 642.1333745478968, 365.1418433766898, 792.7929303415186, 248.55613567495766, -140.13658730866626, 291.39829670894136, 208.0046779461289, 247.43984943706226, -34.77053649189189, -64.63937405293744, -286.86131092400484, -40.58288409511648, -216.048064439553, -186.93151367410516, 276.6757606637621, 706.6482505168299, 71.60579574916832, 512.2157500582477, -16.339299891853514, 793.2128566427535, 231.91243264989757, 26.41608244232287, -485.5474094213122, 53.785348484073346, 316.7418553415741, -302.78951315783934, 18.05802156639262, -313.30878372046277, 30.10127196559067, 267.0338739365438, 131.56290243562498, -77.42509323638157, 112.18227982951761, -69.53849041247715, 386.0083793451035, 259.45056726138466, 362.92045826666555, 14.770509623665916, 95.91601692909933, 1293.2231402736784, 158.20708253770346, -257.2948222843183, 19.812345285960937, 390.8549828312475, -42.960930816952455, 695.2395644500832, 37.537816424187454, 123.90644760965426, 34.38785201515807, -263.0805916531408, 57.03052912421772, -364.197686515403, -828.596502001634, -179.96187722151618, 243.9364596517023, -78.13154599146827], "policy_AGENT-3_reward": [117.33875929458324, 500.20632527657983, -115.1875435503151, 24.783505156097917, -117.78027314775123, 36.64768609150499, -88.55644633087124, -97.92069772278546, -46.25452668246874, 166.80028409350814, 386.27904681219707, 54.90486882718985, -5.926319332585734, -11.764482397971712, 339.0088389854307, 47.83347257170059, 336.88872970498295, -32.811226163389506, 331.163038306576, -4.717447615726483, 425.0820241086926, 4.478873375834706, 315.2889547978069, -102.82257596840984, 130.88859515599643, 70.80426815728114, -36.44688510381235, -115.21962395837743, -26.60674685859871, -95.0662651559331, -35.35801495154881, -84.26086062103452, 0.5565154738518086, -99.3765966977352, 19.039522954307373, -93.23866643804018, 219.76636683188315, 157.95506454873112, 336.78705228415936, -173.9812964756211, 289.23633637543423, 371.043187333587, -44.53290405567467, 368.8086065666547, 329.22509772067684, -72.19600883564435, 389.837259947118, 167.06901556263517, -150.12924483330946, 220.10613496346585, -28.819438679732446, 164.63574401697633, 2.8692101857405703, 247.42593818676335, 10.92711973525917, -26.630031253757252, 3.2139804690460494, -9.365193147647542, 201.2750536505464, 383.876479267216, -10.068068168056968, 308.436645956977, 11.240927265056676, 448.17238340595725, 206.89736938918625, 463.8977481094434, -93.05585153579878, 8.065274751915858, 288.1338344379203, -83.16126986134616, -92.72186934771823, -101.66545421685814, -65.57510141289245, -33.49212175834965, 333.2340185695848, -69.83043477048903, 310.54879282811663, -155.48730388356992, 414.0148113349856, 235.13535158185425, 354.5287249153292, 374.0550555577353, 96.22404836759985, 402.3765592101541, 152.90662367661724, 481.37222282415837, 35.764942581786094, 331.6064172969991, -114.83212276766628, 360.7573327267631, 744.7208816983477, -35.38878863203338, -63.692178045435874, -98.57264597290487, -9.41602175023369, -380.9482319571125, -1.9507792600805938, -173.51586729933646, 337.48889325803594, -135.22424099501222], "policy_AGENT-2_reward": [190.88845802648697, 126.45723649427855, -419.53946737921643, 61.975057808734455, -404.5230721711693, 38.950532765456245, -249.77664021671114, 29.543798866152112, -46.313245461287494, 160.7969451627497, -40.2182370138145, 44.869470266704255, -5.783033465617195, -11.91180574640081, 76.17116245516571, 31.114669606928253, 195.4520056147595, -32.901891047488434, 511.3029122570736, 10.691561239687426, 743.5373613672818, 24.230705949464287, 431.22656865808005, -42.43815741463679, 155.21534245127793, -129.77775441608142, -36.56534770140717, -444.9784359700622, 26.737905578953487, -317.29917114563585, -35.482218976961164, -348.5384506887788, 0.5766631609398878, -77.61488519055268, 18.97823666733765, -79.58694729745669, 12.365149818916777, 43.01527000489381, 163.5064647045555, -66.14783673797335, 333.8529879847242, 469.72647452368227, -44.57451613828511, 675.3943935890081, 634.7730067799527, -72.20010418590435, 762.7025625367257, 163.17510691322673, -142.36960263973924, 123.865753992026, -28.80690409351502, 139.2062787421312, -103.13917326077808, 279.85436942099466, 11.212962780048901, -64.78253091375586, 3.315132560281877, -9.13849470925966, -86.35146611742825, 698.7690229005806, -87.078428768375, 442.5816597371404, -16.899085405617647, 728.5680239542118, -87.94674469654026, 366.93055669278505, -512.8532933025252, 53.19726164534763, 66.21226286769883, -386.3182520803843, 17.49893808580143, -275.59398443214025, 29.550633104178576, -33.55037705219338, 93.69875518978492, -77.97249431853325, 66.5454851921501, -70.10706813337505, -12.627399929757622, 15.794597248242201, 299.0206674371039, 152.09452664065984, 95.35138157080485, 1148.7187160235858, 157.66843498681004, 139.28355668799134, 19.242034867409473, 420.40044312894133, -43.40006219999505, 675.167862094265, 670.2456421301125, -35.1452039987631, 33.84245001917109, -347.6229931831117, 56.465221554419024, -51.636884004331925, -1.768193984624634, -20.684322651219002, 214.2268994376161, -78.69393101297423], "policy_AGENT-1_reward": [188.03831213059635, 550.6171564475931, -114.62395487000359, 49.42918894231495, -117.2178324378699, 39.60501397655805, -87.98806298684431, -91.22352305566906, 159.6140294912529, 213.63987378555893, -39.78724257441415, 68.83395470846807, -262.4454290361979, -186.77252362448985, 76.59554009146706, 31.54351304996245, 137.9888017718784, 250.26811168962166, 471.73575729533627, 18.94776413399628, 766.982792527926, 29.748533312532352, 455.2544922896236, -94.45003879851154, 174.54563020244652, -129.17368494486092, 103.84019613707675, -114.65243169988118, -18.80786121997169, -94.50223323144601, -88.61593889534984, -83.6931281379841, -406.5431033695925, -97.22481112634854, -612.4713041247352, -88.4958778625947, 12.798764750602416, 180.99798214309192, 462.87084774290656, -163.0437716567924, 392.8984456657028, 487.5688860255181, 381.6944160706911, 704.8335639820539, 640.990506164914, 318.4964278241539, 787.3057928792331, 209.9165478986937, -125.39891006009094, 124.67234429825841, 177.89229207084145, 219.55413018846292, -102.56068197002585, -64.62852090063195, -317.55494287838394, -26.065036240933956, -244.92858804242303, -142.99283081585065, -85.6754859965219, 705.4466314019497, -86.65483608201967, 468.7259892997716, 11.806625666286031, 729.1416237945921, -87.34586815882133, 26.47760506307816, -92.48881587031664, 22.04632857127517, 66.92042410571375, -82.58024276310353, -92.15642994286222, -101.0827143114927, -58.3753640271452, 237.521377060926, 464.05328114311436, -67.62581998340421, 368.7055219004939, -154.92454110384682, -12.185321336629578, 16.49495112515474, 455.7533425129754, 32.098572093169, 119.89682352659223, 1160.4603646560752, 210.84197917771198, -240.04319812018167, 36.328868433694225, 470.432784155037, -114.26491870352307, 683.4944799213612, 37.33178694095327, 171.80041280917473, -63.12683545536532, -98.00622611695316, 0.05654867468977143, -51.0334246370427, -892.131219293194, -20.15614527611536, 490.7057842734387, -182.91275873794987]}, "sampler_perf": {"mean_env_wait_ms": 47.181794472583405, "mean_raw_obs_processing_ms": 2.09002869748044, "mean_inference_ms": 2.1791821811956593, "mean_action_processing_ms": 0.133929413662701}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 201600, "timers": {"sample_time_ms": 69283.497, "sample_throughput": 60.62, "load_time_ms": 12.501, "load_throughput": 335964.115, "learn_time_ms": 5894.527, "learn_throughput": 712.525, "update_time_ms": 7.268}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 42.656517028808594, "policy_loss": -0.032512176781892776, "vf_loss": 42.68092346191406, "vf_explained_var": 0.9812314510345459, "kl": 0.01802211068570614, "entropy": 0.9538742303848267, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 50.80131149291992, "policy_loss": -0.03905720263719559, "vf_loss": 50.8333625793457, "vf_explained_var": 0.9772548675537109, "kl": 0.015553787350654602, "entropy": 0.9215279221534729, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 31.884254455566406, "policy_loss": -0.03559715673327446, "vf_loss": 31.91497802734375, "vf_explained_var": 0.9762610197067261, "kl": 0.010829915292561054, "entropy": 0.6888949275016785, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 39.36568832397461, "policy_loss": -0.05563810467720032, "vf_loss": 39.4151496887207, "vf_explained_var": 0.9845076203346252, "kl": 0.013713800348341465, "entropy": 0.8326460719108582, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 201600, "num_steps_trained": 201600}, "done": false, "episodes_total": 1442, "training_iteration": 48, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-25-38", "timestamp": 1624220738, "time_this_iter_s": 62.12106537818909, "time_total_s": 4272.048343658447, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c0fe54d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c0fe53b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5b90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5b90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5b90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5b90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c0fe5830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4272.048343658447, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 49.42696629213483, "ram_util_percent": 95.61685393258429}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 4004.778780163486, "episode_reward_min": -1724.4466945395336, "episode_reward_mean": 432.9798676562226, "episode_len_mean": 220.44, "episodes_this_iter": 18, "policy_reward_min": {"AGENT-0": -828.596502001634, "AGENT-3": -380.9482319571125, "AGENT-2": -512.8532933025252, "AGENT-1": -892.131219293194}, "policy_reward_max": {"AGENT-0": 1293.2231402736784, "AGENT-3": 744.7208816983477, "AGENT-2": 1148.7187160235858, "AGENT-1": 1160.4603646560752}, "policy_reward_mean": {"AGENT-0": 125.03568574738206, "AGENT-3": 121.19404729137783, "AGENT-2": 83.88886493009575, "AGENT-1": 102.8612696873672}, "custom_metrics": {"mean_ego_speed_mean": 39.7826775, "mean_ego_speed_min": 15.514999999999999, "mean_ego_speed_max": 51.197500000000005, "distance_travelled_mean": 91.31770499999999, "distance_travelled_min": 44.314750000000004, "distance_travelled_max": 124.37225000000001}, "hist_stats": {"episode_reward": [-198.83243062889312, 1990.6725139495773, 3.0391797677652903, 1590.7596240701462, 443.67701850291985, 622.790991854793, 289.51966551422424, 816.658327171752, 18.828863721653015, 75.17155597415847, 885.1932586370822, 331.89325411160786, 674.9918386239469, 549.5369405835198, 1463.58481722184, -304.0285858173498, 812.7905295101655, -373.9754462311257, -1117.9311816723364, -340.34224875499785, 498.59879149737566, 425.53349485150636, 1154.9683731599978, -468.74615611841995, 1373.8660564080171, 1959.7681565590228, 599.3332199413297, 2425.196912092104, 2247.121985213439, 539.2421581792954, 2732.6385457045917, 788.7168060495142, -558.0343448418064, 760.0425299626913, 328.2706272437229, 770.8360023846334, -237.60118153695484, 398.0124126541883, -582.2761712870802, -158.0604825035635, -454.4475394526482, -348.42803234686306, 305.9238622003582, 2494.7403840865754, -112.19553726928324, 1731.9600450521361, -10.19083236612854, 2699.094887797515, 263.5171891837223, 883.72199230763, -1183.9453701299528, 137.09421345261183, 738.0083767529077, -854.849277862673, -149.32133963838638, -791.6509366809539, -64.29856037026838, 437.51275218692683, 1022.5489573381094, -292.8538423088081, 857.9820797502776, -450.057403533269, 775.2104694137023, 526.8754672166356, 1472.2231931320712, 573.0186639152306, 407.3882703940965, 4004.778780163486, 679.6241203788428, 123.31775910764368, 111.14819116885067, 1613.294627412224, -315.45803448813683, 2414.6592391924705, 1489.836127193601, 225.1728677880325, -58.58871146647207, -807.2824569261109, 104.136277603093, -847.816227113891, -1724.4466945395336, -394.3182124481871, 1286.3580366207943, -474.96247673740436, 584.9154376912319, 1754.218544753936, -978.5636341953289, 198.71661477682972, -976.2404521017891, 154.7140918522126, -645.8265959392535, -129.64031459770695, 175.24110223077386, 784.7884216134908, 721.495635583557, 214.036461929123, -507.98813090754743, -439.8901886792536, 872.73138537164, 239.81681938571867], "episode_lengths": [999, 363, 120, 323, 135, 285, 124, 126, 379, 114, 351, 101, 406, 115, 164, 117, 110, 119, 322, 113, 142, 103, 231, 117, 154, 228, 134, 180, 187, 339, 195, 161, 130, 318, 129, 128, 96, 764, 146, 113, 134, 125, 305, 203, 309, 176, 102, 186, 131, 672, 232, 123, 129, 279, 66, 99, 114, 134, 230, 114, 380, 73, 272, 123, 350, 205, 103, 310, 107, 330, 114, 165, 53, 196, 828, 112, 77, 348, 115, 322, 366, 136, 374, 111, 759, 243, 313, 102, 331, 108, 135, 116, 104, 145, 373, 111, 132, 128, 333, 297], "policy_AGENT-0_reward": [-9.252235627050908, 517.8750328316661, -3.3390480406854905, 520.8683672767471, 266.1501987717554, 186.76120005771983, 196.3579511293776, 344.82078427830675, 151.4305643929157, 50.754589651863114, 392.80346544226006, 30.03998780737127, 403.76022561848714, 263.03105914958076, 375.23004105692786, -89.6157649803375, 190.0718298250748, -96.59197350694399, -543.4776371692461, -79.02075715690654, 253.6685100959733, 43.56517815478948, 191.8040084283772, -65.57325124803286, 357.8782863821556, 631.4296086762373, 306.7462240645979, 676.1603479543875, 642.1333745478968, 365.1418433766898, 792.7929303415186, 248.55613567495766, -140.13658730866626, 291.39829670894136, 208.0046779461289, 247.43984943706226, -34.77053649189189, -64.63937405293744, -286.86131092400484, -40.58288409511648, -216.048064439553, -186.93151367410516, 276.6757606637621, 706.6482505168299, 71.60579574916832, 512.2157500582477, -16.339299891853514, 793.2128566427535, 231.91243264989757, 26.41608244232287, -485.5474094213122, 53.785348484073346, 316.7418553415741, -302.78951315783934, 18.05802156639262, -313.30878372046277, 30.10127196559067, 267.0338739365438, 131.56290243562498, -77.42509323638157, 112.18227982951761, -69.53849041247715, 386.0083793451035, 259.45056726138466, 362.92045826666555, 14.770509623665916, 95.91601692909933, 1293.2231402736784, 158.20708253770346, -257.2948222843183, 19.812345285960937, 390.8549828312475, -42.960930816952455, 695.2395644500832, 37.537816424187454, 123.90644760965426, 34.38785201515807, -263.0805916531408, 57.03052912421772, -364.197686515403, -828.596502001634, -179.96187722151618, 243.9364596517023, -78.13154599146827, 88.64990823956667, 576.9378265354843, -329.21266839579545, 62.5288628696824, -336.7192743449997, 39.510859018693566, -219.5054464048268, 29.96010731459556, 108.19484488327709, 243.55131857167413, 415.2220683595893, 45.42816812676054, -233.83334907314685, -229.44137691039123, 380.9558438395769, 129.32516415712738], "policy_AGENT-3_reward": [-87.15393560479299, 490.18771457083636, 4.857950602684241, 489.15575458718007, -29.491324367888534, 131.14557416841348, -37.394811989271744, 315.35139609624207, 85.64254095919134, -16.794690055816925, 351.8058219798428, 124.20811722212454, 355.3881970986138, 236.21755442193887, 309.3661361729928, -120.20042081046405, 190.03869637227825, -128.52293522076582, 19.039522954307373, -93.23866643804018, 219.76636683188315, 157.95506454873112, 336.78705228415936, -173.9812964756211, 289.23633637543423, 371.043187333587, -44.53290405567467, 368.8086065666547, 329.22509772067684, -72.19600883564435, 389.837259947118, 167.06901556263517, -150.12924483330946, 220.10613496346585, -28.819438679732446, 164.63574401697633, 2.8692101857405703, 247.42593818676335, 10.92711973525917, -26.630031253757252, 3.2139804690460494, -9.365193147647542, 201.2750536505464, 383.876479267216, -10.068068168056968, 308.436645956977, 11.240927265056676, 448.17238340595725, 206.89736938918625, 463.8977481094434, -93.05585153579878, 8.065274751915858, 288.1338344379203, -83.16126986134616, -92.72186934771823, -101.66545421685814, -65.57510141289245, -33.49212175834965, 333.2340185695848, -69.83043477048903, 310.54879282811663, -155.48730388356992, 414.0148113349856, 235.13535158185425, 354.5287249153292, 374.0550555577353, 96.22404836759985, 402.3765592101541, 152.90662367661724, 481.37222282415837, 35.764942581786094, 331.6064172969991, -114.83212276766628, 360.7573327267631, 744.7208816983477, -35.38878863203338, -63.692178045435874, -98.57264597290487, -9.41602175023369, -380.9482319571125, -1.9507792600805938, -173.51586729933646, 337.48889325803594, -135.22424099501222, 117.33875929458324, 500.20632527657983, -115.1875435503151, 24.783505156097917, -117.78027314775123, 36.64768609150499, -88.55644633087124, -97.92069772278546, -46.25452668246874, 166.80028409350814, 386.27904681219707, 54.90486882718985, -5.926319332585734, -11.764482397971712, 339.0088389854307, 47.83347257170059], "policy_AGENT-2_reward": [-15.835331586109243, 493.7712281850949, -3.9023585167781505, 88.15661607215623, -29.53138184823406, 130.823475581997, -37.275733152652606, 77.89374932292681, -109.44991514999691, 50.19760013129541, 70.07617725194666, 29.48543256000957, -42.34649010411735, 24.90675400240613, 352.8183256569729, -47.32842694226545, 189.50945481488904, -74.80740223516622, 18.97823666733765, -79.58694729745669, 12.365149818916777, 43.01527000489381, 163.5064647045555, -66.14783673797335, 333.8529879847242, 469.72647452368227, -44.57451613828511, 675.3943935890081, 634.7730067799527, -72.20010418590435, 762.7025625367257, 163.17510691322673, -142.36960263973924, 123.865753992026, -28.80690409351502, 139.2062787421312, -103.13917326077808, 279.85436942099466, 11.212962780048901, -64.78253091375586, 3.315132560281877, -9.13849470925966, -86.35146611742825, 698.7690229005806, -87.078428768375, 442.5816597371404, -16.899085405617647, 728.5680239542118, -87.94674469654026, 366.93055669278505, -512.8532933025252, 53.19726164534763, 66.21226286769883, -386.3182520803843, 17.49893808580143, -275.59398443214025, 29.550633104178576, -33.55037705219338, 93.69875518978492, -77.97249431853325, 66.5454851921501, -70.10706813337505, -12.627399929757622, 15.794597248242201, 299.0206674371039, 152.09452664065984, 95.35138157080485, 1148.7187160235858, 157.66843498681004, 139.28355668799134, 19.242034867409473, 420.40044312894133, -43.40006219999505, 675.167862094265, 670.2456421301125, -35.1452039987631, 33.84245001917109, -347.6229931831117, 56.465221554419024, -51.636884004331925, -1.768193984624634, -20.684322651219002, 214.2268994376161, -78.69393101297423, 190.88845802648697, 126.45723649427855, -419.53946737921643, 61.975057808734455, -404.5230721711693, 38.950532765456245, -249.77664021671114, 29.543798866152112, -46.313245461287494, 160.7969451627497, -40.2182370138145, 44.869470266704255, -5.783033465617195, -11.91180574640081, 76.17116245516571, 31.114669606928253], "policy_AGENT-1_reward": [-86.5909278109398, 488.83853836198097, 5.422635722544747, 492.57888613406175, 236.54952594728692, 174.06074204666226, 167.8322595267709, 78.59239747427624, -108.79432648045686, -8.985943753183088, 70.5077939630336, 148.15971652210234, -41.81009398903543, 25.3815730095939, 426.17031433494606, -46.883973084282516, 243.170548497923, -74.05313526824952, -612.4713041247352, -88.4958778625947, 12.798764750602416, 180.99798214309192, 462.87084774290656, -163.0437716567924, 392.8984456657028, 487.5688860255181, 381.6944160706911, 704.8335639820539, 640.990506164914, 318.4964278241539, 787.3057928792331, 209.9165478986937, -125.39891006009094, 124.67234429825841, 177.89229207084145, 219.55413018846292, -102.56068197002585, -64.62852090063195, -317.55494287838394, -26.065036240933956, -244.92858804242303, -142.99283081585065, -85.6754859965219, 705.4466314019497, -86.65483608201967, 468.7259892997716, 11.806625666286031, 729.1416237945921, -87.34586815882133, 26.47760506307816, -92.48881587031664, 22.04632857127517, 66.92042410571375, -82.58024276310353, -92.15642994286222, -101.0827143114927, -58.3753640271452, 237.521377060926, 464.05328114311436, -67.62581998340421, 368.7055219004939, -154.92454110384682, -12.185321336629578, 16.49495112515474, 455.7533425129754, 32.098572093169, 119.89682352659223, 1160.4603646560752, 210.84197917771198, -240.04319812018167, 36.328868433694225, 470.432784155037, -114.26491870352307, 683.4944799213612, 37.33178694095327, 171.80041280917473, -63.12683545536532, -98.00622611695316, 0.05654867468977143, -51.0334246370427, -892.131219293194, -20.15614527611536, 490.7057842734387, -182.91275873794987, 188.03831213059635, 550.6171564475931, -114.62395487000359, 49.42918894231495, -117.2178324378699, 39.60501397655805, -87.98806298684431, -91.22352305566906, 159.6140294912529, 213.63987378555893, -39.78724257441415, 68.83395470846807, -262.4454290361979, -186.77252362448985, 76.59554009146706, 31.54351304996245]}, "sampler_perf": {"mean_env_wait_ms": 46.86360511845423, "mean_raw_obs_processing_ms": 2.0758048720362567, "mean_inference_ms": 2.166181615442247, "mean_action_processing_ms": 0.13343813936346516}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 205800, "timers": {"sample_time_ms": 68772.667, "sample_throughput": 61.071, "load_time_ms": 12.461, "load_throughput": 337052.389, "learn_time_ms": 5818.4, "learn_throughput": 721.848, "update_time_ms": 7.243}, "info": {"learner": {"AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 40.1622200012207, "policy_loss": -0.030478382483124733, "vf_loss": 40.187583923339844, "vf_explained_var": 0.9784890413284302, "kl": 0.011356948874890804, "entropy": 0.709062397480011, "entropy_coeff": 0.0, "model": {}}, "AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 37.885337829589844, "policy_loss": -0.02812783233821392, "vf_loss": 37.9073486328125, "vf_explained_var": 0.981820285320282, "kl": 0.013600236736238003, "entropy": 0.8282411098480225, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 41.939083099365234, "policy_loss": -0.03751446306705475, "vf_loss": 41.969905853271484, "vf_explained_var": 0.9820324182510376, "kl": 0.014863169752061367, "entropy": 0.8106282353401184, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 60.03524398803711, "policy_loss": -0.031589265912771225, "vf_loss": 60.061302185058594, "vf_explained_var": 0.98001629114151, "kl": 0.012311139144003391, "entropy": 0.7528076767921448, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 205800, "num_steps_trained": 205800}, "done": false, "episodes_total": 1460, "training_iteration": 49, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-26-51", "timestamp": 1624220811, "time_this_iter_s": 72.34938073158264, "time_total_s": 4344.39772439003, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c81898c0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c8189680>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688200>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688b00>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688e60>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688f80>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688200>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688b00>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688e60>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688f80>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688200>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688b00>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688e60>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688f80>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688200>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688b00>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688e60>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688f80>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c0fe5dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4344.39772439003, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 45.84903846153846, "ram_util_percent": 95.35576923076923}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 4004.778780163486, "episode_reward_min": -1724.4466945395336, "episode_reward_mean": 361.3033903542757, "episode_len_mean": 227.37, "episodes_this_iter": 17, "policy_reward_min": {"AGENT-0": -828.596502001634, "AGENT-3": -380.9482319571125, "AGENT-2": -512.8532933025252, "AGENT-1": -892.131219293194}, "policy_reward_max": {"AGENT-0": 1293.2231402736784, "AGENT-3": 844.3922980148661, "AGENT-2": 1148.7187160235858, "AGENT-1": 1160.4603646560752}, "policy_reward_mean": {"AGENT-0": 103.74509029130034, "AGENT-3": 120.7730192217544, "AGENT-2": 58.002818832007215, "AGENT-1": 78.78246200921384}, "custom_metrics": {"mean_ego_speed_mean": 39.86271, "mean_ego_speed_min": 15.514999999999999, "mean_ego_speed_max": 50.696, "distance_travelled_mean": 88.1541775, "distance_travelled_min": 44.314750000000004, "distance_travelled_max": 124.1905}, "hist_stats": {"episode_reward": [408.7651957029724, 1556.2746439224818, 23.55554990243627, 2190.5996046490945, -1041.5397952493227, -8.17548224444333, -96.62552799665455, 3.374976976652451, 340.3550866850464, 65.86497113247776, -836.0069294609212, 585.3826732949608, 426.25242865508505, 888.3244612478944, -844.0191215799351, 817.4183474663454, 1700.7949121761783, 770.8360023846334, -237.60118153695484, 398.0124126541883, -582.2761712870802, -158.0604825035635, -454.4475394526482, -348.42803234686306, 305.9238622003582, 2494.7403840865754, -112.19553726928324, 1731.9600450521361, -10.19083236612854, 2699.094887797515, 263.5171891837223, 883.72199230763, -1183.9453701299528, 137.09421345261183, 738.0083767529077, -854.849277862673, -149.32133963838638, -791.6509366809539, -64.29856037026838, 437.51275218692683, 1022.5489573381094, -292.8538423088081, 857.9820797502776, -450.057403533269, 775.2104694137023, 526.8754672166356, 1472.2231931320712, 573.0186639152306, 407.3882703940965, 4004.778780163486, 679.6241203788428, 123.31775910764368, 111.14819116885067, 1613.294627412224, -315.45803448813683, 2414.6592391924705, 1489.836127193601, 225.1728677880325, -58.58871146647207, -807.2824569261109, 104.136277603093, -847.816227113891, -1724.4466945395336, -394.3182124481871, 1286.3580366207943, -474.96247673740436, 584.9154376912319, 1754.218544753936, -978.5636341953289, 198.71661477682972, -976.2404521017891, 154.7140918522126, -645.8265959392535, -129.64031459770695, 175.24110223077386, 784.7884216134908, 721.495635583557, 214.036461929123, -507.98813090754743, -439.8901886792536, 872.73138537164, 239.81681938571867, -198.83243062889312, 1990.6725139495773, 3.0391797677652903, 1590.7596240701462, 443.67701850291985, 622.790991854793, 289.51966551422424, 816.658327171752, 18.828863721653015, 75.17155597415847, 885.1932586370822, 331.89325411160786, 674.9918386239469, 549.5369405835198, 1463.58481722184, -304.0285858173498, 812.7905295101655, -373.9754462311257], "episode_lengths": [133, 286, 599, 195, 374, 70, 117, 116, 124, 102, 133, 117, 138, 127, 129, 362, 754, 128, 96, 764, 146, 113, 134, 125, 305, 203, 309, 176, 102, 186, 131, 672, 232, 123, 129, 279, 66, 99, 114, 134, 230, 114, 380, 73, 272, 123, 350, 205, 103, 310, 107, 330, 114, 165, 53, 196, 828, 112, 77, 348, 115, 322, 366, 136, 374, 111, 759, 243, 313, 102, 331, 108, 135, 116, 104, 145, 373, 111, 132, 128, 333, 297, 999, 363, 120, 323, 135, 285, 124, 126, 379, 114, 351, 101, 406, 115, 164, 117, 110, 119], "policy_AGENT-0_reward": [261.23279652114763, 505.4352872281571, 24.731179516498184, 565.4444006353657, -409.7937753330602, 37.578928119265974, 62.760929920189284, 39.90925078969433, 220.0583242780276, 41.88432172007286, -302.1710729095382, 283.1691909990104, 258.26427178324326, 332.8319377965464, -304.1386706639155, 400.51153458981435, 34.30280887110777, 247.43984943706226, -34.77053649189189, -64.63937405293744, -286.86131092400484, -40.58288409511648, -216.048064439553, -186.93151367410516, 276.6757606637621, 706.6482505168299, 71.60579574916832, 512.2157500582477, -16.339299891853514, 793.2128566427535, 231.91243264989757, 26.41608244232287, -485.5474094213122, 53.785348484073346, 316.7418553415741, -302.78951315783934, 18.05802156639262, -313.30878372046277, 30.10127196559067, 267.0338739365438, 131.56290243562498, -77.42509323638157, 112.18227982951761, -69.53849041247715, 386.0083793451035, 259.45056726138466, 362.92045826666555, 14.770509623665916, 95.91601692909933, 1293.2231402736784, 158.20708253770346, -257.2948222843183, 19.812345285960937, 390.8549828312475, -42.960930816952455, 695.2395644500832, 37.537816424187454, 123.90644760965426, 34.38785201515807, -263.0805916531408, 57.03052912421772, -364.197686515403, -828.596502001634, -179.96187722151618, 243.9364596517023, -78.13154599146827, 88.64990823956667, 576.9378265354843, -329.21266839579545, 62.5288628696824, -336.7192743449997, 39.510859018693566, -219.5054464048268, 29.96010731459556, 108.19484488327709, 243.55131857167413, 415.2220683595893, 45.42816812676054, -233.83334907314685, -229.44137691039123, 380.9558438395769, 129.32516415712738, -9.252235627050908, 517.8750328316661, -3.3390480406854905, 520.8683672767471, 266.1501987717554, 186.76120005771983, 196.3579511293776, 344.82078427830675, 151.4305643929157, 50.754589651863114, 392.80346544226006, 30.03998780737127, 403.76022561848714, 263.03105914958076, 375.23004105692786, -89.6157649803375, 190.0718298250748, -96.59197350694399], "policy_AGENT-3_reward": [-42.220267630602585, 488.97384712976066, 15.19633546644851, 478.320625634269, -90.40757817622651, -41.66864203749473, 36.70140018296481, -39.17424125394798, -35.5058250632096, -21.06226320606098, -99.37036884017475, 259.20852679056634, -29.848835661391384, 302.85694708666324, -102.11687180535625, 339.59819217721434, 844.3922980148661, 164.63574401697633, 2.8692101857405703, 247.42593818676335, 10.92711973525917, -26.630031253757252, 3.2139804690460494, -9.365193147647542, 201.2750536505464, 383.876479267216, -10.068068168056968, 308.436645956977, 11.240927265056676, 448.17238340595725, 206.89736938918625, 463.8977481094434, -93.05585153579878, 8.065274751915858, 288.1338344379203, -83.16126986134616, -92.72186934771823, -101.66545421685814, -65.57510141289245, -33.49212175834965, 333.2340185695848, -69.83043477048903, 310.54879282811663, -155.48730388356992, 414.0148113349856, 235.13535158185425, 354.5287249153292, 374.0550555577353, 96.22404836759985, 402.3765592101541, 152.90662367661724, 481.37222282415837, 35.764942581786094, 331.6064172969991, -114.83212276766628, 360.7573327267631, 744.7208816983477, -35.38878863203338, -63.692178045435874, -98.57264597290487, -9.41602175023369, -380.9482319571125, -1.9507792600805938, -173.51586729933646, 337.48889325803594, -135.22424099501222, 117.33875929458324, 500.20632527657983, -115.1875435503151, 24.783505156097917, -117.78027314775123, 36.64768609150499, -88.55644633087124, -97.92069772278546, -46.25452668246874, 166.80028409350814, 386.27904681219707, 54.90486882718985, -5.926319332585734, -11.764482397971712, 339.0088389854307, 47.83347257170059, -87.15393560479299, 490.18771457083636, 4.857950602684241, 489.15575458718007, -29.491324367888534, 131.14557416841348, -37.394811989271744, 315.35139609624207, 85.64254095919134, -16.794690055816925, 351.8058219798428, 124.20811722212454, 355.3881970986138, 236.21755442193887, 309.3661361729928, -120.20042081046405, 190.03869637227825, -128.52293522076582], "policy_AGENT-2_reward": [-42.19805819489745, 84.21827921185032, -32.13332701628052, 564.8703836363633, -451.493449239162, 37.01912785222565, -98.25853929501493, 39.35944028788732, -35.402907491306706, 41.313684997524724, -335.6598782401541, 21.28727729434684, -29.833445250501136, 126.04146922979052, -336.234601945168, 38.43799514970994, 787.7314356261098, 139.2062787421312, -103.13917326077808, 279.85436942099466, 11.212962780048901, -64.78253091375586, 3.315132560281877, -9.13849470925966, -86.35146611742825, 698.7690229005806, -87.078428768375, 442.5816597371404, -16.899085405617647, 728.5680239542118, -87.94674469654026, 366.93055669278505, -512.8532933025252, 53.19726164534763, 66.21226286769883, -386.3182520803843, 17.49893808580143, -275.59398443214025, 29.550633104178576, -33.55037705219338, 93.69875518978492, -77.97249431853325, 66.5454851921501, -70.10706813337505, -12.627399929757622, 15.794597248242201, 299.0206674371039, 152.09452664065984, 95.35138157080485, 1148.7187160235858, 157.66843498681004, 139.28355668799134, 19.242034867409473, 420.40044312894133, -43.40006219999505, 675.167862094265, 670.2456421301125, -35.1452039987631, 33.84245001917109, -347.6229931831117, 56.465221554419024, -51.636884004331925, -1.768193984624634, -20.684322651219002, 214.2268994376161, -78.69393101297423, 190.88845802648697, 126.45723649427855, -419.53946737921643, 61.975057808734455, -404.5230721711693, 38.950532765456245, -249.77664021671114, 29.543798866152112, -46.313245461287494, 160.7969451627497, -40.2182370138145, 44.869470266704255, -5.783033465617195, -11.91180574640081, 76.17116245516571, 31.114669606928253, -15.835331586109243, 493.7712281850949, -3.9023585167781505, 88.15661607215623, -29.53138184823406, 130.823475581997, -37.275733152652606, 77.89374932292681, -109.44991514999691, 50.19760013129541, 70.07617725194666, 29.48543256000957, -42.34649010411735, 24.90675400240613, 352.8183256569729, -47.32842694226545, 189.50945481488904, -74.80740223516622], "policy_AGENT-1_reward": [231.95072500732456, 477.6472303527138, 15.761361935769983, 581.964194743097, -89.84499250087322, -41.10489617844019, -97.82931880479372, -36.71947284698126, 191.20549496153512, 3.729227620941341, -98.80560947105363, 21.71767821103757, 227.67043778373412, 126.5941071348944, -101.52897716549509, 38.870625549605464, 34.36836966409748, 219.55413018846292, -102.56068197002585, -64.62852090063195, -317.55494287838394, -26.065036240933956, -244.92858804242303, -142.99283081585065, -85.6754859965219, 705.4466314019497, -86.65483608201967, 468.7259892997716, 11.806625666286031, 729.1416237945921, -87.34586815882133, 26.47760506307816, -92.48881587031664, 22.04632857127517, 66.92042410571375, -82.58024276310353, -92.15642994286222, -101.0827143114927, -58.3753640271452, 237.521377060926, 464.05328114311436, -67.62581998340421, 368.7055219004939, -154.92454110384682, -12.185321336629578, 16.49495112515474, 455.7533425129754, 32.098572093169, 119.89682352659223, 1160.4603646560752, 210.84197917771198, -240.04319812018167, 36.328868433694225, 470.432784155037, -114.26491870352307, 683.4944799213612, 37.33178694095327, 171.80041280917473, -63.12683545536532, -98.00622611695316, 0.05654867468977143, -51.0334246370427, -892.131219293194, -20.15614527611536, 490.7057842734387, -182.91275873794987, 188.03831213059635, 550.6171564475931, -114.62395487000359, 49.42918894231495, -117.2178324378699, 39.60501397655805, -87.98806298684431, -91.22352305566906, 159.6140294912529, 213.63987378555893, -39.78724257441415, 68.83395470846807, -262.4454290361979, -186.77252362448985, 76.59554009146706, 31.54351304996245, -86.5909278109398, 488.83853836198097, 5.422635722544747, 492.57888613406175, 236.54952594728692, 174.06074204666226, 167.8322595267709, 78.59239747427624, -108.79432648045686, -8.985943753183088, 70.5077939630336, 148.15971652210234, -41.81009398903543, 25.3815730095939, 426.17031433494606, -46.883973084282516, 243.170548497923, -74.05313526824952]}, "sampler_perf": {"mean_env_wait_ms": 46.48212286627538, "mean_raw_obs_processing_ms": 2.063236347101631, "mean_inference_ms": 2.1570953179226215, "mean_action_processing_ms": 0.13292355997219482}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 210000, "timers": {"sample_time_ms": 67596.008, "sample_throughput": 62.134, "load_time_ms": 12.167, "load_throughput": 345189.236, "learn_time_ms": 5665.553, "learn_throughput": 741.322, "update_time_ms": 7.318}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 51.624656677246094, "policy_loss": -0.02918412908911705, "vf_loss": 51.648780822753906, "vf_explained_var": 0.982124924659729, "kl": 0.011246929876506329, "entropy": 0.8793240785598755, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 68.50012969970703, "policy_loss": -0.0366223081946373, "vf_loss": 68.5308609008789, "vf_explained_var": 0.9773554801940918, "kl": 0.013084989041090012, "entropy": 0.8130536079406738, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 25.316478729248047, "policy_loss": -0.03940771147608757, "vf_loss": 25.351348876953125, "vf_explained_var": 0.9881191849708557, "kl": 0.010085341520607471, "entropy": 0.7015565633773804, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 47.642723083496094, "policy_loss": -0.03515153378248215, "vf_loss": 47.67243194580078, "vf_explained_var": 0.9863470196723938, "kl": 0.012094481848180294, "entropy": 0.7717655301094055, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 210000, "num_steps_trained": 210000}, "done": false, "episodes_total": 1477, "training_iteration": 50, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-27-56", "timestamp": 1624220876, "time_this_iter_s": 64.2253909111023, "time_total_s": 4408.623115301132, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c0f744d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c0f743b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74b90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74b90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74b90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74b90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c0f74950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4408.623115301132, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 49.04565217391305, "ram_util_percent": 95.37826086956517}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 4004.778780163486, "episode_reward_min": -1724.4466945395336, "episode_reward_mean": 339.1235447214637, "episode_len_mean": 219.12, "episodes_this_iter": 27, "policy_reward_min": {"AGENT-2": -451.493449239162, "AGENT-1": -892.131219293194, "AGENT-0": -828.596502001634, "AGENT-3": -380.9482319571125}, "policy_reward_max": {"AGENT-2": 1148.7187160235858, "AGENT-1": 1160.4603646560752, "AGENT-0": 1293.2231402736784, "AGENT-3": 844.3922980148661}, "policy_reward_mean": {"AGENT-2": 58.02754612598268, "AGENT-1": 68.83766550310273, "AGENT-0": 98.15889904061756, "AGENT-3": 114.09943405176092}, "custom_metrics": {"mean_ego_speed_mean": 40.4517875, "mean_ego_speed_min": 15.514999999999999, "mean_ego_speed_max": 50.696, "distance_travelled_mean": 88.67586999999999, "distance_travelled_min": 44.314750000000004, "distance_travelled_max": 124.375}, "hist_stats": {"episode_reward": [404.36573077619244, -66.70375293428843, 2210.1882923928138, 42.745887236330525, 2604.2689960243024, -57.68092998542778, 1984.7802266136193, 836.2479862124064, 316.1829076974325, -105.13877805858304, -474.93782605091707, 147.51856004282675, -819.5222319039175, 101.67024388082301, -487.0873484146861, 862.7759098265354, 482.038654837499, -525.0237061941381, -428.43500428479075, -772.4590080311464, -361.3636649881946, -460.9361340180214, -344.1562957474495, 666.5541744667574, -79.53872257357446, -613.9203632801201, -229.64171896272055, 775.2104694137023, 526.8754672166356, 1472.2231931320712, 573.0186639152306, 407.3882703940965, 4004.778780163486, 679.6241203788428, 123.31775910764368, 111.14819116885067, 1613.294627412224, -315.45803448813683, 2414.6592391924705, 1489.836127193601, 225.1728677880325, -58.58871146647207, -807.2824569261109, 104.136277603093, -847.816227113891, -1724.4466945395336, -394.3182124481871, 1286.3580366207943, -474.96247673740436, 584.9154376912319, 1754.218544753936, -978.5636341953289, 198.71661477682972, -976.2404521017891, 154.7140918522126, -645.8265959392535, -129.64031459770695, 175.24110223077386, 784.7884216134908, 721.495635583557, 214.036461929123, -507.98813090754743, -439.8901886792536, 872.73138537164, 239.81681938571867, -198.83243062889312, 1990.6725139495773, 3.0391797677652903, 1590.7596240701462, 443.67701850291985, 622.790991854793, 289.51966551422424, 816.658327171752, 18.828863721653015, 75.17155597415847, 885.1932586370822, 331.89325411160786, 674.9918386239469, 549.5369405835198, 1463.58481722184, -304.0285858173498, 812.7905295101655, -373.9754462311257, 408.7651957029724, 1556.2746439224818, 23.55554990243627, 2190.5996046490945, -1041.5397952493227, -8.17548224444333, -96.62552799665455, 3.374976976652451, 340.3550866850464, 65.86497113247776, -836.0069294609212, 585.3826732949608, 426.25242865508505, 888.3244612478944, -844.0191215799351, 817.4183474663454, 1700.7949121761783], "episode_lengths": [255, 337, 261, 99, 236, 109, 231, 609, 128, 117, 115, 121, 127, 119, 118, 428, 101, 145, 116, 141, 115, 133, 121, 114, 86, 137, 119, 272, 123, 350, 205, 103, 310, 107, 330, 114, 165, 53, 196, 828, 112, 77, 348, 115, 322, 366, 136, 374, 111, 759, 243, 313, 102, 331, 108, 135, 116, 104, 145, 373, 111, 132, 128, 333, 297, 999, 363, 120, 323, 135, 285, 124, 126, 379, 114, 351, 101, 406, 115, 164, 117, 110, 119, 133, 286, 599, 195, 374, 70, 117, 116, 124, 102, 133, 117, 138, 127, 129, 362, 754], "policy_AGENT-2_reward": [132.12710186457403, -0.2223814597246374, 490.0045593473699, 12.41996788135025, 703.4356196577297, -14.188833791183024, 175.03005680444807, 361.2654219257419, -35.38673435107814, 35.94169442881252, -158.07987639775195, -36.824521657039675, -310.12425923478884, 52.06143278568603, -167.610311262785, -27.0784330082503, 44.639011706865695, 18.24315906217511, -64.58917655919677, 4.9705794507417504, -78.264060793781, -4.109789963319287, -79.79831319444844, 196.81115694650265, -9.699689366406025, -4.594169684383849, -48.49653205808668, -12.627399929757622, 15.794597248242201, 299.0206674371039, 152.09452664065984, 95.35138157080485, 1148.7187160235858, 157.66843498681004, 139.28355668799134, 19.242034867409473, 420.40044312894133, -43.40006219999505, 675.167862094265, 670.2456421301125, -35.1452039987631, 33.84245001917109, -347.6229931831117, 56.465221554419024, -51.636884004331925, -1.768193984624634, -20.684322651219002, 214.2268994376161, -78.69393101297423, 190.88845802648697, 126.45723649427855, -419.53946737921643, 61.975057808734455, -404.5230721711693, 38.950532765456245, -249.77664021671114, 29.543798866152112, -46.313245461287494, 160.7969451627497, -40.2182370138145, 44.869470266704255, -5.783033465617195, -11.91180574640081, 76.17116245516571, 31.114669606928253, -15.835331586109243, 493.7712281850949, -3.9023585167781505, 88.15661607215623, -29.53138184823406, 130.823475581997, -37.275733152652606, 77.89374932292681, -109.44991514999691, 50.19760013129541, 70.07617725194666, 29.48543256000957, -42.34649010411735, 24.90675400240613, 352.8183256569729, -47.32842694226545, 189.50945481488904, -74.80740223516622, -42.19805819489745, 84.21827921185032, -32.13332701628052, 564.8703836363633, -451.493449239162, 37.01912785222565, -98.25853929501493, 39.35944028788732, -35.402907491306706, 41.313684997524724, -335.6598782401541, 21.28727729434684, -29.833445250501136, 126.04146922979052, -336.234601945168, 38.43799514970994, 787.7314356261098], "policy_AGENT-1_reward": [-73.25776205778949, -69.49975828473197, 603.8949672914503, 20.47321653237445, 711.6669308319172, -5.189724286684327, 640.5938417117176, 45.21162279710353, 178.81802389258547, -83.75458329400577, -91.4219724332427, 96.41003375375546, -80.32169560137746, -0.10442829865288594, -86.85258666353087, -26.493938369316282, 208.82027239476875, -297.6374713051723, -148.11929310491124, -368.55805791471977, -101.91730827326131, -240.9512736016397, -91.33580360928818, 173.7004082867122, -30.286790875914907, -317.5410697131432, -48.066631308234186, -12.185321336629578, 16.49495112515474, 455.7533425129754, 32.098572093169, 119.89682352659223, 1160.4603646560752, 210.84197917771198, -240.04319812018167, 36.328868433694225, 470.432784155037, -114.26491870352307, 683.4944799213612, 37.33178694095327, 171.80041280917473, -63.12683545536532, -98.00622611695316, 0.05654867468977143, -51.0334246370427, -892.131219293194, -20.15614527611536, 490.7057842734387, -182.91275873794987, 188.03831213059635, 550.6171564475931, -114.62395487000359, 49.42918894231495, -117.2178324378699, 39.60501397655805, -87.98806298684431, -91.22352305566906, 159.6140294912529, 213.63987378555893, -39.78724257441415, 68.83395470846807, -262.4454290361979, -186.77252362448985, 76.59554009146706, 31.54351304996245, -86.5909278109398, 488.83853836198097, 5.422635722544747, 492.57888613406175, 236.54952594728692, 174.06074204666226, 167.8322595267709, 78.59239747427624, -108.79432648045686, -8.985943753183088, 70.5077939630336, 148.15971652210234, -41.81009398903543, 25.3815730095939, 426.17031433494606, -46.883973084282516, 243.170548497923, -74.05313526824952, 231.95072500732456, 477.6472303527138, 15.761361935769983, 581.964194743097, -89.84499250087322, -41.10489617844019, -97.82931880479372, -36.71947284698126, 191.20549496153512, 3.729227620941341, -98.80560947105363, 21.71767821103757, 227.67043778373412, 126.5941071348944, -101.52897716549509, 38.870625549605464, 34.36836966409748], "policy_AGENT-0_reward": [-77.78896259591646, 73.09399443051629, 631.9357375259333, 13.03363463294143, 804.5483851033291, -13.638856761503792, 670.0178947619851, 45.37139535574313, 208.10586628373528, 36.491261304032015, -133.44892896353832, 124.62807190258926, -348.165683527257, 52.61870250733677, -145.20745143236354, 475.4933986214464, 45.19209574125844, -263.93160379691346, -64.02608527027382, -413.77369742378704, -77.7009417984125, -211.81716508292718, -79.2281972262227, 158.6391030108184, -29.96847050124421, -287.1834858020705, -51.099077866086475, 386.0083793451035, 259.45056726138466, 362.92045826666555, 14.770509623665916, 95.91601692909933, 1293.2231402736784, 158.20708253770346, -257.2948222843183, 19.812345285960937, 390.8549828312475, -42.960930816952455, 695.2395644500832, 37.537816424187454, 123.90644760965426, 34.38785201515807, -263.0805916531408, 57.03052912421772, -364.197686515403, -828.596502001634, -179.96187722151618, 243.9364596517023, -78.13154599146827, 88.64990823956667, 576.9378265354843, -329.21266839579545, 62.5288628696824, -336.7192743449997, 39.510859018693566, -219.5054464048268, 29.96010731459556, 108.19484488327709, 243.55131857167413, 415.2220683595893, 45.42816812676054, -233.83334907314685, -229.44137691039123, 380.9558438395769, 129.32516415712738, -9.252235627050908, 517.8750328316661, -3.3390480406854905, 520.8683672767471, 266.1501987717554, 186.76120005771983, 196.3579511293776, 344.82078427830675, 151.4305643929157, 50.754589651863114, 392.80346544226006, 30.03998780737127, 403.76022561848714, 263.03105914958076, 375.23004105692786, -89.6157649803375, 190.0718298250748, -96.59197350694399, 261.23279652114763, 505.4352872281571, 24.731179516498184, 565.4444006353657, -409.7937753330602, 37.578928119265974, 62.760929920189284, 39.90925078969433, 220.0583242780276, 41.88432172007286, -302.1710729095382, 283.1691909990104, 258.26427178324326, 332.8319377965464, -304.1386706639155, 400.51153458981435, 34.30280887110777], "policy_AGENT-3_reward": [423.2853535653245, -70.07560762034791, 484.35302822805875, -3.1809318103355553, 384.61806043132844, -24.663515146056497, 499.13843333546765, 384.3995461338166, -35.35424812781019, -93.81715049742175, -91.9870482563839, -36.69502395647838, -80.91059354049384, -2.905463113546687, -87.41699905600662, 440.85488258265553, 183.3872749946062, 18.302209845772982, -151.70044935040866, 4.9021678566186715, -103.4813541227404, -4.057905370135236, -93.79398171749024, 137.40350622272427, -9.5837718300093, -4.601638080522361, -81.97947773031333, 414.0148113349856, 235.13535158185425, 354.5287249153292, 374.0550555577353, 96.22404836759985, 402.3765592101541, 152.90662367661724, 481.37222282415837, 35.764942581786094, 331.6064172969991, -114.83212276766628, 360.7573327267631, 744.7208816983477, -35.38878863203338, -63.692178045435874, -98.57264597290487, -9.41602175023369, -380.9482319571125, -1.9507792600805938, -173.51586729933646, 337.48889325803594, -135.22424099501222, 117.33875929458324, 500.20632527657983, -115.1875435503151, 24.783505156097917, -117.78027314775123, 36.64768609150499, -88.55644633087124, -97.92069772278546, -46.25452668246874, 166.80028409350814, 386.27904681219707, 54.90486882718985, -5.926319332585734, -11.764482397971712, 339.0088389854307, 47.83347257170059, -87.15393560479299, 490.18771457083636, 4.857950602684241, 489.15575458718007, -29.491324367888534, 131.14557416841348, -37.394811989271744, 315.35139609624207, 85.64254095919134, -16.794690055816925, 351.8058219798428, 124.20811722212454, 355.3881970986138, 236.21755442193887, 309.3661361729928, -120.20042081046405, 190.03869637227825, -128.52293522076582, -42.220267630602585, 488.97384712976066, 15.19633546644851, 478.320625634269, -90.40757817622651, -41.66864203749473, 36.70140018296481, -39.17424125394798, -35.5058250632096, -21.06226320606098, -99.37036884017475, 259.20852679056634, -29.848835661391384, 302.85694708666324, -102.11687180535625, 339.59819217721434, 844.3922980148661]}, "sampler_perf": {"mean_env_wait_ms": 46.1064532602969, "mean_raw_obs_processing_ms": 2.038899983770103, "mean_inference_ms": 2.1432617379322094, "mean_action_processing_ms": 0.1322491484764481}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 214200, "timers": {"sample_time_ms": 67112.905, "sample_throughput": 62.581, "load_time_ms": 11.824, "load_throughput": 355212.253, "learn_time_ms": 5675.986, "learn_throughput": 739.959, "update_time_ms": 7.352}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 67.0423812866211, "policy_loss": -0.035969242453575134, "vf_loss": 67.07271575927734, "vf_explained_var": 0.978968620300293, "kl": 0.01256644818931818, "entropy": 0.9358764886856079, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 54.064205169677734, "policy_loss": -0.030641114339232445, "vf_loss": 54.08856201171875, "vf_explained_var": 0.9823183417320251, "kl": 0.013946725986897945, "entropy": 0.8623457551002502, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 35.65660858154297, "policy_loss": -0.03509004786610603, "vf_loss": 35.68610763549805, "vf_explained_var": 0.9837318062782288, "kl": 0.0124250128865242, "entropy": 0.8394145965576172, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 57.98328399658203, "policy_loss": -0.027692381292581558, "vf_loss": 58.00613784790039, "vf_explained_var": 0.9802507162094116, "kl": 0.010749081149697304, "entropy": 0.9075397253036499, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 214200, "num_steps_trained": 214200}, "done": false, "episodes_total": 1504, "training_iteration": 51, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-29-09", "timestamp": 1624220949, "time_this_iter_s": 73.26478052139282, "time_total_s": 4481.887895822525, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c0fe55f0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c81d5dd0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c820ee60>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f98c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f95f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e8c0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c820ee60>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f98c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f95f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e8c0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c820ee60>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f98c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f95f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e8c0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c820ee60>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f98c0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c80f95f0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e8c0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c0f74dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4481.887895822525, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 52.88666666666667, "ram_util_percent": 95.42380952380952}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 3002.971733773663, "episode_reward_min": -1041.5397952493227, "episode_reward_mean": 303.83870049725124, "episode_len_mean": 187.31, "episodes_this_iter": 29, "policy_reward_min": {"AGENT-0": -413.77369742378704, "AGENT-3": -152.90407261936102, "AGENT-2": -451.493449239162, "AGENT-1": -368.55805791471977}, "policy_reward_max": {"AGENT-0": 857.595852842914, "AGENT-3": 844.3922980148661, "AGENT-2": 851.0631994772189, "AGENT-1": 875.1836541090138}, "policy_reward_mean": {"AGENT-0": 102.76680591158006, "AGENT-3": 93.57450687952431, "AGENT-2": 49.09955962296709, "AGENT-1": 58.397828083179895}, "custom_metrics": {"mean_ego_speed_mean": 41.3902275, "mean_ego_speed_min": 25.628500000000003, "mean_ego_speed_max": 51.046, "distance_travelled_mean": 86.79670499999999, "distance_travelled_min": 44.314750000000004, "distance_travelled_max": 124.375}, "hist_stats": {"episode_reward": [299.8939315443716, 3002.971733773663, 169.89960863843794, 2692.708842327006, 1840.8591988507474, 310.15294415920425, 2228.1071993164396, -73.5258755435503, 595.0499783816874, 211.68874280456188, -104.01611708093259, -687.0635557943673, 422.1175480196972, -530.7979169676091, 205.9866366664556, -763.0255933650568, 625.1736298605639, 188.79682510676307, -111.76905939471946, -317.50278523798886, 1182.5961071297552, -447.1384337815169, -454.92661635193883, -436.81237519820087, -547.5553044907944, -317.9970966509948, -322.24913772838653, -428.974347175575, -685.0298504200874, -129.64031459770695, 175.24110223077386, 784.7884216134908, 721.495635583557, 214.036461929123, -507.98813090754743, -439.8901886792536, 872.73138537164, 239.81681938571867, -198.83243062889312, 1990.6725139495773, 3.0391797677652903, 1590.7596240701462, 443.67701850291985, 622.790991854793, 289.51966551422424, 816.658327171752, 18.828863721653015, 75.17155597415847, 885.1932586370822, 331.89325411160786, 674.9918386239469, 549.5369405835198, 1463.58481722184, -304.0285858173498, 812.7905295101655, -373.9754462311257, 408.7651957029724, 1556.2746439224818, 23.55554990243627, 2190.5996046490945, -1041.5397952493227, -8.17548224444333, -96.62552799665455, 3.374976976652451, 340.3550866850464, 65.86497113247776, -836.0069294609212, 585.3826732949608, 426.25242865508505, 888.3244612478944, -844.0191215799351, 817.4183474663454, 1700.7949121761783, 404.36573077619244, -66.70375293428843, 2210.1882923928138, 42.745887236330525, 2604.2689960243024, -57.68092998542778, 1984.7802266136193, 836.2479862124064, 316.1829076974325, -105.13877805858304, -474.93782605091707, 147.51856004282675, -819.5222319039175, 101.67024388082301, -487.0873484146861, 862.7759098265354, 482.038654837499, -525.0237061941381, -428.43500428479075, -772.4590080311464, -361.3636649881946, -460.9361340180214, -344.1562957474495, 666.5541744667574, -79.53872257357446, -613.9203632801201, -229.64171896272055], "episode_lengths": [122, 200, 99, 188, 246, 106, 281, 85, 109, 121, 117, 129, 121, 117, 128, 127, 124, 124, 108, 143, 145, 112, 130, 114, 136, 114, 138, 114, 129, 116, 104, 145, 373, 111, 132, 128, 333, 297, 999, 363, 120, 323, 135, 285, 124, 126, 379, 114, 351, 101, 406, 115, 164, 117, 110, 119, 133, 286, 599, 195, 374, 70, 117, 116, 124, 102, 133, 117, 138, 127, 129, 362, 754, 255, 337, 261, 99, 236, 109, 231, 609, 128, 117, 115, 121, 127, 119, 118, 428, 101, 145, 116, 141, 115, 133, 121, 114, 86, 137, 119], "policy_AGENT-0_reward": [190.42873166749644, 857.595852842914, 41.17979887746013, 731.0946102531332, 408.0818542749668, 199.38060861712455, 634.978791319395, -42.79088989457021, 249.86441619242487, 147.52345085698647, 31.907685606089267, -234.8487878164128, 164.66100463553704, -186.58418030690524, 101.06943240376214, -280.48866269674784, 300.4777669565116, 140.6846276839264, 26.725516269903135, -63.84131007558595, 303.7399474045567, -59.35997647134312, -207.7930065427403, -69.50613620008824, -258.8746361883021, -49.44215181980958, -140.29188725365555, -69.6959876740103, -363.9175331628819, 29.96010731459556, 108.19484488327709, 243.55131857167413, 415.2220683595893, 45.42816812676054, -233.83334907314685, -229.44137691039123, 380.9558438395769, 129.32516415712738, -9.252235627050908, 517.8750328316661, -3.3390480406854905, 520.8683672767471, 266.1501987717554, 186.76120005771983, 196.3579511293776, 344.82078427830675, 151.4305643929157, 50.754589651863114, 392.80346544226006, 30.03998780737127, 403.76022561848714, 263.03105914958076, 375.23004105692786, -89.6157649803375, 190.0718298250748, -96.59197350694399, 261.23279652114763, 505.4352872281571, 24.731179516498184, 565.4444006353657, -409.7937753330602, 37.578928119265974, 62.760929920189284, 39.90925078969433, 220.0583242780276, 41.88432172007286, -302.1710729095382, 283.1691909990104, 258.26427178324326, 332.8319377965464, -304.1386706639155, 400.51153458981435, 34.30280887110777, -77.78896259591646, 73.09399443051629, 631.9357375259333, 13.03363463294143, 804.5483851033291, -13.638856761503792, 670.0178947619851, 45.37139535574313, 208.10586628373528, 36.491261304032015, -133.44892896353832, 124.62807190258926, -348.165683527257, 52.61870250733677, -145.20745143236354, 475.4933986214464, 45.19209574125844, -263.93160379691346, -64.02608527027382, -413.77369742378704, -77.7009417984125, -211.81716508292718, -79.2281972262227, 158.6391030108184, -29.96847050124421, -287.1834858020705, -51.099077866086475], "policy_AGENT-3_reward": [-26.538019374894127, 419.12902734452064, 32.263080778387646, 472.35280771629414, 491.5512937455282, -46.064119365406754, 490.26660050697745, 6.028785372556605, 272.7569977029591, -27.745292892279817, -85.77353730644789, -96.88762853163787, 132.68846532123882, -102.39466474774525, -3.7132743470207705, -85.74878781765342, 276.0942345900911, -31.93821521302332, -95.46472053068237, -84.81748906167942, 271.4466752078185, -140.20336386570733, -5.433036560533217, -152.90407261936102, -0.42646654171682075, -109.8158885494772, -9.006372129967314, -146.32714935993957, -1.0055855544802932, -97.92069772278546, -46.25452668246874, 166.80028409350814, 386.27904681219707, 54.90486882718985, -5.926319332585734, -11.764482397971712, 339.0088389854307, 47.83347257170059, -87.15393560479299, 490.18771457083636, 4.857950602684241, 489.15575458718007, -29.491324367888534, 131.14557416841348, -37.394811989271744, 315.35139609624207, 85.64254095919134, -16.794690055816925, 351.8058219798428, 124.20811722212454, 355.3881970986138, 236.21755442193887, 309.3661361729928, -120.20042081046405, 190.03869637227825, -128.52293522076582, -42.220267630602585, 488.97384712976066, 15.19633546644851, 478.320625634269, -90.40757817622651, -41.66864203749473, 36.70140018296481, -39.17424125394798, -35.5058250632096, -21.06226320606098, -99.37036884017475, 259.20852679056634, -29.848835661391384, 302.85694708666324, -102.11687180535625, 339.59819217721434, 844.3922980148661, 423.2853535653245, -70.07560762034791, 484.35302822805875, -3.1809318103355553, 384.61806043132844, -24.663515146056497, 499.13843333546765, 384.3995461338166, -35.35424812781019, -93.81715049742175, -91.9870482563839, -36.69502395647838, -80.91059354049384, -2.905463113546687, -87.41699905600662, 440.85488258265553, 183.3872749946062, 18.302209845772982, -151.70044935040866, 4.9021678566186715, -103.4813541227404, -4.057905370135236, -93.79398171749024, 137.40350622272427, -9.5837718300093, -4.601638080522361, -81.97947773031333], "policy_AGENT-2_reward": [-26.525914181680484, 851.0631994772189, 40.62096820037438, 760.5886933523994, 494.2228254887585, -46.099814047045435, 495.96814970067504, -43.35777144573814, 35.997757416035085, -27.696561126930565, 31.475003333929205, -259.0043396861432, 62.04470245723645, -140.1389947422702, 100.49602964218813, -311.604161137193, 24.04415300767863, -31.880923611810896, 26.141504877393825, -84.59089875232225, 271.8547421918134, -59.91253370283531, -5.391326527207869, -70.05822497395492, -0.3330712388526771, -50.00588468747992, -9.035612606603602, -70.24687565479326, -1.057923134182462, 29.543798866152112, -46.313245461287494, 160.7969451627497, -40.2182370138145, 44.869470266704255, -5.783033465617195, -11.91180574640081, 76.17116245516571, 31.114669606928253, -15.835331586109243, 493.7712281850949, -3.9023585167781505, 88.15661607215623, -29.53138184823406, 130.823475581997, -37.275733152652606, 77.89374932292681, -109.44991514999691, 50.19760013129541, 70.07617725194666, 29.48543256000957, -42.34649010411735, 24.90675400240613, 352.8183256569729, -47.32842694226545, 189.50945481488904, -74.80740223516622, -42.19805819489745, 84.21827921185032, -32.13332701628052, 564.8703836363633, -451.493449239162, 37.01912785222565, -98.25853929501493, 39.35944028788732, -35.402907491306706, 41.313684997524724, -335.6598782401541, 21.28727729434684, -29.833445250501136, 126.04146922979052, -336.234601945168, 38.43799514970994, 787.7314356261098, 132.12710186457403, -0.2223814597246374, 490.0045593473699, 12.41996788135025, 703.4356196577297, -14.188833791183024, 175.03005680444807, 361.2654219257419, -35.38673435107814, 35.94169442881252, -158.07987639775195, -36.824521657039675, -310.12425923478884, 52.06143278568603, -167.610311262785, -27.0784330082503, 44.639011706865695, 18.24315906217511, -64.58917655919677, 4.9705794507417504, -78.264060793781, -4.109789963319287, -79.79831319444844, 196.81115694650265, -9.699689366406025, -4.594169684383849, -48.49653205808668], "policy_AGENT-1_reward": [162.5291334334497, 875.1836541090138, 55.835760782215765, 728.6727310051804, 447.0032253414944, 202.93626895453187, 606.8936577893926, 6.59400042420161, 36.430807070268614, 119.60714596678585, -81.62526871450318, -96.32279976017334, 62.723375605685256, -101.68007717068834, 8.134448967526193, -85.18398171346226, 24.55747530628244, 111.93133624767097, -69.17136001133399, -84.25308734840117, 335.5547423255661, -187.66255974163073, -236.30924672145798, -144.3439414047966, -287.92113052192286, -108.73317159422825, -163.91526573815986, -142.70433448683195, -319.0488085685432, -91.22352305566906, 159.6140294912529, 213.63987378555893, -39.78724257441415, 68.83395470846807, -262.4454290361979, -186.77252362448985, 76.59554009146706, 31.54351304996245, -86.5909278109398, 488.83853836198097, 5.422635722544747, 492.57888613406175, 236.54952594728692, 174.06074204666226, 167.8322595267709, 78.59239747427624, -108.79432648045686, -8.985943753183088, 70.5077939630336, 148.15971652210234, -41.81009398903543, 25.3815730095939, 426.17031433494606, -46.883973084282516, 243.170548497923, -74.05313526824952, 231.95072500732456, 477.6472303527138, 15.761361935769983, 581.964194743097, -89.84499250087322, -41.10489617844019, -97.82931880479372, -36.71947284698126, 191.20549496153512, 3.729227620941341, -98.80560947105363, 21.71767821103757, 227.67043778373412, 126.5941071348944, -101.52897716549509, 38.870625549605464, 34.36836966409748, -73.25776205778949, -69.49975828473197, 603.8949672914503, 20.47321653237445, 711.6669308319172, -5.189724286684327, 640.5938417117176, 45.21162279710353, 178.81802389258547, -83.75458329400577, -91.4219724332427, 96.41003375375546, -80.32169560137746, -0.10442829865288594, -86.85258666353087, -26.493938369316282, 208.82027239476875, -297.6374713051723, -148.11929310491124, -368.55805791471977, -101.91730827326131, -240.9512736016397, -91.33580360928818, 173.7004082867122, -30.286790875914907, -317.5410697131432, -48.066631308234186]}, "sampler_perf": {"mean_env_wait_ms": 45.68337130928392, "mean_raw_obs_processing_ms": 2.022823360755827, "mean_inference_ms": 2.1292072607767376, "mean_action_processing_ms": 0.13161897389505472}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 218400, "timers": {"sample_time_ms": 66933.596, "sample_throughput": 62.749, "load_time_ms": 12.002, "load_throughput": 349936.37, "learn_time_ms": 5680.922, "learn_throughput": 739.317, "update_time_ms": 7.446}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 63.19010925292969, "policy_loss": -0.031028306111693382, "vf_loss": 63.21497344970703, "vf_explained_var": 0.9819995760917664, "kl": 0.01369441021233797, "entropy": 0.9274027347564697, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 53.59090042114258, "policy_loss": -0.027456093579530716, "vf_loss": 53.611114501953125, "vf_explained_var": 0.9843123555183411, "kl": 0.01608443073928356, "entropy": 0.8505589962005615, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 48.789329528808594, "policy_loss": -0.0332355871796608, "vf_loss": 48.81676483154297, "vf_explained_var": 0.98591148853302, "kl": 0.012885856442153454, "entropy": 0.8054003715515137, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 72.73324584960938, "policy_loss": -0.02786341682076454, "vf_loss": 72.75665283203125, "vf_explained_var": 0.9807912111282349, "kl": 0.00990182813256979, "entropy": 0.8383030891418457, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 218400, "num_steps_trained": 218400}, "done": false, "episodes_total": 1533, "training_iteration": 52, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-30-29", "timestamp": 1624221029, "time_this_iter_s": 79.23136329650879, "time_total_s": 4561.119259119034, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c80864d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c80863b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8086170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8086050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8086a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8086b90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8086170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8086050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8086a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8086b90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8086170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8086050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8086a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8086b90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c8086170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8086050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8086a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8086b90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8086950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4561.119259119034, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 52.98318584070796, "ram_util_percent": 95.4}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 3029.4443972517897, "episode_reward_min": -1041.5397952493227, "episode_reward_mean": 330.2865104984583, "episode_len_mean": 170.95, "episodes_this_iter": 27, "policy_reward_min": {"AGENT-2": -451.493449239162, "AGENT-1": -434.43147548387526, "AGENT-0": -413.77369742378704, "AGENT-3": -453.31487887188865}, "policy_reward_max": {"AGENT-2": 856.8372313370112, "AGENT-1": 881.3527450062028, "AGENT-0": 869.9117043790731, "AGENT-3": 844.3922980148661}, "policy_reward_mean": {"AGENT-2": 72.46362854175841, "AGENT-1": 71.07969415629536, "AGENT-0": 106.29531081505344, "AGENT-3": 80.44787698535121}, "custom_metrics": {"mean_ego_speed_mean": 41.835094999999995, "mean_ego_speed_min": 25.628500000000003, "mean_ego_speed_max": 51.046, "distance_travelled_mean": 85.79973249999999, "distance_travelled_min": 53.728500000000004, "distance_travelled_max": 124.375}, "hist_stats": {"episode_reward": [3029.4443972517897, -117.017169416034, 2721.9707259610236, 295.61791683981136, 2838.4799226913938, 82.12211564848442, 2408.402778096544, 2675.0772837030668, -33.9001243934313, -47.53443908914228, -743.4153582735897, 626.0581339567065, 436.59051680777554, 184.11608469056284, 164.59763720201153, -70.70099888415596, -523.6569669207655, -102.06335896267268, 21.892690084627695, -616.4223759467791, 215.09396076905426, 227.47509368448317, 754.247820104992, 443.07620181584, -462.626585601566, -998.1746338885755, 858.8928406568327, 408.7651957029724, 1556.2746439224818, 23.55554990243627, 2190.5996046490945, -1041.5397952493227, -8.17548224444333, -96.62552799665455, 3.374976976652451, 340.3550866850464, 65.86497113247776, -836.0069294609212, 585.3826732949608, 426.25242865508505, 888.3244612478944, -844.0191215799351, 817.4183474663454, 1700.7949121761783, 404.36573077619244, -66.70375293428843, 2210.1882923928138, 42.745887236330525, 2604.2689960243024, -57.68092998542778, 1984.7802266136193, 836.2479862124064, 316.1829076974325, -105.13877805858304, -474.93782605091707, 147.51856004282675, -819.5222319039175, 101.67024388082301, -487.0873484146861, 862.7759098265354, 482.038654837499, -525.0237061941381, -428.43500428479075, -772.4590080311464, -361.3636649881946, -460.9361340180214, -344.1562957474495, 666.5541744667574, -79.53872257357446, -613.9203632801201, -229.64171896272055, 299.8939315443716, 3002.971733773663, 169.89960863843794, 2692.708842327006, 1840.8591988507474, 310.15294415920425, 2228.1071993164396, -73.5258755435503, 595.0499783816874, 211.68874280456188, -104.01611708093259, -687.0635557943673, 422.1175480196972, -530.7979169676091, 205.9866366664556, -763.0255933650568, 625.1736298605639, 188.79682510676307, -111.76905939471946, -317.50278523798886, 1182.5961071297552, -447.1384337815169, -454.92661635193883, -436.81237519820087, -547.5553044907944, -317.9970966509948, -322.24913772838653, -428.974347175575, -685.0298504200874], "episode_lengths": [200, 165, 201, 134, 205, 98, 209, 196, 121, 64, 127, 112, 134, 113, 123, 112, 123, 109, 112, 151, 117, 613, 322, 105, 298, 169, 121, 133, 286, 599, 195, 374, 70, 117, 116, 124, 102, 133, 117, 138, 127, 129, 362, 754, 255, 337, 261, 99, 236, 109, 231, 609, 128, 117, 115, 121, 127, 119, 118, 428, 101, 145, 116, 141, 115, 133, 121, 114, 86, 137, 119, 122, 200, 99, 188, 246, 106, 281, 85, 109, 121, 117, 129, 121, 117, 128, 127, 124, 124, 108, 143, 145, 112, 130, 114, 136, 114, 138, 114, 129], "policy_AGENT-2_reward": [856.8372313370112, -39.14310126929652, 771.6413437565581, -90.67952948445406, 791.9465525945051, 19.072205727263032, 662.7230447761085, 743.3159552826693, 12.332805012991777, 27.214216703023915, -292.9041504059551, 61.48549481447932, -33.16382642285542, 55.233247644896664, -37.72040960400354, 35.34932121375777, -192.47869543688745, 22.297429491709337, -31.45180083859382, 30.938943382881334, -35.742164491262336, 137.38150891308294, 89.57670243423455, 37.70733875091737, -4.003178470048127, -55.43514222190069, 179.50704740325452, -42.19805819489745, 84.21827921185032, -32.13332701628052, 564.8703836363633, -451.493449239162, 37.01912785222565, -98.25853929501493, 39.35944028788732, -35.402907491306706, 41.313684997524724, -335.6598782401541, 21.28727729434684, -29.833445250501136, 126.04146922979052, -336.234601945168, 38.43799514970994, 787.7314356261098, 132.12710186457403, -0.2223814597246374, 490.0045593473699, 12.41996788135025, 703.4356196577297, -14.188833791183024, 175.03005680444807, 361.2654219257419, -35.38673435107814, 35.94169442881252, -158.07987639775195, -36.824521657039675, -310.12425923478884, 52.06143278568603, -167.610311262785, -27.0784330082503, 44.639011706865695, 18.24315906217511, -64.58917655919677, 4.9705794507417504, -78.264060793781, -4.109789963319287, -79.79831319444844, 196.81115694650265, -9.699689366406025, -4.594169684383849, -48.49653205808668, -26.525914181680484, 851.0631994772189, 40.62096820037438, 760.5886933523994, 494.2228254887585, -46.099814047045435, 495.96814970067504, -43.35777144573814, 35.997757416035085, -27.696561126930565, 31.475003333929205, -259.0043396861432, 62.04470245723645, -140.1389947422702, 100.49602964218813, -311.604161137193, 24.04415300767863, -31.880923611810896, 26.141504877393825, -84.59089875232225, 271.8547421918134, -59.91253370283531, -5.391326527207869, -70.05822497395492, -0.3330712388526771, -50.00588468747992, -9.035612606603602, -70.24687565479326, -1.057923134182462], "policy_AGENT-1_reward": [881.3527450062028, -38.509723567842414, 792.8494076956956, -90.02602055711304, 814.957796963711, 33.209067556339924, 628.3636196493776, 764.4191871794487, -29.287396138108644, -50.98256350034435, -93.53511020119745, 62.14403481579124, 236.59895480903972, 38.62381141571712, 106.14682770613622, -91.4251722801457, -88.6101491504267, -70.67768608752957, 53.76629736530896, -329.88540307267823, 129.43017911362162, -69.06047827070773, 90.01345404821585, 195.10356787340336, -262.1723628613673, -434.43147548387526, 249.9559212758492, 231.95072500732456, 477.6472303527138, 15.761361935769983, 581.964194743097, -89.84499250087322, -41.10489617844019, -97.82931880479372, -36.71947284698126, 191.20549496153512, 3.729227620941341, -98.80560947105363, 21.71767821103757, 227.67043778373412, 126.5941071348944, -101.52897716549509, 38.870625549605464, 34.36836966409748, -73.25776205778949, -69.49975828473197, 603.8949672914503, 20.47321653237445, 711.6669308319172, -5.189724286684327, 640.5938417117176, 45.21162279710353, 178.81802389258547, -83.75458329400577, -91.4219724332427, 96.41003375375546, -80.32169560137746, -0.10442829865288594, -86.85258666353087, -26.493938369316282, 208.82027239476875, -297.6374713051723, -148.11929310491124, -368.55805791471977, -101.91730827326131, -240.9512736016397, -91.33580360928818, 173.7004082867122, -30.286790875914907, -317.5410697131432, -48.066631308234186, 162.5291334334497, 875.1836541090138, 55.835760782215765, 728.6727310051804, 447.0032253414944, 202.93626895453187, 606.8936577893926, 6.59400042420161, 36.430807070268614, 119.60714596678585, -81.62526871450318, -96.32279976017334, 62.723375605685256, -101.68007717068834, 8.134448967526193, -85.18398171346226, 24.55747530628244, 111.93133624767097, -69.17136001133399, -84.25308734840117, 335.5547423255661, -187.66255974163073, -236.30924672145798, -144.3439414047966, -287.92113052192286, -108.73317159422825, -163.91526573815986, -142.70433448683195, -319.0488085685432], "policy_AGENT-0_reward": [869.9117043790731, -0.2868372422362846, 771.3667405360723, 253.74420671219417, 796.1606885230134, 19.636936947582214, 663.3378135968077, 751.7898136528813, 12.905946485945307, 27.781836954527567, -262.87883309238276, 263.1281947621796, 266.2775019663186, 55.79074755218954, 133.97549786096428, 35.895006548973505, -153.3743179498952, 22.854234288042445, 30.99060513662449, 31.530914713492436, 157.1843239779368, -68.95475188807353, 283.5369420603905, 38.259806369833065, -192.26328530203244, -54.99313731091192, 180.0612545119228, 261.23279652114763, 505.4352872281571, 24.731179516498184, 565.4444006353657, -409.7937753330602, 37.578928119265974, 62.760929920189284, 39.90925078969433, 220.0583242780276, 41.88432172007286, -302.1710729095382, 283.1691909990104, 258.26427178324326, 332.8319377965464, -304.1386706639155, 400.51153458981435, 34.30280887110777, -77.78896259591646, 73.09399443051629, 631.9357375259333, 13.03363463294143, 804.5483851033291, -13.638856761503792, 670.0178947619851, 45.37139535574313, 208.10586628373528, 36.491261304032015, -133.44892896353832, 124.62807190258926, -348.165683527257, 52.61870250733677, -145.20745143236354, 475.4933986214464, 45.19209574125844, -263.93160379691346, -64.02608527027382, -413.77369742378704, -77.7009417984125, -211.81716508292718, -79.2281972262227, 158.6391030108184, -29.96847050124421, -287.1834858020705, -51.099077866086475, 190.42873166749644, 857.595852842914, 41.17979887746013, 731.0946102531332, 408.0818542749668, 199.38060861712455, 634.978791319395, -42.79088989457021, 249.86441619242487, 147.52345085698647, 31.907685606089267, -234.8487878164128, 164.66100463553704, -186.58418030690524, 101.06943240376214, -280.48866269674784, 300.4777669565116, 140.6846276839264, 26.725516269903135, -63.84131007558595, 303.7399474045567, -59.35997647134312, -207.7930065427403, -69.50613620008824, -258.8746361883021, -49.44215181980958, -140.29188725365555, -69.6959876740103, -363.9175331628819], "policy_AGENT-3_reward": [421.34271652949826, -39.07750733665887, 386.11323397269496, 222.57926016918418, 435.41488461016326, 10.203905417299296, 453.978300074254, 415.55232758806636, -29.851479754259735, -51.54792924634938, -94.09726457405372, 239.30040956425648, -33.12211354472763, 34.46827807775958, -37.80427876108535, -50.52015436674155, -89.19380438355604, -76.53733665489489, -31.41241157871188, -349.00683097047505, -35.77837783124177, 228.10881493018135, 291.12072156215186, 172.00548882168624, -4.18775896811813, -453.31487887188865, 249.36861746580757, -42.220267630602585, 488.97384712976066, 15.19633546644851, 478.320625634269, -90.40757817622651, -41.66864203749473, 36.70140018296481, -39.17424125394798, -35.5058250632096, -21.06226320606098, -99.37036884017475, 259.20852679056634, -29.848835661391384, 302.85694708666324, -102.11687180535625, 339.59819217721434, 844.3922980148661, 423.2853535653245, -70.07560762034791, 484.35302822805875, -3.1809318103355553, 384.61806043132844, -24.663515146056497, 499.13843333546765, 384.3995461338166, -35.35424812781019, -93.81715049742175, -91.9870482563839, -36.69502395647838, -80.91059354049384, -2.905463113546687, -87.41699905600662, 440.85488258265553, 183.3872749946062, 18.302209845772982, -151.70044935040866, 4.9021678566186715, -103.4813541227404, -4.057905370135236, -93.79398171749024, 137.40350622272427, -9.5837718300093, -4.601638080522361, -81.97947773031333, -26.538019374894127, 419.12902734452064, 32.263080778387646, 472.35280771629414, 491.5512937455282, -46.064119365406754, 490.26660050697745, 6.028785372556605, 272.7569977029591, -27.745292892279817, -85.77353730644789, -96.88762853163787, 132.68846532123882, -102.39466474774525, -3.7132743470207705, -85.74878781765342, 276.0942345900911, -31.93821521302332, -95.46472053068237, -84.81748906167942, 271.4466752078185, -140.20336386570733, -5.433036560533217, -152.90407261936102, -0.42646654171682075, -109.8158885494772, -9.006372129967314, -146.32714935993957, -1.0055855544802932]}, "sampler_perf": {"mean_env_wait_ms": 45.52951726723505, "mean_raw_obs_processing_ms": 2.0096557739405143, "mean_inference_ms": 2.1276859690159124, "mean_action_processing_ms": 0.1312971325859951}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 222600, "timers": {"sample_time_ms": 67234.596, "sample_throughput": 62.468, "load_time_ms": 12.037, "load_throughput": 348919.57, "learn_time_ms": 5724.283, "learn_throughput": 733.716, "update_time_ms": 7.336}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 50.035743713378906, "policy_loss": -0.03824756294488907, "vf_loss": 50.06777572631836, "vf_explained_var": 0.9829539656639099, "kl": 0.013815206475555897, "entropy": 0.8872655034065247, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 53.67558670043945, "policy_loss": -0.03384513407945633, "vf_loss": 53.70289611816406, "vf_explained_var": 0.9832055568695068, "kl": 0.014535951428115368, "entropy": 0.8259993195533752, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 40.13607406616211, "policy_loss": -0.03588252514600754, "vf_loss": 40.16633605957031, "vf_explained_var": 0.9859912395477295, "kl": 0.012483691796660423, "entropy": 0.7200657725334167, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 48.53643035888672, "policy_loss": -0.034485287964344025, "vf_loss": 48.56468200683594, "vf_explained_var": 0.9880170226097107, "kl": 0.013858405873179436, "entropy": 0.7998796105384827, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 222600, "num_steps_trained": 222600}, "done": false, "episodes_total": 1560, "training_iteration": 53, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-31-48", "timestamp": 1624221108, "time_this_iter_s": 78.80291032791138, "time_total_s": 4639.922169446945, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c8397a70>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c827fdd0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f745f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688200>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688f80>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f745f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688200>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688f80>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f745f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688200>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688f80>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f745f0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74680>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688200>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8688f80>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8086dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4639.922169446945, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 49.610619469026545, "ram_util_percent": 95.65309734513272}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 3029.4443972517897, "episode_reward_min": -998.1746338885755, "episode_reward_mean": 307.4219939218215, "episode_len_mean": 162.13, "episodes_this_iter": 22, "policy_reward_min": {"AGENT-2": -420.3006611240423, "AGENT-1": -434.43147548387526, "AGENT-0": -413.77369742378704, "AGENT-3": -453.31487887188865}, "policy_reward_max": {"AGENT-2": 856.8372313370112, "AGENT-1": 881.3527450062028, "AGENT-0": 869.9117043790731, "AGENT-3": 499.13843333546765}, "policy_reward_mean": {"AGENT-2": 83.56480848866914, "AGENT-1": 65.97266747101396, "AGENT-0": 85.43981826463016, "AGENT-3": 72.44469969750836}, "custom_metrics": {"mean_ego_speed_mean": 41.571839999999995, "mean_ego_speed_min": 26.8795, "mean_ego_speed_max": 51.046, "distance_travelled_mean": 85.4500725, "distance_travelled_min": 48.46875, "distance_travelled_max": 124.203}, "hist_stats": {"episode_reward": [1609.6104436965866, 2857.240815213475, 574.6627112887047, 1946.5463875938729, 1820.0315609086563, -35.110069104621964, 2750.9502189025043, -70.36159723372128, -492.8980164235615, 658.1455545459079, -705.0597855525339, 27.50333211651234, -834.6179620233488, -58.12777182675607, -971.5767317062457, -151.6765522489683, -564.5335556973088, -473.4369671070266, 1132.800395591821, -84.42568321886645, -548.7284698126603, 702.0712332095981, -57.68092998542778, 1984.7802266136193, 836.2479862124064, 316.1829076974325, -105.13877805858304, -474.93782605091707, 147.51856004282675, -819.5222319039175, 101.67024388082301, -487.0873484146861, 862.7759098265354, 482.038654837499, -525.0237061941381, -428.43500428479075, -772.4590080311464, -361.3636649881946, -460.9361340180214, -344.1562957474495, 666.5541744667574, -79.53872257357446, -613.9203632801201, -229.64171896272055, 299.8939315443716, 3002.971733773663, 169.89960863843794, 2692.708842327006, 1840.8591988507474, 310.15294415920425, 2228.1071993164396, -73.5258755435503, 595.0499783816874, 211.68874280456188, -104.01611708093259, -687.0635557943673, 422.1175480196972, -530.7979169676091, 205.9866366664556, -763.0255933650568, 625.1736298605639, 188.79682510676307, -111.76905939471946, -317.50278523798886, 1182.5961071297552, -447.1384337815169, -454.92661635193883, -436.81237519820087, -547.5553044907944, -317.9970966509948, -322.24913772838653, -428.974347175575, -685.0298504200874, 3029.4443972517897, -117.017169416034, 2721.9707259610236, 295.61791683981136, 2838.4799226913938, 82.12211564848442, 2408.402778096544, 2675.0772837030668, -33.9001243934313, -47.53443908914228, -743.4153582735897, 626.0581339567065, 436.59051680777554, 184.11608469056284, 164.59763720201153, -70.70099888415596, -523.6569669207655, -102.06335896267268, 21.892690084627695, -616.4223759467791, 215.09396076905426, 227.47509368448317, 754.247820104992, 443.07620181584, -462.626585601566, -998.1746338885755, 858.8928406568327], "episode_lengths": [190, 190, 113, 191, 390, 95, 202, 115, 121, 604, 134, 84, 132, 61, 141, 128, 133, 95, 319, 116, 159, 469, 109, 231, 609, 128, 117, 115, 121, 127, 119, 118, 428, 101, 145, 116, 141, 115, 133, 121, 114, 86, 137, 119, 122, 200, 99, 188, 246, 106, 281, 85, 109, 121, 117, 129, 121, 117, 128, 127, 124, 124, 108, 143, 145, 112, 130, 114, 136, 114, 138, 114, 129, 200, 165, 201, 134, 205, 98, 209, 196, 121, 64, 127, 112, 134, 113, 123, 112, 123, 109, 112, 151, 117, 613, 322, 105, 298, 169, 121], "policy_AGENT-2_reward": [413.4609618972984, 778.5278309696514, 143.62755831929286, 523.2213800877335, 493.4000260252377, -33.1050932898322, 777.4431058703937, 22.22612951455295, -175.0378456460888, 286.70512811046854, -276.7252048813566, 51.77741696395391, -315.8671857180686, 30.604522989582023, -420.3006611240423, 14.324984353647986, -9.000894385252941, -69.10442500044073, 155.84196241870296, -11.546126383590376, 11.993902998790055, 434.4802745050623, -14.188833791183024, 175.03005680444807, 361.2654219257419, -35.38673435107814, 35.94169442881252, -158.07987639775195, -36.824521657039675, -310.12425923478884, 52.06143278568603, -167.610311262785, -27.0784330082503, 44.639011706865695, 18.24315906217511, -64.58917655919677, 4.9705794507417504, -78.264060793781, -4.109789963319287, -79.79831319444844, 196.81115694650265, -9.699689366406025, -4.594169684383849, -48.49653205808668, -26.525914181680484, 851.0631994772189, 40.62096820037438, 760.5886933523994, 494.2228254887585, -46.099814047045435, 495.96814970067504, -43.35777144573814, 35.997757416035085, -27.696561126930565, 31.475003333929205, -259.0043396861432, 62.04470245723645, -140.1389947422702, 100.49602964218813, -311.604161137193, 24.04415300767863, -31.880923611810896, 26.141504877393825, -84.59089875232225, 271.8547421918134, -59.91253370283531, -5.391326527207869, -70.05822497395492, -0.3330712388526771, -50.00588468747992, -9.035612606603602, -70.24687565479326, -1.057923134182462, 856.8372313370112, -39.14310126929652, 771.6413437565581, -90.67952948445406, 791.9465525945051, 19.072205727263032, 662.7230447761085, 743.3159552826693, 12.332805012991777, 27.214216703023915, -292.9041504059551, 61.48549481447932, -33.16382642285542, 55.233247644896664, -37.72040960400354, 35.34932121375777, -192.47869543688745, 22.297429491709337, -31.45180083859382, 30.938943382881334, -35.742164491262336, 137.38150891308294, 89.57670243423455, 37.70733875091737, -4.003178470048127, -55.43514222190069, 179.50704740325452], "policy_AGENT-1_reward": [423.9430097223414, 807.7508578758884, 197.09658594923621, 464.57816117909647, 386.2364554806831, 15.54356740642919, 799.8212163590659, -55.90231407076373, -82.60718461940442, 27.72726696455127, -82.39022349853599, -38.02505264252166, -83.47587910493748, -59.6033871664703, -82.53406784223074, -75.55851174803986, -288.0845205655535, -167.6115293783974, 446.52397718365705, -6.755632717547597, -304.6030202189851, -73.84866276536842, -5.189724286684327, 640.5938417117176, 45.21162279710353, 178.81802389258547, -83.75458329400577, -91.4219724332427, 96.41003375375546, -80.32169560137746, -0.10442829865288594, -86.85258666353087, -26.493938369316282, 208.82027239476875, -297.6374713051723, -148.11929310491124, -368.55805791471977, -101.91730827326131, -240.9512736016397, -91.33580360928818, 173.7004082867122, -30.286790875914907, -317.5410697131432, -48.066631308234186, 162.5291334334497, 875.1836541090138, 55.835760782215765, 728.6727310051804, 447.0032253414944, 202.93626895453187, 606.8936577893926, 6.59400042420161, 36.430807070268614, 119.60714596678585, -81.62526871450318, -96.32279976017334, 62.723375605685256, -101.68007717068834, 8.134448967526193, -85.18398171346226, 24.55747530628244, 111.93133624767097, -69.17136001133399, -84.25308734840117, 335.5547423255661, -187.66255974163073, -236.30924672145798, -144.3439414047966, -287.92113052192286, -108.73317159422825, -163.91526573815986, -142.70433448683195, -319.0488085685432, 881.3527450062028, -38.509723567842414, 792.8494076956956, -90.02602055711304, 814.957796963711, 33.209067556339924, 628.3636196493776, 764.4191871794487, -29.287396138108644, -50.98256350034435, -93.53511020119745, 62.14403481579124, 236.59895480903972, 38.62381141571712, 106.14682770613622, -91.4251722801457, -88.6101491504267, -70.67768608752957, 53.76629736530896, -329.88540307267823, 129.43017911362162, -69.06047827070773, 90.01345404821585, 195.10356787340336, -262.1723628613673, -434.43147548387526, 249.9559212758492], "policy_AGENT-0_reward": [414.3074317015763, 803.5431892119312, 144.18995889144233, 464.71522042228867, 450.94259395932283, -32.52616552493609, 779.1539651022747, 22.785262414686578, -152.0792926120291, 27.739934497852914, -262.98439051937083, 52.33715809909095, -351.23514350662043, 31.04030441727461, -385.64322520194764, -75.48896144584764, -258.40132909470736, -68.55066049875238, 204.02544791856027, -54.620775517026274, -268.1042017753927, -73.86114302356584, -13.638856761503792, 670.0178947619851, 45.37139535574313, 208.10586628373528, 36.491261304032015, -133.44892896353832, 124.62807190258926, -348.165683527257, 52.61870250733677, -145.20745143236354, 475.4933986214464, 45.19209574125844, -263.93160379691346, -64.02608527027382, -413.77369742378704, -77.7009417984125, -211.81716508292718, -79.2281972262227, 158.6391030108184, -29.96847050124421, -287.1834858020705, -51.099077866086475, 190.42873166749644, 857.595852842914, 41.17979887746013, 731.0946102531332, 408.0818542749668, 199.38060861712455, 634.978791319395, -42.79088989457021, 249.86441619242487, 147.52345085698647, 31.907685606089267, -234.8487878164128, 164.66100463553704, -186.58418030690524, 101.06943240376214, -280.48866269674784, 300.4777669565116, 140.6846276839264, 26.725516269903135, -63.84131007558595, 303.7399474045567, -59.35997647134312, -207.7930065427403, -69.50613620008824, -258.8746361883021, -49.44215181980958, -140.29188725365555, -69.6959876740103, -363.9175331628819, 869.9117043790731, -0.2868372422362846, 771.3667405360723, 253.74420671219417, 796.1606885230134, 19.636936947582214, 663.3378135968077, 751.7898136528813, 12.905946485945307, 27.781836954527567, -262.87883309238276, 263.1281947621796, 266.2775019663186, 55.79074755218954, 133.97549786096428, 35.895006548973505, -153.3743179498952, 22.854234288042445, 30.99060513662449, 31.530914713492436, 157.1843239779368, -68.95475188807353, 283.5369420603905, 38.259806369833065, -192.26328530203244, -54.99313731091192, 180.0612545119228], "policy_AGENT-3_reward": [357.89904037537366, 467.41893715600435, 89.74860812873246, 494.03162590475347, 489.4524854434132, 14.977622303717133, 394.5319315707708, -59.47067509219714, -83.17369354603912, 315.97322497303514, -82.95996665327029, -38.586190304010714, -84.03975369372203, -60.16921206714235, -83.09877753802505, -14.954063408728857, -9.04681165179525, -168.17035222943608, 326.40900807090156, -11.503148600702241, 11.984849182928237, 415.300764493471, -24.663515146056497, 499.13843333546765, 384.3995461338166, -35.35424812781019, -93.81715049742175, -91.9870482563839, -36.69502395647838, -80.91059354049384, -2.905463113546687, -87.41699905600662, 440.85488258265553, 183.3872749946062, 18.302209845772982, -151.70044935040866, 4.9021678566186715, -103.4813541227404, -4.057905370135236, -93.79398171749024, 137.40350622272427, -9.5837718300093, -4.601638080522361, -81.97947773031333, -26.538019374894127, 419.12902734452064, 32.263080778387646, 472.35280771629414, 491.5512937455282, -46.064119365406754, 490.26660050697745, 6.028785372556605, 272.7569977029591, -27.745292892279817, -85.77353730644789, -96.88762853163787, 132.68846532123882, -102.39466474774525, -3.7132743470207705, -85.74878781765342, 276.0942345900911, -31.93821521302332, -95.46472053068237, -84.81748906167942, 271.4466752078185, -140.20336386570733, -5.433036560533217, -152.90407261936102, -0.42646654171682075, -109.8158885494772, -9.006372129967314, -146.32714935993957, -1.0055855544802932, 421.34271652949826, -39.07750733665887, 386.11323397269496, 222.57926016918418, 435.41488461016326, 10.203905417299296, 453.978300074254, 415.55232758806636, -29.851479754259735, -51.54792924634938, -94.09726457405372, 239.30040956425648, -33.12211354472763, 34.46827807775958, -37.80427876108535, -50.52015436674155, -89.19380438355604, -76.53733665489489, -31.41241157871188, -349.00683097047505, -35.77837783124177, 228.10881493018135, 291.12072156215186, 172.00548882168624, -4.18775896811813, -453.31487887188865, 249.36861746580757]}, "sampler_perf": {"mean_env_wait_ms": 45.39036211488503, "mean_raw_obs_processing_ms": 2.0037420237842527, "mean_inference_ms": 2.1203873175103425, "mean_action_processing_ms": 0.1310512736497231}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 226800, "timers": {"sample_time_ms": 67284.714, "sample_throughput": 62.421, "load_time_ms": 11.91, "load_throughput": 352643.147, "learn_time_ms": 5685.6, "learn_throughput": 738.708, "update_time_ms": 7.338}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 85.96099853515625, "policy_loss": -0.0318073034286499, "vf_loss": 85.9875259399414, "vf_explained_var": 0.9789737462997437, "kl": 0.011715651489794254, "entropy": 0.9025455713272095, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 76.20260620117188, "policy_loss": -0.03501564636826515, "vf_loss": 76.23218536376953, "vf_explained_var": 0.9803326725959778, "kl": 0.01208300981670618, "entropy": 0.8022202253341675, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 60.7348747253418, "policy_loss": -0.02568642422556877, "vf_loss": 60.756263732910156, "vf_explained_var": 0.982735276222229, "kl": 0.009550679475069046, "entropy": 0.6983585357666016, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 57.27216339111328, "policy_loss": -0.03151511773467064, "vf_loss": 57.298274993896484, "vf_explained_var": 0.9854896664619446, "kl": 0.011995230801403522, "entropy": 0.7249297499656677, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 226800, "num_steps_trained": 226800}, "done": false, "episodes_total": 1582, "training_iteration": 54, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-33-05", "timestamp": 1624221185, "time_this_iter_s": 76.73272204399109, "time_total_s": 4716.654891490936, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c0f374d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c0f373b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f37170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f37050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f37a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f37b90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f37170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f37050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f37a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f37b90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f37170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f37050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f37a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f37b90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f37170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f37050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f37a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f37b90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c0f37830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4716.654891490936, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 48.25504587155964, "ram_util_percent": 95.551376146789}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 3029.4443972517897, "episode_reward_min": -998.1746338885755, "episode_reward_mean": 362.2309649962033, "episode_len_mean": 157.72, "episodes_this_iter": 28, "policy_reward_min": {"AGENT-0": -385.64322520194764, "AGENT-3": -453.31487887188865, "AGENT-2": -420.3006611240423, "AGENT-1": -434.43147548387526}, "policy_reward_max": {"AGENT-0": 869.9117043790731, "AGENT-3": 494.03162590475347, "AGENT-2": 856.8372313370112, "AGENT-1": 881.3527450062028}, "policy_reward_mean": {"AGENT-0": 103.21322565478756, "AGENT-3": 75.33033464157155, "AGENT-2": 91.98403040358626, "AGENT-1": 91.70337429625799}, "custom_metrics": {"mean_ego_speed_mean": 41.391425, "mean_ego_speed_min": 26.8795, "mean_ego_speed_max": 51.046, "distance_travelled_mean": 86.41592499999999, "distance_travelled_min": 37.09725, "distance_travelled_max": 124.203}, "hist_stats": {"episode_reward": [-291.2308007910756, 2824.2048446253175, 158.68665183475184, 2539.4127138053864, -82.21972491957375, 2729.5529176669306, -355.2951950206213, 2565.052269674564, 72.51514120479142, -282.5712133620484, -30.604344569716442, -459.4097615561049, 471.45345491968004, 337.20604353111895, -176.30399218163524, -874.0364411077236, -63.153000839909126, 244.17133246798736, 183.36476614663636, 1034.155143808573, -413.57735310296687, 1041.8041140050984, -459.7996006114526, 1082.0904935180486, -145.19774482265356, 817.3077729132033, -153.74523532077916, 1121.4770458999922, 2228.1071993164396, -73.5258755435503, 595.0499783816874, 211.68874280456188, -104.01611708093259, -687.0635557943673, 422.1175480196972, -530.7979169676091, 205.9866366664556, -763.0255933650568, 625.1736298605639, 188.79682510676307, -111.76905939471946, -317.50278523798886, 1182.5961071297552, -447.1384337815169, -454.92661635193883, -436.81237519820087, -547.5553044907944, -317.9970966509948, -322.24913772838653, -428.974347175575, -685.0298504200874, 3029.4443972517897, -117.017169416034, 2721.9707259610236, 295.61791683981136, 2838.4799226913938, 82.12211564848442, 2408.402778096544, 2675.0772837030668, -33.9001243934313, -47.53443908914228, -743.4153582735897, 626.0581339567065, 436.59051680777554, 184.11608469056284, 164.59763720201153, -70.70099888415596, -523.6569669207655, -102.06335896267268, 21.892690084627695, -616.4223759467791, 215.09396076905426, 227.47509368448317, 754.247820104992, 443.07620181584, -462.626585601566, -998.1746338885755, 858.8928406568327, 1609.6104436965866, 2857.240815213475, 574.6627112887047, 1946.5463875938729, 1820.0315609086563, -35.110069104621964, 2750.9502189025043, -70.36159723372128, -492.8980164235615, 658.1455545459079, -705.0597855525339, 27.50333211651234, -834.6179620233488, -58.12777182675607, -971.5767317062457, -151.6765522489683, -564.5335556973088, -473.4369671070266, 1132.800395591821, -84.42568321886645, -548.7284698126603, 702.0712332095981], "episode_lengths": [54, 200, 239, 207, 103, 223, 172, 202, 115, 197, 130, 111, 114, 126, 75, 139, 74, 121, 110, 210, 118, 204, 124, 191, 55, 154, 116, 186, 281, 85, 109, 121, 117, 129, 121, 117, 128, 127, 124, 124, 108, 143, 145, 112, 130, 114, 136, 114, 138, 114, 129, 200, 165, 201, 134, 205, 98, 209, 196, 121, 64, 127, 112, 134, 113, 123, 112, 123, 109, 112, 151, 117, 613, 322, 105, 298, 169, 121, 190, 190, 113, 191, 390, 95, 202, 115, 121, 604, 134, 84, 132, 61, 141, 128, 133, 95, 319, 116, 159, 469], "policy_AGENT-0_reward": [-38.524355003314845, 789.5520867401415, 170.03217205776616, 730.8279265295719, 1.0023857171457657, 797.1742089099573, -54.24273874756138, 692.6006963925039, 57.109524452135624, -33.4847732438445, 32.0609353250215, -130.92082950841927, 215.13806802093984, 210.0212977296051, 19.627923678953103, -335.3304171503547, 41.44080823046978, 168.5083444805213, 34.92635461359199, 157.82587707503208, -67.53058050554947, 158.6726014825422, -195.9643770257823, 212.8006692905895, -63.14862223930574, 164.21164672139372, -38.64108069617669, 206.7245862576061, 634.978791319395, -42.79088989457021, 249.86441619242487, 147.52345085698647, 31.907685606089267, -234.8487878164128, 164.66100463553704, -186.58418030690524, 101.06943240376214, -280.48866269674784, 300.4777669565116, 140.6846276839264, 26.725516269903135, -63.84131007558595, 303.7399474045567, -59.35997647134312, -207.7930065427403, -69.50613620008824, -258.8746361883021, -49.44215181980958, -140.29188725365555, -69.6959876740103, -363.9175331628819, 869.9117043790731, -0.2868372422362846, 771.3667405360723, 253.74420671219417, 796.1606885230134, 19.636936947582214, 663.3378135968077, 751.7898136528813, 12.905946485945307, 27.781836954527567, -262.87883309238276, 263.1281947621796, 266.2775019663186, 55.79074755218954, 133.97549786096428, 35.895006548973505, -153.3743179498952, 22.854234288042445, 30.99060513662449, 31.530914713492436, 157.1843239779368, -68.95475188807353, 283.5369420603905, 38.259806369833065, -192.26328530203244, -54.99313731091192, 180.0612545119228, 414.3074317015763, 803.5431892119312, 144.18995889144233, 464.71522042228867, 450.94259395932283, -32.52616552493609, 779.1539651022747, 22.785262414686578, -152.0792926120291, 27.739934497852914, -262.98439051937083, 52.33715809909095, -351.23514350662043, 31.04030441727461, -385.64322520194764, -75.48896144584764, -258.40132909470736, -68.55066049875238, 204.02544791856027, -54.620775517026274, -268.1042017753927, -73.86114302356584], "policy_AGENT-3_reward": [-107.088648889039, 440.42093955046624, 220.8322551349305, 381.04304772025984, -61.55854463016312, 402.40295148902675, -116.91427060854548, 410.2627123466471, -28.41819286603596, -83.31872987530565, -33.82019452870567, -87.87091030916747, 190.82978641869832, -27.357254166401844, -107.78407415134828, -85.52247456016067, -73.02041433382392, -32.705706480432234, 67.38036138898352, 318.57411672575324, -140.25612598883149, 323.3432486482493, -227.84536343264358, 290.4091030875266, -9.270938013290062, 277.7632459023098, -26.49492498575868, 322.6819657333968, 490.26660050697745, 6.028785372556605, 272.7569977029591, -27.745292892279817, -85.77353730644789, -96.88762853163787, 132.68846532123882, -102.39466474774525, -3.7132743470207705, -85.74878781765342, 276.0942345900911, -31.93821521302332, -95.46472053068237, -84.81748906167942, 271.4466752078185, -140.20336386570733, -5.433036560533217, -152.90407261936102, -0.42646654171682075, -109.8158885494772, -9.006372129967314, -146.32714935993957, -1.0055855544802932, 421.34271652949826, -39.07750733665887, 386.11323397269496, 222.57926016918418, 435.41488461016326, 10.203905417299296, 453.978300074254, 415.55232758806636, -29.851479754259735, -51.54792924634938, -94.09726457405372, 239.30040956425648, -33.12211354472763, 34.46827807775958, -37.80427876108535, -50.52015436674155, -89.19380438355604, -76.53733665489489, -31.41241157871188, -349.00683097047505, -35.77837783124177, 228.10881493018135, 291.12072156215186, 172.00548882168624, -4.18775896811813, -453.31487887188865, 249.36861746580757, 357.89904037537366, 467.41893715600435, 89.74860812873246, 494.03162590475347, 489.4524854434132, 14.977622303717133, 394.5319315707708, -59.47067509219714, -83.17369354603912, 315.97322497303514, -82.95996665327029, -38.586190304010714, -84.03975369372203, -60.16921206714235, -83.09877753802505, -14.954063408728857, -9.04681165179525, -168.17035222943608, 326.40900807090156, -11.503148600702241, 11.984849182928237, 415.300764493471], "policy_AGENT-2_reward": [-39.091296094513105, 785.0748493077297, -116.38141375341922, 702.3328599930893, -61.485662863905176, 761.1011119088181, -80.9452242130661, 722.5566611722799, 56.550475367795684, -83.01631160402587, -33.66201519778136, -153.3164160427261, 32.52576100243777, -27.354149746986497, 19.070703940052315, -368.2287504311516, 40.883940951126334, -32.503998030101016, 34.37944182724382, 122.9161152307201, -68.07922533075116, 122.1607586607917, -18.21060283238629, 176.6138300624402, -9.330629622946368, 135.358833091347, -26.460701340860698, 172.45101615895965, 495.96814970067504, -43.35777144573814, 35.997757416035085, -27.696561126930565, 31.475003333929205, -259.0043396861432, 62.04470245723645, -140.1389947422702, 100.49602964218813, -311.604161137193, 24.04415300767863, -31.880923611810896, 26.141504877393825, -84.59089875232225, 271.8547421918134, -59.91253370283531, -5.391326527207869, -70.05822497395492, -0.3330712388526771, -50.00588468747992, -9.035612606603602, -70.24687565479326, -1.057923134182462, 856.8372313370112, -39.14310126929652, 771.6413437565581, -90.67952948445406, 791.9465525945051, 19.072205727263032, 662.7230447761085, 743.3159552826693, 12.332805012991777, 27.214216703023915, -292.9041504059551, 61.48549481447932, -33.16382642285542, 55.233247644896664, -37.72040960400354, 35.34932121375777, -192.47869543688745, 22.297429491709337, -31.45180083859382, 30.938943382881334, -35.742164491262336, 137.38150891308294, 89.57670243423455, 37.70733875091737, -4.003178470048127, -55.43514222190069, 179.50704740325452, 413.4609618972984, 778.5278309696514, 143.62755831929286, 523.2213800877335, 493.4000260252377, -33.1050932898322, 777.4431058703937, 22.22612951455295, -175.0378456460888, 286.70512811046854, -276.7252048813566, 51.77741696395391, -315.8671857180686, 30.604522989582023, -420.3006611240423, 14.324984353647986, -9.000894385252941, -69.10442500044073, 155.84196241870296, -11.546126383590376, 11.993902998790055, 434.4802745050623], "policy_AGENT-1_reward": [-106.52650080420862, 809.156969026981, -115.79636160452569, 725.2088795624633, 39.822096857348704, 768.87464535913, -103.19296145144799, 739.632199763137, -12.726665749104095, -82.751398638872, 4.8169298317489755, -87.30160569579185, 32.95983947760393, 181.89614971490187, -107.21854564929242, -84.95479896605703, -72.45733568768142, 140.8726924979993, 46.67860831681707, 434.83903477706855, -137.7114212778347, 437.6275052135161, -17.779257320640273, 402.2668910774918, -63.447554947111406, 239.97404719815233, -62.14852829798308, 419.61947775003125, 606.8936577893926, 6.59400042420161, 36.430807070268614, 119.60714596678585, -81.62526871450318, -96.32279976017334, 62.723375605685256, -101.68007717068834, 8.134448967526193, -85.18398171346226, 24.55747530628244, 111.93133624767097, -69.17136001133399, -84.25308734840117, 335.5547423255661, -187.66255974163073, -236.30924672145798, -144.3439414047966, -287.92113052192286, -108.73317159422825, -163.91526573815986, -142.70433448683195, -319.0488085685432, 881.3527450062028, -38.509723567842414, 792.8494076956956, -90.02602055711304, 814.957796963711, 33.209067556339924, 628.3636196493776, 764.4191871794487, -29.287396138108644, -50.98256350034435, -93.53511020119745, 62.14403481579124, 236.59895480903972, 38.62381141571712, 106.14682770613622, -91.4251722801457, -88.6101491504267, -70.67768608752957, 53.76629736530896, -329.88540307267823, 129.43017911362162, -69.06047827070773, 90.01345404821585, 195.10356787340336, -262.1723628613673, -434.43147548387526, 249.9559212758492, 423.9430097223414, 807.7508578758884, 197.09658594923621, 464.57816117909647, 386.2364554806831, 15.54356740642919, 799.8212163590659, -55.90231407076373, -82.60718461940442, 27.72726696455127, -82.39022349853599, -38.02505264252166, -83.47587910493748, -59.6033871664703, -82.53406784223074, -75.55851174803986, -288.0845205655535, -167.6115293783974, 446.52397718365705, -6.755632717547597, -304.6030202189851, -73.84866276536842]}, "sampler_perf": {"mean_env_wait_ms": 45.2142175259806, "mean_raw_obs_processing_ms": 1.9984117618843151, "mean_inference_ms": 2.1162475692702403, "mean_action_processing_ms": 0.13077469883047196}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 231000, "timers": {"sample_time_ms": 67430.928, "sample_throughput": 62.286, "load_time_ms": 12.071, "load_throughput": 347939.585, "learn_time_ms": 5833.914, "learn_throughput": 719.928, "update_time_ms": 7.408}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 55.51123046875, "policy_loss": -0.0323774516582489, "vf_loss": 55.53767395019531, "vf_explained_var": 0.987000048160553, "kl": 0.013176639564335346, "entropy": 0.8831673860549927, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 37.79607391357422, "policy_loss": -0.03783899545669556, "vf_loss": 37.8268928527832, "vf_explained_var": 0.9885700345039368, "kl": 0.015599015168845654, "entropy": 0.7920308709144592, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 67.85244750976562, "policy_loss": -0.029603635892271996, "vf_loss": 67.8763198852539, "vf_explained_var": 0.9863601326942444, "kl": 0.012751951813697815, "entropy": 0.8009528517723083, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 28.530405044555664, "policy_loss": -0.040246132761240005, "vf_loss": 28.564685821533203, "vf_explained_var": 0.993198037147522, "kl": 0.013256525620818138, "entropy": 0.8006734251976013, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 231000, "num_steps_trained": 231000}, "done": false, "episodes_total": 1610, "training_iteration": 55, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-34-23", "timestamp": 1624221263, "time_this_iter_s": 78.4802565574646, "time_total_s": 4795.135148048401, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c80865f0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c81d5dd0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe58c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e8c0>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe58c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e8c0>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe58c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e8c0>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74dd0>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe5e60>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0fe58c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c833e8c0>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c0f37dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4795.135148048401, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 54.15221238938054, "ram_util_percent": 95.59026548672566}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 3029.4443972517897, "episode_reward_min": -1092.3922755001654, "episode_reward_mean": 454.7684425196891, "episode_len_mean": 168.42, "episodes_this_iter": 20, "policy_reward_min": {"AGENT-0": -478.56772359650245, "AGENT-3": -453.31487887188865, "AGENT-2": -448.4342642896545, "AGENT-1": -434.43147548387526}, "policy_reward_max": {"AGENT-0": 926.5674346180731, "AGENT-3": 753.6287762154753, "AGENT-2": 856.8372313370112, "AGENT-1": 881.3527450062028}, "policy_reward_mean": {"AGENT-0": 120.49818738794238, "AGENT-3": 90.66650061041855, "AGENT-2": 124.41296164368978, "AGENT-1": 119.1907928776383}, "custom_metrics": {"mean_ego_speed_mean": 41.146085, "mean_ego_speed_min": 26.8795, "mean_ego_speed_max": 49.8905, "distance_travelled_mean": 87.47936250000001, "distance_travelled_min": 37.09725, "distance_travelled_max": 124.203}, "hist_stats": {"episode_reward": [-90.0291374487974, 2976.151737342624, -300.43253766775007, 2980.30178297694, -290.58859543425353, 2700.9756385164633, -32.60772761431534, 2841.6339723409533, -1092.3922755001654, 583.0417966219999, -618.5382304591477, 1638.426402681824, -496.4148175144953, -11.778882813564778, 110.26169698058794, -354.9882342011163, -755.9668374264917, -98.50946413083913, 778.2428494484437, -345.655446922082, -322.24913772838653, -428.974347175575, -685.0298504200874, 3029.4443972517897, -117.017169416034, 2721.9707259610236, 295.61791683981136, 2838.4799226913938, 82.12211564848442, 2408.402778096544, 2675.0772837030668, -33.9001243934313, -47.53443908914228, -743.4153582735897, 626.0581339567065, 436.59051680777554, 184.11608469056284, 164.59763720201153, -70.70099888415596, -523.6569669207655, -102.06335896267268, 21.892690084627695, -616.4223759467791, 215.09396076905426, 227.47509368448317, 754.247820104992, 443.07620181584, -462.626585601566, -998.1746338885755, 858.8928406568327, 1609.6104436965866, 2857.240815213475, 574.6627112887047, 1946.5463875938729, 1820.0315609086563, -35.110069104621964, 2750.9502189025043, -70.36159723372128, -492.8980164235615, 658.1455545459079, -705.0597855525339, 27.50333211651234, -834.6179620233488, -58.12777182675607, -971.5767317062457, -151.6765522489683, -564.5335556973088, -473.4369671070266, 1132.800395591821, -84.42568321886645, -548.7284698126603, 702.0712332095981, -291.2308007910756, 2824.2048446253175, 158.68665183475184, 2539.4127138053864, -82.21972491957375, 2729.5529176669306, -355.2951950206213, 2565.052269674564, 72.51514120479142, -282.5712133620484, -30.604344569716442, -459.4097615561049, 471.45345491968004, 337.20604353111895, -176.30399218163524, -874.0364411077236, -63.153000839909126, 244.17133246798736, 183.36476614663636, 1034.155143808573, -413.57735310296687, 1041.8041140050984, -459.7996006114526, 1082.0904935180486, -145.19774482265356, 817.3077729132033, -153.74523532077916, 1121.4770458999922], "episode_lengths": [111, 198, 56, 210, 73, 352, 166, 204, 165, 116, 122, 238, 110, 65, 102, 119, 146, 845, 142, 115, 138, 114, 129, 200, 165, 201, 134, 205, 98, 209, 196, 121, 64, 127, 112, 134, 113, 123, 112, 123, 109, 112, 151, 117, 613, 322, 105, 298, 169, 121, 190, 190, 113, 191, 390, 95, 202, 115, 121, 604, 134, 84, 132, 61, 141, 128, 133, 95, 319, 116, 159, 469, 54, 200, 239, 207, 103, 223, 172, 202, 115, 197, 130, 111, 114, 126, 75, 139, 74, 121, 110, 210, 118, 204, 124, 191, 55, 154, 116, 186], "policy_AGENT-0_reward": [13.631698614588837, 839.411522850894, -41.00981206566535, 926.5674346180731, -39.77165337590928, 702.5499357301545, 42.02116532749686, 796.1286518256552, -478.56772359650245, 211.88495374465774, -210.98652793560166, 50.97389884975574, -150.92804633685242, 38.08819676689794, 67.71062142784584, -83.848152500151, -360.8279304735729, -62.88520986559024, 190.03522889186038, -73.57917786596856, -140.29188725365555, -69.6959876740103, -363.9175331628819, 869.9117043790731, -0.2868372422362846, 771.3667405360723, 253.74420671219417, 796.1606885230134, 19.636936947582214, 663.3378135968077, 751.7898136528813, 12.905946485945307, 27.781836954527567, -262.87883309238276, 263.1281947621796, 266.2775019663186, 55.79074755218954, 133.97549786096428, 35.895006548973505, -153.3743179498952, 22.854234288042445, 30.99060513662449, 31.530914713492436, 157.1843239779368, -68.95475188807353, 283.5369420603905, 38.259806369833065, -192.26328530203244, -54.99313731091192, 180.0612545119228, 414.3074317015763, 803.5431892119312, 144.18995889144233, 464.71522042228867, 450.94259395932283, -32.52616552493609, 779.1539651022747, 22.785262414686578, -152.0792926120291, 27.739934497852914, -262.98439051937083, 52.33715809909095, -351.23514350662043, 31.04030441727461, -385.64322520194764, -75.48896144584764, -258.40132909470736, -68.55066049875238, 204.02544791856027, -54.620775517026274, -268.1042017753927, -73.86114302356584, -38.524355003314845, 789.5520867401415, 170.03217205776616, 730.8279265295719, 1.0023857171457657, 797.1742089099573, -54.24273874756138, 692.6006963925039, 57.109524452135624, -33.4847732438445, 32.0609353250215, -130.92082950841927, 215.13806802093984, 210.0212977296051, 19.627923678953103, -335.3304171503547, 41.44080823046978, 168.5083444805213, 34.92635461359199, 157.82587707503208, -67.53058050554947, 158.6726014825422, -195.9643770257823, 212.8006692905895, -63.14862223930574, 164.21164672139372, -38.64108069617669, 206.7245862576061], "policy_AGENT-3_reward": [-69.63510949656424, 433.3203167272931, -109.26855010230105, 416.41924230079627, -105.72071194537367, 386.71687613936416, -58.13656285431247, 420.40371725076477, -82.98302734255026, 187.51489847348168, -83.71892581485889, 753.6287762154753, -83.71104180297871, -43.983290330664026, -32.06770001212222, -91.43109802479135, -1.2371226001658715, 20.37144036219987, 210.6092735370798, -107.45948367839794, -9.006372129967314, -146.32714935993957, -1.0055855544802932, 421.34271652949826, -39.07750733665887, 386.11323397269496, 222.57926016918418, 435.41488461016326, 10.203905417299296, 453.978300074254, 415.55232758806636, -29.851479754259735, -51.54792924634938, -94.09726457405372, 239.30040956425648, -33.12211354472763, 34.46827807775958, -37.80427876108535, -50.52015436674155, -89.19380438355604, -76.53733665489489, -31.41241157871188, -349.00683097047505, -35.77837783124177, 228.10881493018135, 291.12072156215186, 172.00548882168624, -4.18775896811813, -453.31487887188865, 249.36861746580757, 357.89904037537366, 467.41893715600435, 89.74860812873246, 494.03162590475347, 489.4524854434132, 14.977622303717133, 394.5319315707708, -59.47067509219714, -83.17369354603912, 315.97322497303514, -82.95996665327029, -38.586190304010714, -84.03975369372203, -60.16921206714235, -83.09877753802505, -14.954063408728857, -9.04681165179525, -168.17035222943608, 326.40900807090156, -11.503148600702241, 11.984849182928237, 415.300764493471, -107.088648889039, 440.42093955046624, 220.8322551349305, 381.04304772025984, -61.55854463016312, 402.40295148902675, -116.91427060854548, 410.2627123466471, -28.41819286603596, -83.31872987530565, -33.82019452870567, -87.87091030916747, 190.82978641869832, -27.357254166401844, -107.78407415134828, -85.52247456016067, -73.02041433382392, -32.705706480432234, 67.38036138898352, 318.57411672575324, -140.25612598883149, 323.3432486482493, -227.84536343264358, 290.4091030875266, -9.270938013290062, 277.7632459023098, -26.49492498575868, 322.6819657333968], "policy_AGENT-2_reward": [-69.41518952016429, 836.439593350998, -41.45121152856809, 818.440865413789, -40.184139229303, 834.2705746337507, 41.08024771217747, 801.9373155867124, -448.4342642896545, 91.5615151586023, -240.67884007980746, 782.8871877055716, -178.62855809432276, 37.535240857216905, -32.10642286186005, -84.4108536462695, -1.2035075043108132, 7.02377643202766, 166.4221581341897, -74.14501322621054, -9.035612606603602, -70.24687565479326, -1.057923134182462, 856.8372313370112, -39.14310126929652, 771.6413437565581, -90.67952948445406, 791.9465525945051, 19.072205727263032, 662.7230447761085, 743.3159552826693, 12.332805012991777, 27.214216703023915, -292.9041504059551, 61.48549481447932, -33.16382642285542, 55.233247644896664, -37.72040960400354, 35.34932121375777, -192.47869543688745, 22.297429491709337, -31.45180083859382, 30.938943382881334, -35.742164491262336, 137.38150891308294, 89.57670243423455, 37.70733875091737, -4.003178470048127, -55.43514222190069, 179.50704740325452, 413.4609618972984, 778.5278309696514, 143.62755831929286, 523.2213800877335, 493.4000260252377, -33.1050932898322, 777.4431058703937, 22.22612951455295, -175.0378456460888, 286.70512811046854, -276.7252048813566, 51.77741696395391, -315.8671857180686, 30.604522989582023, -420.3006611240423, 14.324984353647986, -9.000894385252941, -69.10442500044073, 155.84196241870296, -11.546126383590376, 11.993902998790055, 434.4802745050623, -39.091296094513105, 785.0748493077297, -116.38141375341922, 702.3328599930893, -61.485662863905176, 761.1011119088181, -80.9452242130661, 722.5566611722799, 56.550475367795684, -83.01631160402587, -33.66201519778136, -153.3164160427261, 32.52576100243777, -27.354149746986497, 19.070703940052315, -368.2287504311516, 40.883940951126334, -32.503998030101016, 34.37944182724382, 122.9161152307201, -68.07922533075116, 122.1607586607917, -18.21060283238629, 176.6138300624402, -9.330629622946368, 135.358833091347, -26.460701340860698, 172.45101615895965], "policy_AGENT-1_reward": [35.38946295334241, 866.9803044134386, -108.70296397121558, 818.8742406442786, -104.91209088366759, 777.4382520131912, -57.57257779967727, 823.164287677823, -82.40726027145837, 92.08042924525799, -83.15393662887993, 50.93653991102126, -83.1471712803417, -43.41903010701561, 106.72519842672429, -95.2981300299045, -392.69827684844216, -63.01947105947667, 211.17618888531507, -90.47177215150505, -163.91526573815986, -142.70433448683195, -319.0488085685432, 881.3527450062028, -38.509723567842414, 792.8494076956956, -90.02602055711304, 814.957796963711, 33.209067556339924, 628.3636196493776, 764.4191871794487, -29.287396138108644, -50.98256350034435, -93.53511020119745, 62.14403481579124, 236.59895480903972, 38.62381141571712, 106.14682770613622, -91.4251722801457, -88.6101491504267, -70.67768608752957, 53.76629736530896, -329.88540307267823, 129.43017911362162, -69.06047827070773, 90.01345404821585, 195.10356787340336, -262.1723628613673, -434.43147548387526, 249.9559212758492, 423.9430097223414, 807.7508578758884, 197.09658594923621, 464.57816117909647, 386.2364554806831, 15.54356740642919, 799.8212163590659, -55.90231407076373, -82.60718461940442, 27.72726696455127, -82.39022349853599, -38.02505264252166, -83.47587910493748, -59.6033871664703, -82.53406784223074, -75.55851174803986, -288.0845205655535, -167.6115293783974, 446.52397718365705, -6.755632717547597, -304.6030202189851, -73.84866276536842, -106.52650080420862, 809.156969026981, -115.79636160452569, 725.2088795624633, 39.822096857348704, 768.87464535913, -103.19296145144799, 739.632199763137, -12.726665749104095, -82.751398638872, 4.8169298317489755, -87.30160569579185, 32.95983947760393, 181.89614971490187, -107.21854564929242, -84.95479896605703, -72.45733568768142, 140.8726924979993, 46.67860831681707, 434.83903477706855, -137.7114212778347, 437.6275052135161, -17.779257320640273, 402.2668910774918, -63.447554947111406, 239.97404719815233, -62.14852829798308, 419.61947775003125]}, "sampler_perf": {"mean_env_wait_ms": 45.26259660776128, "mean_raw_obs_processing_ms": 1.9845305265115007, "mean_inference_ms": 2.1177436954131763, "mean_action_processing_ms": 0.13067931234947924}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 235200, "timers": {"sample_time_ms": 67652.959, "sample_throughput": 62.082, "load_time_ms": 12.234, "load_throughput": 343291.594, "learn_time_ms": 5829.922, "learn_throughput": 720.421, "update_time_ms": 7.538}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 52.8000373840332, "policy_loss": -0.03742506355047226, "vf_loss": 52.831573486328125, "vf_explained_var": 0.9885259866714478, "kl": 0.013091986998915672, "entropy": 0.8318780660629272, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 45.547096252441406, "policy_loss": -0.040672339498996735, "vf_loss": 45.580081939697266, "vf_explained_var": 0.989274263381958, "kl": 0.017083317041397095, "entropy": 0.8014075756072998, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 30.02925682067871, "policy_loss": -0.02688111551105976, "vf_loss": 30.050016403198242, "vf_explained_var": 0.9907703995704651, "kl": 0.013600981794297695, "entropy": 0.6067165732383728, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 71.87956237792969, "policy_loss": -0.03191905841231346, "vf_loss": 71.90656280517578, "vf_explained_var": 0.9792631268501282, "kl": 0.01093759760260582, "entropy": 0.7358288168907166, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 235200, "num_steps_trained": 235200}, "done": false, "episodes_total": 1630, "training_iteration": 56, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-35-37", "timestamp": 1624221337, "time_this_iter_s": 73.74617075920105, "time_total_s": 4868.881318807602, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c06394d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c06393b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0639170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0639050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0639a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c0639b90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0639170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0639050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0639a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c0639b90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0639170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0639050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0639a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c0639b90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0639170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c0639050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c0639a70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c0639b90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c0639830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4868.881318807602, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 49.072380952380946, "ram_util_percent": 95.6}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 2980.30178297694, "episode_reward_min": -1103.698703826893, "episode_reward_mean": 450.22619067821574, "episode_len_mean": 173.18, "episodes_this_iter": 26, "policy_reward_min": {"AGENT-0": -478.56772359650245, "AGENT-3": -453.31487887188865, "AGENT-2": -487.6551206759964, "AGENT-1": -434.43147548387526}, "policy_reward_max": {"AGENT-0": 926.5674346180731, "AGENT-3": 753.6287762154753, "AGENT-2": 883.1972413024636, "AGENT-1": 866.9803044134386}, "policy_reward_mean": {"AGENT-0": 108.29393220824697, "AGENT-3": 95.16075570631371, "AGENT-2": 122.96020238254079, "AGENT-1": 123.81130038111438}, "custom_metrics": {"mean_ego_speed_mean": 40.4264875, "mean_ego_speed_min": 26.8795, "mean_ego_speed_max": 50.288, "distance_travelled_mean": 88.9630125, "distance_travelled_min": 33.791, "distance_travelled_max": 124.07525}, "hist_stats": {"episode_reward": [255.78235141392017, 2012.8080396961448, 205.202965089077, 2834.3458489794457, -289.6907194716316, 2898.5352231827333, 5.100727209519633, 284.40950991681353, -399.1177703684011, 876.5744819036793, 255.9350172543167, 629.4911706996186, 260.8037157720368, -1103.698703826893, 805.8647288298544, -565.3622936509944, -411.36795759838924, 1299.0894141775834, -359.3382934872074, 1254.1260575454098, -497.3489933168307, 657.3646203769388, -354.39419030873813, 1308.593127793923, -471.29232955178617, 1143.5820178742488, 443.07620181584, -462.626585601566, -998.1746338885755, 858.8928406568327, 1609.6104436965866, 2857.240815213475, 574.6627112887047, 1946.5463875938729, 1820.0315609086563, -35.110069104621964, 2750.9502189025043, -70.36159723372128, -492.8980164235615, 658.1455545459079, -705.0597855525339, 27.50333211651234, -834.6179620233488, -58.12777182675607, -971.5767317062457, -151.6765522489683, -564.5335556973088, -473.4369671070266, 1132.800395591821, -84.42568321886645, -548.7284698126603, 702.0712332095981, -291.2308007910756, 2824.2048446253175, 158.68665183475184, 2539.4127138053864, -82.21972491957375, 2729.5529176669306, -355.2951950206213, 2565.052269674564, 72.51514120479142, -282.5712133620484, -30.604344569716442, -459.4097615561049, 471.45345491968004, 337.20604353111895, -176.30399218163524, -874.0364411077236, -63.153000839909126, 244.17133246798736, 183.36476614663636, 1034.155143808573, -413.57735310296687, 1041.8041140050984, -459.7996006114526, 1082.0904935180486, -145.19774482265356, 817.3077729132033, -153.74523532077916, 1121.4770458999922, -90.0291374487974, 2976.151737342624, -300.43253766775007, 2980.30178297694, -290.58859543425353, 2700.9756385164633, -32.60772761431534, 2841.6339723409533, -1092.3922755001654, 583.0417966219999, -618.5382304591477, 1638.426402681824, -496.4148175144953, -11.778882813564778, 110.26169698058794, -354.9882342011163, -755.9668374264917, -98.50946413083913, 778.2428494484437, -345.655446922082], "episode_lengths": [134, 235, 172, 203, 77, 349, 100, 690, 49, 143, 133, 118, 116, 157, 539, 136, 115, 199, 118, 120, 84, 199, 118, 136, 72, 206, 105, 298, 169, 121, 190, 190, 113, 191, 390, 95, 202, 115, 121, 604, 134, 84, 132, 61, 141, 128, 133, 95, 319, 116, 159, 469, 54, 200, 239, 207, 103, 223, 172, 202, 115, 197, 130, 111, 114, 126, 75, 139, 74, 121, 110, 210, 118, 204, 124, 191, 55, 154, 116, 186, 111, 198, 56, 210, 73, 352, 166, 204, 165, 116, 122, 238, 110, 65, 102, 119, 146, 845, 142, 115], "policy_AGENT-0_reward": [203.3991345042143, 482.37144022121424, 204.26392656849103, 786.3187792031537, -37.78407103758022, 767.8303500808582, 3.2191750507704575, 50.676489474063686, -144.16938318441416, 264.1304533205003, 164.3026361745174, 164.99609887613582, 80.80116088525888, -451.71042357560503, 60.04984839772793, -258.2990595322352, -66.7312138332889, 250.52767307510334, -58.220204552710214, 305.6131258174238, -91.56917565049265, 114.98248130564431, -66.5531197046176, 315.83689090748226, -79.87505666849411, 203.5660342994135, 38.259806369833065, -192.26328530203244, -54.99313731091192, 180.0612545119228, 414.3074317015763, 803.5431892119312, 144.18995889144233, 464.71522042228867, 450.94259395932283, -32.52616552493609, 779.1539651022747, 22.785262414686578, -152.0792926120291, 27.739934497852914, -262.98439051937083, 52.33715809909095, -351.23514350662043, 31.04030441727461, -385.64322520194764, -75.48896144584764, -258.40132909470736, -68.55066049875238, 204.02544791856027, -54.620775517026274, -268.1042017753927, -73.86114302356584, -38.524355003314845, 789.5520867401415, 170.03217205776616, 730.8279265295719, 1.0023857171457657, 797.1742089099573, -54.24273874756138, 692.6006963925039, 57.109524452135624, -33.4847732438445, 32.0609353250215, -130.92082950841927, 215.13806802093984, 210.0212977296051, 19.627923678953103, -335.3304171503547, 41.44080823046978, 168.5083444805213, 34.92635461359199, 157.82587707503208, -67.53058050554947, 158.6726014825422, -195.9643770257823, 212.8006692905895, -63.14862223930574, 164.21164672139372, -38.64108069617669, 206.7245862576061, 13.631698614588837, 839.411522850894, -41.00981206566535, 926.5674346180731, -39.77165337590928, 702.5499357301545, 42.02116532749686, 796.1286518256552, -478.56772359650245, 211.88495374465774, -210.98652793560166, 50.97389884975574, -150.92804633685242, 38.08819676689794, 67.71062142784584, -83.848152500151, -360.8279304735729, -62.88520986559024, 190.03522889186038, -73.57917786596856], "policy_AGENT-3_reward": [-60.949352323228396, 502.30705165654757, -88.80368403072714, 408.5463489670765, -107.07169754350065, 419.80885773168654, -12.474608172712546, 79.56561496642061, -85.21805812993205, 187.64860225392783, -30.66484685448454, 134.17060062240608, 44.7376363533926, -82.45111669098878, 370.44292968620715, -8.983294009939753, -142.65664268939113, 341.2207244097698, -122.23586540559089, 274.3246870631691, -157.10536316538798, 297.1919090502657, -111.14813812309376, 294.7096078038967, -155.78034695821611, 324.1882095703089, 172.00548882168624, -4.18775896811813, -453.31487887188865, 249.36861746580757, 357.89904037537366, 467.41893715600435, 89.74860812873246, 494.03162590475347, 489.4524854434132, 14.977622303717133, 394.5319315707708, -59.47067509219714, -83.17369354603912, 315.97322497303514, -82.95996665327029, -38.586190304010714, -84.03975369372203, -60.16921206714235, -83.09877753802505, -14.954063408728857, -9.04681165179525, -168.17035222943608, 326.40900807090156, -11.503148600702241, 11.984849182928237, 415.300764493471, -107.088648889039, 440.42093955046624, 220.8322551349305, 381.04304772025984, -61.55854463016312, 402.40295148902675, -116.91427060854548, 410.2627123466471, -28.41819286603596, -83.31872987530565, -33.82019452870567, -87.87091030916747, 190.82978641869832, -27.357254166401844, -107.78407415134828, -85.52247456016067, -73.02041433382392, -32.705706480432234, 67.38036138898352, 318.57411672575324, -140.25612598883149, 323.3432486482493, -227.84536343264358, 290.4091030875266, -9.270938013290062, 277.7632459023098, -26.49492498575868, 322.6819657333968, -69.63510949656424, 433.3203167272931, -109.26855010230105, 416.41924230079627, -105.72071194537367, 386.71687613936416, -58.13656285431247, 420.40371725076477, -82.98302734255026, 187.51489847348168, -83.71892581485889, 753.6287762154753, -83.71104180297871, -43.983290330664026, -32.06770001212222, -91.43109802479135, -1.2371226001658715, 20.37144036219987, 210.6092735370798, -107.45948367839794], "policy_AGENT-2_reward": [-60.941188687244484, 507.14583987563464, 177.98610780070035, 830.1513778966173, -38.32948864127569, 883.1972413024636, 2.656107510173128, 103.60032779396481, -85.08038827543507, 185.63704092897564, -30.623937539288107, 164.41998619328848, 80.24454746068544, -487.6551206759964, 315.30927611523185, -8.896427042474333, -67.28080293046887, 216.39078522638505, -58.76970525437567, 305.05382354081075, -92.1279243280544, 159.15543975242636, -67.11183563175162, 315.2191430389248, -80.42495255091005, 169.52071474237906, 37.70733875091737, -4.003178470048127, -55.43514222190069, 179.50704740325452, 413.4609618972984, 778.5278309696514, 143.62755831929286, 523.2213800877335, 493.4000260252377, -33.1050932898322, 777.4431058703937, 22.22612951455295, -175.0378456460888, 286.70512811046854, -276.7252048813566, 51.77741696395391, -315.8671857180686, 30.604522989582023, -420.3006611240423, 14.324984353647986, -9.000894385252941, -69.10442500044073, 155.84196241870296, -11.546126383590376, 11.993902998790055, 434.4802745050623, -39.091296094513105, 785.0748493077297, -116.38141375341922, 702.3328599930893, -61.485662863905176, 761.1011119088181, -80.9452242130661, 722.5566611722799, 56.550475367795684, -83.01631160402587, -33.66201519778136, -153.3164160427261, 32.52576100243777, -27.354149746986497, 19.070703940052315, -368.2287504311516, 40.883940951126334, -32.503998030101016, 34.37944182724382, 122.9161152307201, -68.07922533075116, 122.1607586607917, -18.21060283238629, 176.6138300624402, -9.330629622946368, 135.358833091347, -26.460701340860698, 172.45101615895965, -69.41518952016429, 836.439593350998, -41.45121152856809, 818.440865413789, -40.184139229303, 834.2705746337507, 41.08024771217747, 801.9373155867124, -448.4342642896545, 91.5615151586023, -240.67884007980746, 782.8871877055716, -178.62855809432276, 37.535240857216905, -32.10642286186005, -84.4108536462695, -1.2035075043108132, 7.02377643202766, 166.4221581341897, -74.14501322621054], "policy_AGENT-1_reward": [174.27375792017853, 520.9837079427473, -88.24338524938719, 809.3293429125958, -106.50546224927513, 827.6987740677257, 11.700052821288601, 50.56707768236473, -84.64994077861986, 239.15838540027605, 152.92116547357188, 165.90448500778822, 55.02037107269992, -81.88204288430374, 60.062674630686885, -289.18351306634514, -134.6992981452402, 490.95023146632457, -120.1125182745305, 369.13442112400537, -156.54653017289547, 86.03479026860283, -109.58109684927517, 382.82748604361933, -155.21197337416572, 446.3070592621473, 195.10356787340336, -262.1723628613673, -434.43147548387526, 249.9559212758492, 423.9430097223414, 807.7508578758884, 197.09658594923621, 464.57816117909647, 386.2364554806831, 15.54356740642919, 799.8212163590659, -55.90231407076373, -82.60718461940442, 27.72726696455127, -82.39022349853599, -38.02505264252166, -83.47587910493748, -59.6033871664703, -82.53406784223074, -75.55851174803986, -288.0845205655535, -167.6115293783974, 446.52397718365705, -6.755632717547597, -304.6030202189851, -73.84866276536842, -106.52650080420862, 809.156969026981, -115.79636160452569, 725.2088795624633, 39.822096857348704, 768.87464535913, -103.19296145144799, 739.632199763137, -12.726665749104095, -82.751398638872, 4.8169298317489755, -87.30160569579185, 32.95983947760393, 181.89614971490187, -107.21854564929242, -84.95479896605703, -72.45733568768142, 140.8726924979993, 46.67860831681707, 434.83903477706855, -137.7114212778347, 437.6275052135161, -17.779257320640273, 402.2668910774918, -63.447554947111406, 239.97404719815233, -62.14852829798308, 419.61947775003125, 35.38946295334241, 866.9803044134386, -108.70296397121558, 818.8742406442786, -104.91209088366759, 777.4382520131912, -57.57257779967727, 823.164287677823, -82.40726027145837, 92.08042924525799, -83.15393662887993, 50.93653991102126, -83.1471712803417, -43.41903010701561, 106.72519842672429, -95.2981300299045, -392.69827684844216, -63.01947105947667, 211.17618888531507, -90.47177215150505]}, "sampler_perf": {"mean_env_wait_ms": 45.10683122674258, "mean_raw_obs_processing_ms": 1.9745668890355919, "mean_inference_ms": 2.1098844415306393, "mean_action_processing_ms": 0.1303891803559979}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 239400, "timers": {"sample_time_ms": 68080.257, "sample_throughput": 61.692, "load_time_ms": 12.48, "load_throughput": 336548.195, "learn_time_ms": 5928.804, "learn_throughput": 708.406, "update_time_ms": 7.491}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 66.36070251464844, "policy_loss": -0.03351176157593727, "vf_loss": 66.388427734375, "vf_explained_var": 0.9838184118270874, "kl": 0.012853596359491348, "entropy": 0.8471495509147644, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 60.322967529296875, "policy_loss": -0.033793557435274124, "vf_loss": 60.350433349609375, "vf_explained_var": 0.9824676513671875, "kl": 0.014056498184800148, "entropy": 0.7866360545158386, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 62.8333625793457, "policy_loss": -0.023163309320807457, "vf_loss": 62.85090637207031, "vf_explained_var": 0.984961986541748, "kl": 0.012487991712987423, "entropy": 0.6940212845802307, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 39.8539924621582, "policy_loss": -0.035094428807497025, "vf_loss": 39.88349914550781, "vf_explained_var": 0.9900068640708923, "kl": 0.01243046298623085, "entropy": 0.7929404377937317, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 239400, "num_steps_trained": 239400}, "done": false, "episodes_total": 1656, "training_iteration": 57, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-36-59", "timestamp": 1624221419, "time_this_iter_s": 81.55289196968079, "time_total_s": 4950.434210777283, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c8397cb0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c83974d0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74830>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c86478c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647200>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74830>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c86478c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647200>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74830>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c86478c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647200>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c0f74830>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647ef0>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c86478c0>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c8647200>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c0639dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 4950.434210777283, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 52.76068376068377, "ram_util_percent": 95.65470085470088}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
{"episode_reward_max": 2980.30178297694, "episode_reward_min": -1860.0662029575724, "episode_reward_mean": 458.1998581805042, "episode_len_mean": 166.99, "episodes_this_iter": 26, "policy_reward_min": {"AGENT-2": -487.6551206759964, "AGENT-1": -940.893272917837, "AGENT-0": -912.4285847404992, "AGENT-3": -227.84536343264358}, "policy_reward_max": {"AGENT-2": 883.1972413024636, "AGENT-1": 866.9803044134386, "AGENT-0": 926.5674346180731, "AGENT-3": 753.6287762154753}, "policy_reward_mean": {"AGENT-2": 111.05802790023343, "AGENT-1": 135.8592092724459, "AGENT-0": 117.12626217303549, "AGENT-3": 94.15635883478932}, "custom_metrics": {"mean_ego_speed_mean": 40.910115, "mean_ego_speed_min": 27.769750000000002, "mean_ego_speed_max": 50.288, "distance_travelled_mean": 91.8061225, "distance_travelled_min": 33.791, "distance_travelled_max": 124.08875}, "hist_stats": {"episode_reward": [2865.137298083214, 213.69086017771752, 2356.1726921010745, -114.28758205370549, 2272.151609374856, 265.6059862976438, 2887.1487244171344, 1754.980494652527, -1069.3311634076763, 237.15350144798444, -654.5863238154082, 768.6754229734958, -533.1610057455711, 149.47477165673178, -675.3294885756745, 685.2138987248022, 294.5209779192559, 461.16526647671816, -419.0790138987437, 491.0538461333215, -407.69917067773895, 1277.9162655448145, -323.5434592170537, -759.9522443467237, -435.4818969620347, -1860.0662029575724, -291.2308007910756, 2824.2048446253175, 158.68665183475184, 2539.4127138053864, -82.21972491957375, 2729.5529176669306, -355.2951950206213, 2565.052269674564, 72.51514120479142, -282.5712133620484, -30.604344569716442, -459.4097615561049, 471.45345491968004, 337.20604353111895, -176.30399218163524, -874.0364411077236, -63.153000839909126, 244.17133246798736, 183.36476614663636, 1034.155143808573, -413.57735310296687, 1041.8041140050984, -459.7996006114526, 1082.0904935180486, -145.19774482265356, 817.3077729132033, -153.74523532077916, 1121.4770458999922, -90.0291374487974, 2976.151737342624, -300.43253766775007, 2980.30178297694, -290.58859543425353, 2700.9756385164633, -32.60772761431534, 2841.6339723409533, -1092.3922755001654, 583.0417966219999, -618.5382304591477, 1638.426402681824, -496.4148175144953, -11.778882813564778, 110.26169698058794, -354.9882342011163, -755.9668374264917, -98.50946413083913, 778.2428494484437, -345.655446922082, 255.78235141392017, 2012.8080396961448, 205.202965089077, 2834.3458489794457, -289.6907194716316, 2898.5352231827333, 5.100727209519633, 284.40950991681353, -399.1177703684011, 876.5744819036793, 255.9350172543167, 629.4911706996186, 260.8037157720368, -1103.698703826893, 805.8647288298544, -565.3622936509944, -411.36795759838924, 1299.0894141775834, -359.3382934872074, 1254.1260575454098, -497.3489933168307, 657.3646203769388, -354.39419030873813, 1308.593127793923, -471.29232955178617, 1143.5820178742488], "episode_lengths": [240, 128, 243, 102, 269, 134, 173, 275, 155, 114, 121, 227, 125, 111, 118, 127, 132, 125, 118, 201, 121, 293, 117, 146, 121, 220, 54, 200, 239, 207, 103, 223, 172, 202, 115, 197, 130, 111, 114, 126, 75, 139, 74, 121, 110, 210, 118, 204, 124, 191, 55, 154, 116, 186, 111, 198, 56, 210, 73, 352, 166, 204, 165, 116, 122, 238, 110, 65, 102, 119, 146, 845, 142, 115, 134, 235, 172, 203, 77, 349, 100, 690, 49, 143, 133, 118, 116, 157, 539, 136, 115, 199, 118, 120, 84, 199, 118, 136, 72, 206], "policy_AGENT-2_reward": [861.4475084482667, -47.82658098639525, 525.3179230456522, -24.719058947663562, 508.83405192298574, -64.53713218088637, 808.9010471751492, 150.8169899343427, -468.1589270693944, 74.28509090127264, -252.0157968321148, 121.43844273916795, -199.7549783244814, 40.51855153805536, -265.84399303484577, 158.36517816995664, -49.072883358122965, 95.00267046258227, -55.784475385708575, -78.28373043825208, -90.95179519889052, 198.19590595208558, -81.60394814632267, -5.603615719496053, -61.086869652403024, -3.3732091873612755, -39.091296094513105, 785.0748493077297, -116.38141375341922, 702.3328599930893, -61.485662863905176, 761.1011119088181, -80.9452242130661, 722.5566611722799, 56.550475367795684, -83.01631160402587, -33.66201519778136, -153.3164160427261, 32.52576100243777, -27.354149746986497, 19.070703940052315, -368.2287504311516, 40.883940951126334, -32.503998030101016, 34.37944182724382, 122.9161152307201, -68.07922533075116, 122.1607586607917, -18.21060283238629, 176.6138300624402, -9.330629622946368, 135.358833091347, -26.460701340860698, 172.45101615895965, -69.41518952016429, 836.439593350998, -41.45121152856809, 818.440865413789, -40.184139229303, 834.2705746337507, 41.08024771217747, 801.9373155867124, -448.4342642896545, 91.5615151586023, -240.67884007980746, 782.8871877055716, -178.62855809432276, 37.535240857216905, -32.10642286186005, -84.4108536462695, -1.2035075043108132, 7.02377643202766, 166.4221581341897, -74.14501322621054, -60.941188687244484, 507.14583987563464, 177.98610780070035, 830.1513778966173, -38.32948864127569, 883.1972413024636, 2.656107510173128, 103.60032779396481, -85.08038827543507, 185.63704092897564, -30.623937539288107, 164.41998619328848, 80.24454746068544, -487.6551206759964, 315.30927611523185, -8.896427042474333, -67.28080293046887, 216.39078522638505, -58.76970525437567, 305.05382354081075, -92.1279243280544, 159.15543975242636, -67.11183563175162, 315.2191430389248, -80.42495255091005, 169.52071474237906], "policy_AGENT-1_reward": [830.8407851541222, 140.47544455942392, 666.9565286063503, -20.64582786548414, 614.6511343182432, 182.80586967878799, 809.3350873046279, 542.9208231527051, -84.62807502432554, 46.2551932258635, -89.9742623127589, 121.86979833972046, -80.84955443496925, 34.709352684944385, -85.80475624296872, 173.2123651645165, 181.7040125350116, 95.43051131425054, -149.33001868984476, 290.35356166121704, -110.93251126271626, 485.04231476586517, -81.00589081166828, -390.3786124113427, -60.65234877237885, -940.893272917837, -106.52650080420862, 809.156969026981, -115.79636160452569, 725.2088795624633, 39.822096857348704, 768.87464535913, -103.19296145144799, 739.632199763137, -12.726665749104095, -82.751398638872, 4.8169298317489755, -87.30160569579185, 32.95983947760393, 181.89614971490187, -107.21854564929242, -84.95479896605703, -72.45733568768142, 140.8726924979993, 46.67860831681707, 434.83903477706855, -137.7114212778347, 437.6275052135161, -17.779257320640273, 402.2668910774918, -63.447554947111406, 239.97404719815233, -62.14852829798308, 419.61947775003125, 35.38946295334241, 866.9803044134386, -108.70296397121558, 818.8742406442786, -104.91209088366759, 777.4382520131912, -57.57257779967727, 823.164287677823, -82.40726027145837, 92.08042924525799, -83.15393662887993, 50.93653991102126, -83.1471712803417, -43.41903010701561, 106.72519842672429, -95.2981300299045, -392.69827684844216, -63.01947105947667, 211.17618888531507, -90.47177215150505, 174.27375792017853, 520.9837079427473, -88.24338524938719, 809.3293429125958, -106.50546224927513, 827.6987740677257, 11.700052821288601, 50.56707768236473, -84.64994077861986, 239.15838540027605, 152.92116547357188, 165.90448500778822, 55.02037107269992, -81.88204288430374, 60.062674630686885, -289.18351306634514, -134.6992981452402, 490.95023146632457, -120.1125182745305, 369.13442112400537, -156.54653017289547, 86.03479026860283, -109.58109684927517, 382.82748604361933, -155.21197337416572, 446.3070592621473], "policy_AGENT-0_reward": [759.3024995695539, 168.98231796996032, 641.1756247008084, -24.131980110388476, 643.0159791520291, 211.9894115473401, 832.3515448432539, 570.205137729316, -431.3465331760137, 74.85890296765284, -222.05582629502229, 274.14898480149617, -171.14549553550552, 41.066763450186315, -237.31482159682085, 198.50932941002083, 211.10302055516564, 125.43360983874115, -55.23236975502344, -43.78672435361995, -90.39201578092491, 265.2131546616462, -64.87557981455814, -358.3982280346776, -140.66530934034728, -912.4285847404992, -38.524355003314845, 789.5520867401415, 170.03217205776616, 730.8279265295719, 1.0023857171457657, 797.1742089099573, -54.24273874756138, 692.6006963925039, 57.109524452135624, -33.4847732438445, 32.0609353250215, -130.92082950841927, 215.13806802093984, 210.0212977296051, 19.627923678953103, -335.3304171503547, 41.44080823046978, 168.5083444805213, 34.92635461359199, 157.82587707503208, -67.53058050554947, 158.6726014825422, -195.9643770257823, 212.8006692905895, -63.14862223930574, 164.21164672139372, -38.64108069617669, 206.7245862576061, 13.631698614588837, 839.411522850894, -41.00981206566535, 926.5674346180731, -39.77165337590928, 702.5499357301545, 42.02116532749686, 796.1286518256552, -478.56772359650245, 211.88495374465774, -210.98652793560166, 50.97389884975574, -150.92804633685242, 38.08819676689794, 67.71062142784584, -83.848152500151, -360.8279304735729, -62.88520986559024, 190.03522889186038, -73.57917786596856, 203.3991345042143, 482.37144022121424, 204.26392656849103, 786.3187792031537, -37.78407103758022, 767.8303500808582, 3.2191750507704575, 50.676489474063686, -144.16938318441416, 264.1304533205003, 164.3026361745174, 164.99609887613582, 80.80116088525888, -451.71042357560503, 60.04984839772793, -258.2990595322352, -66.7312138332889, 250.52767307510334, -58.220204552710214, 305.6131258174238, -91.56917565049265, 114.98248130564431, -66.5531197046176, 315.83689090748226, -79.87505666849411, 203.5660342994135], "policy_AGENT-3_reward": [413.54650491126995, -47.9403213652714, 522.722615748261, -44.79071513016942, 505.6504439815949, -64.6521627475981, 436.5610450941025, 491.0375438361649, -85.19762813794165, 41.754314353195696, -90.54043837551197, 251.2181970931111, -81.41097745061516, 33.1801039835457, -86.36591770103908, 155.12702598030805, -49.213171812798315, 145.29847486114426, -158.7321500681669, 322.77073926397514, -115.4228484352074, 329.4648901652186, -96.05804044450433, -5.571788181207194, -173.07736919690532, -3.3711361118763925, -107.088648889039, 440.42093955046624, 220.8322551349305, 381.04304772025984, -61.55854463016312, 402.40295148902675, -116.91427060854548, 410.2627123466471, -28.41819286603596, -83.31872987530565, -33.82019452870567, -87.87091030916747, 190.82978641869832, -27.357254166401844, -107.78407415134828, -85.52247456016067, -73.02041433382392, -32.705706480432234, 67.38036138898352, 318.57411672575324, -140.25612598883149, 323.3432486482493, -227.84536343264358, 290.4091030875266, -9.270938013290062, 277.7632459023098, -26.49492498575868, 322.6819657333968, -69.63510949656424, 433.3203167272931, -109.26855010230105, 416.41924230079627, -105.72071194537367, 386.71687613936416, -58.13656285431247, 420.40371725076477, -82.98302734255026, 187.51489847348168, -83.71892581485889, 753.6287762154753, -83.71104180297871, -43.983290330664026, -32.06770001212222, -91.43109802479135, -1.2371226001658715, 20.37144036219987, 210.6092735370798, -107.45948367839794, -60.949352323228396, 502.30705165654757, -88.80368403072714, 408.5463489670765, -107.07169754350065, 419.80885773168654, -12.474608172712546, 79.56561496642061, -85.21805812993205, 187.64860225392783, -30.66484685448454, 134.17060062240608, 44.7376363533926, -82.45111669098878, 370.44292968620715, -8.983294009939753, -142.65664268939113, 341.2207244097698, -122.23586540559089, 274.3246870631691, -157.10536316538798, 297.1919090502657, -111.14813812309376, 294.7096078038967, -155.78034695821611, 324.1882095703089]}, "sampler_perf": {"mean_env_wait_ms": 45.037076191049366, "mean_raw_obs_processing_ms": 1.9690934377754832, "mean_inference_ms": 2.108941440842176, "mean_action_processing_ms": 0.13027012484722714}, "off_policy_estimator": {}, "num_healthy_workers": 3, "timesteps_total": 243600, "timers": {"sample_time_ms": 71331.74, "sample_throughput": 58.88, "load_time_ms": 13.537, "load_throughput": 310254.719, "learn_time_ms": 6225.098, "learn_throughput": 674.688, "update_time_ms": 7.85}, "info": {"learner": {"AGENT-0": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 78.02079010009766, "policy_loss": -0.028529249131679535, "vf_loss": 78.04314422607422, "vf_explained_var": 0.98077791929245, "kl": 0.013740303926169872, "entropy": 0.928520917892456, "entropy_coeff": 0.0, "model": {}}, "AGENT-1": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 61.30377960205078, "policy_loss": -0.03515707328915596, "vf_loss": 61.331417083740234, "vf_explained_var": 0.9851891994476318, "kl": 0.016703594475984573, "entropy": 0.8701504468917847, "entropy_coeff": 0.0, "model": {}}, "AGENT-2": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 91.51484680175781, "policy_loss": -0.029085328802466393, "vf_loss": 91.53868103027344, "vf_explained_var": 0.976255476474762, "kl": 0.01165392342954874, "entropy": 0.9205562472343445, "entropy_coeff": 0.0, "model": {}}, "AGENT-3": {"cur_kl_coeff": 0.44999998807907104, "cur_lr": 0.0003000000142492354, "total_loss": 49.131568908691406, "policy_loss": -0.033227600157260895, "vf_loss": 49.158992767333984, "vf_explained_var": 0.9880647659301758, "kl": 0.012888067401945591, "entropy": 0.8773899078369141, "entropy_coeff": 0.0, "model": {}}}, "num_steps_sampled": 243600, "num_steps_trained": 243600}, "done": true, "episodes_total": 1682, "training_iteration": 58, "experiment_id": "34307f01f794455c888a5da75184f24f", "date": "2021-06-20_20-38-37", "timestamp": 1624221517, "time_this_iter_s": 97.62560081481934, "time_total_s": 5048.059811592102, "pid": 9226, "hostname": "6c107ba13ad6", "node_ip": "172.17.0.2", "config": {"num_workers": 3, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "num_gpus": 0, "train_batch_size": 4000, "model": {"fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action_reward": false, "_time_major": false, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null}, "optimizer": {}, "gamma": 0.99, "horizon": 1000, "soft_horizon": false, "no_done_at_end": false, "env_config": {"custom_config": {"name": "FrameStack", "num_stack": 3, "reward_adapter": "<function FrameStack.get_reward_adapter.<locals>.func at 0x7fc1c05fc4d0>", "observation_adapter": "<function FrameStack.get_observation_adapter.<locals>.func at 0x7fc1c05fc3b0>", "action_adapter": "<function ActionAdapter.discrete_action_adapter at 0x7fc22ee3b200>", "info_adapter": null, "observation_space": "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "action_space": "Discrete(4)"}, "seed": 42, "scenarios": ["/src/benchmark/scenarios/double_merge/cross"], "headless": true, "agent_specs": {"AGENT-0": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c05fc170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c05fc050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c05fca70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c05fcb90>, perform_self_test=False)", "AGENT-1": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c05fc170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c05fc050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c05fca70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c05fcb90>, perform_self_test=False)", "AGENT-2": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c05fc170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c05fc050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c05fca70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c05fcb90>, perform_self_test=False)", "AGENT-3": "AgentSpec(interface=AgentInterface(debug=False, done_criteria=DoneCriteria(collision=True, off_road=True, off_route=True, on_shoulder=False, wrong_way=False, not_moving=False, agents_alive=None), max_episode_steps=1000, neighborhood_vehicles=NeighborhoodVehicles(radius=50), waypoints=Waypoints(lookahead=50), road_waypoints=False, drivable_area_grid_map=False, ogm=False, rgb=False, lidar=False, action=<ActionSpaceType.Lane: 1>, vehicle_type='sedan', accelerometer=Accelerometer(), agent_behavior=None), agent_builder=None, agent_params=None, policy_builder=None, policy_params=None, observation_adapter=<function AgentSpec.<lambda> at 0x7fc1c05fc170>, action_adapter=<function AgentSpec.<lambda> at 0x7fc1c05fc050>, reward_adapter=<function AgentSpec.<lambda> at 0x7fc1c05fca70>, info_adapter=<function AgentSpec.<lambda> at 0x7fc1c05fcb90>, perform_self_test=False)"}}, "env": "FrameStack", "normalize_actions": false, "clip_rewards": null, "clip_actions": true, "preprocessor_pref": "deepmind", "lr": 0.0003, "monitor": false, "log_level": "WARN", "callbacks": "<class 'benchmark.common.SimpleCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "_use_trajectory_view_api": false, "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "memory": 0, "object_store_memory": 0, "memory_per_worker": 0, "object_store_memory_per_worker": 0, "input": "sampler", "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"AGENT-0": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-0"}], "AGENT-1": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-1"}], "AGENT-2": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-2"}], "AGENT-3": ["<class 'ray.rllib.policy.tf_policy_template.PPOTFPolicy'>", "Tuple(Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)), Dict(distance_to_center:Box(-inf, inf, (1,), float32), goal_relative_pos:Box(-inf, inf, (2,), float32), heading_errors:Box(-inf, inf, (20,), float32), neighbor:Box(-inf, inf, (40,), float32), speed:Box(-inf, inf, (1,), float32), steering:Box(-inf, inf, (1,), float32)))", "Discrete(4)", {"custom_preprocessor": "<class 'benchmark.wrappers.rllib.frame_stack.TupleStackingPreprocessor'>", "agent_id": "AGENT-3"}]}, "policy_mapping_fn": "<function gen_config.<locals>.<lambda> at 0x7fc1c8086d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent"}, "logger_config": null, "replay_sequence_length": 1, "use_critic": true, "use_gae": true, "lambda": 0, "kl_coeff": 0.2, "sgd_minibatch_size": 64, "shuffle_sequences": true, "num_sgd_iter": 10, "lr_schedule": null, "vf_share_layers": false, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.2, "vf_clip_param": 10.0, "grad_clip": null, "kl_target": 0.01, "simple_optimizer": false, "_fake_gpus": false}, "time_since_restore": 5048.059811592102, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 53.717266187050356, "ram_util_percent": 95.68705035971225}, "trial_id": "a1fa4_00000", "experiment_tag": "0"}
